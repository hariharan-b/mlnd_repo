{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artificial Intelligence Nanodegree\n",
    "\n",
    "## Convolutional Neural Networks\n",
    "\n",
    "## Project: Write an Algorithm for a Dog Identification App \n",
    "\n",
    "---\n",
    "\n",
    "In this notebook, some template code has already been provided for you, and you will need to implement additional functionality to successfully complete this project. You will not need to modify the included code beyond what is requested. Sections that begin with **'(IMPLEMENTATION)'** in the header indicate that the following block of code will require additional functionality which you must provide. Instructions will be provided for each section, and the specifics of the implementation are marked in the code block with a 'TODO' statement. Please be sure to read the instructions carefully! \n",
    "\n",
    "> **Note**: Once you have completed all of the code implementations, you need to finalize your work by exporting the iPython Notebook as an HTML document. Before exporting the notebook to html, all of the code cells need to have been run so that reviewers can see the final implementation and output. You can then export the notebook by using the menu above and navigating to  \\n\",\n",
    "    \"**File -> Download as -> HTML (.html)**. Include the finished document along with this notebook as your submission.\n",
    "\n",
    "In addition to implementing code, there will be questions that you must answer which relate to the project and your implementation. Each section where you will answer a question is preceded by a **'Question X'** header. Carefully read each question and provide thorough answers in the following text boxes that begin with **'Answer:'**. Your project submission will be evaluated based on your answers to each of the questions and the implementation you provide.\n",
    "\n",
    ">**Note:** Code and Markdown cells can be executed using the **Shift + Enter** keyboard shortcut.  Markdown cells can be edited by double-clicking the cell to enter edit mode.\n",
    "\n",
    "The rubric contains _optional_ \"Stand Out Suggestions\" for enhancing the project beyond the minimum requirements. If you decide to pursue the \"Stand Out Suggestions\", you should include the code in this IPython notebook.\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "### Why We're Here \n",
    "\n",
    "In this notebook, you will make the first steps towards developing an algorithm that could be used as part of a mobile or web app.  At the end of this project, your code will accept any user-supplied image as input.  If a dog is detected in the image, it will provide an estimate of the dog's breed.  If a human is detected, it will provide an estimate of the dog breed that is most resembling.  The image below displays potential sample output of your finished project (... but we expect that each student's algorithm will behave differently!). \n",
    "\n",
    "![Sample Dog Output](images/sample_dog_output.png)\n",
    "\n",
    "In this real-world setting, you will need to piece together a series of models to perform different tasks; for instance, the algorithm that detects humans in an image will be different from the CNN that infers dog breed.  There are many points of possible failure, and no perfect algorithm exists.  Your imperfect solution will nonetheless create a fun user experience!\n",
    "\n",
    "### The Road Ahead\n",
    "\n",
    "We break the notebook into separate steps.  Feel free to use the links below to navigate the notebook.\n",
    "\n",
    "* [Step 0](#step0): Import Datasets\n",
    "* [Step 1](#step1): Detect Humans\n",
    "* [Step 2](#step2): Detect Dogs\n",
    "* [Step 3](#step3): Create a CNN to Classify Dog Breeds (from Scratch)\n",
    "* [Step 4](#step4): Use a CNN to Classify Dog Breeds (using Transfer Learning)\n",
    "* [Step 5](#step5): Create a CNN to Classify Dog Breeds (using Transfer Learning)\n",
    "* [Step 6](#step6): Write your Algorithm\n",
    "* [Step 7](#step7): Test Your Algorithm\n",
    "\n",
    "---\n",
    "<a id='step0'></a>\n",
    "## Step 0: Import Datasets\n",
    "\n",
    "### Import Dog Dataset\n",
    "\n",
    "In the code cell below, we import a dataset of dog images.  We populate a few variables through the use of the `load_files` function from the scikit-learn library:\n",
    "- `train_files`, `valid_files`, `test_files` - numpy arrays containing file paths to images\n",
    "- `train_targets`, `valid_targets`, `test_targets` - numpy arrays containing onehot-encoded classification labels \n",
    "- `dog_names` - list of string-valued dog breed names for translating labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 133 total dog categories.\n",
      "There are 8351 total dog images.\n",
      "\n",
      "There are 6680 training dog images.\n",
      "There are 835 validation dog images.\n",
      "There are 836 test dog images.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_files       \n",
    "from keras.utils import np_utils\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "\n",
    "# define function to load train, test, and validation datasets\n",
    "def load_dataset(path):\n",
    "    data = load_files(path)\n",
    "    dog_files = np.array(data['filenames'])\n",
    "    dog_targets = np_utils.to_categorical(np.array(data['target']), 133)\n",
    "    return dog_files, dog_targets\n",
    "\n",
    "# load train, test, and validation datasets\n",
    "train_files, train_targets = load_dataset('dogImages/train')\n",
    "valid_files, valid_targets = load_dataset('dogImages/valid')\n",
    "test_files, test_targets = load_dataset('dogImages/test')\n",
    "\n",
    "# load list of dog names\n",
    "dog_names = [item[20:-1] for item in sorted(glob(\"dogImages/train/*/\"))]\n",
    "\n",
    "# print statistics about the dataset\n",
    "print('There are %d total dog categories.' % len(dog_names))\n",
    "print('There are %s total dog images.\\n' % len(np.hstack([train_files, valid_files, test_files])))\n",
    "print('There are %d training dog images.' % len(train_files))\n",
    "print('There are %d validation dog images.' % len(valid_files))\n",
    "print('There are %d test dog images.'% len(test_files))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Human Dataset\n",
    "\n",
    "In the code cell below, we import a dataset of human images, where the file paths are stored in the numpy array `human_files`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 13233 total human images.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "random.seed(8675309)\n",
    "\n",
    "# load filenames in shuffled human dataset\n",
    "human_files = np.array(glob(\"lfw/*/*\"))\n",
    "random.shuffle(human_files)\n",
    "\n",
    "# print statistics about the dataset\n",
    "print('There are %d total human images.' % len(human_files))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='step1'></a>\n",
    "## Step 1: Detect Humans\n",
    "\n",
    "We use OpenCV's implementation of [Haar feature-based cascade classifiers](http://docs.opencv.org/trunk/d7/d8b/tutorial_py_face_detection.html) to detect human faces in images.  OpenCV provides many pre-trained face detectors, stored as XML files on [github](https://github.com/opencv/opencv/tree/master/data/haarcascades).  We have downloaded one of these detectors and stored it in the `haarcascades` directory.\n",
    "\n",
    "In the next code cell, we demonstrate how to use this detector to find human faces in a sample image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of faces detected: 1\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQsAAAD8CAYAAABgtYFHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n4YngmllcwzVcwxPBNbO4hmu4hieC/x83Yr05sT1SRwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x19ab5b43198>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import cv2                \n",
    "import matplotlib.pyplot as plt                        \n",
    "%matplotlib inline                               \n",
    "\n",
    "# extract pre-trained face detector\n",
    "face_cascade = cv2.CascadeClassifier('haarcascades/haarcascade_frontalface_alt.xml')\n",
    "\n",
    "# load color (BGR) image\n",
    "img = cv2.imread(human_files[3])\n",
    "# convert BGR image to grayscale\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# find faces in image\n",
    "faces = face_cascade.detectMultiScale(gray)\n",
    "\n",
    "# print number of faces detected in the image\n",
    "print('Number of faces detected:', len(faces))\n",
    "\n",
    "# get bounding box for each detected face\n",
    "for (x,y,w,h) in faces:\n",
    "    # add bounding box to color image\n",
    "    cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "    \n",
    "# convert BGR image to RGB for plotting\n",
    "cv_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# display the image, along with bounding box\n",
    "plt.imshow(cv_rgb)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before using any of the face detectors, it is standard procedure to convert the images to grayscale.  The `detectMultiScale` function executes the classifier stored in `face_cascade` and takes the grayscale image as a parameter.  \n",
    "\n",
    "In the above code, `faces` is a numpy array of detected faces, where each row corresponds to a detected face.  Each detected face is a 1D array with four entries that specifies the bounding box of the detected face.  The first two entries in the array (extracted in the above code as `x` and `y`) specify the horizontal and vertical positions of the top left corner of the bounding box.  The last two entries in the array (extracted here as `w` and `h`) specify the width and height of the box.\n",
    "\n",
    "### Write a Human Face Detector\n",
    "\n",
    "We can use this procedure to write a function that returns `True` if a human face is detected in an image and `False` otherwise.  This function, aptly named `face_detector`, takes a string-valued file path to an image as input and appears in the code block below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# returns \"True\" if face is detected in image stored at img_path\n",
    "def face_detector(img_path):\n",
    "    img = cv2.imread(img_path)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray)\n",
    "    return len(faces) > 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (IMPLEMENTATION) Assess the Human Face Detector\n",
    "\n",
    "__Question 1:__ Use the code cell below to test the performance of the `face_detector` function.  \n",
    "- What percentage of the first 100 images in `human_files` have a detected human face?  \n",
    "- What percentage of the first 100 images in `dog_files` have a detected human face? \n",
    "\n",
    "Ideally, we would like 100% of human images with a detected face and 0% of dog images with a detected face.  You will see that our algorithm falls short of this goal, but still gives acceptable performance.  We extract the file paths for the first 100 images from each of the datasets and store them in the numpy arrays `human_files_short` and `dog_files_short`.\n",
    "\n",
    "__Answer:__ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of human faces in the human files: 99 %\n",
      "Percentage of human faces in the dog files: 11 %\n"
     ]
    }
   ],
   "source": [
    "human_files_short = human_files[:100]\n",
    "dog_files_short = train_files[:100]\n",
    "# Do NOT modify the code above this line.\n",
    "\n",
    "## TODO: Test the performance of the face_detector algorithm \n",
    "## on the images in human_files_short and dog_files_short.\n",
    "count = 0\n",
    "for human_face in human_files_short:\n",
    "    if (face_detector(human_face)):\n",
    "        count = count + 1\n",
    "\n",
    "print(\"Percentage of human faces in the human files:\", count, \"%\")\n",
    "        \n",
    "count = 0\n",
    "for human_face in dog_files_short:\n",
    "    if (face_detector(human_face)):\n",
    "        count = count + 1\n",
    "\n",
    "print(\"Percentage of human faces in the dog files:\", count, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Question 2:__ This algorithmic choice necessitates that we communicate to the user that we accept human images only when they provide a clear view of a face (otherwise, we risk having unneccessarily frustrated users!). In your opinion, is this a reasonable expectation to pose on the user? If not, can you think of a way to detect humans in images that does not necessitate an image with a clearly presented face?\n",
    "\n",
    "__Answer:__\n",
    "While this could be a reasonable expectation in some cases, it not fair to ask the user to present only images with a recognizable face. Instead, we should have some mechanism of figuring out how to recognize a face even when it is not clearly presented. This could be done by training more, or by training on augmented images, where a picture with clearly represented face is deliberately altered to make it less clear.\n",
    "\n",
    "We suggest the face detector from OpenCV as a potential way to detect human images in your algorithm, but you are free to explore other approaches, especially approaches that make use of deep learning :).  Please use the code cell below to design and test your own face detection algorithm.  If you decide to pursue this _optional_ task, report performance on each of the datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## (Optional) TODO: Report the performance of another  \n",
    "## face detection algorithm on the LFW dataset\n",
    "### Feel free to use as many code cells as needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='step2'></a>\n",
    "## Step 2: Detect Dogs\n",
    "\n",
    "In this section, we use a pre-trained [ResNet-50](http://ethereon.github.io/netscope/#/gist/db945b393d40bfa26006) model to detect dogs in images.  Our first line of code downloads the ResNet-50 model, along with weights that have been trained on [ImageNet](http://www.image-net.org/), a very large, very popular dataset used for image classification and other vision tasks.  ImageNet contains over 10 million URLs, each linking to an image containing an object from one of [1000 categories](https://gist.github.com/yrevar/942d3a0ac09ec9e5eb3a).  Given an image, this pre-trained ResNet-50 model returns a prediction (derived from the available categories in ImageNet) for the object that is contained in the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.applications.resnet50 import ResNet50\n",
    "\n",
    "# define ResNet50 model\n",
    "ResNet50_model = ResNet50(weights='imagenet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-process the Data\n",
    "\n",
    "When using TensorFlow as backend, Keras CNNs require a 4D array (which we'll also refer to as a 4D tensor) as input, with shape\n",
    "\n",
    "$$\n",
    "(\\text{nb_samples}, \\text{rows}, \\text{columns}, \\text{channels}),\n",
    "$$\n",
    "\n",
    "where `nb_samples` corresponds to the total number of images (or samples), and `rows`, `columns`, and `channels` correspond to the number of rows, columns, and channels for each image, respectively.  \n",
    "\n",
    "The `path_to_tensor` function below takes a string-valued file path to a color image as input and returns a 4D tensor suitable for supplying to a Keras CNN.  The function first loads the image and resizes it to a square image that is $224 \\times 224$ pixels.  Next, the image is converted to an array, which is then resized to a 4D tensor.  In this case, since we are working with color images, each image has three channels.  Likewise, since we are processing a single image (or sample), the returned tensor will always have shape\n",
    "\n",
    "$$\n",
    "(1, 224, 224, 3).\n",
    "$$\n",
    "\n",
    "The `paths_to_tensor` function takes a numpy array of string-valued image paths as input and returns a 4D tensor with shape \n",
    "\n",
    "$$\n",
    "(\\text{nb_samples}, 224, 224, 3).\n",
    "$$\n",
    "\n",
    "Here, `nb_samples` is the number of samples, or number of images, in the supplied array of image paths.  It is best to think of `nb_samples` as the number of 3D tensors (where each 3D tensor corresponds to a different image) in your dataset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing import image                  \n",
    "from tqdm import tqdm\n",
    "\n",
    "def path_to_tensor(img_path):\n",
    "    # loads RGB image as PIL.Image.Image type\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    # convert PIL.Image.Image type to 3D tensor with shape (224, 224, 3)\n",
    "    x = image.img_to_array(img)\n",
    "    # convert 3D tensor to 4D tensor with shape (1, 224, 224, 3) and return 4D tensor\n",
    "    return np.expand_dims(x, axis=0)\n",
    "\n",
    "def paths_to_tensor(img_paths):\n",
    "    list_of_tensors = [path_to_tensor(img_path) for img_path in tqdm(img_paths)]\n",
    "    return np.vstack(list_of_tensors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making Predictions with ResNet-50\n",
    "\n",
    "Getting the 4D tensor ready for ResNet-50, and for any other pre-trained model in Keras, requires some additional processing.  First, the RGB image is converted to BGR by reordering the channels.  All pre-trained models have the additional normalization step that the mean pixel (expressed in RGB as $[103.939, 116.779, 123.68]$ and calculated from all pixels in all images in ImageNet) must be subtracted from every pixel in each image.  This is implemented in the imported function `preprocess_input`.  If you're curious, you can check the code for `preprocess_input` [here](https://github.com/fchollet/keras/blob/master/keras/applications/imagenet_utils.py).\n",
    "\n",
    "Now that we have a way to format our image for supplying to ResNet-50, we are now ready to use the model to extract the predictions.  This is accomplished with the `predict` method, which returns an array whose $i$-th entry is the model's predicted probability that the image belongs to the $i$-th ImageNet category.  This is implemented in the `ResNet50_predict_labels` function below.\n",
    "\n",
    "By taking the argmax of the predicted probability vector, we obtain an integer corresponding to the model's predicted object class, which we can identify with an object category through the use of this [dictionary](https://gist.github.com/yrevar/942d3a0ac09ec9e5eb3a). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "\n",
    "def ResNet50_predict_labels(img_path):\n",
    "    # returns prediction vector for image located at img_path\n",
    "    img = preprocess_input(path_to_tensor(img_path))\n",
    "    return np.argmax(ResNet50_model.predict(img))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write a Dog Detector\n",
    "\n",
    "While looking at the [dictionary](https://gist.github.com/yrevar/942d3a0ac09ec9e5eb3a), you will notice that the categories corresponding to dogs appear in an uninterrupted sequence and correspond to dictionary keys 151-268, inclusive, to include all categories from `'Chihuahua'` to `'Mexican hairless'`.  Thus, in order to check to see if an image is predicted to contain a dog by the pre-trained ResNet-50 model, we need only check if the `ResNet50_predict_labels` function above returns a value between 151 and 268 (inclusive).\n",
    "\n",
    "We use these ideas to complete the `dog_detector` function below, which returns `True` if a dog is detected in an image (and `False` if not)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### returns \"True\" if a dog is detected in the image stored at img_path\n",
    "def dog_detector(img_path):\n",
    "    prediction = ResNet50_predict_labels(img_path)\n",
    "    return ((prediction <= 268) & (prediction >= 151)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (IMPLEMENTATION) Assess the Dog Detector\n",
    "\n",
    "__Question 3:__ Use the code cell below to test the performance of your `dog_detector` function.  \n",
    "- What percentage of the images in `human_files_short` have a detected dog?  \n",
    "- What percentage of the images in `dog_files_short` have a detected dog?\n",
    "\n",
    "__Answer:__ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of dogs detected in human_files_short = 1.0 %\n",
      "Percentage of dogs detected in dog_files_short = 100.0 %\n"
     ]
    }
   ],
   "source": [
    "### TODO: Test the performance of the dog_detector function\n",
    "### on the images in human_files_short and dog_files_short.\n",
    "dogCount = 0\n",
    "for eachItem in human_files_short:\n",
    "    if (dog_detector(eachItem)):\n",
    "        # Dog detected\n",
    "        dogCount = dogCount + 1\n",
    "\n",
    "print(\"Percentage of dogs detected in human_files_short =\", (dogCount/human_files_short.size) * 100, \"%\")\n",
    "\n",
    "dogCount = 0\n",
    "for eachItem in dog_files_short:\n",
    "    if (dog_detector(eachItem)):\n",
    "        # Dog detected\n",
    "        dogCount = dogCount + 1\n",
    "\n",
    "print(\"Percentage of dogs detected in dog_files_short =\", (dogCount/dog_files_short.size) * 100, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='step3'></a>\n",
    "## Step 3: Create a CNN to Classify Dog Breeds (from Scratch)\n",
    "\n",
    "Now that we have functions for detecting humans and dogs in images, we need a way to predict breed from images.  In this step, you will create a CNN that classifies dog breeds.  You must create your CNN _from scratch_ (so, you can't use transfer learning _yet_!), and you must attain a test accuracy of at least 1%.  In Step 5 of this notebook, you will have the opportunity to use transfer learning to create a CNN that attains greatly improved accuracy.\n",
    "\n",
    "Be careful with adding too many trainable layers!  More parameters means longer training, which means you are more likely to need a GPU to accelerate the training process.  Thankfully, Keras provides a handy estimate of the time that each epoch is likely to take; you can extrapolate this estimate to figure out how long it will take for your algorithm to train. \n",
    "\n",
    "We mention that the task of assigning breed to dogs from images is considered exceptionally challenging.  To see why, consider that *even a human* would have great difficulty in distinguishing between a Brittany and a Welsh Springer Spaniel.  \n",
    "\n",
    "Brittany | Welsh Springer Spaniel\n",
    "- | - \n",
    "<img src=\"images/Brittany_02625.jpg\" width=\"100\"> | <img src=\"images/Welsh_springer_spaniel_08203.jpg\" width=\"200\">\n",
    "\n",
    "It is not difficult to find other dog breed pairs with minimal inter-class variation (for instance, Curly-Coated Retrievers and American Water Spaniels).  \n",
    "\n",
    "Curly-Coated Retriever | American Water Spaniel\n",
    "- | -\n",
    "<img src=\"images/Curly-coated_retriever_03896.jpg\" width=\"200\"> | <img src=\"images/American_water_spaniel_00648.jpg\" width=\"200\">\n",
    "\n",
    "\n",
    "Likewise, recall that labradors come in yellow, chocolate, and black.  Your vision-based algorithm will have to conquer this high intra-class variation to determine how to classify all of these different shades as the same breed.  \n",
    "\n",
    "Yellow Labrador | Chocolate Labrador | Black Labrador\n",
    "- | -\n",
    "<img src=\"images/Labrador_retriever_06457.jpg\" width=\"150\"> | <img src=\"images/Labrador_retriever_06455.jpg\" width=\"240\"> | <img src=\"images/Labrador_retriever_06449.jpg\" width=\"220\">\n",
    "\n",
    "We also mention that random chance presents an exceptionally low bar: setting aside the fact that the classes are slightly imabalanced, a random guess will provide a correct answer roughly 1 in 133 times, which corresponds to an accuracy of less than 1%.  \n",
    "\n",
    "Remember that the practice is far ahead of the theory in deep learning.  Experiment with many different architectures, and trust your intuition.  And, of course, have fun! \n",
    "\n",
    "### Pre-process the Data\n",
    "\n",
    "We rescale the images by dividing every pixel in every image by 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 6680/6680 [00:50<00:00, 131.28it/s]\n",
      "100%|| 835/835 [00:05<00:00, 141.47it/s]\n",
      "100%|| 836/836 [00:05<00:00, 144.47it/s]\n"
     ]
    }
   ],
   "source": [
    "from PIL import ImageFile                            \n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True                 \n",
    "\n",
    "# pre-process the data for Keras\n",
    "train_tensors = paths_to_tensor(train_files).astype('float32')/255\n",
    "valid_tensors = paths_to_tensor(valid_files).astype('float32')/255\n",
    "test_tensors = paths_to_tensor(test_files).astype('float32')/255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (IMPLEMENTATION) Model Architecture\n",
    "\n",
    "Create a CNN to classify dog breed.  At the end of your code cell block, summarize the layers of your model by executing the line:\n",
    "    \n",
    "        model.summary()\n",
    "\n",
    "We have imported some Python modules to get you started, but feel free to import as many modules as you need.  If you end up getting stuck, here's a hint that specifies a model that trains relatively fast on CPU and attains >1% test accuracy in 5 epochs:\n",
    "\n",
    "![Sample CNN](images/sample_cnn.png)\n",
    "           \n",
    "__Question 4:__ Outline the steps you took to get to your final CNN architecture and your reasoning at each step.  If you chose to use the hinted architecture above, describe why you think that CNN architecture should work well for the image classification task.\n",
    "\n",
    "__Answer:__ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 112, 112, 16)      448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 111, 111, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 56, 56, 32)        4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 55, 55, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 28, 28, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 27, 27, 64)        0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 133)               8645      \n",
      "=================================================================\n",
      "Total params: 32,229\n",
      "Trainable params: 32,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras.models import Sequential\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "### TODO: Define your architecture.\n",
    "model.add(Conv2D(filters=16, kernel_size=3, strides=(2, 2), padding='same', activation='relu', input_shape=(224, 224, 3)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(1, 1)))\n",
    "model.add(Conv2D(filters=32, kernel_size=3, strides=(2, 2), padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(1, 1)))\n",
    "model.add(Conv2D(filters=64, kernel_size=3, strides=(2, 2), padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(1, 1)))\n",
    "model.add(GlobalAveragePooling2D())\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(133, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (IMPLEMENTATION) Train the Model\n",
    "\n",
    "Train your model in the code cell below.  Use model checkpointing to save the model that attains the best validation loss.\n",
    "\n",
    "You are welcome to [augment the training data](https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html), but this is not a requirement. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6680 samples, validate on 835 samples\n",
      "Epoch 1/32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4260/6680 [==================>...........] - ETA: 181s - loss: 4.9337 - acc: 0.0000e+0 - ETA: 124s - loss: 4.9234 - acc: 0.0000e+0 - ETA: 105s - loss: 4.9155 - acc: 0.0000e+0 - ETA: 96s - loss: 4.9110 - acc: 0.0000e+0 - ETA: 91s - loss: 4.9167 - acc: 0.0000e+ - ETA: 87s - loss: 4.9098 - acc: 0.0083   - ETA: 84s - loss: 4.9081 - acc: 0.00 - ETA: 82s - loss: 4.9098 - acc: 0.00 - ETA: 81s - loss: 4.9109 - acc: 0.00 - ETA: 79s - loss: 4.9090 - acc: 0.00 - ETA: 78s - loss: 4.9126 - acc: 0.00 - ETA: 77s - loss: 4.9146 - acc: 0.00 - ETA: 76s - loss: 4.9129 - acc: 0.00 - ETA: 75s - loss: 4.9097 - acc: 0.00 - ETA: 74s - loss: 4.9081 - acc: 0.01 - ETA: 74s - loss: 4.9069 - acc: 0.00 - ETA: 73s - loss: 4.9051 - acc: 0.00 - ETA: 72s - loss: 4.9020 - acc: 0.00 - ETA: 72s - loss: 4.8989 - acc: 0.00 - ETA: 71s - loss: 4.8972 - acc: 0.00 - ETA: 71s - loss: 4.8966 - acc: 0.00 - ETA: 71s - loss: 4.8991 - acc: 0.00 - ETA: 70s - loss: 4.8982 - acc: 0.00 - ETA: 70s - loss: 4.9006 - acc: 0.00 - ETA: 69s - loss: 4.9013 - acc: 0.00 - ETA: 69s - loss: 4.9011 - acc: 0.00 - ETA: 68s - loss: 4.9014 - acc: 0.00 - ETA: 68s - loss: 4.9000 - acc: 0.00 - ETA: 68s - loss: 4.8991 - acc: 0.00 - ETA: 67s - loss: 4.8978 - acc: 0.01 - ETA: 67s - loss: 4.8989 - acc: 0.00 - ETA: 67s - loss: 4.8985 - acc: 0.00 - ETA: 66s - loss: 4.8984 - acc: 0.00 - ETA: 66s - loss: 4.8977 - acc: 0.00 - ETA: 66s - loss: 4.8969 - acc: 0.00 - ETA: 65s - loss: 4.8979 - acc: 0.00 - ETA: 65s - loss: 4.8984 - acc: 0.00 - ETA: 65s - loss: 4.8982 - acc: 0.00 - ETA: 65s - loss: 4.8980 - acc: 0.00 - ETA: 64s - loss: 4.8975 - acc: 0.00 - ETA: 64s - loss: 4.8978 - acc: 0.00 - ETA: 64s - loss: 4.8976 - acc: 0.00 - ETA: 64s - loss: 4.8973 - acc: 0.00 - ETA: 63s - loss: 4.8967 - acc: 0.00 - ETA: 63s - loss: 4.8964 - acc: 0.00 - ETA: 63s - loss: 4.8959 - acc: 0.00 - ETA: 63s - loss: 4.8956 - acc: 0.00 - ETA: 62s - loss: 4.8951 - acc: 0.00 - ETA: 62s - loss: 4.8947 - acc: 0.00 - ETA: 62s - loss: 4.8947 - acc: 0.00 - ETA: 62s - loss: 4.8948 - acc: 0.00 - ETA: 61s - loss: 4.8947 - acc: 0.00 - ETA: 61s - loss: 4.8944 - acc: 0.00 - ETA: 61s - loss: 4.8946 - acc: 0.00 - ETA: 61s - loss: 4.8949 - acc: 0.00 - ETA: 60s - loss: 4.8953 - acc: 0.00 - ETA: 60s - loss: 4.8947 - acc: 0.00 - ETA: 60s - loss: 4.8946 - acc: 0.00 - ETA: 60s - loss: 4.8949 - acc: 0.00 - ETA: 59s - loss: 4.8948 - acc: 0.00 - ETA: 59s - loss: 4.8946 - acc: 0.00 - ETA: 59s - loss: 4.8944 - acc: 0.00 - ETA: 59s - loss: 4.8938 - acc: 0.00 - ETA: 58s - loss: 4.8936 - acc: 0.00 - ETA: 58s - loss: 4.8938 - acc: 0.00 - ETA: 58s - loss: 4.8928 - acc: 0.00 - ETA: 58s - loss: 4.8935 - acc: 0.00 - ETA: 58s - loss: 4.8940 - acc: 0.00 - ETA: 57s - loss: 4.8943 - acc: 0.00 - ETA: 57s - loss: 4.8942 - acc: 0.00 - ETA: 57s - loss: 4.8941 - acc: 0.00 - ETA: 57s - loss: 4.8941 - acc: 0.00 - ETA: 56s - loss: 4.8941 - acc: 0.00 - ETA: 56s - loss: 4.8938 - acc: 0.00 - ETA: 56s - loss: 4.8934 - acc: 0.00 - ETA: 56s - loss: 4.8936 - acc: 0.00 - ETA: 55s - loss: 4.8928 - acc: 0.00 - ETA: 55s - loss: 4.8921 - acc: 0.00 - ETA: 55s - loss: 4.8917 - acc: 0.00 - ETA: 55s - loss: 4.8914 - acc: 0.01 - ETA: 54s - loss: 4.8913 - acc: 0.00 - ETA: 54s - loss: 4.8912 - acc: 0.00 - ETA: 54s - loss: 4.8916 - acc: 0.00 - ETA: 54s - loss: 4.8911 - acc: 0.01 - ETA: 53s - loss: 4.8916 - acc: 0.01 - ETA: 53s - loss: 4.8915 - acc: 0.01 - ETA: 53s - loss: 4.8915 - acc: 0.01 - ETA: 53s - loss: 4.8911 - acc: 0.01 - ETA: 53s - loss: 4.8911 - acc: 0.01 - ETA: 52s - loss: 4.8906 - acc: 0.01 - ETA: 52s - loss: 4.8902 - acc: 0.01 - ETA: 52s - loss: 4.8900 - acc: 0.01 - ETA: 52s - loss: 4.8914 - acc: 0.01 - ETA: 51s - loss: 4.8911 - acc: 0.01 - ETA: 51s - loss: 4.8908 - acc: 0.01 - ETA: 51s - loss: 4.8902 - acc: 0.01 - ETA: 51s - loss: 4.8903 - acc: 0.01 - ETA: 50s - loss: 4.8906 - acc: 0.01 - ETA: 50s - loss: 4.8899 - acc: 0.01 - ETA: 50s - loss: 4.8896 - acc: 0.01 - ETA: 50s - loss: 4.8900 - acc: 0.01 - ETA: 50s - loss: 4.8899 - acc: 0.01 - ETA: 49s - loss: 4.8899 - acc: 0.01 - ETA: 49s - loss: 4.8894 - acc: 0.01 - ETA: 49s - loss: 4.8887 - acc: 0.01 - ETA: 49s - loss: 4.8893 - acc: 0.01 - ETA: 48s - loss: 4.8887 - acc: 0.01 - ETA: 48s - loss: 4.8889 - acc: 0.01 - ETA: 48s - loss: 4.8890 - acc: 0.01 - ETA: 48s - loss: 4.8887 - acc: 0.01 - ETA: 48s - loss: 4.8887 - acc: 0.01 - ETA: 47s - loss: 4.8887 - acc: 0.01 - ETA: 47s - loss: 4.8895 - acc: 0.01 - ETA: 47s - loss: 4.8893 - acc: 0.01 - ETA: 47s - loss: 4.8894 - acc: 0.01 - ETA: 46s - loss: 4.8890 - acc: 0.01 - ETA: 46s - loss: 4.8889 - acc: 0.01 - ETA: 46s - loss: 4.8887 - acc: 0.01 - ETA: 46s - loss: 4.8887 - acc: 0.01 - ETA: 46s - loss: 4.8886 - acc: 0.01 - ETA: 45s - loss: 4.8884 - acc: 0.01 - ETA: 45s - loss: 4.8883 - acc: 0.01 - ETA: 45s - loss: 4.8882 - acc: 0.01 - ETA: 45s - loss: 4.8884 - acc: 0.01 - ETA: 44s - loss: 4.8882 - acc: 0.01 - ETA: 44s - loss: 4.8882 - acc: 0.01 - ETA: 44s - loss: 4.8884 - acc: 0.01 - ETA: 44s - loss: 4.8883 - acc: 0.01 - ETA: 44s - loss: 4.8882 - acc: 0.01 - ETA: 43s - loss: 4.8879 - acc: 0.01 - ETA: 43s - loss: 4.8877 - acc: 0.01 - ETA: 43s - loss: 4.8878 - acc: 0.01 - ETA: 43s - loss: 4.8876 - acc: 0.01 - ETA: 43s - loss: 4.8875 - acc: 0.01 - ETA: 42s - loss: 4.8878 - acc: 0.01 - ETA: 42s - loss: 4.8877 - acc: 0.01 - ETA: 42s - loss: 4.8878 - acc: 0.01 - ETA: 42s - loss: 4.8878 - acc: 0.01 - ETA: 41s - loss: 4.8877 - acc: 0.01 - ETA: 41s - loss: 4.8875 - acc: 0.01 - ETA: 41s - loss: 4.8877 - acc: 0.01 - ETA: 41s - loss: 4.8878 - acc: 0.01 - ETA: 41s - loss: 4.8882 - acc: 0.01 - ETA: 40s - loss: 4.8883 - acc: 0.01 - ETA: 40s - loss: 4.8884 - acc: 0.01 - ETA: 40s - loss: 4.8885 - acc: 0.01 - ETA: 40s - loss: 4.8886 - acc: 0.01 - ETA: 40s - loss: 4.8886 - acc: 0.01 - ETA: 39s - loss: 4.8887 - acc: 0.01 - ETA: 39s - loss: 4.8886 - acc: 0.01 - ETA: 39s - loss: 4.8886 - acc: 0.01 - ETA: 39s - loss: 4.8885 - acc: 0.01 - ETA: 38s - loss: 4.8886 - acc: 0.01 - ETA: 38s - loss: 4.8888 - acc: 0.01 - ETA: 38s - loss: 4.8888 - acc: 0.01 - ETA: 38s - loss: 4.8889 - acc: 0.01 - ETA: 38s - loss: 4.8888 - acc: 0.01 - ETA: 37s - loss: 4.8887 - acc: 0.01 - ETA: 37s - loss: 4.8886 - acc: 0.01 - ETA: 37s - loss: 4.8886 - acc: 0.01 - ETA: 37s - loss: 4.8885 - acc: 0.01 - ETA: 37s - loss: 4.8886 - acc: 0.01 - ETA: 36s - loss: 4.8887 - acc: 0.01 - ETA: 36s - loss: 4.8888 - acc: 0.01 - ETA: 36s - loss: 4.8888 - acc: 0.01 - ETA: 36s - loss: 4.8888 - acc: 0.01 - ETA: 35s - loss: 4.8888 - acc: 0.01 - ETA: 35s - loss: 4.8888 - acc: 0.01 - ETA: 35s - loss: 4.8886 - acc: 0.01 - ETA: 35s - loss: 4.8887 - acc: 0.01 - ETA: 35s - loss: 4.8887 - acc: 0.01 - ETA: 34s - loss: 4.8887 - acc: 0.01 - ETA: 34s - loss: 4.8888 - acc: 0.01 - ETA: 34s - loss: 4.8888 - acc: 0.01 - ETA: 34s - loss: 4.8888 - acc: 0.01 - ETA: 34s - loss: 4.8887 - acc: 0.01 - ETA: 33s - loss: 4.8889 - acc: 0.01 - ETA: 33s - loss: 4.8888 - acc: 0.01 - ETA: 33s - loss: 4.8887 - acc: 0.01 - ETA: 33s - loss: 4.8885 - acc: 0.01 - ETA: 32s - loss: 4.8886 - acc: 0.01 - ETA: 32s - loss: 4.8886 - acc: 0.01 - ETA: 32s - loss: 4.8886 - acc: 0.01 - ETA: 32s - loss: 4.8886 - acc: 0.01 - ETA: 32s - loss: 4.8886 - acc: 0.01 - ETA: 31s - loss: 4.8886 - acc: 0.01 - ETA: 31s - loss: 4.8886 - acc: 0.01 - ETA: 31s - loss: 4.8886 - acc: 0.01 - ETA: 31s - loss: 4.8886 - acc: 0.01 - ETA: 31s - loss: 4.8887 - acc: 0.01 - ETA: 30s - loss: 4.8887 - acc: 0.01 - ETA: 30s - loss: 4.8885 - acc: 0.01 - ETA: 30s - loss: 4.8886 - acc: 0.01 - ETA: 30s - loss: 4.8885 - acc: 0.01 - ETA: 29s - loss: 4.8885 - acc: 0.01 - ETA: 29s - loss: 4.8884 - acc: 0.01 - ETA: 29s - loss: 4.8883 - acc: 0.01 - ETA: 29s - loss: 4.8882 - acc: 0.01 - ETA: 29s - loss: 4.8883 - acc: 0.01 - ETA: 28s - loss: 4.8882 - acc: 0.01 - ETA: 28s - loss: 4.8883 - acc: 0.01 - ETA: 28s - loss: 4.8882 - acc: 0.01 - ETA: 28s - loss: 4.8883 - acc: 0.01 - ETA: 28s - loss: 4.8883 - acc: 0.01 - ETA: 27s - loss: 4.8883 - acc: 0.01 - ETA: 27s - loss: 4.8884 - acc: 0.01 - ETA: 27s - loss: 4.8884 - acc: 0.01 - ETA: 27s - loss: 4.8884 - acc: 0.01 - ETA: 26s - loss: 4.8883 - acc: 0.01 - ETA: 26s - loss: 4.8882 - acc: 0.01 - ETA: 26s - loss: 4.8881 - acc: 0.01 - ETA: 26s - loss: 4.8881 - acc: 0.01 - ETA: 26s - loss: 4.8880 - acc: 0.0106\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6660/6680 [============================>.] - ETA: 25s - loss: 4.8883 - acc: 0.01 - ETA: 25s - loss: 4.8884 - acc: 0.01 - ETA: 25s - loss: 4.8885 - acc: 0.01 - ETA: 25s - loss: 4.8885 - acc: 0.01 - ETA: 24s - loss: 4.8884 - acc: 0.01 - ETA: 24s - loss: 4.8883 - acc: 0.01 - ETA: 24s - loss: 4.8883 - acc: 0.01 - ETA: 24s - loss: 4.8884 - acc: 0.01 - ETA: 24s - loss: 4.8883 - acc: 0.01 - ETA: 23s - loss: 4.8882 - acc: 0.01 - ETA: 23s - loss: 4.8882 - acc: 0.01 - ETA: 23s - loss: 4.8881 - acc: 0.01 - ETA: 23s - loss: 4.8881 - acc: 0.01 - ETA: 23s - loss: 4.8880 - acc: 0.01 - ETA: 22s - loss: 4.8880 - acc: 0.01 - ETA: 22s - loss: 4.8879 - acc: 0.01 - ETA: 22s - loss: 4.8879 - acc: 0.01 - ETA: 22s - loss: 4.8878 - acc: 0.01 - ETA: 21s - loss: 4.8876 - acc: 0.00 - ETA: 21s - loss: 4.8877 - acc: 0.01 - ETA: 21s - loss: 4.8876 - acc: 0.01 - ETA: 21s - loss: 4.8878 - acc: 0.01 - ETA: 21s - loss: 4.8877 - acc: 0.01 - ETA: 20s - loss: 4.8877 - acc: 0.00 - ETA: 20s - loss: 4.8878 - acc: 0.00 - ETA: 20s - loss: 4.8878 - acc: 0.00 - ETA: 20s - loss: 4.8879 - acc: 0.00 - ETA: 19s - loss: 4.8880 - acc: 0.00 - ETA: 19s - loss: 4.8880 - acc: 0.00 - ETA: 19s - loss: 4.8880 - acc: 0.00 - ETA: 19s - loss: 4.8880 - acc: 0.00 - ETA: 19s - loss: 4.8879 - acc: 0.00 - ETA: 18s - loss: 4.8880 - acc: 0.00 - ETA: 18s - loss: 4.8879 - acc: 0.00 - ETA: 18s - loss: 4.8879 - acc: 0.00 - ETA: 18s - loss: 4.8878 - acc: 0.00 - ETA: 18s - loss: 4.8878 - acc: 0.00 - ETA: 17s - loss: 4.8879 - acc: 0.00 - ETA: 17s - loss: 4.8877 - acc: 0.00 - ETA: 17s - loss: 4.8877 - acc: 0.00 - ETA: 17s - loss: 4.8876 - acc: 0.00 - ETA: 16s - loss: 4.8873 - acc: 0.00 - ETA: 16s - loss: 4.8873 - acc: 0.00 - ETA: 16s - loss: 4.8871 - acc: 0.00 - ETA: 16s - loss: 4.8869 - acc: 0.00 - ETA: 16s - loss: 4.8866 - acc: 0.00 - ETA: 15s - loss: 4.8865 - acc: 0.00 - ETA: 15s - loss: 4.8865 - acc: 0.00 - ETA: 15s - loss: 4.8864 - acc: 0.00 - ETA: 15s - loss: 4.8865 - acc: 0.00 - ETA: 15s - loss: 4.8863 - acc: 0.00 - ETA: 14s - loss: 4.8862 - acc: 0.00 - ETA: 14s - loss: 4.8860 - acc: 0.00 - ETA: 14s - loss: 4.8861 - acc: 0.00 - ETA: 14s - loss: 4.8862 - acc: 0.00 - ETA: 13s - loss: 4.8862 - acc: 0.00 - ETA: 13s - loss: 4.8861 - acc: 0.00 - ETA: 13s - loss: 4.8860 - acc: 0.00 - ETA: 13s - loss: 4.8859 - acc: 0.00 - ETA: 13s - loss: 4.8857 - acc: 0.00 - ETA: 12s - loss: 4.8856 - acc: 0.00 - ETA: 12s - loss: 4.8856 - acc: 0.00 - ETA: 12s - loss: 4.8857 - acc: 0.00 - ETA: 12s - loss: 4.8860 - acc: 0.00 - ETA: 12s - loss: 4.8858 - acc: 0.00 - ETA: 11s - loss: 4.8858 - acc: 0.00 - ETA: 11s - loss: 4.8859 - acc: 0.00 - ETA: 11s - loss: 4.8858 - acc: 0.00 - ETA: 11s - loss: 4.8858 - acc: 0.00 - ETA: 10s - loss: 4.8859 - acc: 0.00 - ETA: 10s - loss: 4.8859 - acc: 0.00 - ETA: 10s - loss: 4.8860 - acc: 0.00 - ETA: 10s - loss: 4.8860 - acc: 0.00 - ETA: 10s - loss: 4.8859 - acc: 0.00 - ETA: 9s - loss: 4.8860 - acc: 0.0089 - ETA: 9s - loss: 4.8861 - acc: 0.008 - ETA: 9s - loss: 4.8861 - acc: 0.008 - ETA: 9s - loss: 4.8860 - acc: 0.008 - ETA: 8s - loss: 4.8861 - acc: 0.008 - ETA: 8s - loss: 4.8861 - acc: 0.008 - ETA: 8s - loss: 4.8862 - acc: 0.008 - ETA: 8s - loss: 4.8862 - acc: 0.008 - ETA: 8s - loss: 4.8862 - acc: 0.008 - ETA: 7s - loss: 4.8863 - acc: 0.008 - ETA: 7s - loss: 4.8862 - acc: 0.008 - ETA: 7s - loss: 4.8861 - acc: 0.008 - ETA: 7s - loss: 4.8862 - acc: 0.008 - ETA: 7s - loss: 4.8862 - acc: 0.008 - ETA: 6s - loss: 4.8861 - acc: 0.008 - ETA: 6s - loss: 4.8862 - acc: 0.008 - ETA: 6s - loss: 4.8862 - acc: 0.008 - ETA: 6s - loss: 4.8862 - acc: 0.008 - ETA: 5s - loss: 4.8862 - acc: 0.008 - ETA: 5s - loss: 4.8862 - acc: 0.008 - ETA: 5s - loss: 4.8862 - acc: 0.008 - ETA: 5s - loss: 4.8863 - acc: 0.008 - ETA: 5s - loss: 4.8862 - acc: 0.008 - ETA: 4s - loss: 4.8861 - acc: 0.008 - ETA: 4s - loss: 4.8862 - acc: 0.008 - ETA: 4s - loss: 4.8862 - acc: 0.008 - ETA: 4s - loss: 4.8862 - acc: 0.008 - ETA: 4s - loss: 4.8862 - acc: 0.008 - ETA: 3s - loss: 4.8862 - acc: 0.008 - ETA: 3s - loss: 4.8862 - acc: 0.008 - ETA: 3s - loss: 4.8862 - acc: 0.008 - ETA: 3s - loss: 4.8862 - acc: 0.008 - ETA: 2s - loss: 4.8863 - acc: 0.008 - ETA: 2s - loss: 4.8861 - acc: 0.008 - ETA: 2s - loss: 4.8862 - acc: 0.008 - ETA: 2s - loss: 4.8863 - acc: 0.008 - ETA: 2s - loss: 4.8862 - acc: 0.008 - ETA: 1s - loss: 4.8861 - acc: 0.008 - ETA: 1s - loss: 4.8861 - acc: 0.008 - ETA: 1s - loss: 4.8861 - acc: 0.008 - ETA: 1s - loss: 4.8864 - acc: 0.008 - ETA: 1s - loss: 4.8864 - acc: 0.008 - ETA: 0s - loss: 4.8864 - acc: 0.008 - ETA: 0s - loss: 4.8864 - acc: 0.008 - ETA: 0s - loss: 4.8863 - acc: 0.008 - ETA: 0s - loss: 4.8864 - acc: 0.0084Epoch 00000: val_loss improved from inf to 4.87735, saving model to saved_models/weights.best.from_scratch.hdf5\n",
      "6680/6680 [==============================] - 74s - loss: 4.8864 - acc: 0.0084 - val_loss: 4.8773 - val_acc: 0.0132\n",
      "Epoch 2/32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4300/6680 [==================>...........] - ETA: 67s - loss: 4.8861 - acc: 0.0000e+ - ETA: 67s - loss: 4.8934 - acc: 0.0000e+ - ETA: 68s - loss: 4.8843 - acc: 0.0000e+ - ETA: 70s - loss: 4.8795 - acc: 0.0125   - ETA: 70s - loss: 4.8859 - acc: 0.01 - ETA: 70s - loss: 4.8819 - acc: 0.02 - ETA: 70s - loss: 4.8755 - acc: 0.02 - ETA: 70s - loss: 4.8769 - acc: 0.02 - ETA: 70s - loss: 4.8740 - acc: 0.02 - ETA: 69s - loss: 4.8711 - acc: 0.02 - ETA: 69s - loss: 4.8712 - acc: 0.02 - ETA: 69s - loss: 4.8712 - acc: 0.02 - ETA: 68s - loss: 4.8694 - acc: 0.01 - ETA: 68s - loss: 4.8760 - acc: 0.01 - ETA: 67s - loss: 4.8733 - acc: 0.01 - ETA: 67s - loss: 4.8737 - acc: 0.01 - ETA: 67s - loss: 4.8719 - acc: 0.01 - ETA: 67s - loss: 4.8696 - acc: 0.01 - ETA: 67s - loss: 4.8748 - acc: 0.01 - ETA: 66s - loss: 4.8741 - acc: 0.01 - ETA: 66s - loss: 4.8762 - acc: 0.01 - ETA: 66s - loss: 4.8755 - acc: 0.01 - ETA: 66s - loss: 4.8757 - acc: 0.01 - ETA: 65s - loss: 4.8776 - acc: 0.01 - ETA: 65s - loss: 4.8747 - acc: 0.01 - ETA: 65s - loss: 4.8751 - acc: 0.01 - ETA: 65s - loss: 4.8765 - acc: 0.01 - ETA: 64s - loss: 4.8748 - acc: 0.01 - ETA: 64s - loss: 4.8737 - acc: 0.01 - ETA: 64s - loss: 4.8751 - acc: 0.01 - ETA: 64s - loss: 4.8753 - acc: 0.01 - ETA: 64s - loss: 4.8762 - acc: 0.01 - ETA: 63s - loss: 4.8757 - acc: 0.01 - ETA: 63s - loss: 4.8738 - acc: 0.01 - ETA: 63s - loss: 4.8726 - acc: 0.01 - ETA: 63s - loss: 4.8720 - acc: 0.01 - ETA: 63s - loss: 4.8734 - acc: 0.01 - ETA: 62s - loss: 4.8736 - acc: 0.01 - ETA: 62s - loss: 4.8738 - acc: 0.01 - ETA: 62s - loss: 4.8731 - acc: 0.01 - ETA: 62s - loss: 4.8735 - acc: 0.01 - ETA: 61s - loss: 4.8751 - acc: 0.01 - ETA: 61s - loss: 4.8757 - acc: 0.01 - ETA: 61s - loss: 4.8762 - acc: 0.01 - ETA: 61s - loss: 4.8764 - acc: 0.01 - ETA: 61s - loss: 4.8754 - acc: 0.00 - ETA: 60s - loss: 4.8750 - acc: 0.00 - ETA: 60s - loss: 4.8746 - acc: 0.00 - ETA: 60s - loss: 4.8749 - acc: 0.00 - ETA: 60s - loss: 4.8756 - acc: 0.00 - ETA: 60s - loss: 4.8759 - acc: 0.00 - ETA: 59s - loss: 4.8764 - acc: 0.00 - ETA: 59s - loss: 4.8768 - acc: 0.00 - ETA: 59s - loss: 4.8770 - acc: 0.00 - ETA: 59s - loss: 4.8772 - acc: 0.00 - ETA: 58s - loss: 4.8768 - acc: 0.00 - ETA: 58s - loss: 4.8773 - acc: 0.00 - ETA: 58s - loss: 4.8772 - acc: 0.00 - ETA: 58s - loss: 4.8764 - acc: 0.00 - ETA: 58s - loss: 4.8765 - acc: 0.00 - ETA: 57s - loss: 4.8773 - acc: 0.00 - ETA: 57s - loss: 4.8765 - acc: 0.00 - ETA: 57s - loss: 4.8762 - acc: 0.00 - ETA: 57s - loss: 4.8764 - acc: 0.00 - ETA: 57s - loss: 4.8762 - acc: 0.00 - ETA: 56s - loss: 4.8753 - acc: 0.00 - ETA: 56s - loss: 4.8754 - acc: 0.00 - ETA: 56s - loss: 4.8747 - acc: 0.00 - ETA: 56s - loss: 4.8753 - acc: 0.00 - ETA: 55s - loss: 4.8752 - acc: 0.00 - ETA: 55s - loss: 4.8751 - acc: 0.00 - ETA: 55s - loss: 4.8748 - acc: 0.00 - ETA: 55s - loss: 4.8754 - acc: 0.00 - ETA: 55s - loss: 4.8760 - acc: 0.00 - ETA: 54s - loss: 4.8756 - acc: 0.00 - ETA: 54s - loss: 4.8756 - acc: 0.00 - ETA: 54s - loss: 4.8755 - acc: 0.00 - ETA: 54s - loss: 4.8761 - acc: 0.00 - ETA: 54s - loss: 4.8756 - acc: 0.00 - ETA: 53s - loss: 4.8753 - acc: 0.00 - ETA: 53s - loss: 4.8746 - acc: 0.01 - ETA: 53s - loss: 4.8749 - acc: 0.01 - ETA: 53s - loss: 4.8745 - acc: 0.01 - ETA: 53s - loss: 4.8744 - acc: 0.01 - ETA: 52s - loss: 4.8744 - acc: 0.01 - ETA: 52s - loss: 4.8742 - acc: 0.01 - ETA: 52s - loss: 4.8734 - acc: 0.01 - ETA: 52s - loss: 4.8739 - acc: 0.01 - ETA: 51s - loss: 4.8743 - acc: 0.01 - ETA: 51s - loss: 4.8736 - acc: 0.01 - ETA: 51s - loss: 4.8738 - acc: 0.01 - ETA: 51s - loss: 4.8732 - acc: 0.01 - ETA: 51s - loss: 4.8737 - acc: 0.01 - ETA: 50s - loss: 4.8741 - acc: 0.01 - ETA: 50s - loss: 4.8749 - acc: 0.01 - ETA: 50s - loss: 4.8747 - acc: 0.00 - ETA: 50s - loss: 4.8740 - acc: 0.00 - ETA: 49s - loss: 4.8743 - acc: 0.00 - ETA: 49s - loss: 4.8743 - acc: 0.00 - ETA: 49s - loss: 4.8741 - acc: 0.01 - ETA: 49s - loss: 4.8741 - acc: 0.00 - ETA: 49s - loss: 4.8745 - acc: 0.00 - ETA: 48s - loss: 4.8743 - acc: 0.01 - ETA: 48s - loss: 4.8748 - acc: 0.01 - ETA: 48s - loss: 4.8745 - acc: 0.01 - ETA: 48s - loss: 4.8744 - acc: 0.00 - ETA: 48s - loss: 4.8747 - acc: 0.00 - ETA: 47s - loss: 4.8745 - acc: 0.00 - ETA: 47s - loss: 4.8747 - acc: 0.01 - ETA: 47s - loss: 4.8749 - acc: 0.01 - ETA: 47s - loss: 4.8746 - acc: 0.01 - ETA: 46s - loss: 4.8742 - acc: 0.01 - ETA: 46s - loss: 4.8736 - acc: 0.01 - ETA: 46s - loss: 4.8741 - acc: 0.01 - ETA: 46s - loss: 4.8744 - acc: 0.01 - ETA: 46s - loss: 4.8742 - acc: 0.01 - ETA: 45s - loss: 4.8745 - acc: 0.01 - ETA: 45s - loss: 4.8743 - acc: 0.01 - ETA: 45s - loss: 4.8740 - acc: 0.01 - ETA: 45s - loss: 4.8735 - acc: 0.01 - ETA: 44s - loss: 4.8738 - acc: 0.01 - ETA: 44s - loss: 4.8735 - acc: 0.01 - ETA: 44s - loss: 4.8733 - acc: 0.01 - ETA: 44s - loss: 4.8737 - acc: 0.01 - ETA: 44s - loss: 4.8738 - acc: 0.01 - ETA: 43s - loss: 4.8743 - acc: 0.01 - ETA: 43s - loss: 4.8745 - acc: 0.01 - ETA: 43s - loss: 4.8747 - acc: 0.01 - ETA: 43s - loss: 4.8752 - acc: 0.01 - ETA: 43s - loss: 4.8751 - acc: 0.01 - ETA: 42s - loss: 4.8749 - acc: 0.01 - ETA: 42s - loss: 4.8749 - acc: 0.01 - ETA: 42s - loss: 4.8748 - acc: 0.01 - ETA: 42s - loss: 4.8749 - acc: 0.01 - ETA: 41s - loss: 4.8747 - acc: 0.01 - ETA: 41s - loss: 4.8744 - acc: 0.01 - ETA: 41s - loss: 4.8739 - acc: 0.01 - ETA: 41s - loss: 4.8741 - acc: 0.01 - ETA: 41s - loss: 4.8738 - acc: 0.01 - ETA: 40s - loss: 4.8741 - acc: 0.01 - ETA: 40s - loss: 4.8740 - acc: 0.01 - ETA: 40s - loss: 4.8736 - acc: 0.01 - ETA: 40s - loss: 4.8735 - acc: 0.01 - ETA: 40s - loss: 4.8733 - acc: 0.01 - ETA: 39s - loss: 4.8734 - acc: 0.01 - ETA: 39s - loss: 4.8726 - acc: 0.01 - ETA: 39s - loss: 4.8725 - acc: 0.01 - ETA: 39s - loss: 4.8726 - acc: 0.01 - ETA: 39s - loss: 4.8724 - acc: 0.01 - ETA: 38s - loss: 4.8721 - acc: 0.01 - ETA: 38s - loss: 4.8725 - acc: 0.01 - ETA: 38s - loss: 4.8729 - acc: 0.01 - ETA: 38s - loss: 4.8732 - acc: 0.01 - ETA: 37s - loss: 4.8733 - acc: 0.01 - ETA: 37s - loss: 4.8732 - acc: 0.01 - ETA: 37s - loss: 4.8733 - acc: 0.01 - ETA: 37s - loss: 4.8734 - acc: 0.01 - ETA: 37s - loss: 4.8738 - acc: 0.01 - ETA: 36s - loss: 4.8736 - acc: 0.01 - ETA: 36s - loss: 4.8734 - acc: 0.01 - ETA: 36s - loss: 4.8735 - acc: 0.01 - ETA: 36s - loss: 4.8735 - acc: 0.01 - ETA: 36s - loss: 4.8736 - acc: 0.01 - ETA: 35s - loss: 4.8736 - acc: 0.01 - ETA: 35s - loss: 4.8737 - acc: 0.01 - ETA: 35s - loss: 4.8739 - acc: 0.01 - ETA: 35s - loss: 4.8737 - acc: 0.01 - ETA: 35s - loss: 4.8735 - acc: 0.01 - ETA: 34s - loss: 4.8736 - acc: 0.01 - ETA: 34s - loss: 4.8737 - acc: 0.01 - ETA: 34s - loss: 4.8737 - acc: 0.01 - ETA: 34s - loss: 4.8736 - acc: 0.01 - ETA: 33s - loss: 4.8733 - acc: 0.01 - ETA: 33s - loss: 4.8725 - acc: 0.01 - ETA: 33s - loss: 4.8721 - acc: 0.01 - ETA: 33s - loss: 4.8736 - acc: 0.01 - ETA: 33s - loss: 4.8739 - acc: 0.01 - ETA: 32s - loss: 4.8739 - acc: 0.01 - ETA: 32s - loss: 4.8735 - acc: 0.01 - ETA: 32s - loss: 4.8737 - acc: 0.01 - ETA: 32s - loss: 4.8740 - acc: 0.01 - ETA: 32s - loss: 4.8738 - acc: 0.01 - ETA: 31s - loss: 4.8736 - acc: 0.01 - ETA: 31s - loss: 4.8734 - acc: 0.01 - ETA: 31s - loss: 4.8731 - acc: 0.01 - ETA: 31s - loss: 4.8727 - acc: 0.01 - ETA: 30s - loss: 4.8731 - acc: 0.01 - ETA: 30s - loss: 4.8733 - acc: 0.01 - ETA: 30s - loss: 4.8732 - acc: 0.01 - ETA: 30s - loss: 4.8737 - acc: 0.01 - ETA: 30s - loss: 4.8736 - acc: 0.01 - ETA: 29s - loss: 4.8734 - acc: 0.01 - ETA: 29s - loss: 4.8731 - acc: 0.01 - ETA: 29s - loss: 4.8733 - acc: 0.01 - ETA: 29s - loss: 4.8733 - acc: 0.01 - ETA: 29s - loss: 4.8731 - acc: 0.01 - ETA: 28s - loss: 4.8729 - acc: 0.01 - ETA: 28s - loss: 4.8720 - acc: 0.01 - ETA: 28s - loss: 4.8719 - acc: 0.01 - ETA: 28s - loss: 4.8717 - acc: 0.01 - ETA: 28s - loss: 4.8713 - acc: 0.01 - ETA: 27s - loss: 4.8719 - acc: 0.01 - ETA: 27s - loss: 4.8720 - acc: 0.01 - ETA: 27s - loss: 4.8720 - acc: 0.01 - ETA: 27s - loss: 4.8721 - acc: 0.01 - ETA: 26s - loss: 4.8723 - acc: 0.01 - ETA: 26s - loss: 4.8723 - acc: 0.01 - ETA: 26s - loss: 4.8726 - acc: 0.01 - ETA: 26s - loss: 4.8725 - acc: 0.01 - ETA: 26s - loss: 4.8723 - acc: 0.01 - ETA: 25s - loss: 4.8726 - acc: 0.01 - ETA: 25s - loss: 4.8726 - acc: 0.01 - ETA: 25s - loss: 4.8726 - acc: 0.01 - ETA: 25s - loss: 4.8726 - acc: 0.01 - ETA: 25s - loss: 4.8728 - acc: 0.0116"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6660/6680 [============================>.] - ETA: 24s - loss: 4.8727 - acc: 0.01 - ETA: 24s - loss: 4.8726 - acc: 0.01 - ETA: 24s - loss: 4.8724 - acc: 0.01 - ETA: 24s - loss: 4.8722 - acc: 0.01 - ETA: 24s - loss: 4.8723 - acc: 0.01 - ETA: 23s - loss: 4.8723 - acc: 0.01 - ETA: 23s - loss: 4.8721 - acc: 0.01 - ETA: 23s - loss: 4.8721 - acc: 0.01 - ETA: 23s - loss: 4.8720 - acc: 0.01 - ETA: 22s - loss: 4.8717 - acc: 0.01 - ETA: 22s - loss: 4.8716 - acc: 0.01 - ETA: 22s - loss: 4.8716 - acc: 0.01 - ETA: 22s - loss: 4.8716 - acc: 0.01 - ETA: 22s - loss: 4.8716 - acc: 0.01 - ETA: 21s - loss: 4.8717 - acc: 0.01 - ETA: 21s - loss: 4.8719 - acc: 0.01 - ETA: 21s - loss: 4.8718 - acc: 0.01 - ETA: 21s - loss: 4.8718 - acc: 0.01 - ETA: 21s - loss: 4.8716 - acc: 0.01 - ETA: 20s - loss: 4.8715 - acc: 0.01 - ETA: 20s - loss: 4.8714 - acc: 0.01 - ETA: 20s - loss: 4.8715 - acc: 0.01 - ETA: 20s - loss: 4.8712 - acc: 0.01 - ETA: 19s - loss: 4.8718 - acc: 0.01 - ETA: 19s - loss: 4.8718 - acc: 0.01 - ETA: 19s - loss: 4.8719 - acc: 0.01 - ETA: 19s - loss: 4.8720 - acc: 0.01 - ETA: 19s - loss: 4.8717 - acc: 0.01 - ETA: 18s - loss: 4.8718 - acc: 0.01 - ETA: 18s - loss: 4.8719 - acc: 0.01 - ETA: 18s - loss: 4.8719 - acc: 0.01 - ETA: 18s - loss: 4.8717 - acc: 0.01 - ETA: 18s - loss: 4.8718 - acc: 0.01 - ETA: 17s - loss: 4.8717 - acc: 0.01 - ETA: 17s - loss: 4.8716 - acc: 0.01 - ETA: 17s - loss: 4.8718 - acc: 0.01 - ETA: 17s - loss: 4.8718 - acc: 0.01 - ETA: 17s - loss: 4.8716 - acc: 0.01 - ETA: 16s - loss: 4.8715 - acc: 0.01 - ETA: 16s - loss: 4.8715 - acc: 0.01 - ETA: 16s - loss: 4.8711 - acc: 0.01 - ETA: 16s - loss: 4.8711 - acc: 0.01 - ETA: 16s - loss: 4.8711 - acc: 0.01 - ETA: 15s - loss: 4.8711 - acc: 0.01 - ETA: 15s - loss: 4.8711 - acc: 0.01 - ETA: 15s - loss: 4.8709 - acc: 0.01 - ETA: 15s - loss: 4.8708 - acc: 0.01 - ETA: 14s - loss: 4.8707 - acc: 0.01 - ETA: 14s - loss: 4.8703 - acc: 0.01 - ETA: 14s - loss: 4.8707 - acc: 0.01 - ETA: 14s - loss: 4.8705 - acc: 0.01 - ETA: 14s - loss: 4.8703 - acc: 0.01 - ETA: 13s - loss: 4.8702 - acc: 0.01 - ETA: 13s - loss: 4.8703 - acc: 0.01 - ETA: 13s - loss: 4.8704 - acc: 0.01 - ETA: 13s - loss: 4.8708 - acc: 0.01 - ETA: 13s - loss: 4.8706 - acc: 0.01 - ETA: 12s - loss: 4.8706 - acc: 0.01 - ETA: 12s - loss: 4.8709 - acc: 0.01 - ETA: 12s - loss: 4.8709 - acc: 0.01 - ETA: 12s - loss: 4.8710 - acc: 0.01 - ETA: 12s - loss: 4.8711 - acc: 0.01 - ETA: 11s - loss: 4.8711 - acc: 0.01 - ETA: 11s - loss: 4.8710 - acc: 0.01 - ETA: 11s - loss: 4.8707 - acc: 0.01 - ETA: 11s - loss: 4.8710 - acc: 0.01 - ETA: 11s - loss: 4.8710 - acc: 0.01 - ETA: 10s - loss: 4.8711 - acc: 0.01 - ETA: 10s - loss: 4.8711 - acc: 0.01 - ETA: 10s - loss: 4.8712 - acc: 0.01 - ETA: 10s - loss: 4.8710 - acc: 0.01 - ETA: 9s - loss: 4.8708 - acc: 0.0122 - ETA: 9s - loss: 4.8710 - acc: 0.012 - ETA: 9s - loss: 4.8711 - acc: 0.012 - ETA: 9s - loss: 4.8714 - acc: 0.012 - ETA: 9s - loss: 4.8713 - acc: 0.012 - ETA: 8s - loss: 4.8713 - acc: 0.012 - ETA: 8s - loss: 4.8713 - acc: 0.011 - ETA: 8s - loss: 4.8711 - acc: 0.011 - ETA: 8s - loss: 4.8710 - acc: 0.011 - ETA: 8s - loss: 4.8712 - acc: 0.011 - ETA: 7s - loss: 4.8711 - acc: 0.011 - ETA: 7s - loss: 4.8712 - acc: 0.011 - ETA: 7s - loss: 4.8711 - acc: 0.011 - ETA: 7s - loss: 4.8714 - acc: 0.011 - ETA: 7s - loss: 4.8714 - acc: 0.011 - ETA: 6s - loss: 4.8712 - acc: 0.011 - ETA: 6s - loss: 4.8713 - acc: 0.011 - ETA: 6s - loss: 4.8712 - acc: 0.011 - ETA: 6s - loss: 4.8713 - acc: 0.011 - ETA: 5s - loss: 4.8714 - acc: 0.011 - ETA: 5s - loss: 4.8715 - acc: 0.011 - ETA: 5s - loss: 4.8714 - acc: 0.011 - ETA: 5s - loss: 4.8713 - acc: 0.011 - ETA: 5s - loss: 4.8712 - acc: 0.011 - ETA: 4s - loss: 4.8711 - acc: 0.011 - ETA: 4s - loss: 4.8710 - acc: 0.011 - ETA: 4s - loss: 4.8709 - acc: 0.011 - ETA: 4s - loss: 4.8707 - acc: 0.011 - ETA: 4s - loss: 4.8703 - acc: 0.011 - ETA: 3s - loss: 4.8701 - acc: 0.011 - ETA: 3s - loss: 4.8702 - acc: 0.012 - ETA: 3s - loss: 4.8699 - acc: 0.012 - ETA: 3s - loss: 4.8700 - acc: 0.012 - ETA: 2s - loss: 4.8702 - acc: 0.012 - ETA: 2s - loss: 4.8702 - acc: 0.012 - ETA: 2s - loss: 4.8700 - acc: 0.012 - ETA: 2s - loss: 4.8700 - acc: 0.012 - ETA: 2s - loss: 4.8700 - acc: 0.012 - ETA: 1s - loss: 4.8699 - acc: 0.012 - ETA: 1s - loss: 4.8695 - acc: 0.012 - ETA: 1s - loss: 4.8698 - acc: 0.012 - ETA: 1s - loss: 4.8701 - acc: 0.012 - ETA: 1s - loss: 4.8701 - acc: 0.012 - ETA: 0s - loss: 4.8702 - acc: 0.012 - ETA: 0s - loss: 4.8703 - acc: 0.012 - ETA: 0s - loss: 4.8705 - acc: 0.012 - ETA: 0s - loss: 4.8705 - acc: 0.0125Epoch 00001: val_loss improved from 4.87735 to 4.86794, saving model to saved_models/weights.best.from_scratch.hdf5\n",
      "6680/6680 [==============================] - 73s - loss: 4.8707 - acc: 0.0124 - val_loss: 4.8679 - val_acc: 0.0156\n",
      "Epoch 3/32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4300/6680 [==================>...........] - ETA: 65s - loss: 4.8737 - acc: 0.10 - ETA: 65s - loss: 4.8390 - acc: 0.10 - ETA: 66s - loss: 4.8506 - acc: 0.06 - ETA: 67s - loss: 4.8434 - acc: 0.06 - ETA: 68s - loss: 4.8464 - acc: 0.05 - ETA: 67s - loss: 4.8432 - acc: 0.04 - ETA: 67s - loss: 4.8517 - acc: 0.03 - ETA: 67s - loss: 4.8499 - acc: 0.03 - ETA: 67s - loss: 4.8515 - acc: 0.02 - ETA: 67s - loss: 4.8487 - acc: 0.02 - ETA: 67s - loss: 4.8528 - acc: 0.02 - ETA: 66s - loss: 4.8501 - acc: 0.02 - ETA: 66s - loss: 4.8462 - acc: 0.01 - ETA: 66s - loss: 4.8523 - acc: 0.01 - ETA: 66s - loss: 4.8502 - acc: 0.02 - ETA: 66s - loss: 4.8538 - acc: 0.01 - ETA: 66s - loss: 4.8544 - acc: 0.01 - ETA: 65s - loss: 4.8578 - acc: 0.01 - ETA: 65s - loss: 4.8569 - acc: 0.01 - ETA: 65s - loss: 4.8575 - acc: 0.01 - ETA: 65s - loss: 4.8576 - acc: 0.01 - ETA: 65s - loss: 4.8591 - acc: 0.01 - ETA: 64s - loss: 4.8579 - acc: 0.01 - ETA: 64s - loss: 4.8579 - acc: 0.01 - ETA: 64s - loss: 4.8546 - acc: 0.01 - ETA: 64s - loss: 4.8512 - acc: 0.01 - ETA: 64s - loss: 4.8474 - acc: 0.01 - ETA: 64s - loss: 4.8538 - acc: 0.01 - ETA: 63s - loss: 4.8517 - acc: 0.01 - ETA: 63s - loss: 4.8518 - acc: 0.01 - ETA: 63s - loss: 4.8516 - acc: 0.01 - ETA: 63s - loss: 4.8482 - acc: 0.01 - ETA: 63s - loss: 4.8490 - acc: 0.01 - ETA: 62s - loss: 4.8503 - acc: 0.01 - ETA: 62s - loss: 4.8506 - acc: 0.01 - ETA: 62s - loss: 4.8513 - acc: 0.01 - ETA: 62s - loss: 4.8495 - acc: 0.01 - ETA: 62s - loss: 4.8492 - acc: 0.01 - ETA: 61s - loss: 4.8469 - acc: 0.01 - ETA: 61s - loss: 4.8478 - acc: 0.01 - ETA: 61s - loss: 4.8460 - acc: 0.01 - ETA: 61s - loss: 4.8458 - acc: 0.01 - ETA: 60s - loss: 4.8470 - acc: 0.01 - ETA: 60s - loss: 4.8467 - acc: 0.01 - ETA: 60s - loss: 4.8451 - acc: 0.01 - ETA: 60s - loss: 4.8455 - acc: 0.01 - ETA: 60s - loss: 4.8442 - acc: 0.01 - ETA: 59s - loss: 4.8460 - acc: 0.01 - ETA: 59s - loss: 4.8451 - acc: 0.01 - ETA: 59s - loss: 4.8423 - acc: 0.02 - ETA: 59s - loss: 4.8432 - acc: 0.02 - ETA: 58s - loss: 4.8452 - acc: 0.02 - ETA: 58s - loss: 4.8450 - acc: 0.01 - ETA: 58s - loss: 4.8469 - acc: 0.01 - ETA: 58s - loss: 4.8463 - acc: 0.01 - ETA: 58s - loss: 4.8457 - acc: 0.01 - ETA: 58s - loss: 4.8474 - acc: 0.01 - ETA: 57s - loss: 4.8466 - acc: 0.01 - ETA: 57s - loss: 4.8479 - acc: 0.01 - ETA: 57s - loss: 4.8488 - acc: 0.01 - ETA: 57s - loss: 4.8479 - acc: 0.01 - ETA: 56s - loss: 4.8486 - acc: 0.01 - ETA: 56s - loss: 4.8492 - acc: 0.01 - ETA: 56s - loss: 4.8496 - acc: 0.01 - ETA: 56s - loss: 4.8493 - acc: 0.01 - ETA: 56s - loss: 4.8510 - acc: 0.01 - ETA: 55s - loss: 4.8512 - acc: 0.01 - ETA: 55s - loss: 4.8515 - acc: 0.01 - ETA: 55s - loss: 4.8507 - acc: 0.01 - ETA: 55s - loss: 4.8498 - acc: 0.01 - ETA: 55s - loss: 4.8500 - acc: 0.01 - ETA: 54s - loss: 4.8507 - acc: 0.01 - ETA: 54s - loss: 4.8509 - acc: 0.01 - ETA: 54s - loss: 4.8506 - acc: 0.01 - ETA: 54s - loss: 4.8512 - acc: 0.01 - ETA: 53s - loss: 4.8517 - acc: 0.01 - ETA: 53s - loss: 4.8532 - acc: 0.01 - ETA: 53s - loss: 4.8527 - acc: 0.01 - ETA: 53s - loss: 4.8530 - acc: 0.01 - ETA: 53s - loss: 4.8532 - acc: 0.01 - ETA: 52s - loss: 4.8534 - acc: 0.01 - ETA: 52s - loss: 4.8539 - acc: 0.01 - ETA: 52s - loss: 4.8536 - acc: 0.01 - ETA: 52s - loss: 4.8542 - acc: 0.01 - ETA: 52s - loss: 4.8544 - acc: 0.01 - ETA: 51s - loss: 4.8550 - acc: 0.01 - ETA: 51s - loss: 4.8552 - acc: 0.01 - ETA: 51s - loss: 4.8549 - acc: 0.01 - ETA: 51s - loss: 4.8551 - acc: 0.01 - ETA: 51s - loss: 4.8553 - acc: 0.01 - ETA: 50s - loss: 4.8551 - acc: 0.01 - ETA: 50s - loss: 4.8545 - acc: 0.01 - ETA: 50s - loss: 4.8544 - acc: 0.01 - ETA: 50s - loss: 4.8547 - acc: 0.01 - ETA: 49s - loss: 4.8557 - acc: 0.01 - ETA: 49s - loss: 4.8553 - acc: 0.01 - ETA: 49s - loss: 4.8554 - acc: 0.01 - ETA: 49s - loss: 4.8549 - acc: 0.01 - ETA: 49s - loss: 4.8540 - acc: 0.01 - ETA: 48s - loss: 4.8548 - acc: 0.01 - ETA: 48s - loss: 4.8546 - acc: 0.01 - ETA: 48s - loss: 4.8555 - acc: 0.01 - ETA: 48s - loss: 4.8556 - acc: 0.01 - ETA: 48s - loss: 4.8549 - acc: 0.01 - ETA: 47s - loss: 4.8556 - acc: 0.01 - ETA: 47s - loss: 4.8555 - acc: 0.01 - ETA: 47s - loss: 4.8558 - acc: 0.01 - ETA: 47s - loss: 4.8556 - acc: 0.01 - ETA: 47s - loss: 4.8558 - acc: 0.01 - ETA: 46s - loss: 4.8559 - acc: 0.01 - ETA: 46s - loss: 4.8557 - acc: 0.01 - ETA: 46s - loss: 4.8549 - acc: 0.01 - ETA: 46s - loss: 4.8555 - acc: 0.01 - ETA: 45s - loss: 4.8552 - acc: 0.01 - ETA: 45s - loss: 4.8553 - acc: 0.01 - ETA: 45s - loss: 4.8547 - acc: 0.01 - ETA: 45s - loss: 4.8563 - acc: 0.01 - ETA: 45s - loss: 4.8562 - acc: 0.01 - ETA: 44s - loss: 4.8557 - acc: 0.01 - ETA: 44s - loss: 4.8559 - acc: 0.01 - ETA: 44s - loss: 4.8557 - acc: 0.01 - ETA: 44s - loss: 4.8547 - acc: 0.01 - ETA: 44s - loss: 4.8553 - acc: 0.01 - ETA: 43s - loss: 4.8548 - acc: 0.01 - ETA: 43s - loss: 4.8537 - acc: 0.01 - ETA: 43s - loss: 4.8536 - acc: 0.01 - ETA: 43s - loss: 4.8537 - acc: 0.01 - ETA: 43s - loss: 4.8546 - acc: 0.01 - ETA: 42s - loss: 4.8554 - acc: 0.01 - ETA: 42s - loss: 4.8556 - acc: 0.01 - ETA: 42s - loss: 4.8549 - acc: 0.01 - ETA: 42s - loss: 4.8553 - acc: 0.01 - ETA: 42s - loss: 4.8554 - acc: 0.01 - ETA: 41s - loss: 4.8556 - acc: 0.01 - ETA: 41s - loss: 4.8557 - acc: 0.01 - ETA: 41s - loss: 4.8557 - acc: 0.01 - ETA: 41s - loss: 4.8557 - acc: 0.01 - ETA: 41s - loss: 4.8556 - acc: 0.01 - ETA: 40s - loss: 4.8561 - acc: 0.01 - ETA: 40s - loss: 4.8557 - acc: 0.01 - ETA: 40s - loss: 4.8556 - acc: 0.01 - ETA: 40s - loss: 4.8555 - acc: 0.01 - ETA: 40s - loss: 4.8561 - acc: 0.01 - ETA: 39s - loss: 4.8563 - acc: 0.01 - ETA: 39s - loss: 4.8564 - acc: 0.01 - ETA: 39s - loss: 4.8558 - acc: 0.01 - ETA: 39s - loss: 4.8569 - acc: 0.01 - ETA: 38s - loss: 4.8566 - acc: 0.01 - ETA: 38s - loss: 4.8566 - acc: 0.01 - ETA: 38s - loss: 4.8567 - acc: 0.01 - ETA: 38s - loss: 4.8567 - acc: 0.01 - ETA: 38s - loss: 4.8567 - acc: 0.01 - ETA: 37s - loss: 4.8563 - acc: 0.01 - ETA: 37s - loss: 4.8566 - acc: 0.01 - ETA: 37s - loss: 4.8567 - acc: 0.01 - ETA: 37s - loss: 4.8567 - acc: 0.01 - ETA: 37s - loss: 4.8568 - acc: 0.01 - ETA: 36s - loss: 4.8572 - acc: 0.01 - ETA: 36s - loss: 4.8572 - acc: 0.01 - ETA: 36s - loss: 4.8578 - acc: 0.01 - ETA: 36s - loss: 4.8582 - acc: 0.01 - ETA: 36s - loss: 4.8581 - acc: 0.01 - ETA: 35s - loss: 4.8582 - acc: 0.01 - ETA: 35s - loss: 4.8582 - acc: 0.01 - ETA: 35s - loss: 4.8585 - acc: 0.01 - ETA: 35s - loss: 4.8584 - acc: 0.01 - ETA: 34s - loss: 4.8584 - acc: 0.01 - ETA: 34s - loss: 4.8580 - acc: 0.01 - ETA: 34s - loss: 4.8591 - acc: 0.01 - ETA: 34s - loss: 4.8590 - acc: 0.01 - ETA: 34s - loss: 4.8592 - acc: 0.01 - ETA: 33s - loss: 4.8598 - acc: 0.01 - ETA: 33s - loss: 4.8598 - acc: 0.01 - ETA: 33s - loss: 4.8597 - acc: 0.01 - ETA: 33s - loss: 4.8597 - acc: 0.01 - ETA: 33s - loss: 4.8601 - acc: 0.01 - ETA: 32s - loss: 4.8601 - acc: 0.01 - ETA: 32s - loss: 4.8594 - acc: 0.01 - ETA: 32s - loss: 4.8595 - acc: 0.01 - ETA: 32s - loss: 4.8597 - acc: 0.01 - ETA: 32s - loss: 4.8597 - acc: 0.01 - ETA: 31s - loss: 4.8601 - acc: 0.01 - ETA: 31s - loss: 4.8602 - acc: 0.01 - ETA: 31s - loss: 4.8599 - acc: 0.01 - ETA: 31s - loss: 4.8599 - acc: 0.01 - ETA: 30s - loss: 4.8595 - acc: 0.01 - ETA: 30s - loss: 4.8600 - acc: 0.01 - ETA: 30s - loss: 4.8598 - acc: 0.01 - ETA: 30s - loss: 4.8601 - acc: 0.01 - ETA: 30s - loss: 4.8604 - acc: 0.01 - ETA: 29s - loss: 4.8599 - acc: 0.01 - ETA: 29s - loss: 4.8597 - acc: 0.01 - ETA: 29s - loss: 4.8596 - acc: 0.01 - ETA: 29s - loss: 4.8594 - acc: 0.01 - ETA: 29s - loss: 4.8596 - acc: 0.01 - ETA: 28s - loss: 4.8596 - acc: 0.01 - ETA: 28s - loss: 4.8597 - acc: 0.01 - ETA: 28s - loss: 4.8596 - acc: 0.01 - ETA: 28s - loss: 4.8595 - acc: 0.01 - ETA: 28s - loss: 4.8594 - acc: 0.01 - ETA: 27s - loss: 4.8594 - acc: 0.01 - ETA: 27s - loss: 4.8588 - acc: 0.01 - ETA: 27s - loss: 4.8590 - acc: 0.01 - ETA: 27s - loss: 4.8594 - acc: 0.01 - ETA: 27s - loss: 4.8599 - acc: 0.01 - ETA: 26s - loss: 4.8599 - acc: 0.01 - ETA: 26s - loss: 4.8595 - acc: 0.01 - ETA: 26s - loss: 4.8593 - acc: 0.01 - ETA: 26s - loss: 4.8593 - acc: 0.01 - ETA: 26s - loss: 4.8592 - acc: 0.01 - ETA: 25s - loss: 4.8589 - acc: 0.01 - ETA: 25s - loss: 4.8588 - acc: 0.01 - ETA: 25s - loss: 4.8590 - acc: 0.01 - ETA: 25s - loss: 4.8590 - acc: 0.01 - ETA: 24s - loss: 4.8588 - acc: 0.0144"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6660/6680 [============================>.] - ETA: 24s - loss: 4.8589 - acc: 0.01 - ETA: 24s - loss: 4.8584 - acc: 0.01 - ETA: 24s - loss: 4.8582 - acc: 0.01 - ETA: 24s - loss: 4.8577 - acc: 0.01 - ETA: 23s - loss: 4.8583 - acc: 0.01 - ETA: 23s - loss: 4.8584 - acc: 0.01 - ETA: 23s - loss: 4.8583 - acc: 0.01 - ETA: 23s - loss: 4.8584 - acc: 0.01 - ETA: 23s - loss: 4.8586 - acc: 0.01 - ETA: 22s - loss: 4.8586 - acc: 0.01 - ETA: 22s - loss: 4.8585 - acc: 0.01 - ETA: 22s - loss: 4.8587 - acc: 0.01 - ETA: 22s - loss: 4.8584 - acc: 0.01 - ETA: 22s - loss: 4.8584 - acc: 0.01 - ETA: 21s - loss: 4.8584 - acc: 0.01 - ETA: 21s - loss: 4.8583 - acc: 0.01 - ETA: 21s - loss: 4.8584 - acc: 0.01 - ETA: 21s - loss: 4.8584 - acc: 0.01 - ETA: 20s - loss: 4.8585 - acc: 0.01 - ETA: 20s - loss: 4.8585 - acc: 0.01 - ETA: 20s - loss: 4.8584 - acc: 0.01 - ETA: 20s - loss: 4.8580 - acc: 0.01 - ETA: 20s - loss: 4.8573 - acc: 0.01 - ETA: 19s - loss: 4.8582 - acc: 0.01 - ETA: 19s - loss: 4.8578 - acc: 0.01 - ETA: 19s - loss: 4.8581 - acc: 0.01 - ETA: 19s - loss: 4.8579 - acc: 0.01 - ETA: 19s - loss: 4.8576 - acc: 0.01 - ETA: 18s - loss: 4.8580 - acc: 0.01 - ETA: 18s - loss: 4.8573 - acc: 0.01 - ETA: 18s - loss: 4.8574 - acc: 0.01 - ETA: 18s - loss: 4.8571 - acc: 0.01 - ETA: 18s - loss: 4.8571 - acc: 0.01 - ETA: 17s - loss: 4.8569 - acc: 0.01 - ETA: 17s - loss: 4.8570 - acc: 0.01 - ETA: 17s - loss: 4.8569 - acc: 0.01 - ETA: 17s - loss: 4.8567 - acc: 0.01 - ETA: 16s - loss: 4.8569 - acc: 0.01 - ETA: 16s - loss: 4.8569 - acc: 0.01 - ETA: 16s - loss: 4.8571 - acc: 0.01 - ETA: 16s - loss: 4.8572 - acc: 0.01 - ETA: 16s - loss: 4.8573 - acc: 0.01 - ETA: 15s - loss: 4.8572 - acc: 0.01 - ETA: 15s - loss: 4.8572 - acc: 0.01 - ETA: 15s - loss: 4.8569 - acc: 0.01 - ETA: 15s - loss: 4.8574 - acc: 0.01 - ETA: 15s - loss: 4.8573 - acc: 0.01 - ETA: 14s - loss: 4.8576 - acc: 0.01 - ETA: 14s - loss: 4.8575 - acc: 0.01 - ETA: 14s - loss: 4.8575 - acc: 0.01 - ETA: 14s - loss: 4.8578 - acc: 0.01 - ETA: 14s - loss: 4.8579 - acc: 0.01 - ETA: 13s - loss: 4.8576 - acc: 0.01 - ETA: 13s - loss: 4.8575 - acc: 0.01 - ETA: 13s - loss: 4.8571 - acc: 0.01 - ETA: 13s - loss: 4.8568 - acc: 0.01 - ETA: 12s - loss: 4.8565 - acc: 0.01 - ETA: 12s - loss: 4.8563 - acc: 0.01 - ETA: 12s - loss: 4.8561 - acc: 0.01 - ETA: 12s - loss: 4.8558 - acc: 0.01 - ETA: 12s - loss: 4.8563 - acc: 0.01 - ETA: 11s - loss: 4.8564 - acc: 0.01 - ETA: 11s - loss: 4.8564 - acc: 0.01 - ETA: 11s - loss: 4.8564 - acc: 0.01 - ETA: 11s - loss: 4.8563 - acc: 0.01 - ETA: 11s - loss: 4.8559 - acc: 0.01 - ETA: 10s - loss: 4.8556 - acc: 0.01 - ETA: 10s - loss: 4.8552 - acc: 0.01 - ETA: 10s - loss: 4.8550 - acc: 0.01 - ETA: 10s - loss: 4.8549 - acc: 0.01 - ETA: 10s - loss: 4.8547 - acc: 0.01 - ETA: 9s - loss: 4.8550 - acc: 0.0148 - ETA: 9s - loss: 4.8547 - acc: 0.014 - ETA: 9s - loss: 4.8544 - acc: 0.014 - ETA: 9s - loss: 4.8543 - acc: 0.014 - ETA: 9s - loss: 4.8544 - acc: 0.014 - ETA: 8s - loss: 4.8549 - acc: 0.014 - ETA: 8s - loss: 4.8548 - acc: 0.014 - ETA: 8s - loss: 4.8550 - acc: 0.014 - ETA: 8s - loss: 4.8549 - acc: 0.014 - ETA: 7s - loss: 4.8548 - acc: 0.014 - ETA: 7s - loss: 4.8547 - acc: 0.014 - ETA: 7s - loss: 4.8547 - acc: 0.014 - ETA: 7s - loss: 4.8548 - acc: 0.014 - ETA: 7s - loss: 4.8548 - acc: 0.014 - ETA: 6s - loss: 4.8551 - acc: 0.014 - ETA: 6s - loss: 4.8549 - acc: 0.014 - ETA: 6s - loss: 4.8549 - acc: 0.014 - ETA: 6s - loss: 4.8551 - acc: 0.014 - ETA: 6s - loss: 4.8549 - acc: 0.014 - ETA: 5s - loss: 4.8548 - acc: 0.014 - ETA: 5s - loss: 4.8548 - acc: 0.014 - ETA: 5s - loss: 4.8553 - acc: 0.014 - ETA: 5s - loss: 4.8551 - acc: 0.014 - ETA: 5s - loss: 4.8549 - acc: 0.014 - ETA: 4s - loss: 4.8552 - acc: 0.014 - ETA: 4s - loss: 4.8552 - acc: 0.014 - ETA: 4s - loss: 4.8552 - acc: 0.014 - ETA: 4s - loss: 4.8550 - acc: 0.014 - ETA: 3s - loss: 4.8553 - acc: 0.014 - ETA: 3s - loss: 4.8551 - acc: 0.014 - ETA: 3s - loss: 4.8553 - acc: 0.014 - ETA: 3s - loss: 4.8552 - acc: 0.014 - ETA: 3s - loss: 4.8552 - acc: 0.014 - ETA: 2s - loss: 4.8548 - acc: 0.014 - ETA: 2s - loss: 4.8546 - acc: 0.014 - ETA: 2s - loss: 4.8544 - acc: 0.014 - ETA: 2s - loss: 4.8544 - acc: 0.014 - ETA: 2s - loss: 4.8546 - acc: 0.014 - ETA: 1s - loss: 4.8545 - acc: 0.014 - ETA: 1s - loss: 4.8545 - acc: 0.014 - ETA: 1s - loss: 4.8546 - acc: 0.014 - ETA: 1s - loss: 4.8547 - acc: 0.014 - ETA: 1s - loss: 4.8546 - acc: 0.014 - ETA: 0s - loss: 4.8545 - acc: 0.014 - ETA: 0s - loss: 4.8545 - acc: 0.014 - ETA: 0s - loss: 4.8545 - acc: 0.014 - ETA: 0s - loss: 4.8543 - acc: 0.0141Epoch 00002: val_loss improved from 4.86794 to 4.84675, saving model to saved_models/weights.best.from_scratch.hdf5\n",
      "6680/6680 [==============================] - 72s - loss: 4.8540 - acc: 0.0142 - val_loss: 4.8468 - val_acc: 0.0132\n",
      "Epoch 4/32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4300/6680 [==================>...........] - ETA: 66s - loss: 4.8871 - acc: 0.0000e+ - ETA: 67s - loss: 4.8837 - acc: 0.0000e+ - ETA: 67s - loss: 4.8562 - acc: 0.0000e+ - ETA: 67s - loss: 4.8178 - acc: 0.0125   - ETA: 67s - loss: 4.7974 - acc: 0.01 - ETA: 67s - loss: 4.7972 - acc: 0.00 - ETA: 67s - loss: 4.8060 - acc: 0.01 - ETA: 67s - loss: 4.8149 - acc: 0.01 - ETA: 66s - loss: 4.8215 - acc: 0.02 - ETA: 66s - loss: 4.8056 - acc: 0.03 - ETA: 66s - loss: 4.8069 - acc: 0.03 - ETA: 66s - loss: 4.8054 - acc: 0.03 - ETA: 66s - loss: 4.7983 - acc: 0.04 - ETA: 66s - loss: 4.8035 - acc: 0.03 - ETA: 66s - loss: 4.8101 - acc: 0.03 - ETA: 66s - loss: 4.8044 - acc: 0.03 - ETA: 65s - loss: 4.7973 - acc: 0.03 - ETA: 65s - loss: 4.7927 - acc: 0.03 - ETA: 65s - loss: 4.7996 - acc: 0.03 - ETA: 65s - loss: 4.7982 - acc: 0.03 - ETA: 65s - loss: 4.8018 - acc: 0.03 - ETA: 64s - loss: 4.7979 - acc: 0.03 - ETA: 64s - loss: 4.7950 - acc: 0.03 - ETA: 64s - loss: 4.7971 - acc: 0.03 - ETA: 64s - loss: 4.8039 - acc: 0.03 - ETA: 64s - loss: 4.8084 - acc: 0.03 - ETA: 63s - loss: 4.8102 - acc: 0.03 - ETA: 63s - loss: 4.8104 - acc: 0.03 - ETA: 63s - loss: 4.8076 - acc: 0.03 - ETA: 63s - loss: 4.8072 - acc: 0.03 - ETA: 63s - loss: 4.8112 - acc: 0.03 - ETA: 62s - loss: 4.8089 - acc: 0.03 - ETA: 62s - loss: 4.8068 - acc: 0.03 - ETA: 62s - loss: 4.8039 - acc: 0.03 - ETA: 62s - loss: 4.8044 - acc: 0.03 - ETA: 62s - loss: 4.8009 - acc: 0.03 - ETA: 61s - loss: 4.8032 - acc: 0.03 - ETA: 61s - loss: 4.8068 - acc: 0.03 - ETA: 61s - loss: 4.8103 - acc: 0.03 - ETA: 61s - loss: 4.8105 - acc: 0.03 - ETA: 61s - loss: 4.8122 - acc: 0.03 - ETA: 60s - loss: 4.8090 - acc: 0.03 - ETA: 60s - loss: 4.8085 - acc: 0.03 - ETA: 60s - loss: 4.8108 - acc: 0.03 - ETA: 60s - loss: 4.8093 - acc: 0.03 - ETA: 60s - loss: 4.8087 - acc: 0.03 - ETA: 59s - loss: 4.8108 - acc: 0.03 - ETA: 59s - loss: 4.8105 - acc: 0.03 - ETA: 59s - loss: 4.8100 - acc: 0.03 - ETA: 59s - loss: 4.8106 - acc: 0.03 - ETA: 59s - loss: 4.8129 - acc: 0.03 - ETA: 58s - loss: 4.8135 - acc: 0.03 - ETA: 58s - loss: 4.8145 - acc: 0.03 - ETA: 58s - loss: 4.8144 - acc: 0.03 - ETA: 58s - loss: 4.8125 - acc: 0.03 - ETA: 58s - loss: 4.8148 - acc: 0.02 - ETA: 57s - loss: 4.8135 - acc: 0.02 - ETA: 57s - loss: 4.8148 - acc: 0.02 - ETA: 57s - loss: 4.8144 - acc: 0.02 - ETA: 57s - loss: 4.8150 - acc: 0.02 - ETA: 56s - loss: 4.8154 - acc: 0.02 - ETA: 56s - loss: 4.8173 - acc: 0.02 - ETA: 56s - loss: 4.8175 - acc: 0.02 - ETA: 56s - loss: 4.8180 - acc: 0.02 - ETA: 56s - loss: 4.8177 - acc: 0.02 - ETA: 56s - loss: 4.8175 - acc: 0.02 - ETA: 55s - loss: 4.8166 - acc: 0.02 - ETA: 55s - loss: 4.8171 - acc: 0.02 - ETA: 55s - loss: 4.8173 - acc: 0.02 - ETA: 55s - loss: 4.8166 - acc: 0.02 - ETA: 54s - loss: 4.8181 - acc: 0.02 - ETA: 54s - loss: 4.8192 - acc: 0.02 - ETA: 54s - loss: 4.8179 - acc: 0.02 - ETA: 54s - loss: 4.8175 - acc: 0.02 - ETA: 54s - loss: 4.8185 - acc: 0.02 - ETA: 53s - loss: 4.8192 - acc: 0.02 - ETA: 53s - loss: 4.8197 - acc: 0.02 - ETA: 53s - loss: 4.8196 - acc: 0.02 - ETA: 53s - loss: 4.8205 - acc: 0.02 - ETA: 53s - loss: 4.8197 - acc: 0.02 - ETA: 52s - loss: 4.8208 - acc: 0.02 - ETA: 52s - loss: 4.8225 - acc: 0.02 - ETA: 52s - loss: 4.8236 - acc: 0.02 - ETA: 52s - loss: 4.8245 - acc: 0.02 - ETA: 52s - loss: 4.8252 - acc: 0.02 - ETA: 51s - loss: 4.8258 - acc: 0.02 - ETA: 51s - loss: 4.8264 - acc: 0.02 - ETA: 51s - loss: 4.8271 - acc: 0.02 - ETA: 51s - loss: 4.8274 - acc: 0.02 - ETA: 50s - loss: 4.8281 - acc: 0.02 - ETA: 50s - loss: 4.8281 - acc: 0.02 - ETA: 50s - loss: 4.8289 - acc: 0.02 - ETA: 50s - loss: 4.8296 - acc: 0.02 - ETA: 50s - loss: 4.8300 - acc: 0.02 - ETA: 49s - loss: 4.8302 - acc: 0.02 - ETA: 49s - loss: 4.8300 - acc: 0.02 - ETA: 49s - loss: 4.8302 - acc: 0.02 - ETA: 49s - loss: 4.8302 - acc: 0.02 - ETA: 49s - loss: 4.8299 - acc: 0.02 - ETA: 48s - loss: 4.8299 - acc: 0.02 - ETA: 48s - loss: 4.8291 - acc: 0.02 - ETA: 48s - loss: 4.8289 - acc: 0.02 - ETA: 48s - loss: 4.8287 - acc: 0.02 - ETA: 48s - loss: 4.8292 - acc: 0.02 - ETA: 47s - loss: 4.8294 - acc: 0.02 - ETA: 47s - loss: 4.8299 - acc: 0.02 - ETA: 47s - loss: 4.8306 - acc: 0.02 - ETA: 47s - loss: 4.8306 - acc: 0.02 - ETA: 47s - loss: 4.8312 - acc: 0.02 - ETA: 46s - loss: 4.8311 - acc: 0.02 - ETA: 46s - loss: 4.8310 - acc: 0.01 - ETA: 46s - loss: 4.8306 - acc: 0.02 - ETA: 46s - loss: 4.8299 - acc: 0.02 - ETA: 46s - loss: 4.8298 - acc: 0.02 - ETA: 45s - loss: 4.8302 - acc: 0.02 - ETA: 45s - loss: 4.8291 - acc: 0.01 - ETA: 45s - loss: 4.8291 - acc: 0.01 - ETA: 45s - loss: 4.8291 - acc: 0.01 - ETA: 44s - loss: 4.8292 - acc: 0.01 - ETA: 44s - loss: 4.8281 - acc: 0.02 - ETA: 44s - loss: 4.8290 - acc: 0.01 - ETA: 44s - loss: 4.8290 - acc: 0.01 - ETA: 44s - loss: 4.8287 - acc: 0.01 - ETA: 43s - loss: 4.8289 - acc: 0.01 - ETA: 43s - loss: 4.8281 - acc: 0.01 - ETA: 43s - loss: 4.8299 - acc: 0.01 - ETA: 43s - loss: 4.8291 - acc: 0.01 - ETA: 43s - loss: 4.8282 - acc: 0.01 - ETA: 42s - loss: 4.8282 - acc: 0.01 - ETA: 42s - loss: 4.8269 - acc: 0.01 - ETA: 42s - loss: 4.8278 - acc: 0.01 - ETA: 42s - loss: 4.8271 - acc: 0.01 - ETA: 42s - loss: 4.8282 - acc: 0.01 - ETA: 41s - loss: 4.8277 - acc: 0.01 - ETA: 41s - loss: 4.8280 - acc: 0.01 - ETA: 41s - loss: 4.8279 - acc: 0.01 - ETA: 41s - loss: 4.8281 - acc: 0.01 - ETA: 41s - loss: 4.8275 - acc: 0.01 - ETA: 40s - loss: 4.8278 - acc: 0.01 - ETA: 40s - loss: 4.8280 - acc: 0.01 - ETA: 40s - loss: 4.8280 - acc: 0.01 - ETA: 40s - loss: 4.8273 - acc: 0.01 - ETA: 39s - loss: 4.8284 - acc: 0.01 - ETA: 39s - loss: 4.8286 - acc: 0.01 - ETA: 39s - loss: 4.8289 - acc: 0.01 - ETA: 39s - loss: 4.8288 - acc: 0.01 - ETA: 39s - loss: 4.8289 - acc: 0.01 - ETA: 38s - loss: 4.8288 - acc: 0.01 - ETA: 38s - loss: 4.8279 - acc: 0.01 - ETA: 38s - loss: 4.8289 - acc: 0.01 - ETA: 38s - loss: 4.8293 - acc: 0.01 - ETA: 38s - loss: 4.8297 - acc: 0.01 - ETA: 37s - loss: 4.8296 - acc: 0.01 - ETA: 37s - loss: 4.8297 - acc: 0.01 - ETA: 37s - loss: 4.8308 - acc: 0.01 - ETA: 37s - loss: 4.8313 - acc: 0.01 - ETA: 37s - loss: 4.8315 - acc: 0.01 - ETA: 36s - loss: 4.8317 - acc: 0.01 - ETA: 36s - loss: 4.8317 - acc: 0.01 - ETA: 36s - loss: 4.8319 - acc: 0.01 - ETA: 36s - loss: 4.8321 - acc: 0.01 - ETA: 35s - loss: 4.8325 - acc: 0.01 - ETA: 35s - loss: 4.8327 - acc: 0.01 - ETA: 35s - loss: 4.8322 - acc: 0.01 - ETA: 35s - loss: 4.8322 - acc: 0.01 - ETA: 35s - loss: 4.8317 - acc: 0.01 - ETA: 34s - loss: 4.8319 - acc: 0.01 - ETA: 34s - loss: 4.8320 - acc: 0.01 - ETA: 34s - loss: 4.8319 - acc: 0.01 - ETA: 34s - loss: 4.8316 - acc: 0.01 - ETA: 34s - loss: 4.8318 - acc: 0.01 - ETA: 33s - loss: 4.8310 - acc: 0.01 - ETA: 33s - loss: 4.8318 - acc: 0.01 - ETA: 33s - loss: 4.8321 - acc: 0.01 - ETA: 33s - loss: 4.8324 - acc: 0.01 - ETA: 33s - loss: 4.8327 - acc: 0.01 - ETA: 32s - loss: 4.8326 - acc: 0.01 - ETA: 32s - loss: 4.8332 - acc: 0.01 - ETA: 32s - loss: 4.8336 - acc: 0.01 - ETA: 32s - loss: 4.8333 - acc: 0.01 - ETA: 32s - loss: 4.8325 - acc: 0.01 - ETA: 31s - loss: 4.8324 - acc: 0.01 - ETA: 31s - loss: 4.8333 - acc: 0.01 - ETA: 31s - loss: 4.8336 - acc: 0.01 - ETA: 31s - loss: 4.8334 - acc: 0.01 - ETA: 30s - loss: 4.8333 - acc: 0.01 - ETA: 30s - loss: 4.8333 - acc: 0.01 - ETA: 30s - loss: 4.8339 - acc: 0.01 - ETA: 30s - loss: 4.8349 - acc: 0.01 - ETA: 30s - loss: 4.8348 - acc: 0.01 - ETA: 29s - loss: 4.8346 - acc: 0.01 - ETA: 29s - loss: 4.8347 - acc: 0.01 - ETA: 29s - loss: 4.8344 - acc: 0.01 - ETA: 29s - loss: 4.8346 - acc: 0.01 - ETA: 29s - loss: 4.8348 - acc: 0.01 - ETA: 28s - loss: 4.8352 - acc: 0.01 - ETA: 28s - loss: 4.8350 - acc: 0.01 - ETA: 28s - loss: 4.8349 - acc: 0.01 - ETA: 28s - loss: 4.8347 - acc: 0.01 - ETA: 28s - loss: 4.8345 - acc: 0.01 - ETA: 27s - loss: 4.8343 - acc: 0.01 - ETA: 27s - loss: 4.8342 - acc: 0.01 - ETA: 27s - loss: 4.8346 - acc: 0.01 - ETA: 27s - loss: 4.8345 - acc: 0.01 - ETA: 27s - loss: 4.8353 - acc: 0.01 - ETA: 26s - loss: 4.8354 - acc: 0.01 - ETA: 26s - loss: 4.8353 - acc: 0.01 - ETA: 26s - loss: 4.8358 - acc: 0.01 - ETA: 26s - loss: 4.8356 - acc: 0.01 - ETA: 25s - loss: 4.8353 - acc: 0.01 - ETA: 25s - loss: 4.8351 - acc: 0.01 - ETA: 25s - loss: 4.8354 - acc: 0.01 - ETA: 25s - loss: 4.8355 - acc: 0.01 - ETA: 25s - loss: 4.8351 - acc: 0.01 - ETA: 24s - loss: 4.8350 - acc: 0.0184"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6660/6680 [============================>.] - ETA: 24s - loss: 4.8345 - acc: 0.01 - ETA: 24s - loss: 4.8340 - acc: 0.01 - ETA: 24s - loss: 4.8337 - acc: 0.01 - ETA: 24s - loss: 4.8335 - acc: 0.01 - ETA: 23s - loss: 4.8330 - acc: 0.01 - ETA: 23s - loss: 4.8331 - acc: 0.01 - ETA: 23s - loss: 4.8334 - acc: 0.01 - ETA: 23s - loss: 4.8335 - acc: 0.01 - ETA: 23s - loss: 4.8330 - acc: 0.01 - ETA: 22s - loss: 4.8337 - acc: 0.01 - ETA: 22s - loss: 4.8331 - acc: 0.01 - ETA: 22s - loss: 4.8331 - acc: 0.01 - ETA: 22s - loss: 4.8326 - acc: 0.01 - ETA: 21s - loss: 4.8321 - acc: 0.01 - ETA: 21s - loss: 4.8319 - acc: 0.01 - ETA: 21s - loss: 4.8324 - acc: 0.01 - ETA: 21s - loss: 4.8323 - acc: 0.01 - ETA: 21s - loss: 4.8319 - acc: 0.01 - ETA: 20s - loss: 4.8312 - acc: 0.01 - ETA: 20s - loss: 4.8310 - acc: 0.01 - ETA: 20s - loss: 4.8311 - acc: 0.01 - ETA: 20s - loss: 4.8312 - acc: 0.01 - ETA: 20s - loss: 4.8312 - acc: 0.01 - ETA: 19s - loss: 4.8311 - acc: 0.01 - ETA: 19s - loss: 4.8305 - acc: 0.01 - ETA: 19s - loss: 4.8301 - acc: 0.01 - ETA: 19s - loss: 4.8303 - acc: 0.01 - ETA: 19s - loss: 4.8307 - acc: 0.01 - ETA: 18s - loss: 4.8315 - acc: 0.01 - ETA: 18s - loss: 4.8313 - acc: 0.01 - ETA: 18s - loss: 4.8307 - acc: 0.01 - ETA: 18s - loss: 4.8308 - acc: 0.01 - ETA: 18s - loss: 4.8308 - acc: 0.01 - ETA: 17s - loss: 4.8305 - acc: 0.01 - ETA: 17s - loss: 4.8301 - acc: 0.01 - ETA: 17s - loss: 4.8297 - acc: 0.01 - ETA: 17s - loss: 4.8295 - acc: 0.01 - ETA: 16s - loss: 4.8297 - acc: 0.01 - ETA: 16s - loss: 4.8297 - acc: 0.01 - ETA: 16s - loss: 4.8294 - acc: 0.01 - ETA: 16s - loss: 4.8293 - acc: 0.01 - ETA: 16s - loss: 4.8288 - acc: 0.01 - ETA: 15s - loss: 4.8292 - acc: 0.01 - ETA: 15s - loss: 4.8295 - acc: 0.01 - ETA: 15s - loss: 4.8294 - acc: 0.01 - ETA: 15s - loss: 4.8294 - acc: 0.01 - ETA: 15s - loss: 4.8289 - acc: 0.01 - ETA: 14s - loss: 4.8289 - acc: 0.01 - ETA: 14s - loss: 4.8286 - acc: 0.01 - ETA: 14s - loss: 4.8289 - acc: 0.01 - ETA: 14s - loss: 4.8287 - acc: 0.01 - ETA: 14s - loss: 4.8289 - acc: 0.01 - ETA: 13s - loss: 4.8282 - acc: 0.01 - ETA: 13s - loss: 4.8280 - acc: 0.01 - ETA: 13s - loss: 4.8277 - acc: 0.01 - ETA: 13s - loss: 4.8277 - acc: 0.01 - ETA: 12s - loss: 4.8278 - acc: 0.01 - ETA: 12s - loss: 4.8278 - acc: 0.01 - ETA: 12s - loss: 4.8278 - acc: 0.01 - ETA: 12s - loss: 4.8277 - acc: 0.01 - ETA: 12s - loss: 4.8275 - acc: 0.01 - ETA: 11s - loss: 4.8271 - acc: 0.01 - ETA: 11s - loss: 4.8268 - acc: 0.01 - ETA: 11s - loss: 4.8263 - acc: 0.01 - ETA: 11s - loss: 4.8268 - acc: 0.01 - ETA: 11s - loss: 4.8268 - acc: 0.01 - ETA: 10s - loss: 4.8262 - acc: 0.01 - ETA: 10s - loss: 4.8266 - acc: 0.01 - ETA: 10s - loss: 4.8264 - acc: 0.01 - ETA: 10s - loss: 4.8265 - acc: 0.01 - ETA: 10s - loss: 4.8262 - acc: 0.01 - ETA: 9s - loss: 4.8262 - acc: 0.0174 - ETA: 9s - loss: 4.8260 - acc: 0.017 - ETA: 9s - loss: 4.8260 - acc: 0.017 - ETA: 9s - loss: 4.8255 - acc: 0.017 - ETA: 9s - loss: 4.8255 - acc: 0.017 - ETA: 8s - loss: 4.8256 - acc: 0.017 - ETA: 8s - loss: 4.8254 - acc: 0.017 - ETA: 8s - loss: 4.8255 - acc: 0.017 - ETA: 8s - loss: 4.8256 - acc: 0.017 - ETA: 7s - loss: 4.8252 - acc: 0.017 - ETA: 7s - loss: 4.8256 - acc: 0.017 - ETA: 7s - loss: 4.8255 - acc: 0.017 - ETA: 7s - loss: 4.8255 - acc: 0.017 - ETA: 7s - loss: 4.8253 - acc: 0.017 - ETA: 6s - loss: 4.8251 - acc: 0.016 - ETA: 6s - loss: 4.8254 - acc: 0.016 - ETA: 6s - loss: 4.8255 - acc: 0.017 - ETA: 6s - loss: 4.8253 - acc: 0.016 - ETA: 6s - loss: 4.8254 - acc: 0.016 - ETA: 5s - loss: 4.8252 - acc: 0.016 - ETA: 5s - loss: 4.8252 - acc: 0.017 - ETA: 5s - loss: 4.8253 - acc: 0.017 - ETA: 5s - loss: 4.8257 - acc: 0.017 - ETA: 5s - loss: 4.8259 - acc: 0.017 - ETA: 4s - loss: 4.8253 - acc: 0.017 - ETA: 4s - loss: 4.8256 - acc: 0.017 - ETA: 4s - loss: 4.8254 - acc: 0.017 - ETA: 4s - loss: 4.8248 - acc: 0.017 - ETA: 3s - loss: 4.8250 - acc: 0.017 - ETA: 3s - loss: 4.8254 - acc: 0.017 - ETA: 3s - loss: 4.8253 - acc: 0.017 - ETA: 3s - loss: 4.8257 - acc: 0.017 - ETA: 3s - loss: 4.8253 - acc: 0.017 - ETA: 2s - loss: 4.8253 - acc: 0.017 - ETA: 2s - loss: 4.8249 - acc: 0.017 - ETA: 2s - loss: 4.8251 - acc: 0.017 - ETA: 2s - loss: 4.8250 - acc: 0.017 - ETA: 2s - loss: 4.8251 - acc: 0.017 - ETA: 1s - loss: 4.8253 - acc: 0.017 - ETA: 1s - loss: 4.8250 - acc: 0.017 - ETA: 1s - loss: 4.8251 - acc: 0.017 - ETA: 1s - loss: 4.8253 - acc: 0.017 - ETA: 1s - loss: 4.8255 - acc: 0.017 - ETA: 0s - loss: 4.8255 - acc: 0.017 - ETA: 0s - loss: 4.8254 - acc: 0.017 - ETA: 0s - loss: 4.8250 - acc: 0.017 - ETA: 0s - loss: 4.8253 - acc: 0.0174Epoch 00003: val_loss improved from 4.84675 to 4.80026, saving model to saved_models/weights.best.from_scratch.hdf5\n",
      "6680/6680 [==============================] - 72s - loss: 4.8252 - acc: 0.0174 - val_loss: 4.8003 - val_acc: 0.0204\n",
      "Epoch 5/32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4300/6680 [==================>...........] - ETA: 67s - loss: 4.8948 - acc: 0.0000e+ - ETA: 68s - loss: 4.8448 - acc: 0.0000e+ - ETA: 69s - loss: 4.7863 - acc: 0.0167   - ETA: 68s - loss: 4.7664 - acc: 0.03 - ETA: 68s - loss: 4.7967 - acc: 0.03 - ETA: 68s - loss: 4.8111 - acc: 0.02 - ETA: 67s - loss: 4.8115 - acc: 0.02 - ETA: 68s - loss: 4.7800 - acc: 0.02 - ETA: 67s - loss: 4.7683 - acc: 0.02 - ETA: 67s - loss: 4.7665 - acc: 0.02 - ETA: 67s - loss: 4.7803 - acc: 0.02 - ETA: 67s - loss: 4.7736 - acc: 0.02 - ETA: 67s - loss: 4.7738 - acc: 0.02 - ETA: 67s - loss: 4.7693 - acc: 0.02 - ETA: 66s - loss: 4.7663 - acc: 0.03 - ETA: 66s - loss: 4.7525 - acc: 0.02 - ETA: 66s - loss: 4.7492 - acc: 0.02 - ETA: 66s - loss: 4.7577 - acc: 0.02 - ETA: 65s - loss: 4.7587 - acc: 0.02 - ETA: 65s - loss: 4.7637 - acc: 0.02 - ETA: 65s - loss: 4.7677 - acc: 0.02 - ETA: 65s - loss: 4.7743 - acc: 0.02 - ETA: 65s - loss: 4.7717 - acc: 0.02 - ETA: 64s - loss: 4.7715 - acc: 0.02 - ETA: 64s - loss: 4.7754 - acc: 0.02 - ETA: 64s - loss: 4.7722 - acc: 0.02 - ETA: 64s - loss: 4.7722 - acc: 0.02 - ETA: 64s - loss: 4.7711 - acc: 0.02 - ETA: 63s - loss: 4.7726 - acc: 0.02 - ETA: 63s - loss: 4.7723 - acc: 0.02 - ETA: 63s - loss: 4.7751 - acc: 0.02 - ETA: 63s - loss: 4.7771 - acc: 0.02 - ETA: 62s - loss: 4.7820 - acc: 0.02 - ETA: 62s - loss: 4.7799 - acc: 0.02 - ETA: 62s - loss: 4.7782 - acc: 0.02 - ETA: 62s - loss: 4.7795 - acc: 0.02 - ETA: 62s - loss: 4.7823 - acc: 0.02 - ETA: 61s - loss: 4.7842 - acc: 0.02 - ETA: 61s - loss: 4.7848 - acc: 0.02 - ETA: 61s - loss: 4.7792 - acc: 0.02 - ETA: 61s - loss: 4.7852 - acc: 0.02 - ETA: 61s - loss: 4.7864 - acc: 0.02 - ETA: 60s - loss: 4.7871 - acc: 0.02 - ETA: 60s - loss: 4.7886 - acc: 0.02 - ETA: 60s - loss: 4.7880 - acc: 0.02 - ETA: 60s - loss: 4.7870 - acc: 0.02 - ETA: 60s - loss: 4.7855 - acc: 0.02 - ETA: 59s - loss: 4.7816 - acc: 0.02 - ETA: 59s - loss: 4.7809 - acc: 0.02 - ETA: 59s - loss: 4.7838 - acc: 0.02 - ETA: 59s - loss: 4.7824 - acc: 0.02 - ETA: 59s - loss: 4.7839 - acc: 0.02 - ETA: 58s - loss: 4.7858 - acc: 0.02 - ETA: 58s - loss: 4.7866 - acc: 0.02 - ETA: 58s - loss: 4.7880 - acc: 0.02 - ETA: 58s - loss: 4.7884 - acc: 0.02 - ETA: 58s - loss: 4.7886 - acc: 0.02 - ETA: 57s - loss: 4.7899 - acc: 0.02 - ETA: 57s - loss: 4.7931 - acc: 0.02 - ETA: 57s - loss: 4.7916 - acc: 0.02 - ETA: 57s - loss: 4.7907 - acc: 0.02 - ETA: 56s - loss: 4.7940 - acc: 0.02 - ETA: 56s - loss: 4.7938 - acc: 0.01 - ETA: 56s - loss: 4.7951 - acc: 0.02 - ETA: 56s - loss: 4.7958 - acc: 0.02 - ETA: 56s - loss: 4.7955 - acc: 0.01 - ETA: 55s - loss: 4.7931 - acc: 0.01 - ETA: 55s - loss: 4.7927 - acc: 0.01 - ETA: 55s - loss: 4.7917 - acc: 0.02 - ETA: 55s - loss: 4.7931 - acc: 0.02 - ETA: 55s - loss: 4.7927 - acc: 0.02 - ETA: 54s - loss: 4.7926 - acc: 0.02 - ETA: 54s - loss: 4.7921 - acc: 0.02 - ETA: 54s - loss: 4.7919 - acc: 0.02 - ETA: 54s - loss: 4.7936 - acc: 0.02 - ETA: 54s - loss: 4.7933 - acc: 0.01 - ETA: 53s - loss: 4.7943 - acc: 0.01 - ETA: 53s - loss: 4.7914 - acc: 0.01 - ETA: 53s - loss: 4.7899 - acc: 0.02 - ETA: 53s - loss: 4.7897 - acc: 0.02 - ETA: 52s - loss: 4.7891 - acc: 0.02 - ETA: 52s - loss: 4.7885 - acc: 0.02 - ETA: 52s - loss: 4.7875 - acc: 0.01 - ETA: 52s - loss: 4.7904 - acc: 0.01 - ETA: 52s - loss: 4.7895 - acc: 0.02 - ETA: 51s - loss: 4.7897 - acc: 0.01 - ETA: 51s - loss: 4.7907 - acc: 0.01 - ETA: 51s - loss: 4.7905 - acc: 0.01 - ETA: 51s - loss: 4.7912 - acc: 0.01 - ETA: 51s - loss: 4.7901 - acc: 0.02 - ETA: 50s - loss: 4.7938 - acc: 0.01 - ETA: 50s - loss: 4.7928 - acc: 0.01 - ETA: 50s - loss: 4.7919 - acc: 0.01 - ETA: 50s - loss: 4.7920 - acc: 0.01 - ETA: 50s - loss: 4.7917 - acc: 0.02 - ETA: 49s - loss: 4.7932 - acc: 0.01 - ETA: 49s - loss: 4.7943 - acc: 0.01 - ETA: 49s - loss: 4.7946 - acc: 0.01 - ETA: 49s - loss: 4.7950 - acc: 0.01 - ETA: 48s - loss: 4.7954 - acc: 0.02 - ETA: 48s - loss: 4.7949 - acc: 0.01 - ETA: 48s - loss: 4.7938 - acc: 0.02 - ETA: 48s - loss: 4.7932 - acc: 0.02 - ETA: 48s - loss: 4.7939 - acc: 0.02 - ETA: 47s - loss: 4.7947 - acc: 0.02 - ETA: 47s - loss: 4.7942 - acc: 0.02 - ETA: 47s - loss: 4.7931 - acc: 0.02 - ETA: 47s - loss: 4.7925 - acc: 0.02 - ETA: 47s - loss: 4.7933 - acc: 0.02 - ETA: 46s - loss: 4.7941 - acc: 0.02 - ETA: 46s - loss: 4.7941 - acc: 0.02 - ETA: 46s - loss: 4.7938 - acc: 0.02 - ETA: 46s - loss: 4.7948 - acc: 0.02 - ETA: 46s - loss: 4.7946 - acc: 0.02 - ETA: 45s - loss: 4.7940 - acc: 0.02 - ETA: 45s - loss: 4.7946 - acc: 0.02 - ETA: 45s - loss: 4.7946 - acc: 0.02 - ETA: 45s - loss: 4.7946 - acc: 0.01 - ETA: 45s - loss: 4.7950 - acc: 0.01 - ETA: 44s - loss: 4.7940 - acc: 0.01 - ETA: 44s - loss: 4.7950 - acc: 0.01 - ETA: 44s - loss: 4.7934 - acc: 0.01 - ETA: 44s - loss: 4.7927 - acc: 0.01 - ETA: 44s - loss: 4.7923 - acc: 0.01 - ETA: 43s - loss: 4.7933 - acc: 0.01 - ETA: 43s - loss: 4.7936 - acc: 0.01 - ETA: 43s - loss: 4.7947 - acc: 0.01 - ETA: 43s - loss: 4.7948 - acc: 0.01 - ETA: 42s - loss: 4.7944 - acc: 0.01 - ETA: 42s - loss: 4.7944 - acc: 0.01 - ETA: 42s - loss: 4.7940 - acc: 0.01 - ETA: 42s - loss: 4.7946 - acc: 0.01 - ETA: 42s - loss: 4.7940 - acc: 0.01 - ETA: 41s - loss: 4.7940 - acc: 0.01 - ETA: 41s - loss: 4.7937 - acc: 0.01 - ETA: 41s - loss: 4.7941 - acc: 0.01 - ETA: 41s - loss: 4.7947 - acc: 0.01 - ETA: 41s - loss: 4.7948 - acc: 0.01 - ETA: 40s - loss: 4.7958 - acc: 0.01 - ETA: 40s - loss: 4.7949 - acc: 0.01 - ETA: 40s - loss: 4.7960 - acc: 0.01 - ETA: 40s - loss: 4.7965 - acc: 0.01 - ETA: 40s - loss: 4.7955 - acc: 0.01 - ETA: 39s - loss: 4.7950 - acc: 0.01 - ETA: 39s - loss: 4.7939 - acc: 0.01 - ETA: 39s - loss: 4.7922 - acc: 0.01 - ETA: 39s - loss: 4.7918 - acc: 0.01 - ETA: 38s - loss: 4.7916 - acc: 0.01 - ETA: 38s - loss: 4.7936 - acc: 0.01 - ETA: 38s - loss: 4.7930 - acc: 0.01 - ETA: 38s - loss: 4.7943 - acc: 0.01 - ETA: 38s - loss: 4.7938 - acc: 0.01 - ETA: 37s - loss: 4.7933 - acc: 0.01 - ETA: 37s - loss: 4.7930 - acc: 0.01 - ETA: 37s - loss: 4.7923 - acc: 0.02 - ETA: 37s - loss: 4.7919 - acc: 0.01 - ETA: 37s - loss: 4.7912 - acc: 0.01 - ETA: 36s - loss: 4.7919 - acc: 0.01 - ETA: 36s - loss: 4.7925 - acc: 0.01 - ETA: 36s - loss: 4.7914 - acc: 0.02 - ETA: 36s - loss: 4.7902 - acc: 0.02 - ETA: 36s - loss: 4.7894 - acc: 0.02 - ETA: 35s - loss: 4.7898 - acc: 0.02 - ETA: 35s - loss: 4.7889 - acc: 0.02 - ETA: 35s - loss: 4.7903 - acc: 0.02 - ETA: 35s - loss: 4.7915 - acc: 0.02 - ETA: 35s - loss: 4.7918 - acc: 0.02 - ETA: 34s - loss: 4.7922 - acc: 0.02 - ETA: 34s - loss: 4.7916 - acc: 0.02 - ETA: 34s - loss: 4.7900 - acc: 0.02 - ETA: 34s - loss: 4.7909 - acc: 0.01 - ETA: 33s - loss: 4.7915 - acc: 0.01 - ETA: 33s - loss: 4.7908 - acc: 0.01 - ETA: 33s - loss: 4.7892 - acc: 0.02 - ETA: 33s - loss: 4.7886 - acc: 0.02 - ETA: 33s - loss: 4.7891 - acc: 0.02 - ETA: 32s - loss: 4.7890 - acc: 0.02 - ETA: 32s - loss: 4.7884 - acc: 0.02 - ETA: 32s - loss: 4.7884 - acc: 0.02 - ETA: 32s - loss: 4.7892 - acc: 0.02 - ETA: 32s - loss: 4.7900 - acc: 0.02 - ETA: 31s - loss: 4.7901 - acc: 0.02 - ETA: 31s - loss: 4.7902 - acc: 0.02 - ETA: 31s - loss: 4.7894 - acc: 0.02 - ETA: 31s - loss: 4.7906 - acc: 0.02 - ETA: 31s - loss: 4.7906 - acc: 0.02 - ETA: 30s - loss: 4.7912 - acc: 0.02 - ETA: 30s - loss: 4.7910 - acc: 0.01 - ETA: 30s - loss: 4.7910 - acc: 0.01 - ETA: 30s - loss: 4.7913 - acc: 0.01 - ETA: 29s - loss: 4.7906 - acc: 0.01 - ETA: 29s - loss: 4.7900 - acc: 0.01 - ETA: 29s - loss: 4.7896 - acc: 0.01 - ETA: 29s - loss: 4.7901 - acc: 0.01 - ETA: 29s - loss: 4.7900 - acc: 0.01 - ETA: 28s - loss: 4.7897 - acc: 0.01 - ETA: 28s - loss: 4.7885 - acc: 0.01 - ETA: 28s - loss: 4.7893 - acc: 0.01 - ETA: 28s - loss: 4.7888 - acc: 0.01 - ETA: 28s - loss: 4.7888 - acc: 0.01 - ETA: 27s - loss: 4.7890 - acc: 0.01 - ETA: 27s - loss: 4.7901 - acc: 0.01 - ETA: 27s - loss: 4.7892 - acc: 0.01 - ETA: 27s - loss: 4.7893 - acc: 0.01 - ETA: 27s - loss: 4.7899 - acc: 0.01 - ETA: 26s - loss: 4.7902 - acc: 0.01 - ETA: 26s - loss: 4.7906 - acc: 0.01 - ETA: 26s - loss: 4.7906 - acc: 0.01 - ETA: 26s - loss: 4.7902 - acc: 0.01 - ETA: 25s - loss: 4.7906 - acc: 0.01 - ETA: 25s - loss: 4.7907 - acc: 0.01 - ETA: 25s - loss: 4.7897 - acc: 0.01 - ETA: 25s - loss: 4.7901 - acc: 0.01 - ETA: 25s - loss: 4.7900 - acc: 0.01 - ETA: 24s - loss: 4.7902 - acc: 0.0191"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6660/6680 [============================>.] - ETA: 24s - loss: 4.7899 - acc: 0.01 - ETA: 24s - loss: 4.7895 - acc: 0.01 - ETA: 24s - loss: 4.7878 - acc: 0.01 - ETA: 24s - loss: 4.7886 - acc: 0.01 - ETA: 23s - loss: 4.7888 - acc: 0.01 - ETA: 23s - loss: 4.7890 - acc: 0.01 - ETA: 23s - loss: 4.7889 - acc: 0.01 - ETA: 23s - loss: 4.7885 - acc: 0.01 - ETA: 23s - loss: 4.7887 - acc: 0.01 - ETA: 22s - loss: 4.7887 - acc: 0.01 - ETA: 22s - loss: 4.7887 - acc: 0.01 - ETA: 22s - loss: 4.7897 - acc: 0.01 - ETA: 22s - loss: 4.7898 - acc: 0.01 - ETA: 22s - loss: 4.7899 - acc: 0.01 - ETA: 21s - loss: 4.7894 - acc: 0.01 - ETA: 21s - loss: 4.7890 - acc: 0.01 - ETA: 21s - loss: 4.7886 - acc: 0.01 - ETA: 21s - loss: 4.7892 - acc: 0.01 - ETA: 20s - loss: 4.7890 - acc: 0.01 - ETA: 20s - loss: 4.7887 - acc: 0.01 - ETA: 20s - loss: 4.7897 - acc: 0.01 - ETA: 20s - loss: 4.7901 - acc: 0.01 - ETA: 20s - loss: 4.7902 - acc: 0.01 - ETA: 19s - loss: 4.7897 - acc: 0.01 - ETA: 19s - loss: 4.7898 - acc: 0.01 - ETA: 19s - loss: 4.7890 - acc: 0.01 - ETA: 19s - loss: 4.7887 - acc: 0.01 - ETA: 19s - loss: 4.7879 - acc: 0.01 - ETA: 18s - loss: 4.7883 - acc: 0.01 - ETA: 18s - loss: 4.7881 - acc: 0.01 - ETA: 18s - loss: 4.7874 - acc: 0.01 - ETA: 18s - loss: 4.7869 - acc: 0.01 - ETA: 18s - loss: 4.7869 - acc: 0.01 - ETA: 17s - loss: 4.7871 - acc: 0.01 - ETA: 17s - loss: 4.7875 - acc: 0.01 - ETA: 17s - loss: 4.7870 - acc: 0.01 - ETA: 17s - loss: 4.7870 - acc: 0.01 - ETA: 16s - loss: 4.7868 - acc: 0.01 - ETA: 16s - loss: 4.7865 - acc: 0.01 - ETA: 16s - loss: 4.7867 - acc: 0.01 - ETA: 16s - loss: 4.7862 - acc: 0.01 - ETA: 16s - loss: 4.7867 - acc: 0.01 - ETA: 15s - loss: 4.7860 - acc: 0.01 - ETA: 15s - loss: 4.7865 - acc: 0.01 - ETA: 15s - loss: 4.7862 - acc: 0.01 - ETA: 15s - loss: 4.7861 - acc: 0.01 - ETA: 15s - loss: 4.7864 - acc: 0.01 - ETA: 14s - loss: 4.7864 - acc: 0.01 - ETA: 14s - loss: 4.7859 - acc: 0.01 - ETA: 14s - loss: 4.7857 - acc: 0.01 - ETA: 14s - loss: 4.7857 - acc: 0.01 - ETA: 14s - loss: 4.7856 - acc: 0.01 - ETA: 13s - loss: 4.7859 - acc: 0.01 - ETA: 13s - loss: 4.7861 - acc: 0.01 - ETA: 13s - loss: 4.7853 - acc: 0.01 - ETA: 13s - loss: 4.7851 - acc: 0.01 - ETA: 13s - loss: 4.7853 - acc: 0.01 - ETA: 12s - loss: 4.7856 - acc: 0.01 - ETA: 12s - loss: 4.7851 - acc: 0.01 - ETA: 12s - loss: 4.7851 - acc: 0.01 - ETA: 12s - loss: 4.7846 - acc: 0.01 - ETA: 11s - loss: 4.7854 - acc: 0.01 - ETA: 11s - loss: 4.7854 - acc: 0.01 - ETA: 11s - loss: 4.7852 - acc: 0.01 - ETA: 11s - loss: 4.7853 - acc: 0.01 - ETA: 11s - loss: 4.7857 - acc: 0.01 - ETA: 10s - loss: 4.7853 - acc: 0.01 - ETA: 10s - loss: 4.7850 - acc: 0.01 - ETA: 10s - loss: 4.7856 - acc: 0.01 - ETA: 10s - loss: 4.7855 - acc: 0.01 - ETA: 10s - loss: 4.7858 - acc: 0.01 - ETA: 9s - loss: 4.7860 - acc: 0.0179 - ETA: 9s - loss: 4.7862 - acc: 0.017 - ETA: 9s - loss: 4.7863 - acc: 0.017 - ETA: 9s - loss: 4.7864 - acc: 0.017 - ETA: 9s - loss: 4.7868 - acc: 0.018 - ETA: 8s - loss: 4.7868 - acc: 0.018 - ETA: 8s - loss: 4.7870 - acc: 0.017 - ETA: 8s - loss: 4.7868 - acc: 0.018 - ETA: 8s - loss: 4.7867 - acc: 0.018 - ETA: 7s - loss: 4.7868 - acc: 0.017 - ETA: 7s - loss: 4.7869 - acc: 0.017 - ETA: 7s - loss: 4.7863 - acc: 0.018 - ETA: 7s - loss: 4.7862 - acc: 0.017 - ETA: 7s - loss: 4.7864 - acc: 0.017 - ETA: 6s - loss: 4.7860 - acc: 0.017 - ETA: 6s - loss: 4.7853 - acc: 0.017 - ETA: 6s - loss: 4.7853 - acc: 0.017 - ETA: 6s - loss: 4.7847 - acc: 0.017 - ETA: 6s - loss: 4.7844 - acc: 0.017 - ETA: 5s - loss: 4.7849 - acc: 0.017 - ETA: 5s - loss: 4.7848 - acc: 0.017 - ETA: 5s - loss: 4.7841 - acc: 0.017 - ETA: 5s - loss: 4.7843 - acc: 0.017 - ETA: 5s - loss: 4.7847 - acc: 0.017 - ETA: 4s - loss: 4.7846 - acc: 0.017 - ETA: 4s - loss: 4.7838 - acc: 0.017 - ETA: 4s - loss: 4.7838 - acc: 0.018 - ETA: 4s - loss: 4.7834 - acc: 0.018 - ETA: 3s - loss: 4.7836 - acc: 0.018 - ETA: 3s - loss: 4.7840 - acc: 0.018 - ETA: 3s - loss: 4.7840 - acc: 0.018 - ETA: 3s - loss: 4.7839 - acc: 0.018 - ETA: 3s - loss: 4.7839 - acc: 0.018 - ETA: 2s - loss: 4.7839 - acc: 0.018 - ETA: 2s - loss: 4.7844 - acc: 0.017 - ETA: 2s - loss: 4.7844 - acc: 0.017 - ETA: 2s - loss: 4.7842 - acc: 0.017 - ETA: 2s - loss: 4.7845 - acc: 0.017 - ETA: 1s - loss: 4.7844 - acc: 0.017 - ETA: 1s - loss: 4.7844 - acc: 0.017 - ETA: 1s - loss: 4.7842 - acc: 0.017 - ETA: 1s - loss: 4.7837 - acc: 0.017 - ETA: 1s - loss: 4.7835 - acc: 0.017 - ETA: 0s - loss: 4.7839 - acc: 0.017 - ETA: 0s - loss: 4.7838 - acc: 0.017 - ETA: 0s - loss: 4.7840 - acc: 0.017 - ETA: 0s - loss: 4.7842 - acc: 0.0179Epoch 00004: val_loss improved from 4.80026 to 4.76046, saving model to saved_models/weights.best.from_scratch.hdf5\n",
      "6680/6680 [==============================] - 72s - loss: 4.7840 - acc: 0.0180 - val_loss: 4.7605 - val_acc: 0.0240\n",
      "Epoch 6/32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4300/6680 [==================>...........] - ETA: 64s - loss: 4.6307 - acc: 0.0000e+ - ETA: 67s - loss: 4.8764 - acc: 0.0000e+ - ETA: 69s - loss: 4.8454 - acc: 0.0333   - ETA: 68s - loss: 4.8072 - acc: 0.03 - ETA: 68s - loss: 4.8059 - acc: 0.04 - ETA: 68s - loss: 4.7950 - acc: 0.03 - ETA: 67s - loss: 4.7910 - acc: 0.02 - ETA: 68s - loss: 4.7902 - acc: 0.02 - ETA: 67s - loss: 4.7853 - acc: 0.02 - ETA: 67s - loss: 4.7701 - acc: 0.02 - ETA: 67s - loss: 4.7659 - acc: 0.01 - ETA: 67s - loss: 4.7664 - acc: 0.02 - ETA: 67s - loss: 4.7757 - acc: 0.01 - ETA: 66s - loss: 4.7685 - acc: 0.01 - ETA: 66s - loss: 4.7654 - acc: 0.01 - ETA: 66s - loss: 4.7648 - acc: 0.02 - ETA: 66s - loss: 4.7652 - acc: 0.02 - ETA: 66s - loss: 4.7572 - acc: 0.02 - ETA: 65s - loss: 4.7521 - acc: 0.02 - ETA: 65s - loss: 4.7550 - acc: 0.02 - ETA: 65s - loss: 4.7477 - acc: 0.02 - ETA: 65s - loss: 4.7552 - acc: 0.02 - ETA: 64s - loss: 4.7582 - acc: 0.02 - ETA: 64s - loss: 4.7540 - acc: 0.02 - ETA: 64s - loss: 4.7531 - acc: 0.02 - ETA: 64s - loss: 4.7494 - acc: 0.02 - ETA: 64s - loss: 4.7502 - acc: 0.02 - ETA: 63s - loss: 4.7465 - acc: 0.02 - ETA: 63s - loss: 4.7513 - acc: 0.02 - ETA: 63s - loss: 4.7517 - acc: 0.02 - ETA: 63s - loss: 4.7566 - acc: 0.02 - ETA: 63s - loss: 4.7610 - acc: 0.02 - ETA: 62s - loss: 4.7551 - acc: 0.02 - ETA: 62s - loss: 4.7566 - acc: 0.02 - ETA: 62s - loss: 4.7545 - acc: 0.02 - ETA: 62s - loss: 4.7533 - acc: 0.02 - ETA: 62s - loss: 4.7513 - acc: 0.02 - ETA: 61s - loss: 4.7511 - acc: 0.02 - ETA: 61s - loss: 4.7538 - acc: 0.02 - ETA: 61s - loss: 4.7548 - acc: 0.02 - ETA: 61s - loss: 4.7554 - acc: 0.02 - ETA: 61s - loss: 4.7557 - acc: 0.02 - ETA: 60s - loss: 4.7592 - acc: 0.02 - ETA: 60s - loss: 4.7579 - acc: 0.02 - ETA: 60s - loss: 4.7611 - acc: 0.02 - ETA: 60s - loss: 4.7586 - acc: 0.02 - ETA: 59s - loss: 4.7580 - acc: 0.02 - ETA: 59s - loss: 4.7567 - acc: 0.02 - ETA: 59s - loss: 4.7558 - acc: 0.02 - ETA: 59s - loss: 4.7548 - acc: 0.02 - ETA: 59s - loss: 4.7535 - acc: 0.02 - ETA: 59s - loss: 4.7529 - acc: 0.02 - ETA: 58s - loss: 4.7514 - acc: 0.02 - ETA: 58s - loss: 4.7520 - acc: 0.02 - ETA: 58s - loss: 4.7552 - acc: 0.02 - ETA: 58s - loss: 4.7555 - acc: 0.02 - ETA: 58s - loss: 4.7548 - acc: 0.02 - ETA: 57s - loss: 4.7547 - acc: 0.02 - ETA: 57s - loss: 4.7537 - acc: 0.02 - ETA: 57s - loss: 4.7537 - acc: 0.02 - ETA: 57s - loss: 4.7552 - acc: 0.02 - ETA: 57s - loss: 4.7571 - acc: 0.02 - ETA: 56s - loss: 4.7575 - acc: 0.02 - ETA: 56s - loss: 4.7579 - acc: 0.02 - ETA: 56s - loss: 4.7601 - acc: 0.02 - ETA: 56s - loss: 4.7589 - acc: 0.02 - ETA: 56s - loss: 4.7573 - acc: 0.02 - ETA: 55s - loss: 4.7526 - acc: 0.02 - ETA: 55s - loss: 4.7552 - acc: 0.02 - ETA: 55s - loss: 4.7543 - acc: 0.02 - ETA: 55s - loss: 4.7539 - acc: 0.02 - ETA: 55s - loss: 4.7533 - acc: 0.02 - ETA: 54s - loss: 4.7541 - acc: 0.02 - ETA: 54s - loss: 4.7528 - acc: 0.02 - ETA: 54s - loss: 4.7517 - acc: 0.02 - ETA: 54s - loss: 4.7501 - acc: 0.02 - ETA: 54s - loss: 4.7511 - acc: 0.02 - ETA: 53s - loss: 4.7513 - acc: 0.02 - ETA: 53s - loss: 4.7500 - acc: 0.02 - ETA: 53s - loss: 4.7503 - acc: 0.02 - ETA: 53s - loss: 4.7518 - acc: 0.02 - ETA: 53s - loss: 4.7524 - acc: 0.02 - ETA: 52s - loss: 4.7533 - acc: 0.02 - ETA: 52s - loss: 4.7535 - acc: 0.02 - ETA: 52s - loss: 4.7550 - acc: 0.02 - ETA: 52s - loss: 4.7565 - acc: 0.02 - ETA: 51s - loss: 4.7553 - acc: 0.02 - ETA: 51s - loss: 4.7568 - acc: 0.02 - ETA: 51s - loss: 4.7564 - acc: 0.02 - ETA: 51s - loss: 4.7575 - acc: 0.02 - ETA: 51s - loss: 4.7577 - acc: 0.02 - ETA: 50s - loss: 4.7563 - acc: 0.02 - ETA: 50s - loss: 4.7571 - acc: 0.02 - ETA: 50s - loss: 4.7575 - acc: 0.02 - ETA: 50s - loss: 4.7557 - acc: 0.02 - ETA: 50s - loss: 4.7555 - acc: 0.02 - ETA: 49s - loss: 4.7550 - acc: 0.02 - ETA: 49s - loss: 4.7541 - acc: 0.02 - ETA: 49s - loss: 4.7556 - acc: 0.02 - ETA: 49s - loss: 4.7550 - acc: 0.02 - ETA: 48s - loss: 4.7540 - acc: 0.02 - ETA: 48s - loss: 4.7545 - acc: 0.02 - ETA: 48s - loss: 4.7553 - acc: 0.02 - ETA: 48s - loss: 4.7563 - acc: 0.02 - ETA: 48s - loss: 4.7547 - acc: 0.02 - ETA: 47s - loss: 4.7545 - acc: 0.02 - ETA: 47s - loss: 4.7538 - acc: 0.02 - ETA: 47s - loss: 4.7541 - acc: 0.02 - ETA: 47s - loss: 4.7558 - acc: 0.02 - ETA: 47s - loss: 4.7564 - acc: 0.02 - ETA: 46s - loss: 4.7554 - acc: 0.02 - ETA: 46s - loss: 4.7533 - acc: 0.02 - ETA: 46s - loss: 4.7538 - acc: 0.02 - ETA: 46s - loss: 4.7567 - acc: 0.02 - ETA: 46s - loss: 4.7562 - acc: 0.02 - ETA: 45s - loss: 4.7545 - acc: 0.02 - ETA: 45s - loss: 4.7523 - acc: 0.02 - ETA: 45s - loss: 4.7526 - acc: 0.02 - ETA: 45s - loss: 4.7546 - acc: 0.02 - ETA: 45s - loss: 4.7537 - acc: 0.02 - ETA: 44s - loss: 4.7537 - acc: 0.02 - ETA: 44s - loss: 4.7529 - acc: 0.02 - ETA: 44s - loss: 4.7522 - acc: 0.02 - ETA: 44s - loss: 4.7532 - acc: 0.02 - ETA: 44s - loss: 4.7533 - acc: 0.02 - ETA: 43s - loss: 4.7519 - acc: 0.02 - ETA: 43s - loss: 4.7521 - acc: 0.02 - ETA: 43s - loss: 4.7514 - acc: 0.02 - ETA: 43s - loss: 4.7503 - acc: 0.02 - ETA: 43s - loss: 4.7525 - acc: 0.02 - ETA: 42s - loss: 4.7545 - acc: 0.02 - ETA: 42s - loss: 4.7541 - acc: 0.02 - ETA: 42s - loss: 4.7540 - acc: 0.02 - ETA: 42s - loss: 4.7543 - acc: 0.02 - ETA: 42s - loss: 4.7549 - acc: 0.02 - ETA: 41s - loss: 4.7538 - acc: 0.02 - ETA: 41s - loss: 4.7535 - acc: 0.02 - ETA: 41s - loss: 4.7531 - acc: 0.02 - ETA: 41s - loss: 4.7552 - acc: 0.02 - ETA: 41s - loss: 4.7552 - acc: 0.02 - ETA: 40s - loss: 4.7562 - acc: 0.02 - ETA: 40s - loss: 4.7562 - acc: 0.02 - ETA: 40s - loss: 4.7561 - acc: 0.02 - ETA: 40s - loss: 4.7559 - acc: 0.02 - ETA: 39s - loss: 4.7552 - acc: 0.02 - ETA: 39s - loss: 4.7565 - acc: 0.02 - ETA: 39s - loss: 4.7563 - acc: 0.02 - ETA: 39s - loss: 4.7562 - acc: 0.02 - ETA: 39s - loss: 4.7555 - acc: 0.02 - ETA: 38s - loss: 4.7559 - acc: 0.02 - ETA: 38s - loss: 4.7552 - acc: 0.02 - ETA: 38s - loss: 4.7545 - acc: 0.02 - ETA: 38s - loss: 4.7545 - acc: 0.02 - ETA: 38s - loss: 4.7535 - acc: 0.02 - ETA: 37s - loss: 4.7526 - acc: 0.02 - ETA: 37s - loss: 4.7534 - acc: 0.02 - ETA: 37s - loss: 4.7536 - acc: 0.02 - ETA: 37s - loss: 4.7526 - acc: 0.02 - ETA: 36s - loss: 4.7515 - acc: 0.02 - ETA: 36s - loss: 4.7517 - acc: 0.02 - ETA: 36s - loss: 4.7532 - acc: 0.02 - ETA: 36s - loss: 4.7536 - acc: 0.02 - ETA: 36s - loss: 4.7531 - acc: 0.02 - ETA: 35s - loss: 4.7533 - acc: 0.02 - ETA: 35s - loss: 4.7532 - acc: 0.02 - ETA: 35s - loss: 4.7527 - acc: 0.02 - ETA: 35s - loss: 4.7524 - acc: 0.02 - ETA: 35s - loss: 4.7518 - acc: 0.02 - ETA: 34s - loss: 4.7506 - acc: 0.02 - ETA: 34s - loss: 4.7500 - acc: 0.02 - ETA: 34s - loss: 4.7491 - acc: 0.02 - ETA: 34s - loss: 4.7479 - acc: 0.02 - ETA: 33s - loss: 4.7469 - acc: 0.02 - ETA: 33s - loss: 4.7462 - acc: 0.02 - ETA: 33s - loss: 4.7456 - acc: 0.02 - ETA: 33s - loss: 4.7452 - acc: 0.02 - ETA: 33s - loss: 4.7454 - acc: 0.02 - ETA: 32s - loss: 4.7464 - acc: 0.02 - ETA: 32s - loss: 4.7464 - acc: 0.02 - ETA: 32s - loss: 4.7471 - acc: 0.02 - ETA: 32s - loss: 4.7464 - acc: 0.02 - ETA: 32s - loss: 4.7454 - acc: 0.02 - ETA: 31s - loss: 4.7465 - acc: 0.02 - ETA: 31s - loss: 4.7457 - acc: 0.02 - ETA: 31s - loss: 4.7462 - acc: 0.02 - ETA: 31s - loss: 4.7455 - acc: 0.02 - ETA: 31s - loss: 4.7463 - acc: 0.02 - ETA: 30s - loss: 4.7457 - acc: 0.02 - ETA: 30s - loss: 4.7451 - acc: 0.02 - ETA: 30s - loss: 4.7454 - acc: 0.02 - ETA: 30s - loss: 4.7452 - acc: 0.02 - ETA: 29s - loss: 4.7457 - acc: 0.02 - ETA: 29s - loss: 4.7449 - acc: 0.02 - ETA: 29s - loss: 4.7452 - acc: 0.02 - ETA: 29s - loss: 4.7449 - acc: 0.02 - ETA: 29s - loss: 4.7450 - acc: 0.02 - ETA: 28s - loss: 4.7448 - acc: 0.02 - ETA: 28s - loss: 4.7437 - acc: 0.02 - ETA: 28s - loss: 4.7445 - acc: 0.02 - ETA: 28s - loss: 4.7434 - acc: 0.02 - ETA: 28s - loss: 4.7430 - acc: 0.02 - ETA: 27s - loss: 4.7434 - acc: 0.02 - ETA: 27s - loss: 4.7447 - acc: 0.02 - ETA: 27s - loss: 4.7443 - acc: 0.02 - ETA: 27s - loss: 4.7432 - acc: 0.02 - ETA: 26s - loss: 4.7431 - acc: 0.02 - ETA: 26s - loss: 4.7423 - acc: 0.02 - ETA: 26s - loss: 4.7421 - acc: 0.02 - ETA: 26s - loss: 4.7421 - acc: 0.02 - ETA: 26s - loss: 4.7420 - acc: 0.02 - ETA: 25s - loss: 4.7419 - acc: 0.02 - ETA: 25s - loss: 4.7421 - acc: 0.02 - ETA: 25s - loss: 4.7420 - acc: 0.02 - ETA: 25s - loss: 4.7417 - acc: 0.02 - ETA: 25s - loss: 4.7418 - acc: 0.0226"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6660/6680 [============================>.] - ETA: 24s - loss: 4.7406 - acc: 0.02 - ETA: 24s - loss: 4.7409 - acc: 0.02 - ETA: 24s - loss: 4.7417 - acc: 0.02 - ETA: 24s - loss: 4.7409 - acc: 0.02 - ETA: 24s - loss: 4.7418 - acc: 0.02 - ETA: 23s - loss: 4.7417 - acc: 0.02 - ETA: 23s - loss: 4.7420 - acc: 0.02 - ETA: 23s - loss: 4.7424 - acc: 0.02 - ETA: 23s - loss: 4.7414 - acc: 0.02 - ETA: 22s - loss: 4.7424 - acc: 0.02 - ETA: 22s - loss: 4.7428 - acc: 0.02 - ETA: 22s - loss: 4.7424 - acc: 0.02 - ETA: 22s - loss: 4.7425 - acc: 0.02 - ETA: 22s - loss: 4.7430 - acc: 0.02 - ETA: 21s - loss: 4.7428 - acc: 0.02 - ETA: 21s - loss: 4.7439 - acc: 0.02 - ETA: 21s - loss: 4.7443 - acc: 0.02 - ETA: 21s - loss: 4.7445 - acc: 0.02 - ETA: 21s - loss: 4.7443 - acc: 0.02 - ETA: 20s - loss: 4.7437 - acc: 0.02 - ETA: 20s - loss: 4.7428 - acc: 0.02 - ETA: 20s - loss: 4.7425 - acc: 0.02 - ETA: 20s - loss: 4.7420 - acc: 0.02 - ETA: 20s - loss: 4.7413 - acc: 0.02 - ETA: 19s - loss: 4.7410 - acc: 0.02 - ETA: 19s - loss: 4.7401 - acc: 0.02 - ETA: 19s - loss: 4.7405 - acc: 0.02 - ETA: 19s - loss: 4.7404 - acc: 0.02 - ETA: 18s - loss: 4.7400 - acc: 0.02 - ETA: 18s - loss: 4.7394 - acc: 0.02 - ETA: 18s - loss: 4.7405 - acc: 0.02 - ETA: 18s - loss: 4.7407 - acc: 0.02 - ETA: 18s - loss: 4.7408 - acc: 0.02 - ETA: 17s - loss: 4.7397 - acc: 0.02 - ETA: 17s - loss: 4.7398 - acc: 0.02 - ETA: 17s - loss: 4.7409 - acc: 0.02 - ETA: 17s - loss: 4.7408 - acc: 0.02 - ETA: 17s - loss: 4.7408 - acc: 0.02 - ETA: 16s - loss: 4.7410 - acc: 0.02 - ETA: 16s - loss: 4.7413 - acc: 0.02 - ETA: 16s - loss: 4.7412 - acc: 0.02 - ETA: 16s - loss: 4.7414 - acc: 0.02 - ETA: 16s - loss: 4.7419 - acc: 0.02 - ETA: 15s - loss: 4.7416 - acc: 0.02 - ETA: 15s - loss: 4.7408 - acc: 0.02 - ETA: 15s - loss: 4.7410 - acc: 0.02 - ETA: 15s - loss: 4.7404 - acc: 0.02 - ETA: 14s - loss: 4.7409 - acc: 0.02 - ETA: 14s - loss: 4.7416 - acc: 0.02 - ETA: 14s - loss: 4.7412 - acc: 0.02 - ETA: 14s - loss: 4.7409 - acc: 0.02 - ETA: 14s - loss: 4.7407 - acc: 0.02 - ETA: 13s - loss: 4.7405 - acc: 0.02 - ETA: 13s - loss: 4.7407 - acc: 0.02 - ETA: 13s - loss: 4.7402 - acc: 0.02 - ETA: 13s - loss: 4.7405 - acc: 0.02 - ETA: 13s - loss: 4.7405 - acc: 0.02 - ETA: 12s - loss: 4.7406 - acc: 0.02 - ETA: 12s - loss: 4.7413 - acc: 0.02 - ETA: 12s - loss: 4.7413 - acc: 0.02 - ETA: 12s - loss: 4.7410 - acc: 0.02 - ETA: 11s - loss: 4.7401 - acc: 0.02 - ETA: 11s - loss: 4.7399 - acc: 0.02 - ETA: 11s - loss: 4.7401 - acc: 0.02 - ETA: 11s - loss: 4.7398 - acc: 0.02 - ETA: 11s - loss: 4.7391 - acc: 0.02 - ETA: 10s - loss: 4.7395 - acc: 0.02 - ETA: 10s - loss: 4.7389 - acc: 0.02 - ETA: 10s - loss: 4.7393 - acc: 0.02 - ETA: 10s - loss: 4.7396 - acc: 0.02 - ETA: 10s - loss: 4.7394 - acc: 0.02 - ETA: 9s - loss: 4.7392 - acc: 0.0226 - ETA: 9s - loss: 4.7392 - acc: 0.022 - ETA: 9s - loss: 4.7392 - acc: 0.023 - ETA: 9s - loss: 4.7393 - acc: 0.023 - ETA: 9s - loss: 4.7394 - acc: 0.023 - ETA: 8s - loss: 4.7389 - acc: 0.023 - ETA: 8s - loss: 4.7393 - acc: 0.023 - ETA: 8s - loss: 4.7393 - acc: 0.023 - ETA: 8s - loss: 4.7400 - acc: 0.023 - ETA: 7s - loss: 4.7405 - acc: 0.023 - ETA: 7s - loss: 4.7406 - acc: 0.023 - ETA: 7s - loss: 4.7408 - acc: 0.023 - ETA: 7s - loss: 4.7406 - acc: 0.023 - ETA: 7s - loss: 4.7409 - acc: 0.023 - ETA: 6s - loss: 4.7411 - acc: 0.022 - ETA: 6s - loss: 4.7413 - acc: 0.022 - ETA: 6s - loss: 4.7411 - acc: 0.022 - ETA: 6s - loss: 4.7412 - acc: 0.022 - ETA: 6s - loss: 4.7418 - acc: 0.022 - ETA: 5s - loss: 4.7414 - acc: 0.022 - ETA: 5s - loss: 4.7409 - acc: 0.022 - ETA: 5s - loss: 4.7409 - acc: 0.022 - ETA: 5s - loss: 4.7405 - acc: 0.022 - ETA: 5s - loss: 4.7402 - acc: 0.022 - ETA: 4s - loss: 4.7401 - acc: 0.023 - ETA: 4s - loss: 4.7405 - acc: 0.022 - ETA: 4s - loss: 4.7410 - acc: 0.022 - ETA: 4s - loss: 4.7407 - acc: 0.023 - ETA: 3s - loss: 4.7406 - acc: 0.023 - ETA: 3s - loss: 4.7403 - acc: 0.022 - ETA: 3s - loss: 4.7402 - acc: 0.022 - ETA: 3s - loss: 4.7404 - acc: 0.023 - ETA: 3s - loss: 4.7406 - acc: 0.022 - ETA: 2s - loss: 4.7406 - acc: 0.022 - ETA: 2s - loss: 4.7413 - acc: 0.022 - ETA: 2s - loss: 4.7412 - acc: 0.023 - ETA: 2s - loss: 4.7413 - acc: 0.022 - ETA: 2s - loss: 4.7415 - acc: 0.022 - ETA: 1s - loss: 4.7415 - acc: 0.023 - ETA: 1s - loss: 4.7414 - acc: 0.023 - ETA: 1s - loss: 4.7414 - acc: 0.023 - ETA: 1s - loss: 4.7414 - acc: 0.023 - ETA: 1s - loss: 4.7413 - acc: 0.022 - ETA: 0s - loss: 4.7408 - acc: 0.023 - ETA: 0s - loss: 4.7418 - acc: 0.023 - ETA: 0s - loss: 4.7413 - acc: 0.023 - ETA: 0s - loss: 4.7413 - acc: 0.0230Epoch 00005: val_loss improved from 4.76046 to 4.72356, saving model to saved_models/weights.best.from_scratch.hdf5\n",
      "6680/6680 [==============================] - 73s - loss: 4.7414 - acc: 0.0231 - val_loss: 4.7236 - val_acc: 0.0311\n",
      "Epoch 7/32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4300/6680 [==================>...........] - ETA: 66s - loss: 4.5494 - acc: 0.05 - ETA: 69s - loss: 4.7367 - acc: 0.02 - ETA: 71s - loss: 4.7756 - acc: 0.03 - ETA: 72s - loss: 4.7679 - acc: 0.02 - ETA: 72s - loss: 4.8214 - acc: 0.02 - ETA: 71s - loss: 4.7987 - acc: 0.01 - ETA: 71s - loss: 4.7881 - acc: 0.02 - ETA: 70s - loss: 4.7874 - acc: 0.01 - ETA: 70s - loss: 4.7918 - acc: 0.01 - ETA: 69s - loss: 4.7903 - acc: 0.02 - ETA: 69s - loss: 4.7922 - acc: 0.01 - ETA: 69s - loss: 4.7889 - acc: 0.01 - ETA: 69s - loss: 4.7902 - acc: 0.02 - ETA: 68s - loss: 4.7929 - acc: 0.02 - ETA: 68s - loss: 4.7893 - acc: 0.02 - ETA: 68s - loss: 4.7780 - acc: 0.02 - ETA: 68s - loss: 4.7712 - acc: 0.02 - ETA: 67s - loss: 4.7722 - acc: 0.02 - ETA: 67s - loss: 4.7845 - acc: 0.02 - ETA: 67s - loss: 4.7826 - acc: 0.02 - ETA: 66s - loss: 4.7813 - acc: 0.02 - ETA: 66s - loss: 4.7791 - acc: 0.02 - ETA: 66s - loss: 4.7867 - acc: 0.02 - ETA: 66s - loss: 4.7842 - acc: 0.02 - ETA: 65s - loss: 4.7865 - acc: 0.02 - ETA: 65s - loss: 4.7813 - acc: 0.02 - ETA: 65s - loss: 4.7793 - acc: 0.02 - ETA: 65s - loss: 4.7711 - acc: 0.03 - ETA: 64s - loss: 4.7679 - acc: 0.02 - ETA: 64s - loss: 4.7669 - acc: 0.03 - ETA: 64s - loss: 4.7594 - acc: 0.03 - ETA: 64s - loss: 4.7687 - acc: 0.02 - ETA: 63s - loss: 4.7702 - acc: 0.02 - ETA: 63s - loss: 4.7599 - acc: 0.02 - ETA: 63s - loss: 4.7547 - acc: 0.03 - ETA: 63s - loss: 4.7552 - acc: 0.03 - ETA: 63s - loss: 4.7560 - acc: 0.02 - ETA: 62s - loss: 4.7602 - acc: 0.03 - ETA: 62s - loss: 4.7558 - acc: 0.03 - ETA: 62s - loss: 4.7545 - acc: 0.03 - ETA: 62s - loss: 4.7508 - acc: 0.03 - ETA: 61s - loss: 4.7496 - acc: 0.02 - ETA: 61s - loss: 4.7508 - acc: 0.03 - ETA: 61s - loss: 4.7479 - acc: 0.02 - ETA: 61s - loss: 4.7424 - acc: 0.02 - ETA: 61s - loss: 4.7426 - acc: 0.02 - ETA: 60s - loss: 4.7406 - acc: 0.02 - ETA: 60s - loss: 4.7399 - acc: 0.02 - ETA: 60s - loss: 4.7369 - acc: 0.02 - ETA: 60s - loss: 4.7307 - acc: 0.02 - ETA: 60s - loss: 4.7311 - acc: 0.02 - ETA: 59s - loss: 4.7292 - acc: 0.02 - ETA: 59s - loss: 4.7250 - acc: 0.02 - ETA: 59s - loss: 4.7238 - acc: 0.02 - ETA: 59s - loss: 4.7247 - acc: 0.02 - ETA: 59s - loss: 4.7232 - acc: 0.02 - ETA: 58s - loss: 4.7255 - acc: 0.02 - ETA: 58s - loss: 4.7310 - acc: 0.02 - ETA: 58s - loss: 4.7306 - acc: 0.02 - ETA: 58s - loss: 4.7293 - acc: 0.02 - ETA: 57s - loss: 4.7297 - acc: 0.02 - ETA: 57s - loss: 4.7299 - acc: 0.02 - ETA: 57s - loss: 4.7284 - acc: 0.02 - ETA: 57s - loss: 4.7265 - acc: 0.02 - ETA: 57s - loss: 4.7261 - acc: 0.02 - ETA: 56s - loss: 4.7264 - acc: 0.02 - ETA: 56s - loss: 4.7226 - acc: 0.02 - ETA: 56s - loss: 4.7236 - acc: 0.02 - ETA: 56s - loss: 4.7176 - acc: 0.02 - ETA: 56s - loss: 4.7146 - acc: 0.02 - ETA: 55s - loss: 4.7110 - acc: 0.02 - ETA: 55s - loss: 4.7129 - acc: 0.02 - ETA: 55s - loss: 4.7160 - acc: 0.02 - ETA: 55s - loss: 4.7160 - acc: 0.02 - ETA: 54s - loss: 4.7148 - acc: 0.02 - ETA: 54s - loss: 4.7132 - acc: 0.02 - ETA: 54s - loss: 4.7122 - acc: 0.02 - ETA: 54s - loss: 4.7099 - acc: 0.02 - ETA: 54s - loss: 4.7089 - acc: 0.02 - ETA: 53s - loss: 4.7093 - acc: 0.02 - ETA: 53s - loss: 4.7100 - acc: 0.02 - ETA: 53s - loss: 4.7103 - acc: 0.02 - ETA: 53s - loss: 4.7115 - acc: 0.02 - ETA: 52s - loss: 4.7117 - acc: 0.02 - ETA: 52s - loss: 4.7132 - acc: 0.02 - ETA: 52s - loss: 4.7125 - acc: 0.02 - ETA: 52s - loss: 4.7144 - acc: 0.02 - ETA: 52s - loss: 4.7128 - acc: 0.02 - ETA: 51s - loss: 4.7124 - acc: 0.02 - ETA: 51s - loss: 4.7114 - acc: 0.02 - ETA: 51s - loss: 4.7061 - acc: 0.02 - ETA: 51s - loss: 4.7094 - acc: 0.02 - ETA: 51s - loss: 4.7114 - acc: 0.02 - ETA: 50s - loss: 4.7105 - acc: 0.03 - ETA: 50s - loss: 4.7117 - acc: 0.03 - ETA: 50s - loss: 4.7111 - acc: 0.03 - ETA: 50s - loss: 4.7120 - acc: 0.03 - ETA: 49s - loss: 4.7134 - acc: 0.03 - ETA: 49s - loss: 4.7123 - acc: 0.03 - ETA: 49s - loss: 4.7103 - acc: 0.03 - ETA: 49s - loss: 4.7114 - acc: 0.03 - ETA: 49s - loss: 4.7116 - acc: 0.02 - ETA: 48s - loss: 4.7138 - acc: 0.03 - ETA: 48s - loss: 4.7134 - acc: 0.03 - ETA: 48s - loss: 4.7130 - acc: 0.03 - ETA: 48s - loss: 4.7120 - acc: 0.03 - ETA: 48s - loss: 4.7124 - acc: 0.03 - ETA: 47s - loss: 4.7144 - acc: 0.03 - ETA: 47s - loss: 4.7134 - acc: 0.02 - ETA: 47s - loss: 4.7136 - acc: 0.03 - ETA: 47s - loss: 4.7134 - acc: 0.03 - ETA: 47s - loss: 4.7142 - acc: 0.02 - ETA: 46s - loss: 4.7140 - acc: 0.02 - ETA: 46s - loss: 4.7140 - acc: 0.02 - ETA: 46s - loss: 4.7136 - acc: 0.02 - ETA: 46s - loss: 4.7133 - acc: 0.02 - ETA: 46s - loss: 4.7136 - acc: 0.02 - ETA: 45s - loss: 4.7118 - acc: 0.03 - ETA: 45s - loss: 4.7105 - acc: 0.02 - ETA: 45s - loss: 4.7122 - acc: 0.02 - ETA: 45s - loss: 4.7124 - acc: 0.02 - ETA: 44s - loss: 4.7124 - acc: 0.02 - ETA: 44s - loss: 4.7130 - acc: 0.02 - ETA: 44s - loss: 4.7114 - acc: 0.02 - ETA: 44s - loss: 4.7113 - acc: 0.02 - ETA: 44s - loss: 4.7107 - acc: 0.02 - ETA: 43s - loss: 4.7103 - acc: 0.02 - ETA: 43s - loss: 4.7109 - acc: 0.02 - ETA: 43s - loss: 4.7122 - acc: 0.02 - ETA: 43s - loss: 4.7123 - acc: 0.02 - ETA: 43s - loss: 4.7126 - acc: 0.02 - ETA: 42s - loss: 4.7123 - acc: 0.02 - ETA: 42s - loss: 4.7121 - acc: 0.02 - ETA: 42s - loss: 4.7120 - acc: 0.02 - ETA: 42s - loss: 4.7128 - acc: 0.02 - ETA: 41s - loss: 4.7128 - acc: 0.02 - ETA: 41s - loss: 4.7137 - acc: 0.02 - ETA: 41s - loss: 4.7129 - acc: 0.02 - ETA: 41s - loss: 4.7129 - acc: 0.02 - ETA: 41s - loss: 4.7122 - acc: 0.02 - ETA: 40s - loss: 4.7100 - acc: 0.02 - ETA: 40s - loss: 4.7103 - acc: 0.02 - ETA: 40s - loss: 4.7100 - acc: 0.02 - ETA: 40s - loss: 4.7100 - acc: 0.02 - ETA: 40s - loss: 4.7099 - acc: 0.02 - ETA: 39s - loss: 4.7108 - acc: 0.02 - ETA: 39s - loss: 4.7120 - acc: 0.02 - ETA: 39s - loss: 4.7129 - acc: 0.02 - ETA: 39s - loss: 4.7144 - acc: 0.02 - ETA: 38s - loss: 4.7148 - acc: 0.02 - ETA: 38s - loss: 4.7136 - acc: 0.02 - ETA: 38s - loss: 4.7124 - acc: 0.02 - ETA: 38s - loss: 4.7115 - acc: 0.02 - ETA: 38s - loss: 4.7113 - acc: 0.02 - ETA: 37s - loss: 4.7095 - acc: 0.02 - ETA: 37s - loss: 4.7098 - acc: 0.02 - ETA: 37s - loss: 4.7093 - acc: 0.02 - ETA: 37s - loss: 4.7099 - acc: 0.02 - ETA: 37s - loss: 4.7108 - acc: 0.02 - ETA: 36s - loss: 4.7100 - acc: 0.02 - ETA: 36s - loss: 4.7104 - acc: 0.02 - ETA: 36s - loss: 4.7092 - acc: 0.02 - ETA: 36s - loss: 4.7103 - acc: 0.02 - ETA: 36s - loss: 4.7091 - acc: 0.02 - ETA: 35s - loss: 4.7097 - acc: 0.02 - ETA: 35s - loss: 4.7101 - acc: 0.02 - ETA: 35s - loss: 4.7103 - acc: 0.02 - ETA: 35s - loss: 4.7104 - acc: 0.02 - ETA: 34s - loss: 4.7103 - acc: 0.02 - ETA: 34s - loss: 4.7112 - acc: 0.02 - ETA: 34s - loss: 4.7113 - acc: 0.02 - ETA: 34s - loss: 4.7116 - acc: 0.02 - ETA: 34s - loss: 4.7112 - acc: 0.02 - ETA: 33s - loss: 4.7104 - acc: 0.02 - ETA: 33s - loss: 4.7097 - acc: 0.02 - ETA: 33s - loss: 4.7103 - acc: 0.02 - ETA: 33s - loss: 4.7108 - acc: 0.02 - ETA: 33s - loss: 4.7104 - acc: 0.02 - ETA: 32s - loss: 4.7088 - acc: 0.02 - ETA: 32s - loss: 4.7089 - acc: 0.02 - ETA: 32s - loss: 4.7086 - acc: 0.02 - ETA: 32s - loss: 4.7080 - acc: 0.02 - ETA: 31s - loss: 4.7086 - acc: 0.02 - ETA: 31s - loss: 4.7100 - acc: 0.02 - ETA: 31s - loss: 4.7089 - acc: 0.02 - ETA: 31s - loss: 4.7089 - acc: 0.02 - ETA: 31s - loss: 4.7090 - acc: 0.02 - ETA: 30s - loss: 4.7088 - acc: 0.02 - ETA: 30s - loss: 4.7088 - acc: 0.02 - ETA: 30s - loss: 4.7094 - acc: 0.02 - ETA: 30s - loss: 4.7098 - acc: 0.02 - ETA: 30s - loss: 4.7096 - acc: 0.02 - ETA: 29s - loss: 4.7101 - acc: 0.02 - ETA: 29s - loss: 4.7090 - acc: 0.02 - ETA: 29s - loss: 4.7101 - acc: 0.02 - ETA: 29s - loss: 4.7105 - acc: 0.02 - ETA: 29s - loss: 4.7092 - acc: 0.02 - ETA: 28s - loss: 4.7108 - acc: 0.02 - ETA: 28s - loss: 4.7110 - acc: 0.02 - ETA: 28s - loss: 4.7122 - acc: 0.02 - ETA: 28s - loss: 4.7125 - acc: 0.02 - ETA: 27s - loss: 4.7124 - acc: 0.02 - ETA: 27s - loss: 4.7133 - acc: 0.02 - ETA: 27s - loss: 4.7136 - acc: 0.02 - ETA: 27s - loss: 4.7131 - acc: 0.02 - ETA: 27s - loss: 4.7126 - acc: 0.02 - ETA: 26s - loss: 4.7126 - acc: 0.02 - ETA: 26s - loss: 4.7129 - acc: 0.02 - ETA: 26s - loss: 4.7132 - acc: 0.02 - ETA: 26s - loss: 4.7136 - acc: 0.02 - ETA: 26s - loss: 4.7143 - acc: 0.02 - ETA: 25s - loss: 4.7138 - acc: 0.02 - ETA: 25s - loss: 4.7139 - acc: 0.02 - ETA: 25s - loss: 4.7140 - acc: 0.02 - ETA: 25s - loss: 4.7138 - acc: 0.0277"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6660/6680 [============================>.] - ETA: 24s - loss: 4.7140 - acc: 0.02 - ETA: 24s - loss: 4.7144 - acc: 0.02 - ETA: 24s - loss: 4.7144 - acc: 0.02 - ETA: 24s - loss: 4.7147 - acc: 0.02 - ETA: 24s - loss: 4.7143 - acc: 0.02 - ETA: 23s - loss: 4.7134 - acc: 0.02 - ETA: 23s - loss: 4.7130 - acc: 0.02 - ETA: 23s - loss: 4.7127 - acc: 0.02 - ETA: 23s - loss: 4.7119 - acc: 0.02 - ETA: 23s - loss: 4.7119 - acc: 0.02 - ETA: 22s - loss: 4.7116 - acc: 0.02 - ETA: 22s - loss: 4.7121 - acc: 0.02 - ETA: 22s - loss: 4.7115 - acc: 0.02 - ETA: 22s - loss: 4.7117 - acc: 0.02 - ETA: 22s - loss: 4.7121 - acc: 0.02 - ETA: 21s - loss: 4.7118 - acc: 0.02 - ETA: 21s - loss: 4.7115 - acc: 0.02 - ETA: 21s - loss: 4.7121 - acc: 0.02 - ETA: 21s - loss: 4.7112 - acc: 0.02 - ETA: 20s - loss: 4.7110 - acc: 0.02 - ETA: 20s - loss: 4.7111 - acc: 0.02 - ETA: 20s - loss: 4.7121 - acc: 0.02 - ETA: 20s - loss: 4.7121 - acc: 0.02 - ETA: 20s - loss: 4.7123 - acc: 0.02 - ETA: 19s - loss: 4.7121 - acc: 0.02 - ETA: 19s - loss: 4.7114 - acc: 0.02 - ETA: 19s - loss: 4.7120 - acc: 0.02 - ETA: 19s - loss: 4.7126 - acc: 0.02 - ETA: 19s - loss: 4.7125 - acc: 0.02 - ETA: 18s - loss: 4.7122 - acc: 0.02 - ETA: 18s - loss: 4.7121 - acc: 0.02 - ETA: 18s - loss: 4.7120 - acc: 0.02 - ETA: 18s - loss: 4.7120 - acc: 0.02 - ETA: 17s - loss: 4.7117 - acc: 0.02 - ETA: 17s - loss: 4.7110 - acc: 0.02 - ETA: 17s - loss: 4.7106 - acc: 0.02 - ETA: 17s - loss: 4.7103 - acc: 0.02 - ETA: 17s - loss: 4.7100 - acc: 0.02 - ETA: 16s - loss: 4.7105 - acc: 0.02 - ETA: 16s - loss: 4.7113 - acc: 0.02 - ETA: 16s - loss: 4.7103 - acc: 0.02 - ETA: 16s - loss: 4.7100 - acc: 0.02 - ETA: 16s - loss: 4.7096 - acc: 0.02 - ETA: 15s - loss: 4.7090 - acc: 0.02 - ETA: 15s - loss: 4.7080 - acc: 0.02 - ETA: 15s - loss: 4.7070 - acc: 0.02 - ETA: 15s - loss: 4.7080 - acc: 0.02 - ETA: 15s - loss: 4.7078 - acc: 0.02 - ETA: 14s - loss: 4.7065 - acc: 0.02 - ETA: 14s - loss: 4.7060 - acc: 0.02 - ETA: 14s - loss: 4.7054 - acc: 0.02 - ETA: 14s - loss: 4.7062 - acc: 0.02 - ETA: 13s - loss: 4.7066 - acc: 0.02 - ETA: 13s - loss: 4.7078 - acc: 0.02 - ETA: 13s - loss: 4.7080 - acc: 0.02 - ETA: 13s - loss: 4.7082 - acc: 0.02 - ETA: 13s - loss: 4.7084 - acc: 0.02 - ETA: 12s - loss: 4.7087 - acc: 0.02 - ETA: 12s - loss: 4.7084 - acc: 0.02 - ETA: 12s - loss: 4.7082 - acc: 0.02 - ETA: 12s - loss: 4.7083 - acc: 0.02 - ETA: 12s - loss: 4.7083 - acc: 0.02 - ETA: 11s - loss: 4.7078 - acc: 0.02 - ETA: 11s - loss: 4.7075 - acc: 0.02 - ETA: 11s - loss: 4.7072 - acc: 0.02 - ETA: 11s - loss: 4.7070 - acc: 0.02 - ETA: 10s - loss: 4.7069 - acc: 0.02 - ETA: 10s - loss: 4.7080 - acc: 0.02 - ETA: 10s - loss: 4.7083 - acc: 0.02 - ETA: 10s - loss: 4.7083 - acc: 0.02 - ETA: 10s - loss: 4.7082 - acc: 0.02 - ETA: 9s - loss: 4.7083 - acc: 0.0270 - ETA: 9s - loss: 4.7079 - acc: 0.027 - ETA: 9s - loss: 4.7081 - acc: 0.027 - ETA: 9s - loss: 4.7083 - acc: 0.026 - ETA: 9s - loss: 4.7077 - acc: 0.027 - ETA: 8s - loss: 4.7075 - acc: 0.027 - ETA: 8s - loss: 4.7082 - acc: 0.027 - ETA: 8s - loss: 4.7073 - acc: 0.027 - ETA: 8s - loss: 4.7078 - acc: 0.027 - ETA: 8s - loss: 4.7079 - acc: 0.027 - ETA: 7s - loss: 4.7073 - acc: 0.027 - ETA: 7s - loss: 4.7070 - acc: 0.027 - ETA: 7s - loss: 4.7072 - acc: 0.027 - ETA: 7s - loss: 4.7068 - acc: 0.027 - ETA: 6s - loss: 4.7065 - acc: 0.026 - ETA: 6s - loss: 4.7065 - acc: 0.026 - ETA: 6s - loss: 4.7065 - acc: 0.026 - ETA: 6s - loss: 4.7062 - acc: 0.026 - ETA: 6s - loss: 4.7060 - acc: 0.026 - ETA: 5s - loss: 4.7057 - acc: 0.026 - ETA: 5s - loss: 4.7058 - acc: 0.026 - ETA: 5s - loss: 4.7057 - acc: 0.026 - ETA: 5s - loss: 4.7060 - acc: 0.026 - ETA: 5s - loss: 4.7062 - acc: 0.026 - ETA: 4s - loss: 4.7060 - acc: 0.026 - ETA: 4s - loss: 4.7060 - acc: 0.026 - ETA: 4s - loss: 4.7061 - acc: 0.026 - ETA: 4s - loss: 4.7053 - acc: 0.026 - ETA: 4s - loss: 4.7050 - acc: 0.026 - ETA: 3s - loss: 4.7048 - acc: 0.026 - ETA: 3s - loss: 4.7048 - acc: 0.026 - ETA: 3s - loss: 4.7045 - acc: 0.026 - ETA: 3s - loss: 4.7039 - acc: 0.026 - ETA: 2s - loss: 4.7045 - acc: 0.026 - ETA: 2s - loss: 4.7036 - acc: 0.026 - ETA: 2s - loss: 4.7032 - acc: 0.026 - ETA: 2s - loss: 4.7030 - acc: 0.026 - ETA: 2s - loss: 4.7032 - acc: 0.026 - ETA: 1s - loss: 4.7039 - acc: 0.026 - ETA: 1s - loss: 4.7033 - acc: 0.026 - ETA: 1s - loss: 4.7029 - acc: 0.026 - ETA: 1s - loss: 4.7027 - acc: 0.026 - ETA: 1s - loss: 4.7019 - acc: 0.027 - ETA: 0s - loss: 4.7010 - acc: 0.027 - ETA: 0s - loss: 4.7008 - acc: 0.027 - ETA: 0s - loss: 4.7025 - acc: 0.027 - ETA: 0s - loss: 4.7022 - acc: 0.0269Epoch 00006: val_loss improved from 4.72356 to 4.68962, saving model to saved_models/weights.best.from_scratch.hdf5\n",
      "6680/6680 [==============================] - 73s - loss: 4.7023 - acc: 0.0269 - val_loss: 4.6896 - val_acc: 0.0287\n",
      "Epoch 8/32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4300/6680 [==================>...........] - ETA: 70s - loss: 4.6411 - acc: 0.05 - ETA: 68s - loss: 4.7568 - acc: 0.02 - ETA: 68s - loss: 4.7318 - acc: 0.05 - ETA: 67s - loss: 4.7286 - acc: 0.05 - ETA: 68s - loss: 4.7166 - acc: 0.05 - ETA: 68s - loss: 4.6803 - acc: 0.04 - ETA: 68s - loss: 4.6734 - acc: 0.04 - ETA: 68s - loss: 4.6618 - acc: 0.03 - ETA: 68s - loss: 4.6900 - acc: 0.03 - ETA: 67s - loss: 4.6772 - acc: 0.03 - ETA: 67s - loss: 4.6917 - acc: 0.02 - ETA: 67s - loss: 4.6919 - acc: 0.02 - ETA: 67s - loss: 4.6993 - acc: 0.02 - ETA: 66s - loss: 4.7027 - acc: 0.02 - ETA: 66s - loss: 4.7002 - acc: 0.02 - ETA: 66s - loss: 4.6793 - acc: 0.02 - ETA: 66s - loss: 4.6802 - acc: 0.02 - ETA: 66s - loss: 4.6732 - acc: 0.01 - ETA: 65s - loss: 4.6750 - acc: 0.01 - ETA: 65s - loss: 4.6728 - acc: 0.02 - ETA: 65s - loss: 4.6806 - acc: 0.02 - ETA: 65s - loss: 4.6721 - acc: 0.02 - ETA: 65s - loss: 4.6645 - acc: 0.02 - ETA: 64s - loss: 4.6662 - acc: 0.02 - ETA: 64s - loss: 4.6612 - acc: 0.02 - ETA: 64s - loss: 4.6485 - acc: 0.02 - ETA: 64s - loss: 4.6538 - acc: 0.02 - ETA: 64s - loss: 4.6593 - acc: 0.02 - ETA: 63s - loss: 4.6636 - acc: 0.02 - ETA: 63s - loss: 4.6693 - acc: 0.02 - ETA: 63s - loss: 4.6643 - acc: 0.02 - ETA: 63s - loss: 4.6591 - acc: 0.02 - ETA: 63s - loss: 4.6573 - acc: 0.02 - ETA: 62s - loss: 4.6633 - acc: 0.02 - ETA: 62s - loss: 4.6608 - acc: 0.02 - ETA: 62s - loss: 4.6602 - acc: 0.02 - ETA: 62s - loss: 4.6672 - acc: 0.02 - ETA: 61s - loss: 4.6675 - acc: 0.02 - ETA: 61s - loss: 4.6659 - acc: 0.02 - ETA: 61s - loss: 4.6649 - acc: 0.02 - ETA: 61s - loss: 4.6730 - acc: 0.02 - ETA: 61s - loss: 4.6670 - acc: 0.02 - ETA: 60s - loss: 4.6688 - acc: 0.02 - ETA: 60s - loss: 4.6678 - acc: 0.02 - ETA: 60s - loss: 4.6618 - acc: 0.02 - ETA: 60s - loss: 4.6618 - acc: 0.02 - ETA: 60s - loss: 4.6583 - acc: 0.02 - ETA: 59s - loss: 4.6621 - acc: 0.02 - ETA: 59s - loss: 4.6575 - acc: 0.02 - ETA: 59s - loss: 4.6594 - acc: 0.02 - ETA: 59s - loss: 4.6571 - acc: 0.02 - ETA: 59s - loss: 4.6592 - acc: 0.02 - ETA: 58s - loss: 4.6562 - acc: 0.02 - ETA: 58s - loss: 4.6558 - acc: 0.02 - ETA: 58s - loss: 4.6562 - acc: 0.02 - ETA: 58s - loss: 4.6561 - acc: 0.02 - ETA: 58s - loss: 4.6611 - acc: 0.02 - ETA: 57s - loss: 4.6631 - acc: 0.02 - ETA: 57s - loss: 4.6626 - acc: 0.02 - ETA: 57s - loss: 4.6622 - acc: 0.02 - ETA: 57s - loss: 4.6641 - acc: 0.02 - ETA: 57s - loss: 4.6645 - acc: 0.02 - ETA: 56s - loss: 4.6616 - acc: 0.02 - ETA: 56s - loss: 4.6634 - acc: 0.02 - ETA: 56s - loss: 4.6635 - acc: 0.02 - ETA: 56s - loss: 4.6640 - acc: 0.02 - ETA: 56s - loss: 4.6629 - acc: 0.02 - ETA: 55s - loss: 4.6624 - acc: 0.02 - ETA: 55s - loss: 4.6614 - acc: 0.02 - ETA: 55s - loss: 4.6589 - acc: 0.02 - ETA: 55s - loss: 4.6587 - acc: 0.02 - ETA: 54s - loss: 4.6597 - acc: 0.02 - ETA: 54s - loss: 4.6587 - acc: 0.02 - ETA: 54s - loss: 4.6587 - acc: 0.02 - ETA: 54s - loss: 4.6606 - acc: 0.02 - ETA: 54s - loss: 4.6616 - acc: 0.02 - ETA: 53s - loss: 4.6563 - acc: 0.02 - ETA: 53s - loss: 4.6568 - acc: 0.02 - ETA: 53s - loss: 4.6561 - acc: 0.02 - ETA: 53s - loss: 4.6564 - acc: 0.02 - ETA: 53s - loss: 4.6600 - acc: 0.02 - ETA: 52s - loss: 4.6589 - acc: 0.02 - ETA: 52s - loss: 4.6582 - acc: 0.03 - ETA: 52s - loss: 4.6607 - acc: 0.03 - ETA: 52s - loss: 4.6623 - acc: 0.03 - ETA: 52s - loss: 4.6627 - acc: 0.03 - ETA: 51s - loss: 4.6629 - acc: 0.03 - ETA: 51s - loss: 4.6619 - acc: 0.03 - ETA: 51s - loss: 4.6637 - acc: 0.03 - ETA: 51s - loss: 4.6645 - acc: 0.03 - ETA: 51s - loss: 4.6671 - acc: 0.03 - ETA: 50s - loss: 4.6669 - acc: 0.03 - ETA: 50s - loss: 4.6675 - acc: 0.03 - ETA: 50s - loss: 4.6684 - acc: 0.03 - ETA: 50s - loss: 4.6697 - acc: 0.03 - ETA: 49s - loss: 4.6709 - acc: 0.03 - ETA: 49s - loss: 4.6687 - acc: 0.03 - ETA: 49s - loss: 4.6686 - acc: 0.03 - ETA: 49s - loss: 4.6673 - acc: 0.03 - ETA: 49s - loss: 4.6667 - acc: 0.03 - ETA: 48s - loss: 4.6680 - acc: 0.03 - ETA: 48s - loss: 4.6692 - acc: 0.03 - ETA: 48s - loss: 4.6670 - acc: 0.03 - ETA: 48s - loss: 4.6697 - acc: 0.03 - ETA: 48s - loss: 4.6677 - acc: 0.03 - ETA: 47s - loss: 4.6695 - acc: 0.03 - ETA: 47s - loss: 4.6703 - acc: 0.03 - ETA: 47s - loss: 4.6702 - acc: 0.03 - ETA: 47s - loss: 4.6710 - acc: 0.03 - ETA: 47s - loss: 4.6707 - acc: 0.03 - ETA: 47s - loss: 4.6683 - acc: 0.03 - ETA: 46s - loss: 4.6662 - acc: 0.03 - ETA: 46s - loss: 4.6666 - acc: 0.03 - ETA: 46s - loss: 4.6666 - acc: 0.03 - ETA: 46s - loss: 4.6703 - acc: 0.03 - ETA: 45s - loss: 4.6713 - acc: 0.03 - ETA: 45s - loss: 4.6704 - acc: 0.02 - ETA: 45s - loss: 4.6702 - acc: 0.02 - ETA: 45s - loss: 4.6695 - acc: 0.02 - ETA: 45s - loss: 4.6679 - acc: 0.02 - ETA: 44s - loss: 4.6676 - acc: 0.02 - ETA: 44s - loss: 4.6692 - acc: 0.02 - ETA: 44s - loss: 4.6691 - acc: 0.02 - ETA: 44s - loss: 4.6692 - acc: 0.02 - ETA: 44s - loss: 4.6681 - acc: 0.02 - ETA: 43s - loss: 4.6702 - acc: 0.02 - ETA: 43s - loss: 4.6692 - acc: 0.02 - ETA: 43s - loss: 4.6695 - acc: 0.02 - ETA: 43s - loss: 4.6699 - acc: 0.02 - ETA: 42s - loss: 4.6679 - acc: 0.02 - ETA: 42s - loss: 4.6689 - acc: 0.02 - ETA: 42s - loss: 4.6691 - acc: 0.02 - ETA: 42s - loss: 4.6698 - acc: 0.02 - ETA: 42s - loss: 4.6701 - acc: 0.02 - ETA: 41s - loss: 4.6700 - acc: 0.03 - ETA: 41s - loss: 4.6720 - acc: 0.02 - ETA: 41s - loss: 4.6729 - acc: 0.02 - ETA: 41s - loss: 4.6731 - acc: 0.02 - ETA: 41s - loss: 4.6731 - acc: 0.02 - ETA: 40s - loss: 4.6729 - acc: 0.02 - ETA: 40s - loss: 4.6747 - acc: 0.02 - ETA: 40s - loss: 4.6755 - acc: 0.02 - ETA: 40s - loss: 4.6760 - acc: 0.02 - ETA: 40s - loss: 4.6758 - acc: 0.02 - ETA: 39s - loss: 4.6733 - acc: 0.02 - ETA: 39s - loss: 4.6743 - acc: 0.02 - ETA: 39s - loss: 4.6723 - acc: 0.02 - ETA: 39s - loss: 4.6733 - acc: 0.02 - ETA: 38s - loss: 4.6722 - acc: 0.02 - ETA: 38s - loss: 4.6738 - acc: 0.02 - ETA: 38s - loss: 4.6737 - acc: 0.02 - ETA: 38s - loss: 4.6740 - acc: 0.02 - ETA: 38s - loss: 4.6718 - acc: 0.02 - ETA: 37s - loss: 4.6724 - acc: 0.02 - ETA: 37s - loss: 4.6730 - acc: 0.02 - ETA: 37s - loss: 4.6711 - acc: 0.02 - ETA: 37s - loss: 4.6720 - acc: 0.02 - ETA: 37s - loss: 4.6736 - acc: 0.02 - ETA: 36s - loss: 4.6737 - acc: 0.02 - ETA: 36s - loss: 4.6728 - acc: 0.02 - ETA: 36s - loss: 4.6731 - acc: 0.02 - ETA: 36s - loss: 4.6730 - acc: 0.02 - ETA: 36s - loss: 4.6746 - acc: 0.02 - ETA: 35s - loss: 4.6751 - acc: 0.02 - ETA: 35s - loss: 4.6760 - acc: 0.02 - ETA: 35s - loss: 4.6760 - acc: 0.02 - ETA: 35s - loss: 4.6763 - acc: 0.02 - ETA: 34s - loss: 4.6760 - acc: 0.02 - ETA: 34s - loss: 4.6775 - acc: 0.02 - ETA: 34s - loss: 4.6769 - acc: 0.02 - ETA: 34s - loss: 4.6770 - acc: 0.02 - ETA: 34s - loss: 4.6765 - acc: 0.02 - ETA: 33s - loss: 4.6759 - acc: 0.02 - ETA: 33s - loss: 4.6753 - acc: 0.02 - ETA: 33s - loss: 4.6759 - acc: 0.02 - ETA: 33s - loss: 4.6757 - acc: 0.02 - ETA: 33s - loss: 4.6758 - acc: 0.02 - ETA: 32s - loss: 4.6755 - acc: 0.02 - ETA: 32s - loss: 4.6756 - acc: 0.02 - ETA: 32s - loss: 4.6755 - acc: 0.02 - ETA: 32s - loss: 4.6752 - acc: 0.02 - ETA: 31s - loss: 4.6741 - acc: 0.02 - ETA: 31s - loss: 4.6757 - acc: 0.02 - ETA: 31s - loss: 4.6758 - acc: 0.02 - ETA: 31s - loss: 4.6762 - acc: 0.02 - ETA: 31s - loss: 4.6764 - acc: 0.02 - ETA: 30s - loss: 4.6757 - acc: 0.02 - ETA: 30s - loss: 4.6756 - acc: 0.02 - ETA: 30s - loss: 4.6752 - acc: 0.02 - ETA: 30s - loss: 4.6752 - acc: 0.02 - ETA: 30s - loss: 4.6745 - acc: 0.02 - ETA: 29s - loss: 4.6728 - acc: 0.02 - ETA: 29s - loss: 4.6717 - acc: 0.02 - ETA: 29s - loss: 4.6714 - acc: 0.02 - ETA: 29s - loss: 4.6703 - acc: 0.02 - ETA: 29s - loss: 4.6710 - acc: 0.02 - ETA: 28s - loss: 4.6718 - acc: 0.02 - ETA: 28s - loss: 4.6716 - acc: 0.02 - ETA: 28s - loss: 4.6711 - acc: 0.02 - ETA: 28s - loss: 4.6709 - acc: 0.02 - ETA: 28s - loss: 4.6705 - acc: 0.02 - ETA: 27s - loss: 4.6699 - acc: 0.02 - ETA: 27s - loss: 4.6689 - acc: 0.02 - ETA: 27s - loss: 4.6689 - acc: 0.02 - ETA: 27s - loss: 4.6687 - acc: 0.02 - ETA: 26s - loss: 4.6682 - acc: 0.02 - ETA: 26s - loss: 4.6677 - acc: 0.02 - ETA: 26s - loss: 4.6682 - acc: 0.02 - ETA: 26s - loss: 4.6672 - acc: 0.02 - ETA: 26s - loss: 4.6667 - acc: 0.02 - ETA: 25s - loss: 4.6675 - acc: 0.02 - ETA: 25s - loss: 4.6684 - acc: 0.02 - ETA: 25s - loss: 4.6682 - acc: 0.02 - ETA: 25s - loss: 4.6673 - acc: 0.02 - ETA: 25s - loss: 4.6673 - acc: 0.0274"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6660/6680 [============================>.] - ETA: 24s - loss: 4.6670 - acc: 0.02 - ETA: 24s - loss: 4.6678 - acc: 0.02 - ETA: 24s - loss: 4.6685 - acc: 0.02 - ETA: 24s - loss: 4.6689 - acc: 0.02 - ETA: 23s - loss: 4.6694 - acc: 0.02 - ETA: 23s - loss: 4.6707 - acc: 0.02 - ETA: 23s - loss: 4.6713 - acc: 0.02 - ETA: 23s - loss: 4.6712 - acc: 0.02 - ETA: 23s - loss: 4.6701 - acc: 0.02 - ETA: 22s - loss: 4.6699 - acc: 0.02 - ETA: 22s - loss: 4.6692 - acc: 0.02 - ETA: 22s - loss: 4.6693 - acc: 0.02 - ETA: 22s - loss: 4.6694 - acc: 0.02 - ETA: 22s - loss: 4.6688 - acc: 0.02 - ETA: 21s - loss: 4.6691 - acc: 0.02 - ETA: 21s - loss: 4.6693 - acc: 0.02 - ETA: 21s - loss: 4.6699 - acc: 0.02 - ETA: 21s - loss: 4.6699 - acc: 0.02 - ETA: 21s - loss: 4.6702 - acc: 0.02 - ETA: 20s - loss: 4.6700 - acc: 0.02 - ETA: 20s - loss: 4.6697 - acc: 0.02 - ETA: 20s - loss: 4.6695 - acc: 0.02 - ETA: 20s - loss: 4.6686 - acc: 0.02 - ETA: 20s - loss: 4.6680 - acc: 0.02 - ETA: 19s - loss: 4.6679 - acc: 0.02 - ETA: 19s - loss: 4.6683 - acc: 0.02 - ETA: 19s - loss: 4.6688 - acc: 0.02 - ETA: 19s - loss: 4.6681 - acc: 0.02 - ETA: 18s - loss: 4.6675 - acc: 0.02 - ETA: 18s - loss: 4.6673 - acc: 0.02 - ETA: 18s - loss: 4.6682 - acc: 0.02 - ETA: 18s - loss: 4.6679 - acc: 0.02 - ETA: 18s - loss: 4.6679 - acc: 0.02 - ETA: 17s - loss: 4.6689 - acc: 0.02 - ETA: 17s - loss: 4.6687 - acc: 0.02 - ETA: 17s - loss: 4.6692 - acc: 0.02 - ETA: 17s - loss: 4.6691 - acc: 0.02 - ETA: 17s - loss: 4.6702 - acc: 0.02 - ETA: 16s - loss: 4.6704 - acc: 0.02 - ETA: 16s - loss: 4.6702 - acc: 0.02 - ETA: 16s - loss: 4.6698 - acc: 0.02 - ETA: 16s - loss: 4.6699 - acc: 0.02 - ETA: 16s - loss: 4.6697 - acc: 0.02 - ETA: 15s - loss: 4.6709 - acc: 0.02 - ETA: 15s - loss: 4.6719 - acc: 0.02 - ETA: 15s - loss: 4.6709 - acc: 0.02 - ETA: 15s - loss: 4.6704 - acc: 0.02 - ETA: 14s - loss: 4.6713 - acc: 0.02 - ETA: 14s - loss: 4.6713 - acc: 0.02 - ETA: 14s - loss: 4.6723 - acc: 0.02 - ETA: 14s - loss: 4.6725 - acc: 0.02 - ETA: 14s - loss: 4.6717 - acc: 0.02 - ETA: 13s - loss: 4.6715 - acc: 0.02 - ETA: 13s - loss: 4.6724 - acc: 0.02 - ETA: 13s - loss: 4.6729 - acc: 0.02 - ETA: 13s - loss: 4.6728 - acc: 0.02 - ETA: 13s - loss: 4.6728 - acc: 0.02 - ETA: 12s - loss: 4.6734 - acc: 0.02 - ETA: 12s - loss: 4.6729 - acc: 0.02 - ETA: 12s - loss: 4.6722 - acc: 0.02 - ETA: 12s - loss: 4.6720 - acc: 0.02 - ETA: 12s - loss: 4.6722 - acc: 0.02 - ETA: 11s - loss: 4.6717 - acc: 0.02 - ETA: 11s - loss: 4.6703 - acc: 0.02 - ETA: 11s - loss: 4.6696 - acc: 0.02 - ETA: 11s - loss: 4.6698 - acc: 0.02 - ETA: 10s - loss: 4.6694 - acc: 0.02 - ETA: 10s - loss: 4.6688 - acc: 0.02 - ETA: 10s - loss: 4.6683 - acc: 0.02 - ETA: 10s - loss: 4.6681 - acc: 0.02 - ETA: 10s - loss: 4.6686 - acc: 0.02 - ETA: 9s - loss: 4.6701 - acc: 0.0270 - ETA: 9s - loss: 4.6706 - acc: 0.026 - ETA: 9s - loss: 4.6706 - acc: 0.026 - ETA: 9s - loss: 4.6709 - acc: 0.026 - ETA: 9s - loss: 4.6709 - acc: 0.026 - ETA: 8s - loss: 4.6708 - acc: 0.026 - ETA: 8s - loss: 4.6704 - acc: 0.026 - ETA: 8s - loss: 4.6708 - acc: 0.026 - ETA: 8s - loss: 4.6710 - acc: 0.026 - ETA: 8s - loss: 4.6708 - acc: 0.026 - ETA: 7s - loss: 4.6706 - acc: 0.027 - ETA: 7s - loss: 4.6696 - acc: 0.027 - ETA: 7s - loss: 4.6700 - acc: 0.027 - ETA: 7s - loss: 4.6698 - acc: 0.027 - ETA: 6s - loss: 4.6691 - acc: 0.027 - ETA: 6s - loss: 4.6690 - acc: 0.027 - ETA: 6s - loss: 4.6692 - acc: 0.027 - ETA: 6s - loss: 4.6686 - acc: 0.027 - ETA: 6s - loss: 4.6679 - acc: 0.027 - ETA: 5s - loss: 4.6675 - acc: 0.027 - ETA: 5s - loss: 4.6673 - acc: 0.027 - ETA: 5s - loss: 4.6669 - acc: 0.027 - ETA: 5s - loss: 4.6673 - acc: 0.027 - ETA: 5s - loss: 4.6674 - acc: 0.027 - ETA: 4s - loss: 4.6675 - acc: 0.027 - ETA: 4s - loss: 4.6672 - acc: 0.027 - ETA: 4s - loss: 4.6670 - acc: 0.027 - ETA: 4s - loss: 4.6676 - acc: 0.028 - ETA: 4s - loss: 4.6671 - acc: 0.028 - ETA: 3s - loss: 4.6664 - acc: 0.028 - ETA: 3s - loss: 4.6663 - acc: 0.028 - ETA: 3s - loss: 4.6658 - acc: 0.028 - ETA: 3s - loss: 4.6659 - acc: 0.028 - ETA: 2s - loss: 4.6662 - acc: 0.028 - ETA: 2s - loss: 4.6668 - acc: 0.028 - ETA: 2s - loss: 4.6667 - acc: 0.028 - ETA: 2s - loss: 4.6665 - acc: 0.028 - ETA: 2s - loss: 4.6662 - acc: 0.028 - ETA: 1s - loss: 4.6651 - acc: 0.028 - ETA: 1s - loss: 4.6652 - acc: 0.027 - ETA: 1s - loss: 4.6647 - acc: 0.028 - ETA: 1s - loss: 4.6643 - acc: 0.028 - ETA: 1s - loss: 4.6644 - acc: 0.028 - ETA: 0s - loss: 4.6644 - acc: 0.028 - ETA: 0s - loss: 4.6650 - acc: 0.027 - ETA: 0s - loss: 4.6644 - acc: 0.027 - ETA: 0s - loss: 4.6648 - acc: 0.0279Epoch 00007: val_loss improved from 4.68962 to 4.66058, saving model to saved_models/weights.best.from_scratch.hdf5\n",
      "6680/6680 [==============================] - 73s - loss: 4.6641 - acc: 0.0278 - val_loss: 4.6606 - val_acc: 0.0311\n",
      "Epoch 9/32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4300/6680 [==================>...........] - ETA: 67s - loss: 4.9091 - acc: 0.0000e+ - ETA: 67s - loss: 4.5713 - acc: 0.0750   - ETA: 68s - loss: 4.4963 - acc: 0.05 - ETA: 69s - loss: 4.5854 - acc: 0.03 - ETA: 70s - loss: 4.5637 - acc: 0.05 - ETA: 69s - loss: 4.5552 - acc: 0.05 - ETA: 68s - loss: 4.5819 - acc: 0.05 - ETA: 68s - loss: 4.6024 - acc: 0.04 - ETA: 68s - loss: 4.6049 - acc: 0.03 - ETA: 68s - loss: 4.5887 - acc: 0.03 - ETA: 68s - loss: 4.5914 - acc: 0.03 - ETA: 67s - loss: 4.5900 - acc: 0.02 - ETA: 67s - loss: 4.5818 - acc: 0.03 - ETA: 67s - loss: 4.5819 - acc: 0.03 - ETA: 67s - loss: 4.5676 - acc: 0.03 - ETA: 67s - loss: 4.5659 - acc: 0.03 - ETA: 66s - loss: 4.5527 - acc: 0.03 - ETA: 66s - loss: 4.5625 - acc: 0.03 - ETA: 66s - loss: 4.5754 - acc: 0.02 - ETA: 66s - loss: 4.5767 - acc: 0.02 - ETA: 65s - loss: 4.5811 - acc: 0.02 - ETA: 65s - loss: 4.5840 - acc: 0.02 - ETA: 65s - loss: 4.5737 - acc: 0.03 - ETA: 65s - loss: 4.5724 - acc: 0.02 - ETA: 64s - loss: 4.5663 - acc: 0.03 - ETA: 64s - loss: 4.5626 - acc: 0.02 - ETA: 64s - loss: 4.5690 - acc: 0.02 - ETA: 64s - loss: 4.5686 - acc: 0.03 - ETA: 64s - loss: 4.5728 - acc: 0.02 - ETA: 63s - loss: 4.5713 - acc: 0.02 - ETA: 63s - loss: 4.5839 - acc: 0.02 - ETA: 63s - loss: 4.5840 - acc: 0.02 - ETA: 63s - loss: 4.5899 - acc: 0.02 - ETA: 63s - loss: 4.5917 - acc: 0.02 - ETA: 62s - loss: 4.5986 - acc: 0.02 - ETA: 62s - loss: 4.5976 - acc: 0.02 - ETA: 62s - loss: 4.6038 - acc: 0.02 - ETA: 62s - loss: 4.6030 - acc: 0.02 - ETA: 61s - loss: 4.6063 - acc: 0.02 - ETA: 61s - loss: 4.6122 - acc: 0.02 - ETA: 61s - loss: 4.6148 - acc: 0.02 - ETA: 61s - loss: 4.6127 - acc: 0.02 - ETA: 61s - loss: 4.6110 - acc: 0.02 - ETA: 60s - loss: 4.6072 - acc: 0.02 - ETA: 60s - loss: 4.6068 - acc: 0.02 - ETA: 60s - loss: 4.6047 - acc: 0.02 - ETA: 60s - loss: 4.6037 - acc: 0.02 - ETA: 59s - loss: 4.6077 - acc: 0.02 - ETA: 59s - loss: 4.6031 - acc: 0.02 - ETA: 59s - loss: 4.6053 - acc: 0.02 - ETA: 59s - loss: 4.6109 - acc: 0.02 - ETA: 59s - loss: 4.6081 - acc: 0.02 - ETA: 58s - loss: 4.6079 - acc: 0.02 - ETA: 58s - loss: 4.6097 - acc: 0.02 - ETA: 58s - loss: 4.6153 - acc: 0.02 - ETA: 58s - loss: 4.6148 - acc: 0.02 - ETA: 58s - loss: 4.6136 - acc: 0.02 - ETA: 57s - loss: 4.6135 - acc: 0.02 - ETA: 57s - loss: 4.6153 - acc: 0.02 - ETA: 57s - loss: 4.6165 - acc: 0.02 - ETA: 57s - loss: 4.6162 - acc: 0.02 - ETA: 57s - loss: 4.6198 - acc: 0.02 - ETA: 56s - loss: 4.6164 - acc: 0.02 - ETA: 56s - loss: 4.6181 - acc: 0.02 - ETA: 56s - loss: 4.6172 - acc: 0.02 - ETA: 56s - loss: 4.6186 - acc: 0.02 - ETA: 56s - loss: 4.6161 - acc: 0.02 - ETA: 55s - loss: 4.6180 - acc: 0.02 - ETA: 55s - loss: 4.6189 - acc: 0.02 - ETA: 55s - loss: 4.6236 - acc: 0.02 - ETA: 55s - loss: 4.6270 - acc: 0.02 - ETA: 54s - loss: 4.6276 - acc: 0.02 - ETA: 54s - loss: 4.6294 - acc: 0.02 - ETA: 54s - loss: 4.6303 - acc: 0.02 - ETA: 54s - loss: 4.6287 - acc: 0.02 - ETA: 54s - loss: 4.6287 - acc: 0.03 - ETA: 53s - loss: 4.6289 - acc: 0.02 - ETA: 53s - loss: 4.6308 - acc: 0.02 - ETA: 53s - loss: 4.6329 - acc: 0.02 - ETA: 53s - loss: 4.6330 - acc: 0.03 - ETA: 53s - loss: 4.6318 - acc: 0.03 - ETA: 52s - loss: 4.6319 - acc: 0.03 - ETA: 52s - loss: 4.6330 - acc: 0.03 - ETA: 52s - loss: 4.6303 - acc: 0.03 - ETA: 52s - loss: 4.6315 - acc: 0.03 - ETA: 52s - loss: 4.6315 - acc: 0.03 - ETA: 51s - loss: 4.6299 - acc: 0.03 - ETA: 51s - loss: 4.6276 - acc: 0.03 - ETA: 51s - loss: 4.6235 - acc: 0.03 - ETA: 51s - loss: 4.6265 - acc: 0.03 - ETA: 50s - loss: 4.6257 - acc: 0.03 - ETA: 50s - loss: 4.6215 - acc: 0.03 - ETA: 50s - loss: 4.6230 - acc: 0.03 - ETA: 50s - loss: 4.6247 - acc: 0.03 - ETA: 50s - loss: 4.6255 - acc: 0.03 - ETA: 49s - loss: 4.6253 - acc: 0.03 - ETA: 49s - loss: 4.6247 - acc: 0.03 - ETA: 49s - loss: 4.6241 - acc: 0.03 - ETA: 49s - loss: 4.6256 - acc: 0.03 - ETA: 49s - loss: 4.6267 - acc: 0.03 - ETA: 48s - loss: 4.6266 - acc: 0.03 - ETA: 48s - loss: 4.6263 - acc: 0.03 - ETA: 48s - loss: 4.6252 - acc: 0.03 - ETA: 48s - loss: 4.6272 - acc: 0.03 - ETA: 48s - loss: 4.6268 - acc: 0.03 - ETA: 47s - loss: 4.6275 - acc: 0.03 - ETA: 47s - loss: 4.6269 - acc: 0.03 - ETA: 47s - loss: 4.6269 - acc: 0.03 - ETA: 47s - loss: 4.6270 - acc: 0.03 - ETA: 46s - loss: 4.6274 - acc: 0.03 - ETA: 46s - loss: 4.6280 - acc: 0.03 - ETA: 46s - loss: 4.6254 - acc: 0.03 - ETA: 46s - loss: 4.6271 - acc: 0.03 - ETA: 46s - loss: 4.6260 - acc: 0.03 - ETA: 45s - loss: 4.6273 - acc: 0.03 - ETA: 45s - loss: 4.6275 - acc: 0.03 - ETA: 45s - loss: 4.6282 - acc: 0.03 - ETA: 45s - loss: 4.6288 - acc: 0.03 - ETA: 45s - loss: 4.6291 - acc: 0.03 - ETA: 44s - loss: 4.6300 - acc: 0.03 - ETA: 44s - loss: 4.6316 - acc: 0.03 - ETA: 44s - loss: 4.6306 - acc: 0.03 - ETA: 44s - loss: 4.6305 - acc: 0.03 - ETA: 44s - loss: 4.6307 - acc: 0.03 - ETA: 43s - loss: 4.6346 - acc: 0.03 - ETA: 43s - loss: 4.6361 - acc: 0.02 - ETA: 43s - loss: 4.6354 - acc: 0.03 - ETA: 43s - loss: 4.6353 - acc: 0.03 - ETA: 42s - loss: 4.6359 - acc: 0.02 - ETA: 42s - loss: 4.6364 - acc: 0.02 - ETA: 42s - loss: 4.6356 - acc: 0.02 - ETA: 42s - loss: 4.6356 - acc: 0.02 - ETA: 42s - loss: 4.6329 - acc: 0.03 - ETA: 41s - loss: 4.6336 - acc: 0.02 - ETA: 41s - loss: 4.6358 - acc: 0.02 - ETA: 41s - loss: 4.6363 - acc: 0.02 - ETA: 41s - loss: 4.6378 - acc: 0.02 - ETA: 41s - loss: 4.6370 - acc: 0.02 - ETA: 40s - loss: 4.6374 - acc: 0.02 - ETA: 40s - loss: 4.6380 - acc: 0.02 - ETA: 40s - loss: 4.6368 - acc: 0.03 - ETA: 40s - loss: 4.6368 - acc: 0.03 - ETA: 40s - loss: 4.6356 - acc: 0.03 - ETA: 39s - loss: 4.6354 - acc: 0.03 - ETA: 39s - loss: 4.6354 - acc: 0.03 - ETA: 39s - loss: 4.6353 - acc: 0.03 - ETA: 39s - loss: 4.6332 - acc: 0.03 - ETA: 39s - loss: 4.6352 - acc: 0.03 - ETA: 38s - loss: 4.6359 - acc: 0.03 - ETA: 38s - loss: 4.6361 - acc: 0.03 - ETA: 38s - loss: 4.6364 - acc: 0.03 - ETA: 38s - loss: 4.6356 - acc: 0.03 - ETA: 37s - loss: 4.6348 - acc: 0.03 - ETA: 37s - loss: 4.6336 - acc: 0.03 - ETA: 37s - loss: 4.6322 - acc: 0.03 - ETA: 37s - loss: 4.6320 - acc: 0.03 - ETA: 37s - loss: 4.6321 - acc: 0.03 - ETA: 36s - loss: 4.6317 - acc: 0.03 - ETA: 36s - loss: 4.6297 - acc: 0.03 - ETA: 36s - loss: 4.6294 - acc: 0.03 - ETA: 36s - loss: 4.6289 - acc: 0.03 - ETA: 36s - loss: 4.6289 - acc: 0.03 - ETA: 35s - loss: 4.6290 - acc: 0.03 - ETA: 35s - loss: 4.6288 - acc: 0.03 - ETA: 35s - loss: 4.6296 - acc: 0.03 - ETA: 35s - loss: 4.6283 - acc: 0.03 - ETA: 35s - loss: 4.6279 - acc: 0.03 - ETA: 34s - loss: 4.6274 - acc: 0.03 - ETA: 34s - loss: 4.6291 - acc: 0.03 - ETA: 34s - loss: 4.6315 - acc: 0.03 - ETA: 34s - loss: 4.6323 - acc: 0.03 - ETA: 33s - loss: 4.6333 - acc: 0.03 - ETA: 33s - loss: 4.6331 - acc: 0.03 - ETA: 33s - loss: 4.6330 - acc: 0.03 - ETA: 33s - loss: 4.6308 - acc: 0.03 - ETA: 33s - loss: 4.6312 - acc: 0.03 - ETA: 32s - loss: 4.6316 - acc: 0.03 - ETA: 32s - loss: 4.6313 - acc: 0.03 - ETA: 32s - loss: 4.6321 - acc: 0.03 - ETA: 32s - loss: 4.6325 - acc: 0.03 - ETA: 32s - loss: 4.6325 - acc: 0.03 - ETA: 31s - loss: 4.6326 - acc: 0.03 - ETA: 31s - loss: 4.6330 - acc: 0.03 - ETA: 31s - loss: 4.6329 - acc: 0.03 - ETA: 31s - loss: 4.6321 - acc: 0.03 - ETA: 31s - loss: 4.6325 - acc: 0.03 - ETA: 30s - loss: 4.6300 - acc: 0.03 - ETA: 30s - loss: 4.6294 - acc: 0.03 - ETA: 30s - loss: 4.6282 - acc: 0.03 - ETA: 30s - loss: 4.6273 - acc: 0.03 - ETA: 30s - loss: 4.6273 - acc: 0.03 - ETA: 29s - loss: 4.6263 - acc: 0.03 - ETA: 29s - loss: 4.6272 - acc: 0.03 - ETA: 29s - loss: 4.6267 - acc: 0.03 - ETA: 29s - loss: 4.6273 - acc: 0.03 - ETA: 28s - loss: 4.6263 - acc: 0.03 - ETA: 28s - loss: 4.6248 - acc: 0.03 - ETA: 28s - loss: 4.6240 - acc: 0.03 - ETA: 28s - loss: 4.6238 - acc: 0.03 - ETA: 28s - loss: 4.6246 - acc: 0.03 - ETA: 27s - loss: 4.6249 - acc: 0.03 - ETA: 27s - loss: 4.6236 - acc: 0.03 - ETA: 27s - loss: 4.6249 - acc: 0.03 - ETA: 27s - loss: 4.6245 - acc: 0.03 - ETA: 27s - loss: 4.6258 - acc: 0.03 - ETA: 26s - loss: 4.6258 - acc: 0.03 - ETA: 26s - loss: 4.6245 - acc: 0.03 - ETA: 26s - loss: 4.6245 - acc: 0.03 - ETA: 26s - loss: 4.6249 - acc: 0.03 - ETA: 26s - loss: 4.6242 - acc: 0.03 - ETA: 25s - loss: 4.6241 - acc: 0.03 - ETA: 25s - loss: 4.6242 - acc: 0.03 - ETA: 25s - loss: 4.6246 - acc: 0.03 - ETA: 25s - loss: 4.6247 - acc: 0.03 - ETA: 24s - loss: 4.6245 - acc: 0.0340"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6660/6680 [============================>.] - ETA: 24s - loss: 4.6238 - acc: 0.03 - ETA: 24s - loss: 4.6226 - acc: 0.03 - ETA: 24s - loss: 4.6240 - acc: 0.03 - ETA: 24s - loss: 4.6231 - acc: 0.03 - ETA: 23s - loss: 4.6238 - acc: 0.03 - ETA: 23s - loss: 4.6237 - acc: 0.03 - ETA: 23s - loss: 4.6230 - acc: 0.03 - ETA: 23s - loss: 4.6233 - acc: 0.03 - ETA: 23s - loss: 4.6234 - acc: 0.03 - ETA: 22s - loss: 4.6256 - acc: 0.03 - ETA: 22s - loss: 4.6264 - acc: 0.03 - ETA: 22s - loss: 4.6269 - acc: 0.03 - ETA: 22s - loss: 4.6274 - acc: 0.03 - ETA: 22s - loss: 4.6273 - acc: 0.03 - ETA: 21s - loss: 4.6280 - acc: 0.03 - ETA: 21s - loss: 4.6287 - acc: 0.03 - ETA: 21s - loss: 4.6292 - acc: 0.03 - ETA: 21s - loss: 4.6287 - acc: 0.03 - ETA: 20s - loss: 4.6287 - acc: 0.03 - ETA: 20s - loss: 4.6291 - acc: 0.03 - ETA: 20s - loss: 4.6300 - acc: 0.03 - ETA: 20s - loss: 4.6297 - acc: 0.03 - ETA: 20s - loss: 4.6282 - acc: 0.03 - ETA: 19s - loss: 4.6279 - acc: 0.03 - ETA: 19s - loss: 4.6267 - acc: 0.03 - ETA: 19s - loss: 4.6259 - acc: 0.03 - ETA: 19s - loss: 4.6258 - acc: 0.03 - ETA: 19s - loss: 4.6249 - acc: 0.03 - ETA: 18s - loss: 4.6253 - acc: 0.03 - ETA: 18s - loss: 4.6257 - acc: 0.03 - ETA: 18s - loss: 4.6261 - acc: 0.03 - ETA: 18s - loss: 4.6262 - acc: 0.03 - ETA: 18s - loss: 4.6264 - acc: 0.03 - ETA: 17s - loss: 4.6261 - acc: 0.03 - ETA: 17s - loss: 4.6265 - acc: 0.03 - ETA: 17s - loss: 4.6273 - acc: 0.03 - ETA: 17s - loss: 4.6273 - acc: 0.03 - ETA: 16s - loss: 4.6276 - acc: 0.03 - ETA: 16s - loss: 4.6278 - acc: 0.03 - ETA: 16s - loss: 4.6269 - acc: 0.03 - ETA: 16s - loss: 4.6263 - acc: 0.03 - ETA: 16s - loss: 4.6266 - acc: 0.03 - ETA: 15s - loss: 4.6260 - acc: 0.03 - ETA: 15s - loss: 4.6253 - acc: 0.03 - ETA: 15s - loss: 4.6253 - acc: 0.03 - ETA: 15s - loss: 4.6254 - acc: 0.03 - ETA: 15s - loss: 4.6257 - acc: 0.03 - ETA: 14s - loss: 4.6261 - acc: 0.03 - ETA: 14s - loss: 4.6275 - acc: 0.03 - ETA: 14s - loss: 4.6271 - acc: 0.03 - ETA: 14s - loss: 4.6263 - acc: 0.03 - ETA: 14s - loss: 4.6256 - acc: 0.03 - ETA: 13s - loss: 4.6261 - acc: 0.03 - ETA: 13s - loss: 4.6256 - acc: 0.03 - ETA: 13s - loss: 4.6268 - acc: 0.03 - ETA: 13s - loss: 4.6259 - acc: 0.03 - ETA: 13s - loss: 4.6260 - acc: 0.03 - ETA: 12s - loss: 4.6257 - acc: 0.03 - ETA: 12s - loss: 4.6250 - acc: 0.03 - ETA: 12s - loss: 4.6252 - acc: 0.03 - ETA: 12s - loss: 4.6257 - acc: 0.03 - ETA: 11s - loss: 4.6250 - acc: 0.03 - ETA: 11s - loss: 4.6244 - acc: 0.03 - ETA: 11s - loss: 4.6251 - acc: 0.03 - ETA: 11s - loss: 4.6246 - acc: 0.03 - ETA: 11s - loss: 4.6243 - acc: 0.03 - ETA: 10s - loss: 4.6251 - acc: 0.03 - ETA: 10s - loss: 4.6251 - acc: 0.03 - ETA: 10s - loss: 4.6256 - acc: 0.03 - ETA: 10s - loss: 4.6256 - acc: 0.03 - ETA: 10s - loss: 4.6259 - acc: 0.03 - ETA: 9s - loss: 4.6267 - acc: 0.0336 - ETA: 9s - loss: 4.6264 - acc: 0.033 - ETA: 9s - loss: 4.6254 - acc: 0.033 - ETA: 9s - loss: 4.6266 - acc: 0.034 - ETA: 9s - loss: 4.6260 - acc: 0.033 - ETA: 8s - loss: 4.6256 - acc: 0.034 - ETA: 8s - loss: 4.6263 - acc: 0.034 - ETA: 8s - loss: 4.6260 - acc: 0.033 - ETA: 8s - loss: 4.6256 - acc: 0.033 - ETA: 7s - loss: 4.6259 - acc: 0.033 - ETA: 7s - loss: 4.6261 - acc: 0.033 - ETA: 7s - loss: 4.6267 - acc: 0.033 - ETA: 7s - loss: 4.6263 - acc: 0.033 - ETA: 7s - loss: 4.6258 - acc: 0.033 - ETA: 6s - loss: 4.6259 - acc: 0.033 - ETA: 6s - loss: 4.6252 - acc: 0.033 - ETA: 6s - loss: 4.6245 - acc: 0.033 - ETA: 6s - loss: 4.6247 - acc: 0.033 - ETA: 6s - loss: 4.6240 - acc: 0.033 - ETA: 5s - loss: 4.6239 - acc: 0.033 - ETA: 5s - loss: 4.6240 - acc: 0.033 - ETA: 5s - loss: 4.6237 - acc: 0.033 - ETA: 5s - loss: 4.6237 - acc: 0.032 - ETA: 5s - loss: 4.6233 - acc: 0.032 - ETA: 4s - loss: 4.6232 - acc: 0.032 - ETA: 4s - loss: 4.6243 - acc: 0.032 - ETA: 4s - loss: 4.6242 - acc: 0.032 - ETA: 4s - loss: 4.6254 - acc: 0.032 - ETA: 3s - loss: 4.6251 - acc: 0.032 - ETA: 3s - loss: 4.6251 - acc: 0.032 - ETA: 3s - loss: 4.6244 - acc: 0.033 - ETA: 3s - loss: 4.6244 - acc: 0.032 - ETA: 3s - loss: 4.6238 - acc: 0.033 - ETA: 2s - loss: 4.6241 - acc: 0.033 - ETA: 2s - loss: 4.6254 - acc: 0.033 - ETA: 2s - loss: 4.6253 - acc: 0.033 - ETA: 2s - loss: 4.6250 - acc: 0.033 - ETA: 2s - loss: 4.6254 - acc: 0.033 - ETA: 1s - loss: 4.6253 - acc: 0.033 - ETA: 1s - loss: 4.6254 - acc: 0.033 - ETA: 1s - loss: 4.6255 - acc: 0.033 - ETA: 1s - loss: 4.6258 - acc: 0.033 - ETA: 1s - loss: 4.6261 - acc: 0.033 - ETA: 0s - loss: 4.6252 - acc: 0.033 - ETA: 0s - loss: 4.6246 - acc: 0.033 - ETA: 0s - loss: 4.6240 - acc: 0.033 - ETA: 0s - loss: 4.6242 - acc: 0.0335Epoch 00008: val_loss improved from 4.66058 to 4.62569, saving model to saved_models/weights.best.from_scratch.hdf5\n",
      "6680/6680 [==============================] - 72s - loss: 4.6243 - acc: 0.0335 - val_loss: 4.6257 - val_acc: 0.0287\n",
      "Epoch 10/32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4300/6680 [==================>...........] - ETA: 70s - loss: 4.6792 - acc: 0.0000e+ - ETA: 69s - loss: 4.7267 - acc: 0.0000e+ - ETA: 69s - loss: 4.6900 - acc: 0.0167   - ETA: 68s - loss: 4.5846 - acc: 0.03 - ETA: 68s - loss: 4.5683 - acc: 0.03 - ETA: 68s - loss: 4.6002 - acc: 0.02 - ETA: 68s - loss: 4.6289 - acc: 0.02 - ETA: 68s - loss: 4.6081 - acc: 0.03 - ETA: 68s - loss: 4.5845 - acc: 0.03 - ETA: 68s - loss: 4.5580 - acc: 0.04 - ETA: 67s - loss: 4.5657 - acc: 0.03 - ETA: 67s - loss: 4.5491 - acc: 0.03 - ETA: 67s - loss: 4.5450 - acc: 0.03 - ETA: 67s - loss: 4.5448 - acc: 0.03 - ETA: 67s - loss: 4.5256 - acc: 0.03 - ETA: 66s - loss: 4.4917 - acc: 0.04 - ETA: 66s - loss: 4.4995 - acc: 0.03 - ETA: 66s - loss: 4.5166 - acc: 0.03 - ETA: 66s - loss: 4.5228 - acc: 0.03 - ETA: 66s - loss: 4.5250 - acc: 0.03 - ETA: 65s - loss: 4.5245 - acc: 0.03 - ETA: 65s - loss: 4.5248 - acc: 0.03 - ETA: 65s - loss: 4.5378 - acc: 0.03 - ETA: 65s - loss: 4.5338 - acc: 0.03 - ETA: 65s - loss: 4.5400 - acc: 0.03 - ETA: 64s - loss: 4.5410 - acc: 0.02 - ETA: 64s - loss: 4.5381 - acc: 0.02 - ETA: 64s - loss: 4.5303 - acc: 0.02 - ETA: 64s - loss: 4.5314 - acc: 0.02 - ETA: 64s - loss: 4.5302 - acc: 0.02 - ETA: 63s - loss: 4.5405 - acc: 0.02 - ETA: 63s - loss: 4.5407 - acc: 0.02 - ETA: 63s - loss: 4.5422 - acc: 0.02 - ETA: 63s - loss: 4.5438 - acc: 0.02 - ETA: 63s - loss: 4.5480 - acc: 0.02 - ETA: 62s - loss: 4.5586 - acc: 0.02 - ETA: 62s - loss: 4.5612 - acc: 0.02 - ETA: 62s - loss: 4.5652 - acc: 0.02 - ETA: 62s - loss: 4.5684 - acc: 0.02 - ETA: 61s - loss: 4.5707 - acc: 0.02 - ETA: 61s - loss: 4.5702 - acc: 0.02 - ETA: 61s - loss: 4.5649 - acc: 0.02 - ETA: 61s - loss: 4.5676 - acc: 0.03 - ETA: 61s - loss: 4.5642 - acc: 0.03 - ETA: 60s - loss: 4.5603 - acc: 0.03 - ETA: 60s - loss: 4.5625 - acc: 0.03 - ETA: 60s - loss: 4.5669 - acc: 0.03 - ETA: 60s - loss: 4.5699 - acc: 0.03 - ETA: 59s - loss: 4.5697 - acc: 0.03 - ETA: 59s - loss: 4.5638 - acc: 0.03 - ETA: 59s - loss: 4.5611 - acc: 0.03 - ETA: 59s - loss: 4.5627 - acc: 0.03 - ETA: 59s - loss: 4.5618 - acc: 0.03 - ETA: 58s - loss: 4.5584 - acc: 0.03 - ETA: 58s - loss: 4.5626 - acc: 0.03 - ETA: 58s - loss: 4.5626 - acc: 0.03 - ETA: 58s - loss: 4.5700 - acc: 0.03 - ETA: 58s - loss: 4.5694 - acc: 0.03 - ETA: 57s - loss: 4.5698 - acc: 0.03 - ETA: 57s - loss: 4.5667 - acc: 0.03 - ETA: 57s - loss: 4.5669 - acc: 0.03 - ETA: 57s - loss: 4.5668 - acc: 0.03 - ETA: 56s - loss: 4.5630 - acc: 0.03 - ETA: 56s - loss: 4.5644 - acc: 0.03 - ETA: 56s - loss: 4.5636 - acc: 0.03 - ETA: 56s - loss: 4.5608 - acc: 0.03 - ETA: 56s - loss: 4.5587 - acc: 0.03 - ETA: 55s - loss: 4.5598 - acc: 0.03 - ETA: 55s - loss: 4.5621 - acc: 0.03 - ETA: 55s - loss: 4.5632 - acc: 0.03 - ETA: 55s - loss: 4.5648 - acc: 0.03 - ETA: 55s - loss: 4.5636 - acc: 0.03 - ETA: 54s - loss: 4.5625 - acc: 0.03 - ETA: 54s - loss: 4.5594 - acc: 0.03 - ETA: 54s - loss: 4.5590 - acc: 0.03 - ETA: 54s - loss: 4.5589 - acc: 0.03 - ETA: 54s - loss: 4.5582 - acc: 0.03 - ETA: 53s - loss: 4.5568 - acc: 0.03 - ETA: 53s - loss: 4.5600 - acc: 0.03 - ETA: 53s - loss: 4.5585 - acc: 0.03 - ETA: 53s - loss: 4.5588 - acc: 0.03 - ETA: 53s - loss: 4.5663 - acc: 0.03 - ETA: 52s - loss: 4.5708 - acc: 0.03 - ETA: 52s - loss: 4.5729 - acc: 0.03 - ETA: 52s - loss: 4.5709 - acc: 0.03 - ETA: 52s - loss: 4.5700 - acc: 0.03 - ETA: 52s - loss: 4.5685 - acc: 0.03 - ETA: 51s - loss: 4.5714 - acc: 0.03 - ETA: 51s - loss: 4.5713 - acc: 0.03 - ETA: 51s - loss: 4.5700 - acc: 0.03 - ETA: 51s - loss: 4.5705 - acc: 0.03 - ETA: 51s - loss: 4.5701 - acc: 0.03 - ETA: 50s - loss: 4.5707 - acc: 0.03 - ETA: 50s - loss: 4.5698 - acc: 0.03 - ETA: 50s - loss: 4.5717 - acc: 0.03 - ETA: 50s - loss: 4.5727 - acc: 0.03 - ETA: 49s - loss: 4.5728 - acc: 0.03 - ETA: 49s - loss: 4.5730 - acc: 0.03 - ETA: 49s - loss: 4.5729 - acc: 0.03 - ETA: 49s - loss: 4.5759 - acc: 0.03 - ETA: 49s - loss: 4.5748 - acc: 0.03 - ETA: 48s - loss: 4.5742 - acc: 0.03 - ETA: 48s - loss: 4.5733 - acc: 0.03 - ETA: 48s - loss: 4.5717 - acc: 0.03 - ETA: 48s - loss: 4.5735 - acc: 0.03 - ETA: 48s - loss: 4.5742 - acc: 0.03 - ETA: 47s - loss: 4.5739 - acc: 0.03 - ETA: 47s - loss: 4.5723 - acc: 0.03 - ETA: 47s - loss: 4.5732 - acc: 0.03 - ETA: 47s - loss: 4.5746 - acc: 0.03 - ETA: 47s - loss: 4.5746 - acc: 0.03 - ETA: 46s - loss: 4.5754 - acc: 0.03 - ETA: 46s - loss: 4.5753 - acc: 0.03 - ETA: 46s - loss: 4.5741 - acc: 0.03 - ETA: 46s - loss: 4.5754 - acc: 0.03 - ETA: 46s - loss: 4.5745 - acc: 0.03 - ETA: 45s - loss: 4.5751 - acc: 0.03 - ETA: 45s - loss: 4.5767 - acc: 0.03 - ETA: 45s - loss: 4.5761 - acc: 0.03 - ETA: 45s - loss: 4.5765 - acc: 0.03 - ETA: 45s - loss: 4.5771 - acc: 0.03 - ETA: 44s - loss: 4.5760 - acc: 0.03 - ETA: 44s - loss: 4.5791 - acc: 0.03 - ETA: 44s - loss: 4.5804 - acc: 0.03 - ETA: 44s - loss: 4.5798 - acc: 0.03 - ETA: 43s - loss: 4.5814 - acc: 0.03 - ETA: 43s - loss: 4.5809 - acc: 0.03 - ETA: 43s - loss: 4.5812 - acc: 0.03 - ETA: 43s - loss: 4.5820 - acc: 0.03 - ETA: 43s - loss: 4.5817 - acc: 0.03 - ETA: 42s - loss: 4.5794 - acc: 0.03 - ETA: 42s - loss: 4.5785 - acc: 0.03 - ETA: 42s - loss: 4.5777 - acc: 0.03 - ETA: 42s - loss: 4.5759 - acc: 0.03 - ETA: 42s - loss: 4.5759 - acc: 0.03 - ETA: 41s - loss: 4.5778 - acc: 0.03 - ETA: 41s - loss: 4.5775 - acc: 0.03 - ETA: 41s - loss: 4.5785 - acc: 0.03 - ETA: 41s - loss: 4.5798 - acc: 0.03 - ETA: 40s - loss: 4.5807 - acc: 0.03 - ETA: 40s - loss: 4.5808 - acc: 0.03 - ETA: 40s - loss: 4.5808 - acc: 0.03 - ETA: 40s - loss: 4.5802 - acc: 0.03 - ETA: 40s - loss: 4.5810 - acc: 0.03 - ETA: 39s - loss: 4.5820 - acc: 0.03 - ETA: 39s - loss: 4.5817 - acc: 0.03 - ETA: 39s - loss: 4.5811 - acc: 0.03 - ETA: 39s - loss: 4.5822 - acc: 0.03 - ETA: 39s - loss: 4.5813 - acc: 0.03 - ETA: 38s - loss: 4.5812 - acc: 0.03 - ETA: 38s - loss: 4.5814 - acc: 0.03 - ETA: 38s - loss: 4.5837 - acc: 0.03 - ETA: 38s - loss: 4.5833 - acc: 0.03 - ETA: 38s - loss: 4.5838 - acc: 0.03 - ETA: 37s - loss: 4.5843 - acc: 0.03 - ETA: 37s - loss: 4.5854 - acc: 0.03 - ETA: 37s - loss: 4.5841 - acc: 0.03 - ETA: 37s - loss: 4.5847 - acc: 0.03 - ETA: 37s - loss: 4.5845 - acc: 0.03 - ETA: 36s - loss: 4.5839 - acc: 0.03 - ETA: 36s - loss: 4.5853 - acc: 0.03 - ETA: 36s - loss: 4.5852 - acc: 0.03 - ETA: 36s - loss: 4.5846 - acc: 0.03 - ETA: 35s - loss: 4.5834 - acc: 0.03 - ETA: 35s - loss: 4.5831 - acc: 0.03 - ETA: 35s - loss: 4.5815 - acc: 0.03 - ETA: 35s - loss: 4.5805 - acc: 0.03 - ETA: 35s - loss: 4.5820 - acc: 0.03 - ETA: 34s - loss: 4.5822 - acc: 0.03 - ETA: 34s - loss: 4.5816 - acc: 0.03 - ETA: 34s - loss: 4.5825 - acc: 0.03 - ETA: 34s - loss: 4.5831 - acc: 0.03 - ETA: 34s - loss: 4.5817 - acc: 0.03 - ETA: 33s - loss: 4.5807 - acc: 0.03 - ETA: 33s - loss: 4.5800 - acc: 0.03 - ETA: 33s - loss: 4.5793 - acc: 0.03 - ETA: 33s - loss: 4.5784 - acc: 0.03 - ETA: 32s - loss: 4.5779 - acc: 0.03 - ETA: 32s - loss: 4.5766 - acc: 0.03 - ETA: 32s - loss: 4.5776 - acc: 0.03 - ETA: 32s - loss: 4.5777 - acc: 0.03 - ETA: 32s - loss: 4.5776 - acc: 0.03 - ETA: 31s - loss: 4.5784 - acc: 0.03 - ETA: 31s - loss: 4.5775 - acc: 0.03 - ETA: 31s - loss: 4.5784 - acc: 0.03 - ETA: 31s - loss: 4.5795 - acc: 0.03 - ETA: 31s - loss: 4.5790 - acc: 0.03 - ETA: 30s - loss: 4.5783 - acc: 0.03 - ETA: 30s - loss: 4.5780 - acc: 0.03 - ETA: 30s - loss: 4.5769 - acc: 0.03 - ETA: 30s - loss: 4.5786 - acc: 0.03 - ETA: 30s - loss: 4.5784 - acc: 0.03 - ETA: 29s - loss: 4.5764 - acc: 0.03 - ETA: 29s - loss: 4.5781 - acc: 0.03 - ETA: 29s - loss: 4.5771 - acc: 0.03 - ETA: 29s - loss: 4.5766 - acc: 0.03 - ETA: 28s - loss: 4.5754 - acc: 0.03 - ETA: 28s - loss: 4.5764 - acc: 0.03 - ETA: 28s - loss: 4.5759 - acc: 0.03 - ETA: 28s - loss: 4.5761 - acc: 0.03 - ETA: 28s - loss: 4.5756 - acc: 0.03 - ETA: 27s - loss: 4.5750 - acc: 0.03 - ETA: 27s - loss: 4.5752 - acc: 0.03 - ETA: 27s - loss: 4.5748 - acc: 0.03 - ETA: 27s - loss: 4.5740 - acc: 0.03 - ETA: 27s - loss: 4.5743 - acc: 0.03 - ETA: 26s - loss: 4.5752 - acc: 0.03 - ETA: 26s - loss: 4.5752 - acc: 0.03 - ETA: 26s - loss: 4.5768 - acc: 0.03 - ETA: 26s - loss: 4.5772 - acc: 0.03 - ETA: 26s - loss: 4.5785 - acc: 0.03 - ETA: 25s - loss: 4.5782 - acc: 0.03 - ETA: 25s - loss: 4.5776 - acc: 0.03 - ETA: 25s - loss: 4.5764 - acc: 0.03 - ETA: 25s - loss: 4.5765 - acc: 0.0379"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6660/6680 [============================>.] - ETA: 24s - loss: 4.5769 - acc: 0.03 - ETA: 24s - loss: 4.5770 - acc: 0.03 - ETA: 24s - loss: 4.5786 - acc: 0.03 - ETA: 24s - loss: 4.5786 - acc: 0.03 - ETA: 24s - loss: 4.5787 - acc: 0.03 - ETA: 23s - loss: 4.5781 - acc: 0.03 - ETA: 23s - loss: 4.5780 - acc: 0.03 - ETA: 23s - loss: 4.5790 - acc: 0.03 - ETA: 23s - loss: 4.5790 - acc: 0.03 - ETA: 23s - loss: 4.5800 - acc: 0.03 - ETA: 22s - loss: 4.5802 - acc: 0.03 - ETA: 22s - loss: 4.5800 - acc: 0.03 - ETA: 22s - loss: 4.5795 - acc: 0.03 - ETA: 22s - loss: 4.5808 - acc: 0.03 - ETA: 21s - loss: 4.5804 - acc: 0.03 - ETA: 21s - loss: 4.5816 - acc: 0.03 - ETA: 21s - loss: 4.5819 - acc: 0.03 - ETA: 21s - loss: 4.5810 - acc: 0.03 - ETA: 21s - loss: 4.5807 - acc: 0.03 - ETA: 20s - loss: 4.5805 - acc: 0.03 - ETA: 20s - loss: 4.5787 - acc: 0.03 - ETA: 20s - loss: 4.5782 - acc: 0.03 - ETA: 20s - loss: 4.5780 - acc: 0.03 - ETA: 20s - loss: 4.5780 - acc: 0.03 - ETA: 19s - loss: 4.5783 - acc: 0.03 - ETA: 19s - loss: 4.5773 - acc: 0.03 - ETA: 19s - loss: 4.5778 - acc: 0.03 - ETA: 19s - loss: 4.5784 - acc: 0.03 - ETA: 19s - loss: 4.5794 - acc: 0.03 - ETA: 18s - loss: 4.5793 - acc: 0.03 - ETA: 18s - loss: 4.5785 - acc: 0.03 - ETA: 18s - loss: 4.5799 - acc: 0.03 - ETA: 18s - loss: 4.5793 - acc: 0.03 - ETA: 17s - loss: 4.5801 - acc: 0.03 - ETA: 17s - loss: 4.5790 - acc: 0.03 - ETA: 17s - loss: 4.5795 - acc: 0.03 - ETA: 17s - loss: 4.5798 - acc: 0.03 - ETA: 17s - loss: 4.5799 - acc: 0.03 - ETA: 16s - loss: 4.5801 - acc: 0.03 - ETA: 16s - loss: 4.5810 - acc: 0.03 - ETA: 16s - loss: 4.5816 - acc: 0.03 - ETA: 16s - loss: 4.5819 - acc: 0.03 - ETA: 16s - loss: 4.5820 - acc: 0.03 - ETA: 15s - loss: 4.5823 - acc: 0.03 - ETA: 15s - loss: 4.5820 - acc: 0.03 - ETA: 15s - loss: 4.5820 - acc: 0.03 - ETA: 15s - loss: 4.5814 - acc: 0.03 - ETA: 14s - loss: 4.5820 - acc: 0.03 - ETA: 14s - loss: 4.5816 - acc: 0.03 - ETA: 14s - loss: 4.5810 - acc: 0.03 - ETA: 14s - loss: 4.5818 - acc: 0.03 - ETA: 14s - loss: 4.5830 - acc: 0.03 - ETA: 13s - loss: 4.5821 - acc: 0.03 - ETA: 13s - loss: 4.5821 - acc: 0.03 - ETA: 13s - loss: 4.5831 - acc: 0.03 - ETA: 13s - loss: 4.5830 - acc: 0.03 - ETA: 13s - loss: 4.5831 - acc: 0.03 - ETA: 12s - loss: 4.5828 - acc: 0.03 - ETA: 12s - loss: 4.5836 - acc: 0.03 - ETA: 12s - loss: 4.5834 - acc: 0.03 - ETA: 12s - loss: 4.5841 - acc: 0.03 - ETA: 12s - loss: 4.5846 - acc: 0.03 - ETA: 11s - loss: 4.5842 - acc: 0.03 - ETA: 11s - loss: 4.5838 - acc: 0.03 - ETA: 11s - loss: 4.5846 - acc: 0.03 - ETA: 11s - loss: 4.5854 - acc: 0.03 - ETA: 10s - loss: 4.5854 - acc: 0.03 - ETA: 10s - loss: 4.5842 - acc: 0.03 - ETA: 10s - loss: 4.5836 - acc: 0.03 - ETA: 10s - loss: 4.5827 - acc: 0.03 - ETA: 10s - loss: 4.5839 - acc: 0.03 - ETA: 9s - loss: 4.5838 - acc: 0.0387 - ETA: 9s - loss: 4.5838 - acc: 0.038 - ETA: 9s - loss: 4.5845 - acc: 0.038 - ETA: 9s - loss: 4.5845 - acc: 0.038 - ETA: 9s - loss: 4.5835 - acc: 0.038 - ETA: 8s - loss: 4.5843 - acc: 0.038 - ETA: 8s - loss: 4.5853 - acc: 0.038 - ETA: 8s - loss: 4.5855 - acc: 0.037 - ETA: 8s - loss: 4.5851 - acc: 0.038 - ETA: 8s - loss: 4.5857 - acc: 0.038 - ETA: 7s - loss: 4.5860 - acc: 0.037 - ETA: 7s - loss: 4.5858 - acc: 0.037 - ETA: 7s - loss: 4.5839 - acc: 0.038 - ETA: 7s - loss: 4.5855 - acc: 0.038 - ETA: 6s - loss: 4.5848 - acc: 0.038 - ETA: 6s - loss: 4.5849 - acc: 0.038 - ETA: 6s - loss: 4.5841 - acc: 0.038 - ETA: 6s - loss: 4.5840 - acc: 0.038 - ETA: 6s - loss: 4.5832 - acc: 0.039 - ETA: 5s - loss: 4.5821 - acc: 0.039 - ETA: 5s - loss: 4.5830 - acc: 0.039 - ETA: 5s - loss: 4.5843 - acc: 0.039 - ETA: 5s - loss: 4.5841 - acc: 0.039 - ETA: 5s - loss: 4.5848 - acc: 0.039 - ETA: 4s - loss: 4.5848 - acc: 0.039 - ETA: 4s - loss: 4.5841 - acc: 0.039 - ETA: 4s - loss: 4.5835 - acc: 0.039 - ETA: 4s - loss: 4.5847 - acc: 0.039 - ETA: 4s - loss: 4.5842 - acc: 0.039 - ETA: 3s - loss: 4.5851 - acc: 0.039 - ETA: 3s - loss: 4.5853 - acc: 0.039 - ETA: 3s - loss: 4.5839 - acc: 0.039 - ETA: 3s - loss: 4.5833 - acc: 0.039 - ETA: 2s - loss: 4.5835 - acc: 0.039 - ETA: 2s - loss: 4.5832 - acc: 0.039 - ETA: 2s - loss: 4.5848 - acc: 0.039 - ETA: 2s - loss: 4.5846 - acc: 0.039 - ETA: 2s - loss: 4.5847 - acc: 0.039 - ETA: 1s - loss: 4.5851 - acc: 0.039 - ETA: 1s - loss: 4.5851 - acc: 0.039 - ETA: 1s - loss: 4.5849 - acc: 0.039 - ETA: 1s - loss: 4.5847 - acc: 0.039 - ETA: 1s - loss: 4.5843 - acc: 0.039 - ETA: 0s - loss: 4.5841 - acc: 0.039 - ETA: 0s - loss: 4.5840 - acc: 0.039 - ETA: 0s - loss: 4.5836 - acc: 0.039 - ETA: 0s - loss: 4.5822 - acc: 0.0398Epoch 00009: val_loss did not improve\n",
      "6680/6680 [==============================] - 73s - loss: 4.5831 - acc: 0.0397 - val_loss: 4.6378 - val_acc: 0.0395\n",
      "Epoch 11/32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4300/6680 [==================>...........] - ETA: 66s - loss: 4.3231 - acc: 0.10 - ETA: 66s - loss: 4.4400 - acc: 0.12 - ETA: 68s - loss: 4.5695 - acc: 0.08 - ETA: 68s - loss: 4.5940 - acc: 0.10 - ETA: 68s - loss: 4.6131 - acc: 0.09 - ETA: 68s - loss: 4.5731 - acc: 0.08 - ETA: 68s - loss: 4.5593 - acc: 0.07 - ETA: 67s - loss: 4.6088 - acc: 0.06 - ETA: 67s - loss: 4.6116 - acc: 0.06 - ETA: 67s - loss: 4.5995 - acc: 0.05 - ETA: 67s - loss: 4.6038 - acc: 0.05 - ETA: 66s - loss: 4.5876 - acc: 0.05 - ETA: 66s - loss: 4.6034 - acc: 0.05 - ETA: 66s - loss: 4.5997 - acc: 0.05 - ETA: 66s - loss: 4.6225 - acc: 0.05 - ETA: 66s - loss: 4.6259 - acc: 0.05 - ETA: 65s - loss: 4.6368 - acc: 0.05 - ETA: 65s - loss: 4.6309 - acc: 0.05 - ETA: 65s - loss: 4.6202 - acc: 0.04 - ETA: 65s - loss: 4.6164 - acc: 0.04 - ETA: 65s - loss: 4.6050 - acc: 0.04 - ETA: 64s - loss: 4.6131 - acc: 0.04 - ETA: 64s - loss: 4.6080 - acc: 0.04 - ETA: 64s - loss: 4.5942 - acc: 0.04 - ETA: 64s - loss: 4.6027 - acc: 0.04 - ETA: 64s - loss: 4.5969 - acc: 0.04 - ETA: 64s - loss: 4.6009 - acc: 0.04 - ETA: 63s - loss: 4.5925 - acc: 0.04 - ETA: 63s - loss: 4.5951 - acc: 0.04 - ETA: 63s - loss: 4.5837 - acc: 0.04 - ETA: 63s - loss: 4.5853 - acc: 0.04 - ETA: 63s - loss: 4.5873 - acc: 0.04 - ETA: 62s - loss: 4.5955 - acc: 0.04 - ETA: 62s - loss: 4.6042 - acc: 0.04 - ETA: 62s - loss: 4.6028 - acc: 0.04 - ETA: 62s - loss: 4.6007 - acc: 0.04 - ETA: 61s - loss: 4.5979 - acc: 0.04 - ETA: 61s - loss: 4.5940 - acc: 0.04 - ETA: 61s - loss: 4.5920 - acc: 0.04 - ETA: 61s - loss: 4.5852 - acc: 0.04 - ETA: 61s - loss: 4.5871 - acc: 0.04 - ETA: 60s - loss: 4.5825 - acc: 0.04 - ETA: 60s - loss: 4.5773 - acc: 0.04 - ETA: 60s - loss: 4.5751 - acc: 0.04 - ETA: 60s - loss: 4.5798 - acc: 0.04 - ETA: 60s - loss: 4.5759 - acc: 0.04 - ETA: 59s - loss: 4.5715 - acc: 0.04 - ETA: 59s - loss: 4.5719 - acc: 0.04 - ETA: 59s - loss: 4.5700 - acc: 0.04 - ETA: 59s - loss: 4.5718 - acc: 0.04 - ETA: 59s - loss: 4.5736 - acc: 0.04 - ETA: 58s - loss: 4.5806 - acc: 0.04 - ETA: 58s - loss: 4.5846 - acc: 0.04 - ETA: 58s - loss: 4.5892 - acc: 0.04 - ETA: 58s - loss: 4.5891 - acc: 0.04 - ETA: 58s - loss: 4.5819 - acc: 0.04 - ETA: 58s - loss: 4.5844 - acc: 0.04 - ETA: 57s - loss: 4.5841 - acc: 0.04 - ETA: 57s - loss: 4.5809 - acc: 0.04 - ETA: 57s - loss: 4.5807 - acc: 0.04 - ETA: 57s - loss: 4.5751 - acc: 0.04 - ETA: 57s - loss: 4.5731 - acc: 0.04 - ETA: 56s - loss: 4.5719 - acc: 0.04 - ETA: 56s - loss: 4.5721 - acc: 0.04 - ETA: 56s - loss: 4.5759 - acc: 0.04 - ETA: 56s - loss: 4.5769 - acc: 0.04 - ETA: 56s - loss: 4.5708 - acc: 0.04 - ETA: 55s - loss: 4.5683 - acc: 0.04 - ETA: 55s - loss: 4.5661 - acc: 0.04 - ETA: 55s - loss: 4.5651 - acc: 0.04 - ETA: 55s - loss: 4.5648 - acc: 0.04 - ETA: 54s - loss: 4.5574 - acc: 0.04 - ETA: 54s - loss: 4.5568 - acc: 0.04 - ETA: 54s - loss: 4.5533 - acc: 0.04 - ETA: 54s - loss: 4.5514 - acc: 0.04 - ETA: 54s - loss: 4.5600 - acc: 0.04 - ETA: 53s - loss: 4.5611 - acc: 0.04 - ETA: 53s - loss: 4.5630 - acc: 0.04 - ETA: 53s - loss: 4.5608 - acc: 0.04 - ETA: 53s - loss: 4.5610 - acc: 0.04 - ETA: 53s - loss: 4.5621 - acc: 0.04 - ETA: 52s - loss: 4.5604 - acc: 0.04 - ETA: 52s - loss: 4.5617 - acc: 0.04 - ETA: 52s - loss: 4.5597 - acc: 0.04 - ETA: 52s - loss: 4.5555 - acc: 0.04 - ETA: 52s - loss: 4.5533 - acc: 0.04 - ETA: 51s - loss: 4.5599 - acc: 0.04 - ETA: 51s - loss: 4.5579 - acc: 0.04 - ETA: 51s - loss: 4.5596 - acc: 0.04 - ETA: 51s - loss: 4.5594 - acc: 0.04 - ETA: 51s - loss: 4.5629 - acc: 0.04 - ETA: 50s - loss: 4.5648 - acc: 0.04 - ETA: 50s - loss: 4.5659 - acc: 0.04 - ETA: 50s - loss: 4.5657 - acc: 0.04 - ETA: 50s - loss: 4.5660 - acc: 0.04 - ETA: 49s - loss: 4.5653 - acc: 0.04 - ETA: 49s - loss: 4.5642 - acc: 0.04 - ETA: 49s - loss: 4.5619 - acc: 0.04 - ETA: 49s - loss: 4.5626 - acc: 0.04 - ETA: 49s - loss: 4.5613 - acc: 0.04 - ETA: 48s - loss: 4.5608 - acc: 0.04 - ETA: 48s - loss: 4.5598 - acc: 0.04 - ETA: 48s - loss: 4.5600 - acc: 0.04 - ETA: 48s - loss: 4.5590 - acc: 0.04 - ETA: 48s - loss: 4.5574 - acc: 0.04 - ETA: 47s - loss: 4.5571 - acc: 0.04 - ETA: 47s - loss: 4.5565 - acc: 0.04 - ETA: 47s - loss: 4.5571 - acc: 0.04 - ETA: 47s - loss: 4.5560 - acc: 0.04 - ETA: 46s - loss: 4.5563 - acc: 0.04 - ETA: 46s - loss: 4.5563 - acc: 0.04 - ETA: 46s - loss: 4.5560 - acc: 0.04 - ETA: 46s - loss: 4.5537 - acc: 0.04 - ETA: 46s - loss: 4.5549 - acc: 0.04 - ETA: 45s - loss: 4.5532 - acc: 0.04 - ETA: 45s - loss: 4.5520 - acc: 0.04 - ETA: 45s - loss: 4.5524 - acc: 0.04 - ETA: 45s - loss: 4.5511 - acc: 0.04 - ETA: 45s - loss: 4.5513 - acc: 0.04 - ETA: 44s - loss: 4.5527 - acc: 0.04 - ETA: 44s - loss: 4.5515 - acc: 0.04 - ETA: 44s - loss: 4.5504 - acc: 0.04 - ETA: 44s - loss: 4.5525 - acc: 0.04 - ETA: 44s - loss: 4.5531 - acc: 0.04 - ETA: 43s - loss: 4.5525 - acc: 0.04 - ETA: 43s - loss: 4.5550 - acc: 0.04 - ETA: 43s - loss: 4.5561 - acc: 0.04 - ETA: 43s - loss: 4.5557 - acc: 0.04 - ETA: 43s - loss: 4.5565 - acc: 0.04 - ETA: 42s - loss: 4.5559 - acc: 0.04 - ETA: 42s - loss: 4.5545 - acc: 0.04 - ETA: 42s - loss: 4.5559 - acc: 0.04 - ETA: 42s - loss: 4.5556 - acc: 0.04 - ETA: 41s - loss: 4.5553 - acc: 0.04 - ETA: 41s - loss: 4.5550 - acc: 0.04 - ETA: 41s - loss: 4.5559 - acc: 0.04 - ETA: 41s - loss: 4.5550 - acc: 0.04 - ETA: 41s - loss: 4.5521 - acc: 0.04 - ETA: 40s - loss: 4.5526 - acc: 0.04 - ETA: 40s - loss: 4.5530 - acc: 0.04 - ETA: 40s - loss: 4.5513 - acc: 0.04 - ETA: 40s - loss: 4.5497 - acc: 0.04 - ETA: 40s - loss: 4.5495 - acc: 0.04 - ETA: 39s - loss: 4.5495 - acc: 0.04 - ETA: 39s - loss: 4.5510 - acc: 0.04 - ETA: 39s - loss: 4.5500 - acc: 0.04 - ETA: 39s - loss: 4.5518 - acc: 0.04 - ETA: 39s - loss: 4.5523 - acc: 0.04 - ETA: 38s - loss: 4.5497 - acc: 0.04 - ETA: 38s - loss: 4.5485 - acc: 0.04 - ETA: 38s - loss: 4.5515 - acc: 0.04 - ETA: 38s - loss: 4.5535 - acc: 0.04 - ETA: 37s - loss: 4.5549 - acc: 0.04 - ETA: 37s - loss: 4.5540 - acc: 0.04 - ETA: 37s - loss: 4.5565 - acc: 0.04 - ETA: 37s - loss: 4.5570 - acc: 0.04 - ETA: 37s - loss: 4.5569 - acc: 0.04 - ETA: 36s - loss: 4.5567 - acc: 0.04 - ETA: 36s - loss: 4.5585 - acc: 0.04 - ETA: 36s - loss: 4.5575 - acc: 0.04 - ETA: 36s - loss: 4.5575 - acc: 0.04 - ETA: 36s - loss: 4.5559 - acc: 0.04 - ETA: 35s - loss: 4.5545 - acc: 0.04 - ETA: 35s - loss: 4.5535 - acc: 0.04 - ETA: 35s - loss: 4.5538 - acc: 0.04 - ETA: 35s - loss: 4.5545 - acc: 0.04 - ETA: 35s - loss: 4.5547 - acc: 0.04 - ETA: 34s - loss: 4.5556 - acc: 0.04 - ETA: 34s - loss: 4.5552 - acc: 0.04 - ETA: 34s - loss: 4.5551 - acc: 0.04 - ETA: 34s - loss: 4.5555 - acc: 0.04 - ETA: 33s - loss: 4.5546 - acc: 0.04 - ETA: 33s - loss: 4.5536 - acc: 0.04 - ETA: 33s - loss: 4.5545 - acc: 0.04 - ETA: 33s - loss: 4.5538 - acc: 0.04 - ETA: 33s - loss: 4.5526 - acc: 0.04 - ETA: 32s - loss: 4.5531 - acc: 0.04 - ETA: 32s - loss: 4.5526 - acc: 0.04 - ETA: 32s - loss: 4.5537 - acc: 0.04 - ETA: 32s - loss: 4.5550 - acc: 0.04 - ETA: 32s - loss: 4.5557 - acc: 0.04 - ETA: 31s - loss: 4.5552 - acc: 0.04 - ETA: 31s - loss: 4.5554 - acc: 0.04 - ETA: 31s - loss: 4.5552 - acc: 0.04 - ETA: 31s - loss: 4.5541 - acc: 0.04 - ETA: 31s - loss: 4.5539 - acc: 0.04 - ETA: 30s - loss: 4.5536 - acc: 0.04 - ETA: 30s - loss: 4.5531 - acc: 0.04 - ETA: 30s - loss: 4.5534 - acc: 0.04 - ETA: 30s - loss: 4.5550 - acc: 0.04 - ETA: 30s - loss: 4.5549 - acc: 0.04 - ETA: 29s - loss: 4.5549 - acc: 0.04 - ETA: 29s - loss: 4.5542 - acc: 0.04 - ETA: 29s - loss: 4.5529 - acc: 0.04 - ETA: 29s - loss: 4.5514 - acc: 0.04 - ETA: 28s - loss: 4.5512 - acc: 0.04 - ETA: 28s - loss: 4.5505 - acc: 0.04 - ETA: 28s - loss: 4.5505 - acc: 0.04 - ETA: 28s - loss: 4.5504 - acc: 0.04 - ETA: 28s - loss: 4.5490 - acc: 0.04 - ETA: 27s - loss: 4.5496 - acc: 0.04 - ETA: 27s - loss: 4.5488 - acc: 0.04 - ETA: 27s - loss: 4.5483 - acc: 0.04 - ETA: 27s - loss: 4.5486 - acc: 0.04 - ETA: 27s - loss: 4.5501 - acc: 0.03 - ETA: 26s - loss: 4.5498 - acc: 0.04 - ETA: 26s - loss: 4.5496 - acc: 0.03 - ETA: 26s - loss: 4.5488 - acc: 0.03 - ETA: 26s - loss: 4.5484 - acc: 0.04 - ETA: 26s - loss: 4.5478 - acc: 0.04 - ETA: 25s - loss: 4.5478 - acc: 0.03 - ETA: 25s - loss: 4.5461 - acc: 0.03 - ETA: 25s - loss: 4.5454 - acc: 0.03 - ETA: 25s - loss: 4.5467 - acc: 0.03 - ETA: 24s - loss: 4.5469 - acc: 0.0393"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6660/6680 [============================>.] - ETA: 24s - loss: 4.5449 - acc: 0.03 - ETA: 24s - loss: 4.5444 - acc: 0.03 - ETA: 24s - loss: 4.5436 - acc: 0.03 - ETA: 24s - loss: 4.5450 - acc: 0.03 - ETA: 23s - loss: 4.5454 - acc: 0.03 - ETA: 23s - loss: 4.5466 - acc: 0.03 - ETA: 23s - loss: 4.5472 - acc: 0.03 - ETA: 23s - loss: 4.5484 - acc: 0.03 - ETA: 23s - loss: 4.5481 - acc: 0.03 - ETA: 22s - loss: 4.5491 - acc: 0.03 - ETA: 22s - loss: 4.5491 - acc: 0.03 - ETA: 22s - loss: 4.5499 - acc: 0.03 - ETA: 22s - loss: 4.5498 - acc: 0.03 - ETA: 22s - loss: 4.5492 - acc: 0.03 - ETA: 21s - loss: 4.5507 - acc: 0.03 - ETA: 21s - loss: 4.5504 - acc: 0.03 - ETA: 21s - loss: 4.5495 - acc: 0.03 - ETA: 21s - loss: 4.5485 - acc: 0.03 - ETA: 20s - loss: 4.5476 - acc: 0.03 - ETA: 20s - loss: 4.5470 - acc: 0.03 - ETA: 20s - loss: 4.5464 - acc: 0.03 - ETA: 20s - loss: 4.5458 - acc: 0.03 - ETA: 20s - loss: 4.5465 - acc: 0.03 - ETA: 19s - loss: 4.5469 - acc: 0.03 - ETA: 19s - loss: 4.5464 - acc: 0.03 - ETA: 19s - loss: 4.5475 - acc: 0.03 - ETA: 19s - loss: 4.5470 - acc: 0.03 - ETA: 19s - loss: 4.5472 - acc: 0.03 - ETA: 18s - loss: 4.5481 - acc: 0.03 - ETA: 18s - loss: 4.5485 - acc: 0.03 - ETA: 18s - loss: 4.5483 - acc: 0.03 - ETA: 18s - loss: 4.5487 - acc: 0.03 - ETA: 18s - loss: 4.5484 - acc: 0.03 - ETA: 17s - loss: 4.5490 - acc: 0.03 - ETA: 17s - loss: 4.5477 - acc: 0.03 - ETA: 17s - loss: 4.5492 - acc: 0.03 - ETA: 17s - loss: 4.5489 - acc: 0.03 - ETA: 16s - loss: 4.5495 - acc: 0.03 - ETA: 16s - loss: 4.5497 - acc: 0.03 - ETA: 16s - loss: 4.5503 - acc: 0.03 - ETA: 16s - loss: 4.5495 - acc: 0.03 - ETA: 16s - loss: 4.5477 - acc: 0.03 - ETA: 15s - loss: 4.5479 - acc: 0.03 - ETA: 15s - loss: 4.5489 - acc: 0.03 - ETA: 15s - loss: 4.5481 - acc: 0.03 - ETA: 15s - loss: 4.5470 - acc: 0.03 - ETA: 15s - loss: 4.5487 - acc: 0.03 - ETA: 14s - loss: 4.5492 - acc: 0.03 - ETA: 14s - loss: 4.5492 - acc: 0.03 - ETA: 14s - loss: 4.5504 - acc: 0.03 - ETA: 14s - loss: 4.5496 - acc: 0.03 - ETA: 14s - loss: 4.5495 - acc: 0.03 - ETA: 13s - loss: 4.5487 - acc: 0.03 - ETA: 13s - loss: 4.5480 - acc: 0.03 - ETA: 13s - loss: 4.5486 - acc: 0.03 - ETA: 13s - loss: 4.5483 - acc: 0.03 - ETA: 13s - loss: 4.5480 - acc: 0.03 - ETA: 12s - loss: 4.5484 - acc: 0.03 - ETA: 12s - loss: 4.5488 - acc: 0.03 - ETA: 12s - loss: 4.5482 - acc: 0.03 - ETA: 12s - loss: 4.5482 - acc: 0.03 - ETA: 11s - loss: 4.5480 - acc: 0.03 - ETA: 11s - loss: 4.5482 - acc: 0.03 - ETA: 11s - loss: 4.5473 - acc: 0.03 - ETA: 11s - loss: 4.5469 - acc: 0.03 - ETA: 11s - loss: 4.5476 - acc: 0.03 - ETA: 10s - loss: 4.5488 - acc: 0.03 - ETA: 10s - loss: 4.5489 - acc: 0.03 - ETA: 10s - loss: 4.5479 - acc: 0.03 - ETA: 10s - loss: 4.5484 - acc: 0.03 - ETA: 10s - loss: 4.5479 - acc: 0.03 - ETA: 9s - loss: 4.5476 - acc: 0.0385 - ETA: 9s - loss: 4.5484 - acc: 0.038 - ETA: 9s - loss: 4.5468 - acc: 0.039 - ETA: 9s - loss: 4.5469 - acc: 0.039 - ETA: 9s - loss: 4.5465 - acc: 0.039 - ETA: 8s - loss: 4.5462 - acc: 0.039 - ETA: 8s - loss: 4.5451 - acc: 0.039 - ETA: 8s - loss: 4.5463 - acc: 0.039 - ETA: 8s - loss: 4.5470 - acc: 0.039 - ETA: 7s - loss: 4.5468 - acc: 0.039 - ETA: 7s - loss: 4.5464 - acc: 0.039 - ETA: 7s - loss: 4.5456 - acc: 0.039 - ETA: 7s - loss: 4.5460 - acc: 0.039 - ETA: 7s - loss: 4.5458 - acc: 0.039 - ETA: 6s - loss: 4.5452 - acc: 0.039 - ETA: 6s - loss: 4.5444 - acc: 0.039 - ETA: 6s - loss: 4.5440 - acc: 0.039 - ETA: 6s - loss: 4.5439 - acc: 0.039 - ETA: 6s - loss: 4.5429 - acc: 0.040 - ETA: 5s - loss: 4.5431 - acc: 0.040 - ETA: 5s - loss: 4.5436 - acc: 0.040 - ETA: 5s - loss: 4.5442 - acc: 0.039 - ETA: 5s - loss: 4.5443 - acc: 0.039 - ETA: 5s - loss: 4.5442 - acc: 0.040 - ETA: 4s - loss: 4.5451 - acc: 0.040 - ETA: 4s - loss: 4.5447 - acc: 0.040 - ETA: 4s - loss: 4.5441 - acc: 0.040 - ETA: 4s - loss: 4.5445 - acc: 0.040 - ETA: 3s - loss: 4.5461 - acc: 0.040 - ETA: 3s - loss: 4.5463 - acc: 0.040 - ETA: 3s - loss: 4.5465 - acc: 0.039 - ETA: 3s - loss: 4.5464 - acc: 0.039 - ETA: 3s - loss: 4.5464 - acc: 0.040 - ETA: 2s - loss: 4.5463 - acc: 0.040 - ETA: 2s - loss: 4.5468 - acc: 0.040 - ETA: 2s - loss: 4.5469 - acc: 0.040 - ETA: 2s - loss: 4.5473 - acc: 0.040 - ETA: 2s - loss: 4.5477 - acc: 0.040 - ETA: 1s - loss: 4.5473 - acc: 0.040 - ETA: 1s - loss: 4.5474 - acc: 0.040 - ETA: 1s - loss: 4.5475 - acc: 0.040 - ETA: 1s - loss: 4.5465 - acc: 0.039 - ETA: 1s - loss: 4.5467 - acc: 0.040 - ETA: 0s - loss: 4.5474 - acc: 0.040 - ETA: 0s - loss: 4.5481 - acc: 0.039 - ETA: 0s - loss: 4.5477 - acc: 0.039 - ETA: 0s - loss: 4.5476 - acc: 0.0401Epoch 00010: val_loss improved from 4.62569 to 4.57474, saving model to saved_models/weights.best.from_scratch.hdf5\n",
      "6680/6680 [==============================] - 72s - loss: 4.5473 - acc: 0.0403 - val_loss: 4.5747 - val_acc: 0.0539\n",
      "Epoch 12/32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4300/6680 [==================>...........] - ETA: 71s - loss: 4.6705 - acc: 0.0000e+ - ETA: 71s - loss: 4.4472 - acc: 0.0750   - ETA: 70s - loss: 4.5018 - acc: 0.05 - ETA: 69s - loss: 4.5447 - acc: 0.03 - ETA: 69s - loss: 4.5635 - acc: 0.05 - ETA: 69s - loss: 4.5064 - acc: 0.06 - ETA: 68s - loss: 4.4925 - acc: 0.07 - ETA: 68s - loss: 4.4315 - acc: 0.08 - ETA: 68s - loss: 4.4347 - acc: 0.07 - ETA: 68s - loss: 4.4629 - acc: 0.07 - ETA: 67s - loss: 4.4827 - acc: 0.07 - ETA: 67s - loss: 4.4848 - acc: 0.06 - ETA: 67s - loss: 4.4855 - acc: 0.06 - ETA: 67s - loss: 4.4736 - acc: 0.06 - ETA: 67s - loss: 4.4768 - acc: 0.06 - ETA: 66s - loss: 4.4769 - acc: 0.05 - ETA: 66s - loss: 4.4827 - acc: 0.05 - ETA: 66s - loss: 4.4898 - acc: 0.05 - ETA: 65s - loss: 4.4939 - acc: 0.05 - ETA: 65s - loss: 4.5017 - acc: 0.05 - ETA: 65s - loss: 4.4934 - acc: 0.05 - ETA: 65s - loss: 4.4896 - acc: 0.05 - ETA: 65s - loss: 4.5077 - acc: 0.05 - ETA: 64s - loss: 4.5006 - acc: 0.04 - ETA: 64s - loss: 4.4955 - acc: 0.04 - ETA: 64s - loss: 4.4941 - acc: 0.04 - ETA: 64s - loss: 4.4999 - acc: 0.04 - ETA: 64s - loss: 4.5042 - acc: 0.04 - ETA: 63s - loss: 4.4998 - acc: 0.04 - ETA: 63s - loss: 4.4940 - acc: 0.04 - ETA: 63s - loss: 4.4827 - acc: 0.04 - ETA: 63s - loss: 4.4877 - acc: 0.04 - ETA: 62s - loss: 4.4802 - acc: 0.04 - ETA: 62s - loss: 4.4970 - acc: 0.04 - ETA: 62s - loss: 4.5041 - acc: 0.04 - ETA: 62s - loss: 4.5025 - acc: 0.04 - ETA: 62s - loss: 4.5068 - acc: 0.04 - ETA: 61s - loss: 4.5108 - acc: 0.03 - ETA: 61s - loss: 4.5037 - acc: 0.03 - ETA: 61s - loss: 4.5079 - acc: 0.04 - ETA: 61s - loss: 4.5023 - acc: 0.04 - ETA: 61s - loss: 4.4999 - acc: 0.04 - ETA: 60s - loss: 4.5019 - acc: 0.04 - ETA: 60s - loss: 4.5088 - acc: 0.04 - ETA: 60s - loss: 4.5147 - acc: 0.04 - ETA: 60s - loss: 4.5117 - acc: 0.04 - ETA: 59s - loss: 4.5082 - acc: 0.04 - ETA: 59s - loss: 4.5054 - acc: 0.04 - ETA: 59s - loss: 4.5024 - acc: 0.04 - ETA: 59s - loss: 4.4905 - acc: 0.04 - ETA: 59s - loss: 4.4945 - acc: 0.04 - ETA: 58s - loss: 4.4943 - acc: 0.04 - ETA: 58s - loss: 4.4935 - acc: 0.04 - ETA: 58s - loss: 4.4893 - acc: 0.04 - ETA: 58s - loss: 4.4870 - acc: 0.04 - ETA: 58s - loss: 4.4862 - acc: 0.04 - ETA: 57s - loss: 4.4915 - acc: 0.04 - ETA: 57s - loss: 4.4855 - acc: 0.03 - ETA: 57s - loss: 4.4869 - acc: 0.03 - ETA: 57s - loss: 4.4923 - acc: 0.04 - ETA: 57s - loss: 4.4924 - acc: 0.04 - ETA: 56s - loss: 4.4912 - acc: 0.04 - ETA: 56s - loss: 4.4897 - acc: 0.04 - ETA: 56s - loss: 4.4875 - acc: 0.04 - ETA: 56s - loss: 4.4885 - acc: 0.04 - ETA: 56s - loss: 4.4916 - acc: 0.04 - ETA: 55s - loss: 4.4904 - acc: 0.04 - ETA: 55s - loss: 4.4899 - acc: 0.04 - ETA: 55s - loss: 4.4917 - acc: 0.04 - ETA: 55s - loss: 4.4925 - acc: 0.04 - ETA: 54s - loss: 4.4903 - acc: 0.04 - ETA: 54s - loss: 4.4861 - acc: 0.04 - ETA: 54s - loss: 4.4893 - acc: 0.04 - ETA: 54s - loss: 4.4876 - acc: 0.04 - ETA: 54s - loss: 4.4875 - acc: 0.04 - ETA: 53s - loss: 4.4857 - acc: 0.04 - ETA: 53s - loss: 4.4868 - acc: 0.04 - ETA: 53s - loss: 4.4881 - acc: 0.04 - ETA: 53s - loss: 4.4858 - acc: 0.04 - ETA: 53s - loss: 4.4842 - acc: 0.04 - ETA: 52s - loss: 4.4901 - acc: 0.04 - ETA: 52s - loss: 4.4896 - acc: 0.04 - ETA: 52s - loss: 4.4904 - acc: 0.04 - ETA: 52s - loss: 4.4941 - acc: 0.04 - ETA: 52s - loss: 4.4947 - acc: 0.04 - ETA: 51s - loss: 4.4912 - acc: 0.04 - ETA: 51s - loss: 4.4893 - acc: 0.04 - ETA: 51s - loss: 4.4877 - acc: 0.04 - ETA: 51s - loss: 4.4880 - acc: 0.04 - ETA: 51s - loss: 4.4902 - acc: 0.04 - ETA: 50s - loss: 4.4905 - acc: 0.04 - ETA: 50s - loss: 4.4907 - acc: 0.04 - ETA: 50s - loss: 4.4919 - acc: 0.04 - ETA: 50s - loss: 4.4908 - acc: 0.04 - ETA: 50s - loss: 4.4896 - acc: 0.04 - ETA: 49s - loss: 4.4920 - acc: 0.04 - ETA: 49s - loss: 4.4911 - acc: 0.04 - ETA: 49s - loss: 4.4939 - acc: 0.04 - ETA: 49s - loss: 4.4962 - acc: 0.04 - ETA: 49s - loss: 4.4985 - acc: 0.04 - ETA: 48s - loss: 4.4973 - acc: 0.04 - ETA: 48s - loss: 4.5003 - acc: 0.04 - ETA: 48s - loss: 4.5023 - acc: 0.04 - ETA: 48s - loss: 4.5033 - acc: 0.04 - ETA: 48s - loss: 4.5046 - acc: 0.04 - ETA: 47s - loss: 4.5063 - acc: 0.04 - ETA: 47s - loss: 4.5070 - acc: 0.04 - ETA: 47s - loss: 4.5089 - acc: 0.04 - ETA: 47s - loss: 4.5056 - acc: 0.04 - ETA: 46s - loss: 4.5031 - acc: 0.04 - ETA: 46s - loss: 4.5032 - acc: 0.04 - ETA: 46s - loss: 4.5022 - acc: 0.04 - ETA: 46s - loss: 4.5033 - acc: 0.04 - ETA: 46s - loss: 4.5032 - acc: 0.04 - ETA: 45s - loss: 4.5023 - acc: 0.04 - ETA: 45s - loss: 4.5027 - acc: 0.04 - ETA: 45s - loss: 4.4999 - acc: 0.04 - ETA: 45s - loss: 4.4980 - acc: 0.04 - ETA: 45s - loss: 4.4979 - acc: 0.04 - ETA: 44s - loss: 4.4994 - acc: 0.04 - ETA: 44s - loss: 4.4991 - acc: 0.04 - ETA: 44s - loss: 4.4974 - acc: 0.04 - ETA: 44s - loss: 4.4965 - acc: 0.04 - ETA: 44s - loss: 4.4957 - acc: 0.04 - ETA: 43s - loss: 4.4944 - acc: 0.04 - ETA: 43s - loss: 4.4931 - acc: 0.04 - ETA: 43s - loss: 4.4940 - acc: 0.04 - ETA: 43s - loss: 4.4947 - acc: 0.04 - ETA: 42s - loss: 4.4962 - acc: 0.04 - ETA: 42s - loss: 4.4948 - acc: 0.04 - ETA: 42s - loss: 4.4937 - acc: 0.04 - ETA: 42s - loss: 4.4959 - acc: 0.04 - ETA: 42s - loss: 4.4975 - acc: 0.04 - ETA: 41s - loss: 4.4991 - acc: 0.04 - ETA: 41s - loss: 4.4975 - acc: 0.04 - ETA: 41s - loss: 4.4968 - acc: 0.04 - ETA: 41s - loss: 4.4961 - acc: 0.04 - ETA: 41s - loss: 4.4974 - acc: 0.04 - ETA: 40s - loss: 4.4967 - acc: 0.04 - ETA: 40s - loss: 4.4962 - acc: 0.04 - ETA: 40s - loss: 4.4963 - acc: 0.04 - ETA: 40s - loss: 4.4960 - acc: 0.04 - ETA: 39s - loss: 4.4953 - acc: 0.04 - ETA: 39s - loss: 4.4953 - acc: 0.04 - ETA: 39s - loss: 4.4940 - acc: 0.04 - ETA: 39s - loss: 4.4931 - acc: 0.04 - ETA: 39s - loss: 4.4935 - acc: 0.04 - ETA: 38s - loss: 4.4942 - acc: 0.04 - ETA: 38s - loss: 4.4956 - acc: 0.04 - ETA: 38s - loss: 4.4936 - acc: 0.04 - ETA: 38s - loss: 4.4942 - acc: 0.04 - ETA: 38s - loss: 4.4941 - acc: 0.04 - ETA: 37s - loss: 4.4950 - acc: 0.04 - ETA: 37s - loss: 4.4952 - acc: 0.04 - ETA: 37s - loss: 4.4939 - acc: 0.04 - ETA: 37s - loss: 4.4928 - acc: 0.04 - ETA: 37s - loss: 4.4927 - acc: 0.04 - ETA: 36s - loss: 4.4920 - acc: 0.04 - ETA: 36s - loss: 4.4939 - acc: 0.04 - ETA: 36s - loss: 4.4957 - acc: 0.04 - ETA: 36s - loss: 4.4964 - acc: 0.04 - ETA: 36s - loss: 4.4976 - acc: 0.04 - ETA: 35s - loss: 4.4981 - acc: 0.04 - ETA: 35s - loss: 4.4976 - acc: 0.04 - ETA: 35s - loss: 4.4948 - acc: 0.04 - ETA: 35s - loss: 4.4963 - acc: 0.04 - ETA: 34s - loss: 4.4972 - acc: 0.04 - ETA: 34s - loss: 4.4973 - acc: 0.04 - ETA: 34s - loss: 4.4966 - acc: 0.04 - ETA: 34s - loss: 4.4975 - acc: 0.04 - ETA: 34s - loss: 4.4971 - acc: 0.04 - ETA: 33s - loss: 4.4948 - acc: 0.04 - ETA: 33s - loss: 4.4957 - acc: 0.04 - ETA: 33s - loss: 4.4960 - acc: 0.04 - ETA: 33s - loss: 4.4967 - acc: 0.04 - ETA: 33s - loss: 4.4971 - acc: 0.04 - ETA: 32s - loss: 4.4975 - acc: 0.04 - ETA: 32s - loss: 4.4958 - acc: 0.04 - ETA: 32s - loss: 4.4954 - acc: 0.04 - ETA: 32s - loss: 4.4958 - acc: 0.04 - ETA: 32s - loss: 4.4963 - acc: 0.04 - ETA: 31s - loss: 4.4963 - acc: 0.04 - ETA: 31s - loss: 4.4949 - acc: 0.04 - ETA: 31s - loss: 4.4963 - acc: 0.04 - ETA: 31s - loss: 4.4969 - acc: 0.04 - ETA: 30s - loss: 4.4961 - acc: 0.04 - ETA: 30s - loss: 4.4962 - acc: 0.04 - ETA: 30s - loss: 4.4961 - acc: 0.04 - ETA: 30s - loss: 4.4964 - acc: 0.04 - ETA: 30s - loss: 4.4954 - acc: 0.04 - ETA: 29s - loss: 4.4961 - acc: 0.04 - ETA: 29s - loss: 4.4956 - acc: 0.04 - ETA: 29s - loss: 4.4965 - acc: 0.04 - ETA: 29s - loss: 4.4967 - acc: 0.04 - ETA: 29s - loss: 4.4988 - acc: 0.04 - ETA: 28s - loss: 4.4998 - acc: 0.04 - ETA: 28s - loss: 4.5004 - acc: 0.04 - ETA: 28s - loss: 4.4998 - acc: 0.04 - ETA: 28s - loss: 4.5003 - acc: 0.04 - ETA: 28s - loss: 4.5015 - acc: 0.04 - ETA: 27s - loss: 4.5009 - acc: 0.04 - ETA: 27s - loss: 4.5017 - acc: 0.04 - ETA: 27s - loss: 4.5007 - acc: 0.04 - ETA: 27s - loss: 4.5001 - acc: 0.04 - ETA: 27s - loss: 4.5002 - acc: 0.04 - ETA: 26s - loss: 4.5007 - acc: 0.04 - ETA: 26s - loss: 4.5019 - acc: 0.04 - ETA: 26s - loss: 4.5008 - acc: 0.04 - ETA: 26s - loss: 4.5012 - acc: 0.04 - ETA: 25s - loss: 4.5024 - acc: 0.04 - ETA: 25s - loss: 4.5026 - acc: 0.04 - ETA: 25s - loss: 4.5013 - acc: 0.04 - ETA: 25s - loss: 4.5014 - acc: 0.04 - ETA: 25s - loss: 4.5020 - acc: 0.04 - ETA: 24s - loss: 4.5030 - acc: 0.0426"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6660/6680 [============================>.] - ETA: 24s - loss: 4.5031 - acc: 0.04 - ETA: 24s - loss: 4.5024 - acc: 0.04 - ETA: 24s - loss: 4.5032 - acc: 0.04 - ETA: 24s - loss: 4.5038 - acc: 0.04 - ETA: 23s - loss: 4.5031 - acc: 0.04 - ETA: 23s - loss: 4.5031 - acc: 0.04 - ETA: 23s - loss: 4.5052 - acc: 0.04 - ETA: 23s - loss: 4.5059 - acc: 0.04 - ETA: 23s - loss: 4.5068 - acc: 0.04 - ETA: 22s - loss: 4.5060 - acc: 0.04 - ETA: 22s - loss: 4.5059 - acc: 0.04 - ETA: 22s - loss: 4.5068 - acc: 0.04 - ETA: 22s - loss: 4.5063 - acc: 0.04 - ETA: 21s - loss: 4.5062 - acc: 0.04 - ETA: 21s - loss: 4.5069 - acc: 0.04 - ETA: 21s - loss: 4.5077 - acc: 0.04 - ETA: 21s - loss: 4.5075 - acc: 0.04 - ETA: 21s - loss: 4.5071 - acc: 0.04 - ETA: 20s - loss: 4.5078 - acc: 0.04 - ETA: 20s - loss: 4.5080 - acc: 0.04 - ETA: 20s - loss: 4.5074 - acc: 0.04 - ETA: 20s - loss: 4.5072 - acc: 0.04 - ETA: 20s - loss: 4.5067 - acc: 0.04 - ETA: 19s - loss: 4.5083 - acc: 0.04 - ETA: 19s - loss: 4.5078 - acc: 0.04 - ETA: 19s - loss: 4.5075 - acc: 0.04 - ETA: 19s - loss: 4.5077 - acc: 0.04 - ETA: 19s - loss: 4.5076 - acc: 0.04 - ETA: 18s - loss: 4.5078 - acc: 0.04 - ETA: 18s - loss: 4.5087 - acc: 0.04 - ETA: 18s - loss: 4.5077 - acc: 0.04 - ETA: 18s - loss: 4.5076 - acc: 0.04 - ETA: 18s - loss: 4.5071 - acc: 0.04 - ETA: 17s - loss: 4.5083 - acc: 0.04 - ETA: 17s - loss: 4.5096 - acc: 0.04 - ETA: 17s - loss: 4.5110 - acc: 0.04 - ETA: 17s - loss: 4.5111 - acc: 0.04 - ETA: 16s - loss: 4.5105 - acc: 0.04 - ETA: 16s - loss: 4.5111 - acc: 0.04 - ETA: 16s - loss: 4.5109 - acc: 0.04 - ETA: 16s - loss: 4.5103 - acc: 0.04 - ETA: 16s - loss: 4.5109 - acc: 0.04 - ETA: 15s - loss: 4.5091 - acc: 0.04 - ETA: 15s - loss: 4.5092 - acc: 0.04 - ETA: 15s - loss: 4.5084 - acc: 0.04 - ETA: 15s - loss: 4.5094 - acc: 0.04 - ETA: 15s - loss: 4.5093 - acc: 0.04 - ETA: 14s - loss: 4.5099 - acc: 0.04 - ETA: 14s - loss: 4.5097 - acc: 0.04 - ETA: 14s - loss: 4.5093 - acc: 0.04 - ETA: 14s - loss: 4.5104 - acc: 0.04 - ETA: 14s - loss: 4.5100 - acc: 0.04 - ETA: 13s - loss: 4.5101 - acc: 0.04 - ETA: 13s - loss: 4.5099 - acc: 0.04 - ETA: 13s - loss: 4.5085 - acc: 0.04 - ETA: 13s - loss: 4.5084 - acc: 0.04 - ETA: 12s - loss: 4.5070 - acc: 0.04 - ETA: 12s - loss: 4.5080 - acc: 0.04 - ETA: 12s - loss: 4.5076 - acc: 0.04 - ETA: 12s - loss: 4.5072 - acc: 0.04 - ETA: 12s - loss: 4.5066 - acc: 0.04 - ETA: 11s - loss: 4.5053 - acc: 0.04 - ETA: 11s - loss: 4.5058 - acc: 0.04 - ETA: 11s - loss: 4.5052 - acc: 0.04 - ETA: 11s - loss: 4.5052 - acc: 0.04 - ETA: 11s - loss: 4.5050 - acc: 0.04 - ETA: 10s - loss: 4.5047 - acc: 0.04 - ETA: 10s - loss: 4.5048 - acc: 0.04 - ETA: 10s - loss: 4.5052 - acc: 0.04 - ETA: 10s - loss: 4.5057 - acc: 0.04 - ETA: 10s - loss: 4.5059 - acc: 0.04 - ETA: 9s - loss: 4.5059 - acc: 0.0432 - ETA: 9s - loss: 4.5056 - acc: 0.043 - ETA: 9s - loss: 4.5072 - acc: 0.042 - ETA: 9s - loss: 4.5076 - acc: 0.042 - ETA: 9s - loss: 4.5074 - acc: 0.043 - ETA: 8s - loss: 4.5068 - acc: 0.043 - ETA: 8s - loss: 4.5069 - acc: 0.043 - ETA: 8s - loss: 4.5072 - acc: 0.043 - ETA: 8s - loss: 4.5072 - acc: 0.043 - ETA: 7s - loss: 4.5072 - acc: 0.043 - ETA: 7s - loss: 4.5072 - acc: 0.043 - ETA: 7s - loss: 4.5071 - acc: 0.043 - ETA: 7s - loss: 4.5072 - acc: 0.043 - ETA: 7s - loss: 4.5081 - acc: 0.043 - ETA: 6s - loss: 4.5076 - acc: 0.043 - ETA: 6s - loss: 4.5068 - acc: 0.042 - ETA: 6s - loss: 4.5074 - acc: 0.042 - ETA: 6s - loss: 4.5059 - acc: 0.043 - ETA: 6s - loss: 4.5063 - acc: 0.043 - ETA: 5s - loss: 4.5070 - acc: 0.043 - ETA: 5s - loss: 4.5056 - acc: 0.043 - ETA: 5s - loss: 4.5057 - acc: 0.043 - ETA: 5s - loss: 4.5047 - acc: 0.043 - ETA: 5s - loss: 4.5042 - acc: 0.044 - ETA: 4s - loss: 4.5048 - acc: 0.044 - ETA: 4s - loss: 4.5051 - acc: 0.043 - ETA: 4s - loss: 4.5059 - acc: 0.043 - ETA: 4s - loss: 4.5061 - acc: 0.043 - ETA: 3s - loss: 4.5052 - acc: 0.044 - ETA: 3s - loss: 4.5049 - acc: 0.043 - ETA: 3s - loss: 4.5055 - acc: 0.043 - ETA: 3s - loss: 4.5054 - acc: 0.043 - ETA: 3s - loss: 4.5056 - acc: 0.043 - ETA: 2s - loss: 4.5055 - acc: 0.043 - ETA: 2s - loss: 4.5058 - acc: 0.043 - ETA: 2s - loss: 4.5083 - acc: 0.043 - ETA: 2s - loss: 4.5077 - acc: 0.043 - ETA: 2s - loss: 4.5077 - acc: 0.043 - ETA: 1s - loss: 4.5078 - acc: 0.043 - ETA: 1s - loss: 4.5070 - acc: 0.043 - ETA: 1s - loss: 4.5068 - acc: 0.043 - ETA: 1s - loss: 4.5062 - acc: 0.043 - ETA: 1s - loss: 4.5062 - acc: 0.043 - ETA: 0s - loss: 4.5059 - acc: 0.043 - ETA: 0s - loss: 4.5060 - acc: 0.043 - ETA: 0s - loss: 4.5062 - acc: 0.043 - ETA: 0s - loss: 4.5065 - acc: 0.0437Epoch 00011: val_loss improved from 4.57474 to 4.50706, saving model to saved_models/weights.best.from_scratch.hdf5\n",
      "6680/6680 [==============================] - 72s - loss: 4.5065 - acc: 0.0439 - val_loss: 4.5071 - val_acc: 0.0455\n",
      "Epoch 13/32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4300/6680 [==================>...........] - ETA: 65s - loss: 4.5914 - acc: 0.0000e+ - ETA: 67s - loss: 4.5533 - acc: 0.0250   - ETA: 68s - loss: 4.5073 - acc: 0.01 - ETA: 68s - loss: 4.5174 - acc: 0.03 - ETA: 68s - loss: 4.4632 - acc: 0.04 - ETA: 67s - loss: 4.4757 - acc: 0.03 - ETA: 68s - loss: 4.5113 - acc: 0.02 - ETA: 67s - loss: 4.5117 - acc: 0.03 - ETA: 67s - loss: 4.5517 - acc: 0.02 - ETA: 67s - loss: 4.5565 - acc: 0.03 - ETA: 67s - loss: 4.5511 - acc: 0.03 - ETA: 67s - loss: 4.5219 - acc: 0.04 - ETA: 66s - loss: 4.5133 - acc: 0.04 - ETA: 66s - loss: 4.5097 - acc: 0.05 - ETA: 66s - loss: 4.4960 - acc: 0.05 - ETA: 66s - loss: 4.4703 - acc: 0.06 - ETA: 66s - loss: 4.4690 - acc: 0.06 - ETA: 66s - loss: 4.4599 - acc: 0.06 - ETA: 65s - loss: 4.4709 - acc: 0.06 - ETA: 65s - loss: 4.4578 - acc: 0.06 - ETA: 65s - loss: 4.4695 - acc: 0.06 - ETA: 65s - loss: 4.4758 - acc: 0.06 - ETA: 65s - loss: 4.4693 - acc: 0.06 - ETA: 64s - loss: 4.4694 - acc: 0.06 - ETA: 64s - loss: 4.4687 - acc: 0.06 - ETA: 64s - loss: 4.4562 - acc: 0.05 - ETA: 64s - loss: 4.4564 - acc: 0.06 - ETA: 64s - loss: 4.4534 - acc: 0.06 - ETA: 63s - loss: 4.4450 - acc: 0.06 - ETA: 63s - loss: 4.4437 - acc: 0.06 - ETA: 63s - loss: 4.4536 - acc: 0.06 - ETA: 63s - loss: 4.4648 - acc: 0.06 - ETA: 62s - loss: 4.4673 - acc: 0.06 - ETA: 62s - loss: 4.4609 - acc: 0.06 - ETA: 62s - loss: 4.4521 - acc: 0.06 - ETA: 62s - loss: 4.4561 - acc: 0.05 - ETA: 62s - loss: 4.4599 - acc: 0.05 - ETA: 61s - loss: 4.4632 - acc: 0.05 - ETA: 61s - loss: 4.4691 - acc: 0.05 - ETA: 61s - loss: 4.4730 - acc: 0.05 - ETA: 61s - loss: 4.4701 - acc: 0.05 - ETA: 61s - loss: 4.4722 - acc: 0.05 - ETA: 60s - loss: 4.4695 - acc: 0.05 - ETA: 60s - loss: 4.4768 - acc: 0.05 - ETA: 60s - loss: 4.4708 - acc: 0.05 - ETA: 60s - loss: 4.4745 - acc: 0.05 - ETA: 60s - loss: 4.4742 - acc: 0.05 - ETA: 59s - loss: 4.4716 - acc: 0.05 - ETA: 59s - loss: 4.4656 - acc: 0.05 - ETA: 59s - loss: 4.4654 - acc: 0.05 - ETA: 59s - loss: 4.4688 - acc: 0.05 - ETA: 58s - loss: 4.4707 - acc: 0.05 - ETA: 58s - loss: 4.4727 - acc: 0.05 - ETA: 58s - loss: 4.4694 - acc: 0.05 - ETA: 58s - loss: 4.4642 - acc: 0.05 - ETA: 58s - loss: 4.4638 - acc: 0.05 - ETA: 57s - loss: 4.4656 - acc: 0.05 - ETA: 57s - loss: 4.4666 - acc: 0.05 - ETA: 57s - loss: 4.4730 - acc: 0.05 - ETA: 57s - loss: 4.4766 - acc: 0.05 - ETA: 57s - loss: 4.4734 - acc: 0.05 - ETA: 56s - loss: 4.4744 - acc: 0.05 - ETA: 56s - loss: 4.4788 - acc: 0.05 - ETA: 56s - loss: 4.4788 - acc: 0.05 - ETA: 56s - loss: 4.4765 - acc: 0.05 - ETA: 56s - loss: 4.4701 - acc: 0.05 - ETA: 55s - loss: 4.4730 - acc: 0.05 - ETA: 55s - loss: 4.4711 - acc: 0.05 - ETA: 55s - loss: 4.4681 - acc: 0.05 - ETA: 55s - loss: 4.4707 - acc: 0.05 - ETA: 55s - loss: 4.4708 - acc: 0.05 - ETA: 54s - loss: 4.4730 - acc: 0.05 - ETA: 54s - loss: 4.4706 - acc: 0.05 - ETA: 54s - loss: 4.4711 - acc: 0.05 - ETA: 54s - loss: 4.4674 - acc: 0.05 - ETA: 53s - loss: 4.4679 - acc: 0.05 - ETA: 53s - loss: 4.4640 - acc: 0.05 - ETA: 53s - loss: 4.4663 - acc: 0.05 - ETA: 53s - loss: 4.4670 - acc: 0.05 - ETA: 53s - loss: 4.4662 - acc: 0.05 - ETA: 52s - loss: 4.4675 - acc: 0.05 - ETA: 52s - loss: 4.4704 - acc: 0.05 - ETA: 52s - loss: 4.4712 - acc: 0.05 - ETA: 52s - loss: 4.4709 - acc: 0.05 - ETA: 52s - loss: 4.4724 - acc: 0.05 - ETA: 51s - loss: 4.4706 - acc: 0.05 - ETA: 51s - loss: 4.4734 - acc: 0.05 - ETA: 51s - loss: 4.4758 - acc: 0.05 - ETA: 51s - loss: 4.4762 - acc: 0.05 - ETA: 51s - loss: 4.4778 - acc: 0.05 - ETA: 50s - loss: 4.4766 - acc: 0.05 - ETA: 50s - loss: 4.4760 - acc: 0.05 - ETA: 50s - loss: 4.4776 - acc: 0.05 - ETA: 50s - loss: 4.4791 - acc: 0.04 - ETA: 50s - loss: 4.4843 - acc: 0.04 - ETA: 49s - loss: 4.4858 - acc: 0.04 - ETA: 49s - loss: 4.4876 - acc: 0.04 - ETA: 49s - loss: 4.4885 - acc: 0.04 - ETA: 49s - loss: 4.4877 - acc: 0.04 - ETA: 48s - loss: 4.4864 - acc: 0.04 - ETA: 48s - loss: 4.4888 - acc: 0.04 - ETA: 48s - loss: 4.4851 - acc: 0.04 - ETA: 48s - loss: 4.4862 - acc: 0.04 - ETA: 48s - loss: 4.4836 - acc: 0.04 - ETA: 47s - loss: 4.4814 - acc: 0.04 - ETA: 47s - loss: 4.4800 - acc: 0.04 - ETA: 47s - loss: 4.4778 - acc: 0.04 - ETA: 47s - loss: 4.4756 - acc: 0.04 - ETA: 47s - loss: 4.4743 - acc: 0.04 - ETA: 46s - loss: 4.4752 - acc: 0.04 - ETA: 46s - loss: 4.4728 - acc: 0.04 - ETA: 46s - loss: 4.4747 - acc: 0.04 - ETA: 46s - loss: 4.4732 - acc: 0.04 - ETA: 46s - loss: 4.4738 - acc: 0.04 - ETA: 45s - loss: 4.4721 - acc: 0.04 - ETA: 45s - loss: 4.4722 - acc: 0.04 - ETA: 45s - loss: 4.4732 - acc: 0.04 - ETA: 45s - loss: 4.4716 - acc: 0.04 - ETA: 44s - loss: 4.4728 - acc: 0.04 - ETA: 44s - loss: 4.4724 - acc: 0.04 - ETA: 44s - loss: 4.4726 - acc: 0.04 - ETA: 44s - loss: 4.4724 - acc: 0.04 - ETA: 44s - loss: 4.4714 - acc: 0.04 - ETA: 43s - loss: 4.4732 - acc: 0.04 - ETA: 43s - loss: 4.4743 - acc: 0.04 - ETA: 43s - loss: 4.4750 - acc: 0.04 - ETA: 43s - loss: 4.4756 - acc: 0.04 - ETA: 43s - loss: 4.4760 - acc: 0.04 - ETA: 42s - loss: 4.4768 - acc: 0.04 - ETA: 42s - loss: 4.4765 - acc: 0.04 - ETA: 42s - loss: 4.4758 - acc: 0.04 - ETA: 42s - loss: 4.4748 - acc: 0.04 - ETA: 42s - loss: 4.4775 - acc: 0.04 - ETA: 41s - loss: 4.4782 - acc: 0.04 - ETA: 41s - loss: 4.4780 - acc: 0.04 - ETA: 41s - loss: 4.4808 - acc: 0.04 - ETA: 41s - loss: 4.4799 - acc: 0.04 - ETA: 41s - loss: 4.4797 - acc: 0.04 - ETA: 40s - loss: 4.4797 - acc: 0.04 - ETA: 40s - loss: 4.4806 - acc: 0.04 - ETA: 40s - loss: 4.4790 - acc: 0.04 - ETA: 40s - loss: 4.4787 - acc: 0.04 - ETA: 39s - loss: 4.4792 - acc: 0.04 - ETA: 39s - loss: 4.4792 - acc: 0.04 - ETA: 39s - loss: 4.4796 - acc: 0.04 - ETA: 39s - loss: 4.4809 - acc: 0.04 - ETA: 39s - loss: 4.4802 - acc: 0.04 - ETA: 38s - loss: 4.4816 - acc: 0.04 - ETA: 38s - loss: 4.4834 - acc: 0.04 - ETA: 38s - loss: 4.4860 - acc: 0.04 - ETA: 38s - loss: 4.4855 - acc: 0.04 - ETA: 38s - loss: 4.4851 - acc: 0.04 - ETA: 37s - loss: 4.4828 - acc: 0.04 - ETA: 37s - loss: 4.4840 - acc: 0.04 - ETA: 37s - loss: 4.4840 - acc: 0.04 - ETA: 37s - loss: 4.4854 - acc: 0.04 - ETA: 37s - loss: 4.4839 - acc: 0.04 - ETA: 36s - loss: 4.4863 - acc: 0.04 - ETA: 36s - loss: 4.4853 - acc: 0.04 - ETA: 36s - loss: 4.4844 - acc: 0.04 - ETA: 36s - loss: 4.4843 - acc: 0.04 - ETA: 36s - loss: 4.4841 - acc: 0.04 - ETA: 35s - loss: 4.4849 - acc: 0.04 - ETA: 35s - loss: 4.4859 - acc: 0.04 - ETA: 35s - loss: 4.4864 - acc: 0.04 - ETA: 35s - loss: 4.4852 - acc: 0.04 - ETA: 34s - loss: 4.4832 - acc: 0.04 - ETA: 34s - loss: 4.4840 - acc: 0.04 - ETA: 34s - loss: 4.4829 - acc: 0.04 - ETA: 34s - loss: 4.4834 - acc: 0.04 - ETA: 34s - loss: 4.4835 - acc: 0.04 - ETA: 33s - loss: 4.4807 - acc: 0.04 - ETA: 33s - loss: 4.4809 - acc: 0.04 - ETA: 33s - loss: 4.4805 - acc: 0.04 - ETA: 33s - loss: 4.4788 - acc: 0.04 - ETA: 33s - loss: 4.4795 - acc: 0.04 - ETA: 32s - loss: 4.4806 - acc: 0.04 - ETA: 32s - loss: 4.4776 - acc: 0.04 - ETA: 32s - loss: 4.4788 - acc: 0.04 - ETA: 32s - loss: 4.4785 - acc: 0.04 - ETA: 32s - loss: 4.4787 - acc: 0.04 - ETA: 31s - loss: 4.4764 - acc: 0.04 - ETA: 31s - loss: 4.4765 - acc: 0.04 - ETA: 31s - loss: 4.4745 - acc: 0.04 - ETA: 31s - loss: 4.4739 - acc: 0.04 - ETA: 30s - loss: 4.4729 - acc: 0.04 - ETA: 30s - loss: 4.4720 - acc: 0.04 - ETA: 30s - loss: 4.4725 - acc: 0.04 - ETA: 30s - loss: 4.4725 - acc: 0.04 - ETA: 30s - loss: 4.4721 - acc: 0.04 - ETA: 29s - loss: 4.4711 - acc: 0.04 - ETA: 29s - loss: 4.4709 - acc: 0.04 - ETA: 29s - loss: 4.4707 - acc: 0.04 - ETA: 29s - loss: 4.4698 - acc: 0.04 - ETA: 29s - loss: 4.4692 - acc: 0.04 - ETA: 28s - loss: 4.4691 - acc: 0.04 - ETA: 28s - loss: 4.4681 - acc: 0.04 - ETA: 28s - loss: 4.4699 - acc: 0.04 - ETA: 28s - loss: 4.4715 - acc: 0.04 - ETA: 28s - loss: 4.4715 - acc: 0.04 - ETA: 27s - loss: 4.4705 - acc: 0.04 - ETA: 27s - loss: 4.4696 - acc: 0.04 - ETA: 27s - loss: 4.4683 - acc: 0.04 - ETA: 27s - loss: 4.4692 - acc: 0.04 - ETA: 27s - loss: 4.4689 - acc: 0.04 - ETA: 26s - loss: 4.4689 - acc: 0.04 - ETA: 26s - loss: 4.4696 - acc: 0.04 - ETA: 26s - loss: 4.4694 - acc: 0.04 - ETA: 26s - loss: 4.4699 - acc: 0.04 - ETA: 25s - loss: 4.4693 - acc: 0.04 - ETA: 25s - loss: 4.4709 - acc: 0.04 - ETA: 25s - loss: 4.4711 - acc: 0.04 - ETA: 25s - loss: 4.4706 - acc: 0.04 - ETA: 25s - loss: 4.4709 - acc: 0.04 - ETA: 24s - loss: 4.4710 - acc: 0.0463"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6660/6680 [============================>.] - ETA: 24s - loss: 4.4700 - acc: 0.04 - ETA: 24s - loss: 4.4719 - acc: 0.04 - ETA: 24s - loss: 4.4719 - acc: 0.04 - ETA: 24s - loss: 4.4712 - acc: 0.04 - ETA: 23s - loss: 4.4721 - acc: 0.04 - ETA: 23s - loss: 4.4740 - acc: 0.04 - ETA: 23s - loss: 4.4739 - acc: 0.04 - ETA: 23s - loss: 4.4755 - acc: 0.04 - ETA: 23s - loss: 4.4758 - acc: 0.04 - ETA: 22s - loss: 4.4756 - acc: 0.04 - ETA: 22s - loss: 4.4750 - acc: 0.04 - ETA: 22s - loss: 4.4742 - acc: 0.04 - ETA: 22s - loss: 4.4739 - acc: 0.04 - ETA: 22s - loss: 4.4741 - acc: 0.04 - ETA: 21s - loss: 4.4753 - acc: 0.04 - ETA: 21s - loss: 4.4751 - acc: 0.04 - ETA: 21s - loss: 4.4740 - acc: 0.04 - ETA: 21s - loss: 4.4738 - acc: 0.04 - ETA: 20s - loss: 4.4738 - acc: 0.04 - ETA: 20s - loss: 4.4744 - acc: 0.04 - ETA: 20s - loss: 4.4751 - acc: 0.04 - ETA: 20s - loss: 4.4743 - acc: 0.04 - ETA: 20s - loss: 4.4737 - acc: 0.04 - ETA: 19s - loss: 4.4743 - acc: 0.04 - ETA: 19s - loss: 4.4742 - acc: 0.04 - ETA: 19s - loss: 4.4737 - acc: 0.04 - ETA: 19s - loss: 4.4733 - acc: 0.04 - ETA: 19s - loss: 4.4758 - acc: 0.04 - ETA: 18s - loss: 4.4761 - acc: 0.04 - ETA: 18s - loss: 4.4773 - acc: 0.04 - ETA: 18s - loss: 4.4768 - acc: 0.04 - ETA: 18s - loss: 4.4765 - acc: 0.04 - ETA: 18s - loss: 4.4756 - acc: 0.04 - ETA: 17s - loss: 4.4757 - acc: 0.04 - ETA: 17s - loss: 4.4770 - acc: 0.04 - ETA: 17s - loss: 4.4770 - acc: 0.04 - ETA: 17s - loss: 4.4768 - acc: 0.04 - ETA: 16s - loss: 4.4765 - acc: 0.04 - ETA: 16s - loss: 4.4759 - acc: 0.04 - ETA: 16s - loss: 4.4746 - acc: 0.04 - ETA: 16s - loss: 4.4746 - acc: 0.04 - ETA: 16s - loss: 4.4750 - acc: 0.04 - ETA: 15s - loss: 4.4757 - acc: 0.04 - ETA: 15s - loss: 4.4764 - acc: 0.04 - ETA: 15s - loss: 4.4769 - acc: 0.04 - ETA: 15s - loss: 4.4762 - acc: 0.04 - ETA: 15s - loss: 4.4764 - acc: 0.04 - ETA: 14s - loss: 4.4759 - acc: 0.04 - ETA: 14s - loss: 4.4747 - acc: 0.04 - ETA: 14s - loss: 4.4744 - acc: 0.04 - ETA: 14s - loss: 4.4750 - acc: 0.04 - ETA: 14s - loss: 4.4752 - acc: 0.04 - ETA: 13s - loss: 4.4760 - acc: 0.04 - ETA: 13s - loss: 4.4757 - acc: 0.04 - ETA: 13s - loss: 4.4763 - acc: 0.04 - ETA: 13s - loss: 4.4760 - acc: 0.04 - ETA: 12s - loss: 4.4759 - acc: 0.04 - ETA: 12s - loss: 4.4749 - acc: 0.04 - ETA: 12s - loss: 4.4756 - acc: 0.04 - ETA: 12s - loss: 4.4749 - acc: 0.04 - ETA: 12s - loss: 4.4741 - acc: 0.04 - ETA: 11s - loss: 4.4751 - acc: 0.04 - ETA: 11s - loss: 4.4750 - acc: 0.04 - ETA: 11s - loss: 4.4750 - acc: 0.04 - ETA: 11s - loss: 4.4761 - acc: 0.04 - ETA: 11s - loss: 4.4763 - acc: 0.04 - ETA: 10s - loss: 4.4762 - acc: 0.04 - ETA: 10s - loss: 4.4761 - acc: 0.04 - ETA: 10s - loss: 4.4760 - acc: 0.04 - ETA: 10s - loss: 4.4759 - acc: 0.04 - ETA: 10s - loss: 4.4759 - acc: 0.04 - ETA: 9s - loss: 4.4763 - acc: 0.0448 - ETA: 9s - loss: 4.4760 - acc: 0.044 - ETA: 9s - loss: 4.4757 - acc: 0.045 - ETA: 9s - loss: 4.4760 - acc: 0.044 - ETA: 9s - loss: 4.4769 - acc: 0.044 - ETA: 8s - loss: 4.4766 - acc: 0.044 - ETA: 8s - loss: 4.4761 - acc: 0.044 - ETA: 8s - loss: 4.4761 - acc: 0.044 - ETA: 8s - loss: 4.4757 - acc: 0.044 - ETA: 7s - loss: 4.4758 - acc: 0.044 - ETA: 7s - loss: 4.4753 - acc: 0.044 - ETA: 7s - loss: 4.4742 - acc: 0.045 - ETA: 7s - loss: 4.4743 - acc: 0.044 - ETA: 7s - loss: 4.4741 - acc: 0.045 - ETA: 6s - loss: 4.4739 - acc: 0.045 - ETA: 6s - loss: 4.4734 - acc: 0.044 - ETA: 6s - loss: 4.4729 - acc: 0.044 - ETA: 6s - loss: 4.4722 - acc: 0.044 - ETA: 6s - loss: 4.4720 - acc: 0.044 - ETA: 5s - loss: 4.4737 - acc: 0.044 - ETA: 5s - loss: 4.4746 - acc: 0.044 - ETA: 5s - loss: 4.4750 - acc: 0.044 - ETA: 5s - loss: 4.4743 - acc: 0.045 - ETA: 5s - loss: 4.4734 - acc: 0.045 - ETA: 4s - loss: 4.4740 - acc: 0.045 - ETA: 4s - loss: 4.4745 - acc: 0.045 - ETA: 4s - loss: 4.4746 - acc: 0.045 - ETA: 4s - loss: 4.4750 - acc: 0.045 - ETA: 3s - loss: 4.4744 - acc: 0.045 - ETA: 3s - loss: 4.4745 - acc: 0.045 - ETA: 3s - loss: 4.4742 - acc: 0.045 - ETA: 3s - loss: 4.4742 - acc: 0.045 - ETA: 3s - loss: 4.4753 - acc: 0.045 - ETA: 2s - loss: 4.4743 - acc: 0.045 - ETA: 2s - loss: 4.4748 - acc: 0.045 - ETA: 2s - loss: 4.4750 - acc: 0.045 - ETA: 2s - loss: 4.4752 - acc: 0.045 - ETA: 2s - loss: 4.4754 - acc: 0.045 - ETA: 1s - loss: 4.4748 - acc: 0.045 - ETA: 1s - loss: 4.4739 - acc: 0.046 - ETA: 1s - loss: 4.4741 - acc: 0.046 - ETA: 1s - loss: 4.4742 - acc: 0.046 - ETA: 1s - loss: 4.4735 - acc: 0.046 - ETA: 0s - loss: 4.4734 - acc: 0.046 - ETA: 0s - loss: 4.4749 - acc: 0.046 - ETA: 0s - loss: 4.4748 - acc: 0.046 - ETA: 0s - loss: 4.4744 - acc: 0.0462Epoch 00012: val_loss did not improve\n",
      "6680/6680 [==============================] - 72s - loss: 4.4741 - acc: 0.0463 - val_loss: 4.5284 - val_acc: 0.0467\n",
      "Epoch 14/32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4300/6680 [==================>...........] - ETA: 64s - loss: 4.3106 - acc: 0.05 - ETA: 68s - loss: 4.3642 - acc: 0.07 - ETA: 68s - loss: 4.3709 - acc: 0.05 - ETA: 67s - loss: 4.3624 - acc: 0.08 - ETA: 68s - loss: 4.3491 - acc: 0.09 - ETA: 67s - loss: 4.3087 - acc: 0.10 - ETA: 68s - loss: 4.3518 - acc: 0.10 - ETA: 67s - loss: 4.4027 - acc: 0.09 - ETA: 67s - loss: 4.4232 - acc: 0.08 - ETA: 67s - loss: 4.4050 - acc: 0.08 - ETA: 67s - loss: 4.4114 - acc: 0.07 - ETA: 67s - loss: 4.4051 - acc: 0.06 - ETA: 67s - loss: 4.4004 - acc: 0.06 - ETA: 66s - loss: 4.4127 - acc: 0.06 - ETA: 66s - loss: 4.4145 - acc: 0.06 - ETA: 66s - loss: 4.4157 - acc: 0.05 - ETA: 66s - loss: 4.4209 - acc: 0.05 - ETA: 65s - loss: 4.4134 - acc: 0.05 - ETA: 65s - loss: 4.4406 - acc: 0.05 - ETA: 65s - loss: 4.4373 - acc: 0.05 - ETA: 65s - loss: 4.4227 - acc: 0.05 - ETA: 65s - loss: 4.4162 - acc: 0.05 - ETA: 64s - loss: 4.4122 - acc: 0.05 - ETA: 64s - loss: 4.4095 - acc: 0.05 - ETA: 64s - loss: 4.3985 - acc: 0.05 - ETA: 64s - loss: 4.3969 - acc: 0.05 - ETA: 64s - loss: 4.4002 - acc: 0.05 - ETA: 63s - loss: 4.3962 - acc: 0.05 - ETA: 63s - loss: 4.3949 - acc: 0.05 - ETA: 63s - loss: 4.4052 - acc: 0.05 - ETA: 63s - loss: 4.4076 - acc: 0.05 - ETA: 63s - loss: 4.4105 - acc: 0.05 - ETA: 62s - loss: 4.4055 - acc: 0.05 - ETA: 62s - loss: 4.4109 - acc: 0.05 - ETA: 62s - loss: 4.4114 - acc: 0.05 - ETA: 62s - loss: 4.4077 - acc: 0.05 - ETA: 61s - loss: 4.4112 - acc: 0.05 - ETA: 61s - loss: 4.4085 - acc: 0.05 - ETA: 61s - loss: 4.4088 - acc: 0.05 - ETA: 61s - loss: 4.4111 - acc: 0.05 - ETA: 61s - loss: 4.4050 - acc: 0.05 - ETA: 60s - loss: 4.4000 - acc: 0.05 - ETA: 60s - loss: 4.4011 - acc: 0.05 - ETA: 60s - loss: 4.3990 - acc: 0.05 - ETA: 60s - loss: 4.3966 - acc: 0.05 - ETA: 60s - loss: 4.3989 - acc: 0.05 - ETA: 59s - loss: 4.4022 - acc: 0.05 - ETA: 59s - loss: 4.4021 - acc: 0.05 - ETA: 59s - loss: 4.4048 - acc: 0.05 - ETA: 59s - loss: 4.3989 - acc: 0.05 - ETA: 59s - loss: 4.3917 - acc: 0.05 - ETA: 58s - loss: 4.4048 - acc: 0.05 - ETA: 58s - loss: 4.4041 - acc: 0.05 - ETA: 58s - loss: 4.4073 - acc: 0.05 - ETA: 58s - loss: 4.4112 - acc: 0.05 - ETA: 58s - loss: 4.4135 - acc: 0.05 - ETA: 57s - loss: 4.4134 - acc: 0.05 - ETA: 57s - loss: 4.4185 - acc: 0.05 - ETA: 57s - loss: 4.4186 - acc: 0.05 - ETA: 57s - loss: 4.4149 - acc: 0.05 - ETA: 57s - loss: 4.4137 - acc: 0.05 - ETA: 56s - loss: 4.4179 - acc: 0.05 - ETA: 56s - loss: 4.4170 - acc: 0.05 - ETA: 56s - loss: 4.4168 - acc: 0.05 - ETA: 56s - loss: 4.4180 - acc: 0.05 - ETA: 56s - loss: 4.4156 - acc: 0.05 - ETA: 55s - loss: 4.4172 - acc: 0.05 - ETA: 55s - loss: 4.4181 - acc: 0.05 - ETA: 55s - loss: 4.4201 - acc: 0.05 - ETA: 55s - loss: 4.4215 - acc: 0.04 - ETA: 54s - loss: 4.4191 - acc: 0.04 - ETA: 54s - loss: 4.4226 - acc: 0.04 - ETA: 54s - loss: 4.4211 - acc: 0.05 - ETA: 54s - loss: 4.4215 - acc: 0.05 - ETA: 54s - loss: 4.4231 - acc: 0.05 - ETA: 53s - loss: 4.4231 - acc: 0.05 - ETA: 53s - loss: 4.4254 - acc: 0.05 - ETA: 53s - loss: 4.4303 - acc: 0.05 - ETA: 53s - loss: 4.4290 - acc: 0.05 - ETA: 53s - loss: 4.4333 - acc: 0.05 - ETA: 52s - loss: 4.4323 - acc: 0.05 - ETA: 52s - loss: 4.4310 - acc: 0.05 - ETA: 52s - loss: 4.4319 - acc: 0.05 - ETA: 52s - loss: 4.4333 - acc: 0.05 - ETA: 52s - loss: 4.4336 - acc: 0.05 - ETA: 51s - loss: 4.4343 - acc: 0.05 - ETA: 51s - loss: 4.4369 - acc: 0.04 - ETA: 51s - loss: 4.4385 - acc: 0.04 - ETA: 51s - loss: 4.4394 - acc: 0.05 - ETA: 51s - loss: 4.4443 - acc: 0.05 - ETA: 50s - loss: 4.4448 - acc: 0.05 - ETA: 50s - loss: 4.4441 - acc: 0.05 - ETA: 50s - loss: 4.4414 - acc: 0.05 - ETA: 50s - loss: 4.4428 - acc: 0.05 - ETA: 50s - loss: 4.4429 - acc: 0.05 - ETA: 49s - loss: 4.4438 - acc: 0.05 - ETA: 49s - loss: 4.4411 - acc: 0.05 - ETA: 49s - loss: 4.4393 - acc: 0.05 - ETA: 49s - loss: 4.4405 - acc: 0.05 - ETA: 48s - loss: 4.4397 - acc: 0.05 - ETA: 48s - loss: 4.4406 - acc: 0.05 - ETA: 48s - loss: 4.4391 - acc: 0.05 - ETA: 48s - loss: 4.4413 - acc: 0.05 - ETA: 48s - loss: 4.4449 - acc: 0.05 - ETA: 47s - loss: 4.4462 - acc: 0.05 - ETA: 47s - loss: 4.4448 - acc: 0.05 - ETA: 47s - loss: 4.4414 - acc: 0.05 - ETA: 47s - loss: 4.4460 - acc: 0.05 - ETA: 47s - loss: 4.4445 - acc: 0.05 - ETA: 46s - loss: 4.4444 - acc: 0.05 - ETA: 46s - loss: 4.4443 - acc: 0.05 - ETA: 46s - loss: 4.4439 - acc: 0.05 - ETA: 46s - loss: 4.4410 - acc: 0.05 - ETA: 46s - loss: 4.4393 - acc: 0.05 - ETA: 45s - loss: 4.4392 - acc: 0.05 - ETA: 45s - loss: 4.4415 - acc: 0.05 - ETA: 45s - loss: 4.4417 - acc: 0.05 - ETA: 45s - loss: 4.4378 - acc: 0.05 - ETA: 45s - loss: 4.4382 - acc: 0.05 - ETA: 44s - loss: 4.4391 - acc: 0.05 - ETA: 44s - loss: 4.4394 - acc: 0.05 - ETA: 44s - loss: 4.4395 - acc: 0.05 - ETA: 44s - loss: 4.4404 - acc: 0.05 - ETA: 43s - loss: 4.4427 - acc: 0.05 - ETA: 43s - loss: 4.4429 - acc: 0.05 - ETA: 43s - loss: 4.4412 - acc: 0.05 - ETA: 43s - loss: 4.4419 - acc: 0.05 - ETA: 43s - loss: 4.4435 - acc: 0.05 - ETA: 42s - loss: 4.4407 - acc: 0.05 - ETA: 42s - loss: 4.4402 - acc: 0.05 - ETA: 42s - loss: 4.4400 - acc: 0.05 - ETA: 42s - loss: 4.4374 - acc: 0.05 - ETA: 42s - loss: 4.4380 - acc: 0.05 - ETA: 41s - loss: 4.4362 - acc: 0.05 - ETA: 41s - loss: 4.4356 - acc: 0.05 - ETA: 41s - loss: 4.4346 - acc: 0.05 - ETA: 41s - loss: 4.4322 - acc: 0.05 - ETA: 41s - loss: 4.4308 - acc: 0.05 - ETA: 40s - loss: 4.4299 - acc: 0.05 - ETA: 40s - loss: 4.4307 - acc: 0.05 - ETA: 40s - loss: 4.4346 - acc: 0.05 - ETA: 40s - loss: 4.4354 - acc: 0.05 - ETA: 39s - loss: 4.4360 - acc: 0.05 - ETA: 39s - loss: 4.4363 - acc: 0.05 - ETA: 39s - loss: 4.4350 - acc: 0.05 - ETA: 39s - loss: 4.4366 - acc: 0.05 - ETA: 39s - loss: 4.4391 - acc: 0.05 - ETA: 38s - loss: 4.4398 - acc: 0.05 - ETA: 38s - loss: 4.4412 - acc: 0.05 - ETA: 38s - loss: 4.4406 - acc: 0.05 - ETA: 38s - loss: 4.4402 - acc: 0.05 - ETA: 38s - loss: 4.4375 - acc: 0.05 - ETA: 37s - loss: 4.4334 - acc: 0.05 - ETA: 37s - loss: 4.4340 - acc: 0.05 - ETA: 37s - loss: 4.4340 - acc: 0.05 - ETA: 37s - loss: 4.4344 - acc: 0.05 - ETA: 37s - loss: 4.4354 - acc: 0.05 - ETA: 36s - loss: 4.4347 - acc: 0.05 - ETA: 36s - loss: 4.4312 - acc: 0.05 - ETA: 36s - loss: 4.4330 - acc: 0.05 - ETA: 36s - loss: 4.4324 - acc: 0.05 - ETA: 36s - loss: 4.4317 - acc: 0.05 - ETA: 35s - loss: 4.4325 - acc: 0.05 - ETA: 35s - loss: 4.4331 - acc: 0.05 - ETA: 35s - loss: 4.4340 - acc: 0.05 - ETA: 35s - loss: 4.4338 - acc: 0.05 - ETA: 34s - loss: 4.4343 - acc: 0.05 - ETA: 34s - loss: 4.4347 - acc: 0.05 - ETA: 34s - loss: 4.4348 - acc: 0.05 - ETA: 34s - loss: 4.4354 - acc: 0.05 - ETA: 34s - loss: 4.4376 - acc: 0.05 - ETA: 33s - loss: 4.4363 - acc: 0.05 - ETA: 33s - loss: 4.4381 - acc: 0.05 - ETA: 33s - loss: 4.4389 - acc: 0.05 - ETA: 33s - loss: 4.4408 - acc: 0.05 - ETA: 33s - loss: 4.4404 - acc: 0.05 - ETA: 32s - loss: 4.4396 - acc: 0.05 - ETA: 32s - loss: 4.4381 - acc: 0.05 - ETA: 32s - loss: 4.4391 - acc: 0.05 - ETA: 32s - loss: 4.4397 - acc: 0.05 - ETA: 32s - loss: 4.4378 - acc: 0.05 - ETA: 31s - loss: 4.4368 - acc: 0.05 - ETA: 31s - loss: 4.4379 - acc: 0.05 - ETA: 31s - loss: 4.4377 - acc: 0.05 - ETA: 31s - loss: 4.4370 - acc: 0.05 - ETA: 31s - loss: 4.4390 - acc: 0.05 - ETA: 30s - loss: 4.4392 - acc: 0.05 - ETA: 30s - loss: 4.4395 - acc: 0.05 - ETA: 30s - loss: 4.4391 - acc: 0.05 - ETA: 30s - loss: 4.4383 - acc: 0.05 - ETA: 29s - loss: 4.4364 - acc: 0.05 - ETA: 29s - loss: 4.4363 - acc: 0.05 - ETA: 29s - loss: 4.4361 - acc: 0.05 - ETA: 29s - loss: 4.4349 - acc: 0.05 - ETA: 29s - loss: 4.4337 - acc: 0.05 - ETA: 28s - loss: 4.4344 - acc: 0.05 - ETA: 28s - loss: 4.4335 - acc: 0.05 - ETA: 28s - loss: 4.4339 - acc: 0.05 - ETA: 28s - loss: 4.4346 - acc: 0.05 - ETA: 28s - loss: 4.4347 - acc: 0.05 - ETA: 27s - loss: 4.4329 - acc: 0.05 - ETA: 27s - loss: 4.4327 - acc: 0.05 - ETA: 27s - loss: 4.4323 - acc: 0.05 - ETA: 27s - loss: 4.4332 - acc: 0.05 - ETA: 27s - loss: 4.4325 - acc: 0.05 - ETA: 26s - loss: 4.4323 - acc: 0.05 - ETA: 26s - loss: 4.4324 - acc: 0.05 - ETA: 26s - loss: 4.4331 - acc: 0.05 - ETA: 26s - loss: 4.4318 - acc: 0.05 - ETA: 26s - loss: 4.4328 - acc: 0.05 - ETA: 25s - loss: 4.4333 - acc: 0.05 - ETA: 25s - loss: 4.4323 - acc: 0.05 - ETA: 25s - loss: 4.4355 - acc: 0.05 - ETA: 25s - loss: 4.4361 - acc: 0.05 - ETA: 24s - loss: 4.4354 - acc: 0.0547"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6660/6680 [============================>.] - ETA: 24s - loss: 4.4355 - acc: 0.05 - ETA: 24s - loss: 4.4355 - acc: 0.05 - ETA: 24s - loss: 4.4343 - acc: 0.05 - ETA: 24s - loss: 4.4344 - acc: 0.05 - ETA: 23s - loss: 4.4348 - acc: 0.05 - ETA: 23s - loss: 4.4342 - acc: 0.05 - ETA: 23s - loss: 4.4354 - acc: 0.05 - ETA: 23s - loss: 4.4357 - acc: 0.05 - ETA: 23s - loss: 4.4358 - acc: 0.05 - ETA: 22s - loss: 4.4353 - acc: 0.05 - ETA: 22s - loss: 4.4357 - acc: 0.05 - ETA: 22s - loss: 4.4351 - acc: 0.05 - ETA: 22s - loss: 4.4352 - acc: 0.05 - ETA: 22s - loss: 4.4340 - acc: 0.05 - ETA: 21s - loss: 4.4351 - acc: 0.05 - ETA: 21s - loss: 4.4352 - acc: 0.05 - ETA: 21s - loss: 4.4357 - acc: 0.05 - ETA: 21s - loss: 4.4348 - acc: 0.05 - ETA: 20s - loss: 4.4344 - acc: 0.05 - ETA: 20s - loss: 4.4336 - acc: 0.05 - ETA: 20s - loss: 4.4340 - acc: 0.05 - ETA: 20s - loss: 4.4340 - acc: 0.05 - ETA: 20s - loss: 4.4344 - acc: 0.05 - ETA: 19s - loss: 4.4361 - acc: 0.05 - ETA: 19s - loss: 4.4355 - acc: 0.05 - ETA: 19s - loss: 4.4348 - acc: 0.05 - ETA: 19s - loss: 4.4342 - acc: 0.05 - ETA: 19s - loss: 4.4355 - acc: 0.05 - ETA: 18s - loss: 4.4359 - acc: 0.05 - ETA: 18s - loss: 4.4354 - acc: 0.05 - ETA: 18s - loss: 4.4344 - acc: 0.05 - ETA: 18s - loss: 4.4350 - acc: 0.05 - ETA: 18s - loss: 4.4351 - acc: 0.05 - ETA: 17s - loss: 4.4359 - acc: 0.05 - ETA: 17s - loss: 4.4346 - acc: 0.05 - ETA: 17s - loss: 4.4335 - acc: 0.05 - ETA: 17s - loss: 4.4346 - acc: 0.05 - ETA: 16s - loss: 4.4344 - acc: 0.05 - ETA: 16s - loss: 4.4341 - acc: 0.05 - ETA: 16s - loss: 4.4338 - acc: 0.05 - ETA: 16s - loss: 4.4335 - acc: 0.05 - ETA: 16s - loss: 4.4340 - acc: 0.05 - ETA: 15s - loss: 4.4333 - acc: 0.05 - ETA: 15s - loss: 4.4337 - acc: 0.05 - ETA: 15s - loss: 4.4348 - acc: 0.05 - ETA: 15s - loss: 4.4348 - acc: 0.05 - ETA: 15s - loss: 4.4344 - acc: 0.05 - ETA: 14s - loss: 4.4355 - acc: 0.05 - ETA: 14s - loss: 4.4363 - acc: 0.05 - ETA: 14s - loss: 4.4359 - acc: 0.05 - ETA: 14s - loss: 4.4355 - acc: 0.05 - ETA: 14s - loss: 4.4348 - acc: 0.05 - ETA: 13s - loss: 4.4335 - acc: 0.05 - ETA: 13s - loss: 4.4345 - acc: 0.05 - ETA: 13s - loss: 4.4329 - acc: 0.05 - ETA: 13s - loss: 4.4346 - acc: 0.05 - ETA: 12s - loss: 4.4354 - acc: 0.05 - ETA: 12s - loss: 4.4355 - acc: 0.05 - ETA: 12s - loss: 4.4349 - acc: 0.05 - ETA: 12s - loss: 4.4345 - acc: 0.05 - ETA: 12s - loss: 4.4350 - acc: 0.05 - ETA: 11s - loss: 4.4354 - acc: 0.05 - ETA: 11s - loss: 4.4354 - acc: 0.05 - ETA: 11s - loss: 4.4352 - acc: 0.05 - ETA: 11s - loss: 4.4351 - acc: 0.05 - ETA: 11s - loss: 4.4345 - acc: 0.05 - ETA: 10s - loss: 4.4332 - acc: 0.05 - ETA: 10s - loss: 4.4336 - acc: 0.05 - ETA: 10s - loss: 4.4351 - acc: 0.05 - ETA: 10s - loss: 4.4353 - acc: 0.05 - ETA: 10s - loss: 4.4358 - acc: 0.05 - ETA: 9s - loss: 4.4358 - acc: 0.0526 - ETA: 9s - loss: 4.4355 - acc: 0.052 - ETA: 9s - loss: 4.4354 - acc: 0.052 - ETA: 9s - loss: 4.4356 - acc: 0.052 - ETA: 9s - loss: 4.4354 - acc: 0.052 - ETA: 8s - loss: 4.4356 - acc: 0.052 - ETA: 8s - loss: 4.4351 - acc: 0.052 - ETA: 8s - loss: 4.4358 - acc: 0.052 - ETA: 8s - loss: 4.4360 - acc: 0.052 - ETA: 7s - loss: 4.4369 - acc: 0.052 - ETA: 7s - loss: 4.4367 - acc: 0.052 - ETA: 7s - loss: 4.4367 - acc: 0.052 - ETA: 7s - loss: 4.4363 - acc: 0.053 - ETA: 7s - loss: 4.4370 - acc: 0.053 - ETA: 6s - loss: 4.4354 - acc: 0.053 - ETA: 6s - loss: 4.4361 - acc: 0.053 - ETA: 6s - loss: 4.4360 - acc: 0.053 - ETA: 6s - loss: 4.4364 - acc: 0.053 - ETA: 6s - loss: 4.4359 - acc: 0.053 - ETA: 5s - loss: 4.4356 - acc: 0.053 - ETA: 5s - loss: 4.4352 - acc: 0.053 - ETA: 5s - loss: 4.4345 - acc: 0.053 - ETA: 5s - loss: 4.4335 - acc: 0.053 - ETA: 5s - loss: 4.4327 - acc: 0.053 - ETA: 4s - loss: 4.4318 - acc: 0.053 - ETA: 4s - loss: 4.4332 - acc: 0.053 - ETA: 4s - loss: 4.4337 - acc: 0.053 - ETA: 4s - loss: 4.4349 - acc: 0.053 - ETA: 3s - loss: 4.4358 - acc: 0.053 - ETA: 3s - loss: 4.4366 - acc: 0.053 - ETA: 3s - loss: 4.4370 - acc: 0.053 - ETA: 3s - loss: 4.4373 - acc: 0.053 - ETA: 3s - loss: 4.4365 - acc: 0.053 - ETA: 2s - loss: 4.4370 - acc: 0.053 - ETA: 2s - loss: 4.4376 - acc: 0.053 - ETA: 2s - loss: 4.4384 - acc: 0.053 - ETA: 2s - loss: 4.4380 - acc: 0.053 - ETA: 2s - loss: 4.4377 - acc: 0.052 - ETA: 1s - loss: 4.4370 - acc: 0.052 - ETA: 1s - loss: 4.4376 - acc: 0.052 - ETA: 1s - loss: 4.4365 - acc: 0.052 - ETA: 1s - loss: 4.4366 - acc: 0.052 - ETA: 1s - loss: 4.4371 - acc: 0.052 - ETA: 0s - loss: 4.4376 - acc: 0.052 - ETA: 0s - loss: 4.4370 - acc: 0.052 - ETA: 0s - loss: 4.4368 - acc: 0.052 - ETA: 0s - loss: 4.4368 - acc: 0.0524Epoch 00013: val_loss improved from 4.50706 to 4.46887, saving model to saved_models/weights.best.from_scratch.hdf5\n",
      "6680/6680 [==============================] - 72s - loss: 4.4377 - acc: 0.0522 - val_loss: 4.4689 - val_acc: 0.0563\n",
      "Epoch 15/32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4300/6680 [==================>...........] - ETA: 68s - loss: 4.3105 - acc: 0.05 - ETA: 67s - loss: 4.3913 - acc: 0.05 - ETA: 68s - loss: 4.3927 - acc: 0.06 - ETA: 68s - loss: 4.3441 - acc: 0.07 - ETA: 68s - loss: 4.3390 - acc: 0.06 - ETA: 68s - loss: 4.4594 - acc: 0.06 - ETA: 68s - loss: 4.4392 - acc: 0.05 - ETA: 68s - loss: 4.4290 - acc: 0.06 - ETA: 68s - loss: 4.4694 - acc: 0.06 - ETA: 67s - loss: 4.4833 - acc: 0.05 - ETA: 68s - loss: 4.4615 - acc: 0.05 - ETA: 67s - loss: 4.4399 - acc: 0.05 - ETA: 67s - loss: 4.4509 - acc: 0.05 - ETA: 67s - loss: 4.4280 - acc: 0.06 - ETA: 66s - loss: 4.4042 - acc: 0.07 - ETA: 66s - loss: 4.4006 - acc: 0.07 - ETA: 66s - loss: 4.3964 - acc: 0.07 - ETA: 66s - loss: 4.4059 - acc: 0.06 - ETA: 66s - loss: 4.3956 - acc: 0.06 - ETA: 65s - loss: 4.3948 - acc: 0.06 - ETA: 65s - loss: 4.3810 - acc: 0.06 - ETA: 65s - loss: 4.3982 - acc: 0.06 - ETA: 65s - loss: 4.3882 - acc: 0.06 - ETA: 64s - loss: 4.3835 - acc: 0.06 - ETA: 64s - loss: 4.3930 - acc: 0.06 - ETA: 64s - loss: 4.3985 - acc: 0.06 - ETA: 64s - loss: 4.3976 - acc: 0.06 - ETA: 64s - loss: 4.4008 - acc: 0.06 - ETA: 63s - loss: 4.4209 - acc: 0.06 - ETA: 63s - loss: 4.4129 - acc: 0.06 - ETA: 63s - loss: 4.4129 - acc: 0.06 - ETA: 63s - loss: 4.4082 - acc: 0.06 - ETA: 63s - loss: 4.4145 - acc: 0.06 - ETA: 62s - loss: 4.4060 - acc: 0.06 - ETA: 62s - loss: 4.4019 - acc: 0.06 - ETA: 62s - loss: 4.3992 - acc: 0.06 - ETA: 62s - loss: 4.4033 - acc: 0.06 - ETA: 61s - loss: 4.4005 - acc: 0.06 - ETA: 61s - loss: 4.4075 - acc: 0.06 - ETA: 61s - loss: 4.4011 - acc: 0.06 - ETA: 61s - loss: 4.3980 - acc: 0.06 - ETA: 61s - loss: 4.3971 - acc: 0.06 - ETA: 60s - loss: 4.4029 - acc: 0.06 - ETA: 60s - loss: 4.4081 - acc: 0.06 - ETA: 60s - loss: 4.4093 - acc: 0.06 - ETA: 60s - loss: 4.4095 - acc: 0.06 - ETA: 60s - loss: 4.4108 - acc: 0.06 - ETA: 59s - loss: 4.4129 - acc: 0.06 - ETA: 59s - loss: 4.4173 - acc: 0.06 - ETA: 59s - loss: 4.4302 - acc: 0.06 - ETA: 59s - loss: 4.4270 - acc: 0.05 - ETA: 59s - loss: 4.4265 - acc: 0.05 - ETA: 58s - loss: 4.4240 - acc: 0.05 - ETA: 58s - loss: 4.4298 - acc: 0.05 - ETA: 58s - loss: 4.4358 - acc: 0.05 - ETA: 58s - loss: 4.4381 - acc: 0.05 - ETA: 58s - loss: 4.4406 - acc: 0.05 - ETA: 57s - loss: 4.4362 - acc: 0.05 - ETA: 57s - loss: 4.4374 - acc: 0.05 - ETA: 57s - loss: 4.4356 - acc: 0.05 - ETA: 57s - loss: 4.4334 - acc: 0.05 - ETA: 56s - loss: 4.4305 - acc: 0.05 - ETA: 56s - loss: 4.4305 - acc: 0.06 - ETA: 56s - loss: 4.4386 - acc: 0.06 - ETA: 56s - loss: 4.4336 - acc: 0.06 - ETA: 56s - loss: 4.4323 - acc: 0.05 - ETA: 55s - loss: 4.4381 - acc: 0.05 - ETA: 55s - loss: 4.4343 - acc: 0.05 - ETA: 55s - loss: 4.4318 - acc: 0.05 - ETA: 55s - loss: 4.4346 - acc: 0.05 - ETA: 55s - loss: 4.4345 - acc: 0.05 - ETA: 54s - loss: 4.4355 - acc: 0.05 - ETA: 54s - loss: 4.4359 - acc: 0.05 - ETA: 54s - loss: 4.4365 - acc: 0.05 - ETA: 54s - loss: 4.4338 - acc: 0.05 - ETA: 54s - loss: 4.4349 - acc: 0.05 - ETA: 53s - loss: 4.4355 - acc: 0.05 - ETA: 53s - loss: 4.4346 - acc: 0.05 - ETA: 53s - loss: 4.4313 - acc: 0.05 - ETA: 53s - loss: 4.4318 - acc: 0.05 - ETA: 52s - loss: 4.4336 - acc: 0.05 - ETA: 52s - loss: 4.4388 - acc: 0.05 - ETA: 52s - loss: 4.4440 - acc: 0.05 - ETA: 52s - loss: 4.4444 - acc: 0.05 - ETA: 52s - loss: 4.4459 - acc: 0.05 - ETA: 51s - loss: 4.4479 - acc: 0.05 - ETA: 51s - loss: 4.4496 - acc: 0.05 - ETA: 51s - loss: 4.4471 - acc: 0.05 - ETA: 51s - loss: 4.4471 - acc: 0.05 - ETA: 51s - loss: 4.4460 - acc: 0.05 - ETA: 50s - loss: 4.4454 - acc: 0.05 - ETA: 50s - loss: 4.4462 - acc: 0.05 - ETA: 50s - loss: 4.4462 - acc: 0.05 - ETA: 50s - loss: 4.4482 - acc: 0.05 - ETA: 50s - loss: 4.4502 - acc: 0.05 - ETA: 50s - loss: 4.4474 - acc: 0.05 - ETA: 49s - loss: 4.4452 - acc: 0.05 - ETA: 49s - loss: 4.4439 - acc: 0.05 - ETA: 49s - loss: 4.4411 - acc: 0.05 - ETA: 49s - loss: 4.4390 - acc: 0.05 - ETA: 49s - loss: 4.4383 - acc: 0.05 - ETA: 48s - loss: 4.4370 - acc: 0.05 - ETA: 48s - loss: 4.4358 - acc: 0.05 - ETA: 48s - loss: 4.4376 - acc: 0.05 - ETA: 48s - loss: 4.4370 - acc: 0.05 - ETA: 47s - loss: 4.4325 - acc: 0.05 - ETA: 47s - loss: 4.4358 - acc: 0.05 - ETA: 47s - loss: 4.4386 - acc: 0.05 - ETA: 47s - loss: 4.4402 - acc: 0.05 - ETA: 47s - loss: 4.4396 - acc: 0.05 - ETA: 46s - loss: 4.4382 - acc: 0.05 - ETA: 46s - loss: 4.4360 - acc: 0.05 - ETA: 46s - loss: 4.4355 - acc: 0.05 - ETA: 46s - loss: 4.4350 - acc: 0.05 - ETA: 46s - loss: 4.4352 - acc: 0.05 - ETA: 45s - loss: 4.4373 - acc: 0.05 - ETA: 45s - loss: 4.4363 - acc: 0.05 - ETA: 45s - loss: 4.4320 - acc: 0.05 - ETA: 45s - loss: 4.4302 - acc: 0.05 - ETA: 45s - loss: 4.4289 - acc: 0.05 - ETA: 44s - loss: 4.4279 - acc: 0.05 - ETA: 44s - loss: 4.4263 - acc: 0.05 - ETA: 44s - loss: 4.4264 - acc: 0.05 - ETA: 44s - loss: 4.4282 - acc: 0.05 - ETA: 44s - loss: 4.4293 - acc: 0.05 - ETA: 43s - loss: 4.4313 - acc: 0.05 - ETA: 43s - loss: 4.4301 - acc: 0.05 - ETA: 43s - loss: 4.4282 - acc: 0.05 - ETA: 43s - loss: 4.4285 - acc: 0.05 - ETA: 42s - loss: 4.4280 - acc: 0.05 - ETA: 42s - loss: 4.4253 - acc: 0.05 - ETA: 42s - loss: 4.4296 - acc: 0.05 - ETA: 42s - loss: 4.4286 - acc: 0.05 - ETA: 42s - loss: 4.4286 - acc: 0.05 - ETA: 41s - loss: 4.4276 - acc: 0.05 - ETA: 41s - loss: 4.4285 - acc: 0.05 - ETA: 41s - loss: 4.4277 - acc: 0.05 - ETA: 41s - loss: 4.4299 - acc: 0.05 - ETA: 41s - loss: 4.4312 - acc: 0.05 - ETA: 40s - loss: 4.4313 - acc: 0.05 - ETA: 40s - loss: 4.4307 - acc: 0.05 - ETA: 40s - loss: 4.4308 - acc: 0.05 - ETA: 40s - loss: 4.4305 - acc: 0.05 - ETA: 39s - loss: 4.4311 - acc: 0.05 - ETA: 39s - loss: 4.4325 - acc: 0.05 - ETA: 39s - loss: 4.4324 - acc: 0.05 - ETA: 39s - loss: 4.4321 - acc: 0.05 - ETA: 39s - loss: 4.4312 - acc: 0.05 - ETA: 38s - loss: 4.4319 - acc: 0.05 - ETA: 38s - loss: 4.4315 - acc: 0.05 - ETA: 38s - loss: 4.4298 - acc: 0.05 - ETA: 38s - loss: 4.4295 - acc: 0.05 - ETA: 38s - loss: 4.4266 - acc: 0.05 - ETA: 37s - loss: 4.4255 - acc: 0.05 - ETA: 37s - loss: 4.4260 - acc: 0.05 - ETA: 37s - loss: 4.4277 - acc: 0.05 - ETA: 37s - loss: 4.4263 - acc: 0.05 - ETA: 36s - loss: 4.4264 - acc: 0.05 - ETA: 36s - loss: 4.4250 - acc: 0.05 - ETA: 36s - loss: 4.4242 - acc: 0.05 - ETA: 36s - loss: 4.4222 - acc: 0.05 - ETA: 36s - loss: 4.4207 - acc: 0.05 - ETA: 35s - loss: 4.4207 - acc: 0.05 - ETA: 35s - loss: 4.4203 - acc: 0.05 - ETA: 35s - loss: 4.4216 - acc: 0.05 - ETA: 35s - loss: 4.4218 - acc: 0.05 - ETA: 35s - loss: 4.4246 - acc: 0.05 - ETA: 34s - loss: 4.4227 - acc: 0.05 - ETA: 34s - loss: 4.4217 - acc: 0.05 - ETA: 34s - loss: 4.4218 - acc: 0.05 - ETA: 34s - loss: 4.4225 - acc: 0.05 - ETA: 34s - loss: 4.4217 - acc: 0.05 - ETA: 33s - loss: 4.4214 - acc: 0.05 - ETA: 33s - loss: 4.4215 - acc: 0.05 - ETA: 33s - loss: 4.4217 - acc: 0.05 - ETA: 33s - loss: 4.4215 - acc: 0.05 - ETA: 33s - loss: 4.4212 - acc: 0.05 - ETA: 32s - loss: 4.4218 - acc: 0.05 - ETA: 32s - loss: 4.4225 - acc: 0.05 - ETA: 32s - loss: 4.4213 - acc: 0.05 - ETA: 32s - loss: 4.4217 - acc: 0.05 - ETA: 31s - loss: 4.4215 - acc: 0.05 - ETA: 31s - loss: 4.4208 - acc: 0.05 - ETA: 31s - loss: 4.4213 - acc: 0.05 - ETA: 31s - loss: 4.4205 - acc: 0.05 - ETA: 31s - loss: 4.4232 - acc: 0.05 - ETA: 30s - loss: 4.4231 - acc: 0.05 - ETA: 30s - loss: 4.4227 - acc: 0.05 - ETA: 30s - loss: 4.4237 - acc: 0.05 - ETA: 30s - loss: 4.4230 - acc: 0.05 - ETA: 30s - loss: 4.4213 - acc: 0.05 - ETA: 29s - loss: 4.4201 - acc: 0.05 - ETA: 29s - loss: 4.4186 - acc: 0.05 - ETA: 29s - loss: 4.4200 - acc: 0.05 - ETA: 29s - loss: 4.4199 - acc: 0.05 - ETA: 29s - loss: 4.4198 - acc: 0.05 - ETA: 28s - loss: 4.4183 - acc: 0.05 - ETA: 28s - loss: 4.4191 - acc: 0.05 - ETA: 28s - loss: 4.4170 - acc: 0.05 - ETA: 28s - loss: 4.4166 - acc: 0.05 - ETA: 27s - loss: 4.4184 - acc: 0.05 - ETA: 27s - loss: 4.4186 - acc: 0.05 - ETA: 27s - loss: 4.4184 - acc: 0.05 - ETA: 27s - loss: 4.4180 - acc: 0.05 - ETA: 27s - loss: 4.4171 - acc: 0.05 - ETA: 26s - loss: 4.4160 - acc: 0.05 - ETA: 26s - loss: 4.4145 - acc: 0.05 - ETA: 26s - loss: 4.4120 - acc: 0.05 - ETA: 26s - loss: 4.4131 - acc: 0.05 - ETA: 26s - loss: 4.4133 - acc: 0.05 - ETA: 25s - loss: 4.4153 - acc: 0.05 - ETA: 25s - loss: 4.4167 - acc: 0.05 - ETA: 25s - loss: 4.4157 - acc: 0.05 - ETA: 25s - loss: 4.4162 - acc: 0.05 - ETA: 25s - loss: 4.4162 - acc: 0.0537"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6660/6680 [============================>.] - ETA: 24s - loss: 4.4169 - acc: 0.05 - ETA: 24s - loss: 4.4159 - acc: 0.05 - ETA: 24s - loss: 4.4164 - acc: 0.05 - ETA: 24s - loss: 4.4160 - acc: 0.05 - ETA: 23s - loss: 4.4162 - acc: 0.05 - ETA: 23s - loss: 4.4157 - acc: 0.05 - ETA: 23s - loss: 4.4156 - acc: 0.05 - ETA: 23s - loss: 4.4147 - acc: 0.05 - ETA: 23s - loss: 4.4146 - acc: 0.05 - ETA: 22s - loss: 4.4148 - acc: 0.05 - ETA: 22s - loss: 4.4140 - acc: 0.05 - ETA: 22s - loss: 4.4134 - acc: 0.05 - ETA: 22s - loss: 4.4154 - acc: 0.05 - ETA: 22s - loss: 4.4159 - acc: 0.05 - ETA: 21s - loss: 4.4173 - acc: 0.05 - ETA: 21s - loss: 4.4175 - acc: 0.05 - ETA: 21s - loss: 4.4178 - acc: 0.05 - ETA: 21s - loss: 4.4166 - acc: 0.05 - ETA: 21s - loss: 4.4188 - acc: 0.05 - ETA: 20s - loss: 4.4173 - acc: 0.05 - ETA: 20s - loss: 4.4172 - acc: 0.05 - ETA: 20s - loss: 4.4182 - acc: 0.05 - ETA: 20s - loss: 4.4176 - acc: 0.05 - ETA: 19s - loss: 4.4186 - acc: 0.05 - ETA: 19s - loss: 4.4187 - acc: 0.05 - ETA: 19s - loss: 4.4172 - acc: 0.05 - ETA: 19s - loss: 4.4173 - acc: 0.05 - ETA: 19s - loss: 4.4173 - acc: 0.05 - ETA: 18s - loss: 4.4168 - acc: 0.05 - ETA: 18s - loss: 4.4180 - acc: 0.05 - ETA: 18s - loss: 4.4180 - acc: 0.05 - ETA: 18s - loss: 4.4179 - acc: 0.05 - ETA: 18s - loss: 4.4167 - acc: 0.05 - ETA: 17s - loss: 4.4161 - acc: 0.05 - ETA: 17s - loss: 4.4166 - acc: 0.05 - ETA: 17s - loss: 4.4177 - acc: 0.05 - ETA: 17s - loss: 4.4174 - acc: 0.05 - ETA: 17s - loss: 4.4173 - acc: 0.05 - ETA: 16s - loss: 4.4172 - acc: 0.05 - ETA: 16s - loss: 4.4167 - acc: 0.05 - ETA: 16s - loss: 4.4158 - acc: 0.05 - ETA: 16s - loss: 4.4158 - acc: 0.05 - ETA: 15s - loss: 4.4144 - acc: 0.05 - ETA: 15s - loss: 4.4135 - acc: 0.05 - ETA: 15s - loss: 4.4138 - acc: 0.05 - ETA: 15s - loss: 4.4141 - acc: 0.05 - ETA: 15s - loss: 4.4146 - acc: 0.05 - ETA: 14s - loss: 4.4143 - acc: 0.05 - ETA: 14s - loss: 4.4144 - acc: 0.05 - ETA: 14s - loss: 4.4150 - acc: 0.05 - ETA: 14s - loss: 4.4151 - acc: 0.05 - ETA: 14s - loss: 4.4147 - acc: 0.05 - ETA: 13s - loss: 4.4142 - acc: 0.05 - ETA: 13s - loss: 4.4152 - acc: 0.05 - ETA: 13s - loss: 4.4147 - acc: 0.05 - ETA: 13s - loss: 4.4128 - acc: 0.05 - ETA: 13s - loss: 4.4115 - acc: 0.05 - ETA: 12s - loss: 4.4110 - acc: 0.05 - ETA: 12s - loss: 4.4101 - acc: 0.05 - ETA: 12s - loss: 4.4095 - acc: 0.05 - ETA: 12s - loss: 4.4085 - acc: 0.05 - ETA: 11s - loss: 4.4080 - acc: 0.05 - ETA: 11s - loss: 4.4081 - acc: 0.05 - ETA: 11s - loss: 4.4076 - acc: 0.05 - ETA: 11s - loss: 4.4079 - acc: 0.05 - ETA: 11s - loss: 4.4094 - acc: 0.05 - ETA: 10s - loss: 4.4092 - acc: 0.05 - ETA: 10s - loss: 4.4101 - acc: 0.05 - ETA: 10s - loss: 4.4101 - acc: 0.05 - ETA: 10s - loss: 4.4094 - acc: 0.05 - ETA: 10s - loss: 4.4094 - acc: 0.05 - ETA: 9s - loss: 4.4097 - acc: 0.0524 - ETA: 9s - loss: 4.4095 - acc: 0.052 - ETA: 9s - loss: 4.4099 - acc: 0.052 - ETA: 9s - loss: 4.4092 - acc: 0.052 - ETA: 9s - loss: 4.4097 - acc: 0.052 - ETA: 8s - loss: 4.4091 - acc: 0.053 - ETA: 8s - loss: 4.4097 - acc: 0.052 - ETA: 8s - loss: 4.4093 - acc: 0.052 - ETA: 8s - loss: 4.4090 - acc: 0.052 - ETA: 7s - loss: 4.4084 - acc: 0.052 - ETA: 7s - loss: 4.4102 - acc: 0.052 - ETA: 7s - loss: 4.4102 - acc: 0.052 - ETA: 7s - loss: 4.4095 - acc: 0.052 - ETA: 7s - loss: 4.4096 - acc: 0.052 - ETA: 6s - loss: 4.4114 - acc: 0.052 - ETA: 6s - loss: 4.4099 - acc: 0.053 - ETA: 6s - loss: 4.4099 - acc: 0.053 - ETA: 6s - loss: 4.4104 - acc: 0.053 - ETA: 6s - loss: 4.4112 - acc: 0.052 - ETA: 5s - loss: 4.4111 - acc: 0.052 - ETA: 5s - loss: 4.4103 - acc: 0.052 - ETA: 5s - loss: 4.4094 - acc: 0.052 - ETA: 5s - loss: 4.4095 - acc: 0.052 - ETA: 5s - loss: 4.4089 - acc: 0.052 - ETA: 4s - loss: 4.4102 - acc: 0.052 - ETA: 4s - loss: 4.4107 - acc: 0.052 - ETA: 4s - loss: 4.4096 - acc: 0.052 - ETA: 4s - loss: 4.4097 - acc: 0.053 - ETA: 3s - loss: 4.4102 - acc: 0.052 - ETA: 3s - loss: 4.4103 - acc: 0.052 - ETA: 3s - loss: 4.4109 - acc: 0.052 - ETA: 3s - loss: 4.4123 - acc: 0.052 - ETA: 3s - loss: 4.4109 - acc: 0.052 - ETA: 2s - loss: 4.4112 - acc: 0.052 - ETA: 2s - loss: 4.4109 - acc: 0.052 - ETA: 2s - loss: 4.4120 - acc: 0.052 - ETA: 2s - loss: 4.4120 - acc: 0.052 - ETA: 2s - loss: 4.4121 - acc: 0.052 - ETA: 1s - loss: 4.4123 - acc: 0.052 - ETA: 1s - loss: 4.4130 - acc: 0.052 - ETA: 1s - loss: 4.4142 - acc: 0.052 - ETA: 1s - loss: 4.4149 - acc: 0.052 - ETA: 1s - loss: 4.4154 - acc: 0.052 - ETA: 0s - loss: 4.4147 - acc: 0.052 - ETA: 0s - loss: 4.4139 - acc: 0.052 - ETA: 0s - loss: 4.4131 - acc: 0.052 - ETA: 0s - loss: 4.4132 - acc: 0.0527Epoch 00014: val_loss improved from 4.46887 to 4.44351, saving model to saved_models/weights.best.from_scratch.hdf5\n",
      "6680/6680 [==============================] - 73s - loss: 4.4135 - acc: 0.0527 - val_loss: 4.4435 - val_acc: 0.0551\n",
      "Epoch 16/32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4300/6680 [==================>...........] - ETA: 69s - loss: 4.3197 - acc: 0.05 - ETA: 68s - loss: 4.4120 - acc: 0.07 - ETA: 69s - loss: 4.3122 - acc: 0.08 - ETA: 68s - loss: 4.3226 - acc: 0.08 - ETA: 68s - loss: 4.3126 - acc: 0.09 - ETA: 68s - loss: 4.2947 - acc: 0.09 - ETA: 67s - loss: 4.3125 - acc: 0.08 - ETA: 68s - loss: 4.3529 - acc: 0.08 - ETA: 68s - loss: 4.3753 - acc: 0.07 - ETA: 67s - loss: 4.3404 - acc: 0.08 - ETA: 67s - loss: 4.3753 - acc: 0.08 - ETA: 67s - loss: 4.3737 - acc: 0.07 - ETA: 67s - loss: 4.3869 - acc: 0.07 - ETA: 67s - loss: 4.3895 - acc: 0.07 - ETA: 66s - loss: 4.3873 - acc: 0.07 - ETA: 66s - loss: 4.3780 - acc: 0.06 - ETA: 66s - loss: 4.3948 - acc: 0.06 - ETA: 66s - loss: 4.3714 - acc: 0.06 - ETA: 66s - loss: 4.3753 - acc: 0.06 - ETA: 65s - loss: 4.3658 - acc: 0.07 - ETA: 65s - loss: 4.3795 - acc: 0.07 - ETA: 65s - loss: 4.3724 - acc: 0.07 - ETA: 65s - loss: 4.3684 - acc: 0.07 - ETA: 65s - loss: 4.3839 - acc: 0.07 - ETA: 64s - loss: 4.3759 - acc: 0.07 - ETA: 64s - loss: 4.3788 - acc: 0.07 - ETA: 64s - loss: 4.3832 - acc: 0.07 - ETA: 64s - loss: 4.3815 - acc: 0.07 - ETA: 64s - loss: 4.3789 - acc: 0.07 - ETA: 63s - loss: 4.3688 - acc: 0.07 - ETA: 63s - loss: 4.3616 - acc: 0.07 - ETA: 63s - loss: 4.3753 - acc: 0.07 - ETA: 63s - loss: 4.3714 - acc: 0.07 - ETA: 63s - loss: 4.3724 - acc: 0.07 - ETA: 62s - loss: 4.3684 - acc: 0.07 - ETA: 62s - loss: 4.3842 - acc: 0.06 - ETA: 62s - loss: 4.3882 - acc: 0.06 - ETA: 62s - loss: 4.3853 - acc: 0.06 - ETA: 62s - loss: 4.3912 - acc: 0.06 - ETA: 61s - loss: 4.3875 - acc: 0.06 - ETA: 61s - loss: 4.3857 - acc: 0.06 - ETA: 61s - loss: 4.3806 - acc: 0.06 - ETA: 61s - loss: 4.3797 - acc: 0.06 - ETA: 61s - loss: 4.3803 - acc: 0.06 - ETA: 60s - loss: 4.3907 - acc: 0.06 - ETA: 60s - loss: 4.3903 - acc: 0.06 - ETA: 60s - loss: 4.3978 - acc: 0.06 - ETA: 60s - loss: 4.4075 - acc: 0.06 - ETA: 60s - loss: 4.4088 - acc: 0.06 - ETA: 59s - loss: 4.4099 - acc: 0.06 - ETA: 59s - loss: 4.4121 - acc: 0.06 - ETA: 59s - loss: 4.4152 - acc: 0.06 - ETA: 59s - loss: 4.4145 - acc: 0.06 - ETA: 59s - loss: 4.4153 - acc: 0.06 - ETA: 58s - loss: 4.4129 - acc: 0.06 - ETA: 58s - loss: 4.4069 - acc: 0.06 - ETA: 58s - loss: 4.4127 - acc: 0.06 - ETA: 58s - loss: 4.4020 - acc: 0.06 - ETA: 58s - loss: 4.4042 - acc: 0.06 - ETA: 58s - loss: 4.4020 - acc: 0.06 - ETA: 57s - loss: 4.4025 - acc: 0.06 - ETA: 57s - loss: 4.4001 - acc: 0.06 - ETA: 57s - loss: 4.4004 - acc: 0.06 - ETA: 57s - loss: 4.3966 - acc: 0.06 - ETA: 57s - loss: 4.3970 - acc: 0.06 - ETA: 56s - loss: 4.3951 - acc: 0.06 - ETA: 56s - loss: 4.3960 - acc: 0.06 - ETA: 56s - loss: 4.3921 - acc: 0.06 - ETA: 56s - loss: 4.3922 - acc: 0.06 - ETA: 55s - loss: 4.3900 - acc: 0.06 - ETA: 55s - loss: 4.3952 - acc: 0.06 - ETA: 55s - loss: 4.3946 - acc: 0.06 - ETA: 55s - loss: 4.3985 - acc: 0.06 - ETA: 55s - loss: 4.3976 - acc: 0.06 - ETA: 54s - loss: 4.3983 - acc: 0.06 - ETA: 54s - loss: 4.3940 - acc: 0.06 - ETA: 54s - loss: 4.3957 - acc: 0.06 - ETA: 54s - loss: 4.3935 - acc: 0.06 - ETA: 54s - loss: 4.3902 - acc: 0.06 - ETA: 53s - loss: 4.3906 - acc: 0.06 - ETA: 53s - loss: 4.3912 - acc: 0.06 - ETA: 53s - loss: 4.3925 - acc: 0.06 - ETA: 53s - loss: 4.3877 - acc: 0.06 - ETA: 52s - loss: 4.3914 - acc: 0.06 - ETA: 52s - loss: 4.3952 - acc: 0.06 - ETA: 52s - loss: 4.3957 - acc: 0.06 - ETA: 52s - loss: 4.3988 - acc: 0.05 - ETA: 52s - loss: 4.3986 - acc: 0.05 - ETA: 51s - loss: 4.3991 - acc: 0.05 - ETA: 51s - loss: 4.3979 - acc: 0.05 - ETA: 51s - loss: 4.3966 - acc: 0.05 - ETA: 51s - loss: 4.3962 - acc: 0.05 - ETA: 50s - loss: 4.3911 - acc: 0.05 - ETA: 50s - loss: 4.3849 - acc: 0.05 - ETA: 50s - loss: 4.3824 - acc: 0.05 - ETA: 50s - loss: 4.3863 - acc: 0.05 - ETA: 50s - loss: 4.3889 - acc: 0.05 - ETA: 49s - loss: 4.3886 - acc: 0.05 - ETA: 49s - loss: 4.3892 - acc: 0.05 - ETA: 49s - loss: 4.3875 - acc: 0.05 - ETA: 49s - loss: 4.3867 - acc: 0.05 - ETA: 49s - loss: 4.3877 - acc: 0.05 - ETA: 48s - loss: 4.3851 - acc: 0.05 - ETA: 48s - loss: 4.3860 - acc: 0.05 - ETA: 48s - loss: 4.3870 - acc: 0.05 - ETA: 48s - loss: 4.3875 - acc: 0.05 - ETA: 47s - loss: 4.3888 - acc: 0.05 - ETA: 47s - loss: 4.3857 - acc: 0.05 - ETA: 47s - loss: 4.3847 - acc: 0.05 - ETA: 47s - loss: 4.3825 - acc: 0.05 - ETA: 47s - loss: 4.3816 - acc: 0.05 - ETA: 46s - loss: 4.3840 - acc: 0.05 - ETA: 46s - loss: 4.3834 - acc: 0.05 - ETA: 46s - loss: 4.3815 - acc: 0.05 - ETA: 46s - loss: 4.3821 - acc: 0.05 - ETA: 46s - loss: 4.3809 - acc: 0.05 - ETA: 45s - loss: 4.3796 - acc: 0.05 - ETA: 45s - loss: 4.3805 - acc: 0.05 - ETA: 45s - loss: 4.3789 - acc: 0.05 - ETA: 45s - loss: 4.3763 - acc: 0.05 - ETA: 44s - loss: 4.3740 - acc: 0.05 - ETA: 44s - loss: 4.3738 - acc: 0.05 - ETA: 44s - loss: 4.3753 - acc: 0.05 - ETA: 44s - loss: 4.3764 - acc: 0.05 - ETA: 44s - loss: 4.3754 - acc: 0.05 - ETA: 43s - loss: 4.3734 - acc: 0.05 - ETA: 43s - loss: 4.3729 - acc: 0.05 - ETA: 43s - loss: 4.3717 - acc: 0.05 - ETA: 43s - loss: 4.3726 - acc: 0.05 - ETA: 43s - loss: 4.3726 - acc: 0.05 - ETA: 42s - loss: 4.3727 - acc: 0.05 - ETA: 42s - loss: 4.3715 - acc: 0.05 - ETA: 42s - loss: 4.3703 - acc: 0.05 - ETA: 42s - loss: 4.3721 - acc: 0.05 - ETA: 41s - loss: 4.3740 - acc: 0.05 - ETA: 41s - loss: 4.3722 - acc: 0.05 - ETA: 41s - loss: 4.3711 - acc: 0.05 - ETA: 41s - loss: 4.3716 - acc: 0.05 - ETA: 41s - loss: 4.3720 - acc: 0.05 - ETA: 40s - loss: 4.3704 - acc: 0.05 - ETA: 40s - loss: 4.3693 - acc: 0.05 - ETA: 40s - loss: 4.3686 - acc: 0.05 - ETA: 40s - loss: 4.3683 - acc: 0.05 - ETA: 40s - loss: 4.3697 - acc: 0.05 - ETA: 39s - loss: 4.3689 - acc: 0.05 - ETA: 39s - loss: 4.3690 - acc: 0.05 - ETA: 39s - loss: 4.3697 - acc: 0.06 - ETA: 39s - loss: 4.3690 - acc: 0.06 - ETA: 38s - loss: 4.3700 - acc: 0.06 - ETA: 38s - loss: 4.3714 - acc: 0.05 - ETA: 38s - loss: 4.3696 - acc: 0.05 - ETA: 38s - loss: 4.3694 - acc: 0.05 - ETA: 38s - loss: 4.3726 - acc: 0.05 - ETA: 37s - loss: 4.3722 - acc: 0.05 - ETA: 37s - loss: 4.3727 - acc: 0.05 - ETA: 37s - loss: 4.3722 - acc: 0.05 - ETA: 37s - loss: 4.3702 - acc: 0.05 - ETA: 37s - loss: 4.3689 - acc: 0.06 - ETA: 36s - loss: 4.3690 - acc: 0.05 - ETA: 36s - loss: 4.3699 - acc: 0.05 - ETA: 36s - loss: 4.3706 - acc: 0.05 - ETA: 36s - loss: 4.3679 - acc: 0.05 - ETA: 36s - loss: 4.3656 - acc: 0.05 - ETA: 35s - loss: 4.3659 - acc: 0.05 - ETA: 35s - loss: 4.3683 - acc: 0.05 - ETA: 35s - loss: 4.3674 - acc: 0.05 - ETA: 35s - loss: 4.3668 - acc: 0.05 - ETA: 34s - loss: 4.3666 - acc: 0.05 - ETA: 34s - loss: 4.3658 - acc: 0.05 - ETA: 34s - loss: 4.3640 - acc: 0.05 - ETA: 34s - loss: 4.3636 - acc: 0.05 - ETA: 34s - loss: 4.3641 - acc: 0.05 - ETA: 33s - loss: 4.3655 - acc: 0.05 - ETA: 33s - loss: 4.3683 - acc: 0.05 - ETA: 33s - loss: 4.3687 - acc: 0.05 - ETA: 33s - loss: 4.3706 - acc: 0.05 - ETA: 33s - loss: 4.3749 - acc: 0.05 - ETA: 32s - loss: 4.3753 - acc: 0.05 - ETA: 32s - loss: 4.3741 - acc: 0.05 - ETA: 32s - loss: 4.3750 - acc: 0.05 - ETA: 32s - loss: 4.3747 - acc: 0.05 - ETA: 32s - loss: 4.3747 - acc: 0.05 - ETA: 31s - loss: 4.3756 - acc: 0.05 - ETA: 31s - loss: 4.3752 - acc: 0.05 - ETA: 31s - loss: 4.3754 - acc: 0.05 - ETA: 31s - loss: 4.3765 - acc: 0.05 - ETA: 30s - loss: 4.3762 - acc: 0.05 - ETA: 30s - loss: 4.3785 - acc: 0.05 - ETA: 30s - loss: 4.3766 - acc: 0.05 - ETA: 30s - loss: 4.3774 - acc: 0.05 - ETA: 30s - loss: 4.3764 - acc: 0.05 - ETA: 29s - loss: 4.3750 - acc: 0.05 - ETA: 29s - loss: 4.3756 - acc: 0.05 - ETA: 29s - loss: 4.3749 - acc: 0.05 - ETA: 29s - loss: 4.3733 - acc: 0.05 - ETA: 29s - loss: 4.3734 - acc: 0.05 - ETA: 28s - loss: 4.3739 - acc: 0.05 - ETA: 28s - loss: 4.3738 - acc: 0.05 - ETA: 28s - loss: 4.3732 - acc: 0.05 - ETA: 28s - loss: 4.3733 - acc: 0.05 - ETA: 28s - loss: 4.3737 - acc: 0.05 - ETA: 27s - loss: 4.3748 - acc: 0.05 - ETA: 27s - loss: 4.3749 - acc: 0.05 - ETA: 27s - loss: 4.3752 - acc: 0.05 - ETA: 27s - loss: 4.3758 - acc: 0.05 - ETA: 26s - loss: 4.3751 - acc: 0.05 - ETA: 26s - loss: 4.3737 - acc: 0.05 - ETA: 26s - loss: 4.3729 - acc: 0.05 - ETA: 26s - loss: 4.3738 - acc: 0.05 - ETA: 26s - loss: 4.3750 - acc: 0.05 - ETA: 25s - loss: 4.3753 - acc: 0.05 - ETA: 25s - loss: 4.3759 - acc: 0.05 - ETA: 25s - loss: 4.3772 - acc: 0.05 - ETA: 25s - loss: 4.3772 - acc: 0.05 - ETA: 25s - loss: 4.3767 - acc: 0.0565"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6660/6680 [============================>.] - ETA: 24s - loss: 4.3785 - acc: 0.05 - ETA: 24s - loss: 4.3797 - acc: 0.05 - ETA: 24s - loss: 4.3801 - acc: 0.05 - ETA: 24s - loss: 4.3795 - acc: 0.05 - ETA: 24s - loss: 4.3796 - acc: 0.05 - ETA: 23s - loss: 4.3806 - acc: 0.05 - ETA: 23s - loss: 4.3797 - acc: 0.05 - ETA: 23s - loss: 4.3798 - acc: 0.05 - ETA: 23s - loss: 4.3804 - acc: 0.05 - ETA: 22s - loss: 4.3823 - acc: 0.05 - ETA: 22s - loss: 4.3815 - acc: 0.05 - ETA: 22s - loss: 4.3809 - acc: 0.05 - ETA: 22s - loss: 4.3798 - acc: 0.05 - ETA: 22s - loss: 4.3799 - acc: 0.05 - ETA: 21s - loss: 4.3808 - acc: 0.05 - ETA: 21s - loss: 4.3813 - acc: 0.05 - ETA: 21s - loss: 4.3805 - acc: 0.05 - ETA: 21s - loss: 4.3796 - acc: 0.05 - ETA: 21s - loss: 4.3780 - acc: 0.05 - ETA: 20s - loss: 4.3774 - acc: 0.05 - ETA: 20s - loss: 4.3764 - acc: 0.05 - ETA: 20s - loss: 4.3760 - acc: 0.05 - ETA: 20s - loss: 4.3763 - acc: 0.05 - ETA: 20s - loss: 4.3764 - acc: 0.05 - ETA: 19s - loss: 4.3757 - acc: 0.05 - ETA: 19s - loss: 4.3795 - acc: 0.05 - ETA: 19s - loss: 4.3793 - acc: 0.05 - ETA: 19s - loss: 4.3792 - acc: 0.05 - ETA: 18s - loss: 4.3788 - acc: 0.05 - ETA: 18s - loss: 4.3784 - acc: 0.05 - ETA: 18s - loss: 4.3773 - acc: 0.05 - ETA: 18s - loss: 4.3775 - acc: 0.05 - ETA: 18s - loss: 4.3785 - acc: 0.05 - ETA: 17s - loss: 4.3780 - acc: 0.05 - ETA: 17s - loss: 4.3782 - acc: 0.05 - ETA: 17s - loss: 4.3793 - acc: 0.05 - ETA: 17s - loss: 4.3793 - acc: 0.05 - ETA: 17s - loss: 4.3785 - acc: 0.05 - ETA: 16s - loss: 4.3791 - acc: 0.05 - ETA: 16s - loss: 4.3795 - acc: 0.05 - ETA: 16s - loss: 4.3796 - acc: 0.05 - ETA: 16s - loss: 4.3792 - acc: 0.05 - ETA: 16s - loss: 4.3800 - acc: 0.05 - ETA: 15s - loss: 4.3791 - acc: 0.05 - ETA: 15s - loss: 4.3797 - acc: 0.05 - ETA: 15s - loss: 4.3799 - acc: 0.05 - ETA: 15s - loss: 4.3788 - acc: 0.05 - ETA: 14s - loss: 4.3788 - acc: 0.05 - ETA: 14s - loss: 4.3800 - acc: 0.05 - ETA: 14s - loss: 4.3811 - acc: 0.05 - ETA: 14s - loss: 4.3813 - acc: 0.05 - ETA: 14s - loss: 4.3797 - acc: 0.05 - ETA: 13s - loss: 4.3788 - acc: 0.05 - ETA: 13s - loss: 4.3777 - acc: 0.05 - ETA: 13s - loss: 4.3774 - acc: 0.05 - ETA: 13s - loss: 4.3775 - acc: 0.05 - ETA: 13s - loss: 4.3767 - acc: 0.05 - ETA: 12s - loss: 4.3769 - acc: 0.05 - ETA: 12s - loss: 4.3770 - acc: 0.05 - ETA: 12s - loss: 4.3775 - acc: 0.05 - ETA: 12s - loss: 4.3769 - acc: 0.05 - ETA: 12s - loss: 4.3778 - acc: 0.05 - ETA: 11s - loss: 4.3775 - acc: 0.05 - ETA: 11s - loss: 4.3767 - acc: 0.05 - ETA: 11s - loss: 4.3774 - acc: 0.05 - ETA: 11s - loss: 4.3768 - acc: 0.05 - ETA: 10s - loss: 4.3770 - acc: 0.05 - ETA: 10s - loss: 4.3772 - acc: 0.05 - ETA: 10s - loss: 4.3767 - acc: 0.05 - ETA: 10s - loss: 4.3759 - acc: 0.05 - ETA: 10s - loss: 4.3760 - acc: 0.05 - ETA: 9s - loss: 4.3765 - acc: 0.0554 - ETA: 9s - loss: 4.3758 - acc: 0.055 - ETA: 9s - loss: 4.3767 - acc: 0.055 - ETA: 9s - loss: 4.3770 - acc: 0.055 - ETA: 9s - loss: 4.3781 - acc: 0.055 - ETA: 8s - loss: 4.3784 - acc: 0.055 - ETA: 8s - loss: 4.3773 - acc: 0.054 - ETA: 8s - loss: 4.3779 - acc: 0.054 - ETA: 8s - loss: 4.3778 - acc: 0.054 - ETA: 8s - loss: 4.3783 - acc: 0.054 - ETA: 7s - loss: 4.3767 - acc: 0.054 - ETA: 7s - loss: 4.3775 - acc: 0.054 - ETA: 7s - loss: 4.3767 - acc: 0.054 - ETA: 7s - loss: 4.3762 - acc: 0.054 - ETA: 6s - loss: 4.3773 - acc: 0.054 - ETA: 6s - loss: 4.3774 - acc: 0.054 - ETA: 6s - loss: 4.3779 - acc: 0.054 - ETA: 6s - loss: 4.3773 - acc: 0.053 - ETA: 6s - loss: 4.3774 - acc: 0.053 - ETA: 5s - loss: 4.3767 - acc: 0.053 - ETA: 5s - loss: 4.3771 - acc: 0.053 - ETA: 5s - loss: 4.3784 - acc: 0.053 - ETA: 5s - loss: 4.3791 - acc: 0.053 - ETA: 5s - loss: 4.3786 - acc: 0.053 - ETA: 4s - loss: 4.3782 - acc: 0.053 - ETA: 4s - loss: 4.3781 - acc: 0.053 - ETA: 4s - loss: 4.3783 - acc: 0.053 - ETA: 4s - loss: 4.3787 - acc: 0.053 - ETA: 4s - loss: 4.3779 - acc: 0.053 - ETA: 3s - loss: 4.3779 - acc: 0.053 - ETA: 3s - loss: 4.3802 - acc: 0.053 - ETA: 3s - loss: 4.3807 - acc: 0.053 - ETA: 3s - loss: 4.3804 - acc: 0.053 - ETA: 2s - loss: 4.3804 - acc: 0.053 - ETA: 2s - loss: 4.3800 - acc: 0.053 - ETA: 2s - loss: 4.3800 - acc: 0.053 - ETA: 2s - loss: 4.3792 - acc: 0.053 - ETA: 2s - loss: 4.3789 - acc: 0.053 - ETA: 1s - loss: 4.3785 - acc: 0.053 - ETA: 1s - loss: 4.3774 - acc: 0.053 - ETA: 1s - loss: 4.3778 - acc: 0.053 - ETA: 1s - loss: 4.3783 - acc: 0.053 - ETA: 1s - loss: 4.3792 - acc: 0.053 - ETA: 0s - loss: 4.3785 - acc: 0.053 - ETA: 0s - loss: 4.3776 - acc: 0.053 - ETA: 0s - loss: 4.3772 - acc: 0.053 - ETA: 0s - loss: 4.3768 - acc: 0.0538Epoch 00015: val_loss did not improve\n",
      "6680/6680 [==============================] - 73s - loss: 4.3760 - acc: 0.0539 - val_loss: 4.4678 - val_acc: 0.0527\n",
      "Epoch 17/32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4300/6680 [==================>...........] - ETA: 70s - loss: 4.5351 - acc: 0.15 - ETA: 71s - loss: 4.4523 - acc: 0.12 - ETA: 72s - loss: 4.4448 - acc: 0.10 - ETA: 71s - loss: 4.4127 - acc: 0.08 - ETA: 71s - loss: 4.4029 - acc: 0.09 - ETA: 70s - loss: 4.3621 - acc: 0.11 - ETA: 69s - loss: 4.3534 - acc: 0.10 - ETA: 69s - loss: 4.3443 - acc: 0.09 - ETA: 68s - loss: 4.3437 - acc: 0.10 - ETA: 68s - loss: 4.3469 - acc: 0.10 - ETA: 68s - loss: 4.3500 - acc: 0.10 - ETA: 68s - loss: 4.3463 - acc: 0.10 - ETA: 68s - loss: 4.3640 - acc: 0.09 - ETA: 67s - loss: 4.3693 - acc: 0.09 - ETA: 67s - loss: 4.3827 - acc: 0.09 - ETA: 67s - loss: 4.3820 - acc: 0.08 - ETA: 67s - loss: 4.3923 - acc: 0.08 - ETA: 66s - loss: 4.4034 - acc: 0.07 - ETA: 66s - loss: 4.4010 - acc: 0.07 - ETA: 66s - loss: 4.3958 - acc: 0.07 - ETA: 66s - loss: 4.3915 - acc: 0.07 - ETA: 66s - loss: 4.3900 - acc: 0.07 - ETA: 65s - loss: 4.3856 - acc: 0.07 - ETA: 65s - loss: 4.3663 - acc: 0.07 - ETA: 65s - loss: 4.3675 - acc: 0.07 - ETA: 65s - loss: 4.3698 - acc: 0.07 - ETA: 65s - loss: 4.3708 - acc: 0.07 - ETA: 64s - loss: 4.3769 - acc: 0.07 - ETA: 64s - loss: 4.3803 - acc: 0.07 - ETA: 64s - loss: 4.3764 - acc: 0.07 - ETA: 64s - loss: 4.3854 - acc: 0.07 - ETA: 63s - loss: 4.3890 - acc: 0.07 - ETA: 63s - loss: 4.3852 - acc: 0.07 - ETA: 63s - loss: 4.3886 - acc: 0.07 - ETA: 63s - loss: 4.3875 - acc: 0.07 - ETA: 63s - loss: 4.3897 - acc: 0.06 - ETA: 62s - loss: 4.3903 - acc: 0.07 - ETA: 62s - loss: 4.3962 - acc: 0.06 - ETA: 62s - loss: 4.3989 - acc: 0.06 - ETA: 62s - loss: 4.3885 - acc: 0.06 - ETA: 62s - loss: 4.3793 - acc: 0.06 - ETA: 61s - loss: 4.3791 - acc: 0.06 - ETA: 61s - loss: 4.3748 - acc: 0.06 - ETA: 61s - loss: 4.3790 - acc: 0.06 - ETA: 61s - loss: 4.3832 - acc: 0.06 - ETA: 60s - loss: 4.3791 - acc: 0.06 - ETA: 60s - loss: 4.3836 - acc: 0.06 - ETA: 60s - loss: 4.3806 - acc: 0.06 - ETA: 60s - loss: 4.3797 - acc: 0.06 - ETA: 59s - loss: 4.3781 - acc: 0.06 - ETA: 59s - loss: 4.3775 - acc: 0.06 - ETA: 59s - loss: 4.3750 - acc: 0.06 - ETA: 59s - loss: 4.3755 - acc: 0.06 - ETA: 59s - loss: 4.3786 - acc: 0.06 - ETA: 58s - loss: 4.3807 - acc: 0.06 - ETA: 58s - loss: 4.3794 - acc: 0.06 - ETA: 58s - loss: 4.3816 - acc: 0.06 - ETA: 58s - loss: 4.3800 - acc: 0.06 - ETA: 58s - loss: 4.3792 - acc: 0.06 - ETA: 57s - loss: 4.3737 - acc: 0.06 - ETA: 57s - loss: 4.3712 - acc: 0.06 - ETA: 57s - loss: 4.3710 - acc: 0.06 - ETA: 57s - loss: 4.3695 - acc: 0.06 - ETA: 57s - loss: 4.3675 - acc: 0.06 - ETA: 56s - loss: 4.3602 - acc: 0.06 - ETA: 56s - loss: 4.3701 - acc: 0.06 - ETA: 56s - loss: 4.3674 - acc: 0.06 - ETA: 56s - loss: 4.3746 - acc: 0.06 - ETA: 55s - loss: 4.3728 - acc: 0.06 - ETA: 55s - loss: 4.3689 - acc: 0.06 - ETA: 55s - loss: 4.3739 - acc: 0.06 - ETA: 55s - loss: 4.3727 - acc: 0.06 - ETA: 55s - loss: 4.3687 - acc: 0.06 - ETA: 54s - loss: 4.3677 - acc: 0.06 - ETA: 54s - loss: 4.3696 - acc: 0.06 - ETA: 54s - loss: 4.3727 - acc: 0.05 - ETA: 54s - loss: 4.3691 - acc: 0.05 - ETA: 53s - loss: 4.3692 - acc: 0.05 - ETA: 53s - loss: 4.3638 - acc: 0.06 - ETA: 53s - loss: 4.3703 - acc: 0.06 - ETA: 53s - loss: 4.3684 - acc: 0.06 - ETA: 53s - loss: 4.3648 - acc: 0.06 - ETA: 52s - loss: 4.3621 - acc: 0.06 - ETA: 52s - loss: 4.3658 - acc: 0.06 - ETA: 52s - loss: 4.3649 - acc: 0.06 - ETA: 52s - loss: 4.3644 - acc: 0.06 - ETA: 52s - loss: 4.3644 - acc: 0.06 - ETA: 51s - loss: 4.3661 - acc: 0.06 - ETA: 51s - loss: 4.3653 - acc: 0.06 - ETA: 51s - loss: 4.3667 - acc: 0.06 - ETA: 51s - loss: 4.3698 - acc: 0.06 - ETA: 51s - loss: 4.3662 - acc: 0.06 - ETA: 50s - loss: 4.3624 - acc: 0.06 - ETA: 50s - loss: 4.3631 - acc: 0.06 - ETA: 50s - loss: 4.3601 - acc: 0.06 - ETA: 50s - loss: 4.3595 - acc: 0.06 - ETA: 50s - loss: 4.3614 - acc: 0.06 - ETA: 49s - loss: 4.3657 - acc: 0.06 - ETA: 49s - loss: 4.3666 - acc: 0.05 - ETA: 49s - loss: 4.3649 - acc: 0.06 - ETA: 49s - loss: 4.3659 - acc: 0.06 - ETA: 48s - loss: 4.3672 - acc: 0.06 - ETA: 48s - loss: 4.3648 - acc: 0.06 - ETA: 48s - loss: 4.3632 - acc: 0.06 - ETA: 48s - loss: 4.3597 - acc: 0.06 - ETA: 48s - loss: 4.3563 - acc: 0.06 - ETA: 47s - loss: 4.3623 - acc: 0.06 - ETA: 47s - loss: 4.3626 - acc: 0.06 - ETA: 47s - loss: 4.3646 - acc: 0.06 - ETA: 47s - loss: 4.3651 - acc: 0.06 - ETA: 47s - loss: 4.3653 - acc: 0.06 - ETA: 46s - loss: 4.3658 - acc: 0.06 - ETA: 46s - loss: 4.3684 - acc: 0.06 - ETA: 46s - loss: 4.3650 - acc: 0.06 - ETA: 46s - loss: 4.3647 - acc: 0.06 - ETA: 45s - loss: 4.3629 - acc: 0.06 - ETA: 45s - loss: 4.3639 - acc: 0.06 - ETA: 45s - loss: 4.3601 - acc: 0.06 - ETA: 45s - loss: 4.3592 - acc: 0.06 - ETA: 45s - loss: 4.3603 - acc: 0.06 - ETA: 44s - loss: 4.3595 - acc: 0.06 - ETA: 44s - loss: 4.3600 - acc: 0.06 - ETA: 44s - loss: 4.3626 - acc: 0.06 - ETA: 44s - loss: 4.3633 - acc: 0.06 - ETA: 44s - loss: 4.3644 - acc: 0.06 - ETA: 43s - loss: 4.3637 - acc: 0.06 - ETA: 43s - loss: 4.3612 - acc: 0.06 - ETA: 43s - loss: 4.3551 - acc: 0.06 - ETA: 43s - loss: 4.3595 - acc: 0.06 - ETA: 43s - loss: 4.3603 - acc: 0.06 - ETA: 42s - loss: 4.3613 - acc: 0.06 - ETA: 42s - loss: 4.3621 - acc: 0.06 - ETA: 42s - loss: 4.3637 - acc: 0.06 - ETA: 42s - loss: 4.3641 - acc: 0.06 - ETA: 41s - loss: 4.3663 - acc: 0.06 - ETA: 41s - loss: 4.3648 - acc: 0.05 - ETA: 41s - loss: 4.3635 - acc: 0.06 - ETA: 41s - loss: 4.3652 - acc: 0.06 - ETA: 41s - loss: 4.3638 - acc: 0.06 - ETA: 40s - loss: 4.3631 - acc: 0.06 - ETA: 40s - loss: 4.3636 - acc: 0.05 - ETA: 40s - loss: 4.3621 - acc: 0.05 - ETA: 40s - loss: 4.3625 - acc: 0.05 - ETA: 40s - loss: 4.3610 - acc: 0.05 - ETA: 39s - loss: 4.3606 - acc: 0.05 - ETA: 39s - loss: 4.3619 - acc: 0.05 - ETA: 39s - loss: 4.3599 - acc: 0.05 - ETA: 39s - loss: 4.3570 - acc: 0.05 - ETA: 38s - loss: 4.3575 - acc: 0.05 - ETA: 38s - loss: 4.3610 - acc: 0.05 - ETA: 38s - loss: 4.3609 - acc: 0.05 - ETA: 38s - loss: 4.3595 - acc: 0.05 - ETA: 38s - loss: 4.3605 - acc: 0.05 - ETA: 37s - loss: 4.3607 - acc: 0.05 - ETA: 37s - loss: 4.3602 - acc: 0.05 - ETA: 37s - loss: 4.3600 - acc: 0.05 - ETA: 37s - loss: 4.3596 - acc: 0.05 - ETA: 37s - loss: 4.3618 - acc: 0.05 - ETA: 36s - loss: 4.3604 - acc: 0.05 - ETA: 36s - loss: 4.3604 - acc: 0.05 - ETA: 36s - loss: 4.3623 - acc: 0.05 - ETA: 36s - loss: 4.3608 - acc: 0.05 - ETA: 35s - loss: 4.3605 - acc: 0.05 - ETA: 35s - loss: 4.3584 - acc: 0.05 - ETA: 35s - loss: 4.3600 - acc: 0.05 - ETA: 35s - loss: 4.3569 - acc: 0.05 - ETA: 35s - loss: 4.3573 - acc: 0.05 - ETA: 34s - loss: 4.3550 - acc: 0.05 - ETA: 34s - loss: 4.3584 - acc: 0.05 - ETA: 34s - loss: 4.3572 - acc: 0.05 - ETA: 34s - loss: 4.3559 - acc: 0.05 - ETA: 34s - loss: 4.3559 - acc: 0.05 - ETA: 33s - loss: 4.3572 - acc: 0.05 - ETA: 33s - loss: 4.3558 - acc: 0.05 - ETA: 33s - loss: 4.3574 - acc: 0.05 - ETA: 33s - loss: 4.3558 - acc: 0.05 - ETA: 33s - loss: 4.3544 - acc: 0.05 - ETA: 32s - loss: 4.3553 - acc: 0.05 - ETA: 32s - loss: 4.3542 - acc: 0.05 - ETA: 32s - loss: 4.3534 - acc: 0.05 - ETA: 32s - loss: 4.3542 - acc: 0.05 - ETA: 31s - loss: 4.3544 - acc: 0.05 - ETA: 31s - loss: 4.3532 - acc: 0.05 - ETA: 31s - loss: 4.3535 - acc: 0.06 - ETA: 31s - loss: 4.3535 - acc: 0.06 - ETA: 31s - loss: 4.3539 - acc: 0.06 - ETA: 30s - loss: 4.3535 - acc: 0.06 - ETA: 30s - loss: 4.3527 - acc: 0.06 - ETA: 30s - loss: 4.3535 - acc: 0.06 - ETA: 30s - loss: 4.3500 - acc: 0.06 - ETA: 30s - loss: 4.3501 - acc: 0.06 - ETA: 29s - loss: 4.3482 - acc: 0.06 - ETA: 29s - loss: 4.3486 - acc: 0.06 - ETA: 29s - loss: 4.3495 - acc: 0.06 - ETA: 29s - loss: 4.3506 - acc: 0.06 - ETA: 29s - loss: 4.3511 - acc: 0.06 - ETA: 28s - loss: 4.3516 - acc: 0.06 - ETA: 28s - loss: 4.3521 - acc: 0.06 - ETA: 28s - loss: 4.3530 - acc: 0.06 - ETA: 28s - loss: 4.3526 - acc: 0.06 - ETA: 27s - loss: 4.3522 - acc: 0.06 - ETA: 27s - loss: 4.3518 - acc: 0.06 - ETA: 27s - loss: 4.3506 - acc: 0.06 - ETA: 27s - loss: 4.3500 - acc: 0.06 - ETA: 27s - loss: 4.3498 - acc: 0.06 - ETA: 26s - loss: 4.3515 - acc: 0.06 - ETA: 26s - loss: 4.3528 - acc: 0.06 - ETA: 26s - loss: 4.3524 - acc: 0.06 - ETA: 26s - loss: 4.3530 - acc: 0.06 - ETA: 26s - loss: 4.3518 - acc: 0.06 - ETA: 25s - loss: 4.3515 - acc: 0.06 - ETA: 25s - loss: 4.3518 - acc: 0.06 - ETA: 25s - loss: 4.3513 - acc: 0.06 - ETA: 25s - loss: 4.3494 - acc: 0.06 - ETA: 25s - loss: 4.3488 - acc: 0.0600"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6660/6680 [============================>.] - ETA: 24s - loss: 4.3492 - acc: 0.05 - ETA: 24s - loss: 4.3472 - acc: 0.05 - ETA: 24s - loss: 4.3489 - acc: 0.05 - ETA: 24s - loss: 4.3495 - acc: 0.05 - ETA: 23s - loss: 4.3494 - acc: 0.05 - ETA: 23s - loss: 4.3509 - acc: 0.05 - ETA: 23s - loss: 4.3509 - acc: 0.05 - ETA: 23s - loss: 4.3500 - acc: 0.05 - ETA: 23s - loss: 4.3501 - acc: 0.05 - ETA: 22s - loss: 4.3506 - acc: 0.05 - ETA: 22s - loss: 4.3511 - acc: 0.05 - ETA: 22s - loss: 4.3510 - acc: 0.05 - ETA: 22s - loss: 4.3510 - acc: 0.05 - ETA: 22s - loss: 4.3507 - acc: 0.05 - ETA: 21s - loss: 4.3500 - acc: 0.05 - ETA: 21s - loss: 4.3496 - acc: 0.05 - ETA: 21s - loss: 4.3498 - acc: 0.05 - ETA: 21s - loss: 4.3488 - acc: 0.05 - ETA: 21s - loss: 4.3502 - acc: 0.05 - ETA: 20s - loss: 4.3490 - acc: 0.05 - ETA: 20s - loss: 4.3486 - acc: 0.05 - ETA: 20s - loss: 4.3486 - acc: 0.05 - ETA: 20s - loss: 4.3487 - acc: 0.05 - ETA: 19s - loss: 4.3473 - acc: 0.05 - ETA: 19s - loss: 4.3466 - acc: 0.05 - ETA: 19s - loss: 4.3483 - acc: 0.05 - ETA: 19s - loss: 4.3477 - acc: 0.05 - ETA: 19s - loss: 4.3469 - acc: 0.05 - ETA: 18s - loss: 4.3468 - acc: 0.05 - ETA: 18s - loss: 4.3471 - acc: 0.05 - ETA: 18s - loss: 4.3480 - acc: 0.05 - ETA: 18s - loss: 4.3474 - acc: 0.05 - ETA: 18s - loss: 4.3467 - acc: 0.05 - ETA: 17s - loss: 4.3466 - acc: 0.05 - ETA: 17s - loss: 4.3466 - acc: 0.05 - ETA: 17s - loss: 4.3448 - acc: 0.05 - ETA: 17s - loss: 4.3435 - acc: 0.05 - ETA: 17s - loss: 4.3456 - acc: 0.05 - ETA: 16s - loss: 4.3464 - acc: 0.05 - ETA: 16s - loss: 4.3455 - acc: 0.05 - ETA: 16s - loss: 4.3438 - acc: 0.05 - ETA: 16s - loss: 4.3442 - acc: 0.05 - ETA: 15s - loss: 4.3450 - acc: 0.05 - ETA: 15s - loss: 4.3434 - acc: 0.05 - ETA: 15s - loss: 4.3426 - acc: 0.05 - ETA: 15s - loss: 4.3427 - acc: 0.05 - ETA: 15s - loss: 4.3437 - acc: 0.05 - ETA: 14s - loss: 4.3437 - acc: 0.05 - ETA: 14s - loss: 4.3436 - acc: 0.05 - ETA: 14s - loss: 4.3451 - acc: 0.05 - ETA: 14s - loss: 4.3456 - acc: 0.05 - ETA: 14s - loss: 4.3462 - acc: 0.05 - ETA: 13s - loss: 4.3464 - acc: 0.05 - ETA: 13s - loss: 4.3462 - acc: 0.05 - ETA: 13s - loss: 4.3450 - acc: 0.05 - ETA: 13s - loss: 4.3465 - acc: 0.05 - ETA: 13s - loss: 4.3460 - acc: 0.05 - ETA: 12s - loss: 4.3453 - acc: 0.05 - ETA: 12s - loss: 4.3447 - acc: 0.05 - ETA: 12s - loss: 4.3460 - acc: 0.05 - ETA: 12s - loss: 4.3452 - acc: 0.05 - ETA: 11s - loss: 4.3452 - acc: 0.05 - ETA: 11s - loss: 4.3442 - acc: 0.05 - ETA: 11s - loss: 4.3440 - acc: 0.05 - ETA: 11s - loss: 4.3445 - acc: 0.05 - ETA: 11s - loss: 4.3456 - acc: 0.05 - ETA: 10s - loss: 4.3452 - acc: 0.05 - ETA: 10s - loss: 4.3449 - acc: 0.05 - ETA: 10s - loss: 4.3457 - acc: 0.05 - ETA: 10s - loss: 4.3461 - acc: 0.05 - ETA: 10s - loss: 4.3461 - acc: 0.05 - ETA: 9s - loss: 4.3456 - acc: 0.0598 - ETA: 9s - loss: 4.3469 - acc: 0.059 - ETA: 9s - loss: 4.3471 - acc: 0.059 - ETA: 9s - loss: 4.3471 - acc: 0.059 - ETA: 9s - loss: 4.3480 - acc: 0.059 - ETA: 8s - loss: 4.3492 - acc: 0.059 - ETA: 8s - loss: 4.3477 - acc: 0.059 - ETA: 8s - loss: 4.3479 - acc: 0.059 - ETA: 8s - loss: 4.3470 - acc: 0.060 - ETA: 7s - loss: 4.3489 - acc: 0.060 - ETA: 7s - loss: 4.3498 - acc: 0.060 - ETA: 7s - loss: 4.3501 - acc: 0.060 - ETA: 7s - loss: 4.3502 - acc: 0.060 - ETA: 7s - loss: 4.3510 - acc: 0.060 - ETA: 6s - loss: 4.3510 - acc: 0.060 - ETA: 6s - loss: 4.3507 - acc: 0.059 - ETA: 6s - loss: 4.3502 - acc: 0.059 - ETA: 6s - loss: 4.3513 - acc: 0.060 - ETA: 6s - loss: 4.3513 - acc: 0.060 - ETA: 5s - loss: 4.3513 - acc: 0.060 - ETA: 5s - loss: 4.3512 - acc: 0.059 - ETA: 5s - loss: 4.3510 - acc: 0.060 - ETA: 5s - loss: 4.3506 - acc: 0.060 - ETA: 5s - loss: 4.3507 - acc: 0.060 - ETA: 4s - loss: 4.3508 - acc: 0.060 - ETA: 4s - loss: 4.3508 - acc: 0.059 - ETA: 4s - loss: 4.3514 - acc: 0.059 - ETA: 4s - loss: 4.3505 - acc: 0.060 - ETA: 3s - loss: 4.3503 - acc: 0.060 - ETA: 3s - loss: 4.3498 - acc: 0.060 - ETA: 3s - loss: 4.3491 - acc: 0.059 - ETA: 3s - loss: 4.3488 - acc: 0.059 - ETA: 3s - loss: 4.3494 - acc: 0.059 - ETA: 2s - loss: 4.3494 - acc: 0.059 - ETA: 2s - loss: 4.3501 - acc: 0.059 - ETA: 2s - loss: 4.3503 - acc: 0.059 - ETA: 2s - loss: 4.3504 - acc: 0.059 - ETA: 2s - loss: 4.3495 - acc: 0.059 - ETA: 1s - loss: 4.3502 - acc: 0.059 - ETA: 1s - loss: 4.3504 - acc: 0.059 - ETA: 1s - loss: 4.3514 - acc: 0.059 - ETA: 1s - loss: 4.3513 - acc: 0.059 - ETA: 1s - loss: 4.3513 - acc: 0.059 - ETA: 0s - loss: 4.3511 - acc: 0.059 - ETA: 0s - loss: 4.3509 - acc: 0.059 - ETA: 0s - loss: 4.3511 - acc: 0.059 - ETA: 0s - loss: 4.3514 - acc: 0.0598Epoch 00016: val_loss improved from 4.44351 to 4.38575, saving model to saved_models/weights.best.from_scratch.hdf5\n",
      "6680/6680 [==============================] - 72s - loss: 4.3520 - acc: 0.0596 - val_loss: 4.3858 - val_acc: 0.0659\n",
      "Epoch 18/32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4300/6680 [==================>...........] - ETA: 67s - loss: 4.0720 - acc: 0.15 - ETA: 67s - loss: 4.2263 - acc: 0.15 - ETA: 68s - loss: 4.2239 - acc: 0.11 - ETA: 68s - loss: 4.2391 - acc: 0.12 - ETA: 68s - loss: 4.2498 - acc: 0.10 - ETA: 67s - loss: 4.2763 - acc: 0.09 - ETA: 68s - loss: 4.2542 - acc: 0.10 - ETA: 68s - loss: 4.2279 - acc: 0.10 - ETA: 68s - loss: 4.2468 - acc: 0.08 - ETA: 68s - loss: 4.2383 - acc: 0.08 - ETA: 67s - loss: 4.2286 - acc: 0.07 - ETA: 67s - loss: 4.2390 - acc: 0.07 - ETA: 67s - loss: 4.2306 - acc: 0.07 - ETA: 67s - loss: 4.2254 - acc: 0.06 - ETA: 66s - loss: 4.2317 - acc: 0.06 - ETA: 66s - loss: 4.2238 - acc: 0.06 - ETA: 66s - loss: 4.2332 - acc: 0.07 - ETA: 66s - loss: 4.2082 - acc: 0.07 - ETA: 65s - loss: 4.2112 - acc: 0.07 - ETA: 65s - loss: 4.2122 - acc: 0.07 - ETA: 65s - loss: 4.1991 - acc: 0.06 - ETA: 65s - loss: 4.2225 - acc: 0.06 - ETA: 65s - loss: 4.2346 - acc: 0.06 - ETA: 64s - loss: 4.2437 - acc: 0.06 - ETA: 64s - loss: 4.2399 - acc: 0.06 - ETA: 64s - loss: 4.2360 - acc: 0.06 - ETA: 64s - loss: 4.2463 - acc: 0.06 - ETA: 63s - loss: 4.2335 - acc: 0.06 - ETA: 63s - loss: 4.2356 - acc: 0.06 - ETA: 63s - loss: 4.2327 - acc: 0.06 - ETA: 63s - loss: 4.2205 - acc: 0.06 - ETA: 63s - loss: 4.2149 - acc: 0.06 - ETA: 62s - loss: 4.2220 - acc: 0.06 - ETA: 62s - loss: 4.2232 - acc: 0.06 - ETA: 62s - loss: 4.2238 - acc: 0.06 - ETA: 62s - loss: 4.2248 - acc: 0.06 - ETA: 62s - loss: 4.2262 - acc: 0.06 - ETA: 61s - loss: 4.2248 - acc: 0.06 - ETA: 61s - loss: 4.2262 - acc: 0.06 - ETA: 61s - loss: 4.2272 - acc: 0.06 - ETA: 61s - loss: 4.2179 - acc: 0.06 - ETA: 61s - loss: 4.2256 - acc: 0.06 - ETA: 60s - loss: 4.2319 - acc: 0.06 - ETA: 60s - loss: 4.2346 - acc: 0.06 - ETA: 60s - loss: 4.2378 - acc: 0.06 - ETA: 60s - loss: 4.2401 - acc: 0.06 - ETA: 60s - loss: 4.2399 - acc: 0.06 - ETA: 59s - loss: 4.2435 - acc: 0.05 - ETA: 59s - loss: 4.2458 - acc: 0.06 - ETA: 59s - loss: 4.2403 - acc: 0.06 - ETA: 59s - loss: 4.2343 - acc: 0.06 - ETA: 58s - loss: 4.2312 - acc: 0.06 - ETA: 58s - loss: 4.2468 - acc: 0.06 - ETA: 58s - loss: 4.2493 - acc: 0.06 - ETA: 58s - loss: 4.2480 - acc: 0.06 - ETA: 58s - loss: 4.2554 - acc: 0.06 - ETA: 57s - loss: 4.2585 - acc: 0.06 - ETA: 57s - loss: 4.2591 - acc: 0.06 - ETA: 57s - loss: 4.2629 - acc: 0.06 - ETA: 57s - loss: 4.2683 - acc: 0.06 - ETA: 57s - loss: 4.2720 - acc: 0.06 - ETA: 56s - loss: 4.2693 - acc: 0.06 - ETA: 56s - loss: 4.2740 - acc: 0.06 - ETA: 56s - loss: 4.2756 - acc: 0.06 - ETA: 56s - loss: 4.2779 - acc: 0.06 - ETA: 56s - loss: 4.2762 - acc: 0.06 - ETA: 55s - loss: 4.2788 - acc: 0.06 - ETA: 55s - loss: 4.2743 - acc: 0.06 - ETA: 55s - loss: 4.2708 - acc: 0.06 - ETA: 55s - loss: 4.2697 - acc: 0.06 - ETA: 55s - loss: 4.2669 - acc: 0.06 - ETA: 54s - loss: 4.2629 - acc: 0.07 - ETA: 54s - loss: 4.2607 - acc: 0.07 - ETA: 54s - loss: 4.2734 - acc: 0.06 - ETA: 54s - loss: 4.2754 - acc: 0.06 - ETA: 54s - loss: 4.2730 - acc: 0.06 - ETA: 53s - loss: 4.2720 - acc: 0.06 - ETA: 53s - loss: 4.2725 - acc: 0.06 - ETA: 53s - loss: 4.2735 - acc: 0.06 - ETA: 53s - loss: 4.2738 - acc: 0.06 - ETA: 52s - loss: 4.2714 - acc: 0.06 - ETA: 52s - loss: 4.2677 - acc: 0.06 - ETA: 52s - loss: 4.2667 - acc: 0.06 - ETA: 52s - loss: 4.2686 - acc: 0.06 - ETA: 52s - loss: 4.2708 - acc: 0.06 - ETA: 51s - loss: 4.2673 - acc: 0.06 - ETA: 51s - loss: 4.2656 - acc: 0.06 - ETA: 51s - loss: 4.2685 - acc: 0.06 - ETA: 51s - loss: 4.2703 - acc: 0.06 - ETA: 51s - loss: 4.2701 - acc: 0.06 - ETA: 50s - loss: 4.2692 - acc: 0.06 - ETA: 50s - loss: 4.2742 - acc: 0.06 - ETA: 50s - loss: 4.2743 - acc: 0.06 - ETA: 50s - loss: 4.2752 - acc: 0.06 - ETA: 50s - loss: 4.2719 - acc: 0.06 - ETA: 49s - loss: 4.2728 - acc: 0.06 - ETA: 49s - loss: 4.2715 - acc: 0.06 - ETA: 49s - loss: 4.2743 - acc: 0.06 - ETA: 49s - loss: 4.2790 - acc: 0.06 - ETA: 48s - loss: 4.2794 - acc: 0.06 - ETA: 48s - loss: 4.2808 - acc: 0.06 - ETA: 48s - loss: 4.2826 - acc: 0.06 - ETA: 48s - loss: 4.2844 - acc: 0.06 - ETA: 48s - loss: 4.2837 - acc: 0.06 - ETA: 47s - loss: 4.2892 - acc: 0.06 - ETA: 47s - loss: 4.2908 - acc: 0.06 - ETA: 47s - loss: 4.2908 - acc: 0.06 - ETA: 47s - loss: 4.2920 - acc: 0.06 - ETA: 47s - loss: 4.2947 - acc: 0.06 - ETA: 46s - loss: 4.2984 - acc: 0.06 - ETA: 46s - loss: 4.3004 - acc: 0.06 - ETA: 46s - loss: 4.2991 - acc: 0.06 - ETA: 46s - loss: 4.2973 - acc: 0.06 - ETA: 46s - loss: 4.2952 - acc: 0.06 - ETA: 45s - loss: 4.2942 - acc: 0.06 - ETA: 45s - loss: 4.2988 - acc: 0.06 - ETA: 45s - loss: 4.2975 - acc: 0.06 - ETA: 45s - loss: 4.3011 - acc: 0.06 - ETA: 45s - loss: 4.3019 - acc: 0.06 - ETA: 44s - loss: 4.3014 - acc: 0.06 - ETA: 44s - loss: 4.3001 - acc: 0.06 - ETA: 44s - loss: 4.3034 - acc: 0.06 - ETA: 44s - loss: 4.3039 - acc: 0.06 - ETA: 43s - loss: 4.3054 - acc: 0.06 - ETA: 43s - loss: 4.3075 - acc: 0.06 - ETA: 43s - loss: 4.3090 - acc: 0.06 - ETA: 43s - loss: 4.3107 - acc: 0.06 - ETA: 43s - loss: 4.3128 - acc: 0.06 - ETA: 42s - loss: 4.3130 - acc: 0.06 - ETA: 42s - loss: 4.3113 - acc: 0.06 - ETA: 42s - loss: 4.3135 - acc: 0.06 - ETA: 42s - loss: 4.3110 - acc: 0.06 - ETA: 42s - loss: 4.3112 - acc: 0.06 - ETA: 41s - loss: 4.3104 - acc: 0.06 - ETA: 41s - loss: 4.3106 - acc: 0.06 - ETA: 41s - loss: 4.3126 - acc: 0.06 - ETA: 41s - loss: 4.3134 - acc: 0.06 - ETA: 41s - loss: 4.3150 - acc: 0.06 - ETA: 40s - loss: 4.3184 - acc: 0.06 - ETA: 40s - loss: 4.3190 - acc: 0.06 - ETA: 40s - loss: 4.3213 - acc: 0.06 - ETA: 40s - loss: 4.3213 - acc: 0.06 - ETA: 39s - loss: 4.3229 - acc: 0.06 - ETA: 39s - loss: 4.3248 - acc: 0.06 - ETA: 39s - loss: 4.3255 - acc: 0.06 - ETA: 39s - loss: 4.3241 - acc: 0.06 - ETA: 39s - loss: 4.3247 - acc: 0.06 - ETA: 38s - loss: 4.3265 - acc: 0.06 - ETA: 38s - loss: 4.3267 - acc: 0.06 - ETA: 38s - loss: 4.3260 - acc: 0.06 - ETA: 38s - loss: 4.3262 - acc: 0.06 - ETA: 38s - loss: 4.3259 - acc: 0.06 - ETA: 37s - loss: 4.3301 - acc: 0.06 - ETA: 37s - loss: 4.3295 - acc: 0.06 - ETA: 37s - loss: 4.3295 - acc: 0.06 - ETA: 37s - loss: 4.3272 - acc: 0.06 - ETA: 37s - loss: 4.3258 - acc: 0.06 - ETA: 36s - loss: 4.3263 - acc: 0.06 - ETA: 36s - loss: 4.3275 - acc: 0.06 - ETA: 36s - loss: 4.3261 - acc: 0.06 - ETA: 36s - loss: 4.3272 - acc: 0.06 - ETA: 36s - loss: 4.3270 - acc: 0.06 - ETA: 35s - loss: 4.3264 - acc: 0.06 - ETA: 35s - loss: 4.3274 - acc: 0.06 - ETA: 35s - loss: 4.3264 - acc: 0.06 - ETA: 35s - loss: 4.3269 - acc: 0.06 - ETA: 34s - loss: 4.3265 - acc: 0.06 - ETA: 34s - loss: 4.3264 - acc: 0.06 - ETA: 34s - loss: 4.3241 - acc: 0.06 - ETA: 34s - loss: 4.3235 - acc: 0.06 - ETA: 34s - loss: 4.3228 - acc: 0.06 - ETA: 33s - loss: 4.3212 - acc: 0.06 - ETA: 33s - loss: 4.3234 - acc: 0.06 - ETA: 33s - loss: 4.3223 - acc: 0.06 - ETA: 33s - loss: 4.3243 - acc: 0.06 - ETA: 33s - loss: 4.3245 - acc: 0.06 - ETA: 32s - loss: 4.3247 - acc: 0.06 - ETA: 32s - loss: 4.3259 - acc: 0.06 - ETA: 32s - loss: 4.3276 - acc: 0.06 - ETA: 32s - loss: 4.3274 - acc: 0.06 - ETA: 32s - loss: 4.3277 - acc: 0.06 - ETA: 31s - loss: 4.3262 - acc: 0.06 - ETA: 31s - loss: 4.3239 - acc: 0.06 - ETA: 31s - loss: 4.3259 - acc: 0.06 - ETA: 31s - loss: 4.3249 - acc: 0.06 - ETA: 30s - loss: 4.3256 - acc: 0.06 - ETA: 30s - loss: 4.3264 - acc: 0.06 - ETA: 30s - loss: 4.3256 - acc: 0.06 - ETA: 30s - loss: 4.3271 - acc: 0.06 - ETA: 30s - loss: 4.3286 - acc: 0.06 - ETA: 29s - loss: 4.3284 - acc: 0.06 - ETA: 29s - loss: 4.3286 - acc: 0.06 - ETA: 29s - loss: 4.3320 - acc: 0.06 - ETA: 29s - loss: 4.3331 - acc: 0.06 - ETA: 29s - loss: 4.3336 - acc: 0.06 - ETA: 28s - loss: 4.3338 - acc: 0.06 - ETA: 28s - loss: 4.3351 - acc: 0.06 - ETA: 28s - loss: 4.3358 - acc: 0.06 - ETA: 28s - loss: 4.3371 - acc: 0.06 - ETA: 28s - loss: 4.3372 - acc: 0.06 - ETA: 27s - loss: 4.3372 - acc: 0.06 - ETA: 27s - loss: 4.3374 - acc: 0.06 - ETA: 27s - loss: 4.3379 - acc: 0.06 - ETA: 27s - loss: 4.3377 - acc: 0.06 - ETA: 27s - loss: 4.3365 - acc: 0.06 - ETA: 26s - loss: 4.3357 - acc: 0.06 - ETA: 26s - loss: 4.3360 - acc: 0.06 - ETA: 26s - loss: 4.3398 - acc: 0.06 - ETA: 26s - loss: 4.3390 - acc: 0.06 - ETA: 25s - loss: 4.3384 - acc: 0.06 - ETA: 25s - loss: 4.3385 - acc: 0.06 - ETA: 25s - loss: 4.3384 - acc: 0.06 - ETA: 25s - loss: 4.3376 - acc: 0.06 - ETA: 25s - loss: 4.3373 - acc: 0.06 - ETA: 24s - loss: 4.3363 - acc: 0.0630"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6660/6680 [============================>.] - ETA: 24s - loss: 4.3360 - acc: 0.06 - ETA: 24s - loss: 4.3371 - acc: 0.06 - ETA: 24s - loss: 4.3390 - acc: 0.06 - ETA: 24s - loss: 4.3391 - acc: 0.06 - ETA: 23s - loss: 4.3386 - acc: 0.06 - ETA: 23s - loss: 4.3386 - acc: 0.06 - ETA: 23s - loss: 4.3397 - acc: 0.06 - ETA: 23s - loss: 4.3400 - acc: 0.06 - ETA: 23s - loss: 4.3401 - acc: 0.06 - ETA: 22s - loss: 4.3396 - acc: 0.06 - ETA: 22s - loss: 4.3395 - acc: 0.06 - ETA: 22s - loss: 4.3393 - acc: 0.06 - ETA: 22s - loss: 4.3392 - acc: 0.06 - ETA: 22s - loss: 4.3394 - acc: 0.06 - ETA: 21s - loss: 4.3405 - acc: 0.06 - ETA: 21s - loss: 4.3411 - acc: 0.06 - ETA: 21s - loss: 4.3426 - acc: 0.06 - ETA: 21s - loss: 4.3422 - acc: 0.06 - ETA: 20s - loss: 4.3421 - acc: 0.06 - ETA: 20s - loss: 4.3430 - acc: 0.06 - ETA: 20s - loss: 4.3436 - acc: 0.06 - ETA: 20s - loss: 4.3435 - acc: 0.06 - ETA: 20s - loss: 4.3435 - acc: 0.06 - ETA: 19s - loss: 4.3441 - acc: 0.06 - ETA: 19s - loss: 4.3456 - acc: 0.06 - ETA: 19s - loss: 4.3453 - acc: 0.06 - ETA: 19s - loss: 4.3451 - acc: 0.06 - ETA: 19s - loss: 4.3441 - acc: 0.06 - ETA: 18s - loss: 4.3436 - acc: 0.06 - ETA: 18s - loss: 4.3441 - acc: 0.06 - ETA: 18s - loss: 4.3434 - acc: 0.06 - ETA: 18s - loss: 4.3435 - acc: 0.06 - ETA: 18s - loss: 4.3439 - acc: 0.06 - ETA: 17s - loss: 4.3418 - acc: 0.06 - ETA: 17s - loss: 4.3414 - acc: 0.06 - ETA: 17s - loss: 4.3418 - acc: 0.06 - ETA: 17s - loss: 4.3409 - acc: 0.06 - ETA: 16s - loss: 4.3407 - acc: 0.06 - ETA: 16s - loss: 4.3402 - acc: 0.06 - ETA: 16s - loss: 4.3398 - acc: 0.06 - ETA: 16s - loss: 4.3401 - acc: 0.06 - ETA: 16s - loss: 4.3399 - acc: 0.06 - ETA: 15s - loss: 4.3408 - acc: 0.06 - ETA: 15s - loss: 4.3409 - acc: 0.06 - ETA: 15s - loss: 4.3409 - acc: 0.06 - ETA: 15s - loss: 4.3395 - acc: 0.06 - ETA: 15s - loss: 4.3396 - acc: 0.06 - ETA: 14s - loss: 4.3400 - acc: 0.06 - ETA: 14s - loss: 4.3396 - acc: 0.06 - ETA: 14s - loss: 4.3392 - acc: 0.06 - ETA: 14s - loss: 4.3390 - acc: 0.06 - ETA: 14s - loss: 4.3385 - acc: 0.06 - ETA: 13s - loss: 4.3378 - acc: 0.06 - ETA: 13s - loss: 4.3382 - acc: 0.06 - ETA: 13s - loss: 4.3394 - acc: 0.06 - ETA: 13s - loss: 4.3392 - acc: 0.06 - ETA: 13s - loss: 4.3384 - acc: 0.06 - ETA: 12s - loss: 4.3393 - acc: 0.06 - ETA: 12s - loss: 4.3404 - acc: 0.06 - ETA: 12s - loss: 4.3409 - acc: 0.06 - ETA: 12s - loss: 4.3392 - acc: 0.06 - ETA: 11s - loss: 4.3393 - acc: 0.06 - ETA: 11s - loss: 4.3410 - acc: 0.06 - ETA: 11s - loss: 4.3417 - acc: 0.06 - ETA: 11s - loss: 4.3408 - acc: 0.06 - ETA: 11s - loss: 4.3392 - acc: 0.06 - ETA: 10s - loss: 4.3367 - acc: 0.06 - ETA: 10s - loss: 4.3350 - acc: 0.06 - ETA: 10s - loss: 4.3362 - acc: 0.06 - ETA: 10s - loss: 4.3357 - acc: 0.06 - ETA: 10s - loss: 4.3359 - acc: 0.06 - ETA: 9s - loss: 4.3359 - acc: 0.0639 - ETA: 9s - loss: 4.3360 - acc: 0.063 - ETA: 9s - loss: 4.3352 - acc: 0.064 - ETA: 9s - loss: 4.3356 - acc: 0.064 - ETA: 9s - loss: 4.3356 - acc: 0.064 - ETA: 8s - loss: 4.3360 - acc: 0.064 - ETA: 8s - loss: 4.3359 - acc: 0.064 - ETA: 8s - loss: 4.3366 - acc: 0.064 - ETA: 8s - loss: 4.3352 - acc: 0.064 - ETA: 7s - loss: 4.3351 - acc: 0.065 - ETA: 7s - loss: 4.3350 - acc: 0.065 - ETA: 7s - loss: 4.3347 - acc: 0.065 - ETA: 7s - loss: 4.3347 - acc: 0.065 - ETA: 7s - loss: 4.3346 - acc: 0.065 - ETA: 6s - loss: 4.3336 - acc: 0.065 - ETA: 6s - loss: 4.3333 - acc: 0.065 - ETA: 6s - loss: 4.3336 - acc: 0.065 - ETA: 6s - loss: 4.3326 - acc: 0.065 - ETA: 6s - loss: 4.3319 - acc: 0.065 - ETA: 5s - loss: 4.3318 - acc: 0.065 - ETA: 5s - loss: 4.3295 - acc: 0.066 - ETA: 5s - loss: 4.3299 - acc: 0.066 - ETA: 5s - loss: 4.3294 - acc: 0.066 - ETA: 5s - loss: 4.3304 - acc: 0.066 - ETA: 4s - loss: 4.3310 - acc: 0.066 - ETA: 4s - loss: 4.3315 - acc: 0.066 - ETA: 4s - loss: 4.3305 - acc: 0.066 - ETA: 4s - loss: 4.3301 - acc: 0.066 - ETA: 3s - loss: 4.3299 - acc: 0.066 - ETA: 3s - loss: 4.3304 - acc: 0.066 - ETA: 3s - loss: 4.3300 - acc: 0.066 - ETA: 3s - loss: 4.3296 - acc: 0.066 - ETA: 3s - loss: 4.3294 - acc: 0.066 - ETA: 2s - loss: 4.3302 - acc: 0.066 - ETA: 2s - loss: 4.3305 - acc: 0.066 - ETA: 2s - loss: 4.3309 - acc: 0.065 - ETA: 2s - loss: 4.3290 - acc: 0.066 - ETA: 2s - loss: 4.3284 - acc: 0.066 - ETA: 1s - loss: 4.3290 - acc: 0.066 - ETA: 1s - loss: 4.3293 - acc: 0.065 - ETA: 1s - loss: 4.3294 - acc: 0.065 - ETA: 1s - loss: 4.3297 - acc: 0.065 - ETA: 1s - loss: 4.3294 - acc: 0.065 - ETA: 0s - loss: 4.3302 - acc: 0.065 - ETA: 0s - loss: 4.3299 - acc: 0.065 - ETA: 0s - loss: 4.3309 - acc: 0.065 - ETA: 0s - loss: 4.3310 - acc: 0.0652Epoch 00017: val_loss improved from 4.38575 to 4.38349, saving model to saved_models/weights.best.from_scratch.hdf5\n",
      "6680/6680 [==============================] - 72s - loss: 4.3305 - acc: 0.0653 - val_loss: 4.3835 - val_acc: 0.0575\n",
      "Epoch 19/32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4300/6680 [==================>...........] - ETA: 68s - loss: 3.9399 - acc: 0.10 - ETA: 68s - loss: 4.0396 - acc: 0.07 - ETA: 68s - loss: 4.2113 - acc: 0.05 - ETA: 68s - loss: 4.2080 - acc: 0.05 - ETA: 68s - loss: 4.2378 - acc: 0.04 - ETA: 68s - loss: 4.2649 - acc: 0.03 - ETA: 67s - loss: 4.2649 - acc: 0.03 - ETA: 67s - loss: 4.2789 - acc: 0.03 - ETA: 67s - loss: 4.2877 - acc: 0.03 - ETA: 67s - loss: 4.3076 - acc: 0.04 - ETA: 67s - loss: 4.3061 - acc: 0.03 - ETA: 66s - loss: 4.3079 - acc: 0.03 - ETA: 66s - loss: 4.3339 - acc: 0.03 - ETA: 66s - loss: 4.3456 - acc: 0.05 - ETA: 66s - loss: 4.3303 - acc: 0.05 - ETA: 66s - loss: 4.3445 - acc: 0.05 - ETA: 66s - loss: 4.3339 - acc: 0.05 - ETA: 65s - loss: 4.3257 - acc: 0.05 - ETA: 65s - loss: 4.3131 - acc: 0.05 - ETA: 65s - loss: 4.3131 - acc: 0.05 - ETA: 65s - loss: 4.3095 - acc: 0.05 - ETA: 64s - loss: 4.3018 - acc: 0.05 - ETA: 64s - loss: 4.3014 - acc: 0.05 - ETA: 64s - loss: 4.3107 - acc: 0.05 - ETA: 64s - loss: 4.3117 - acc: 0.06 - ETA: 64s - loss: 4.3190 - acc: 0.05 - ETA: 64s - loss: 4.3168 - acc: 0.05 - ETA: 63s - loss: 4.3060 - acc: 0.06 - ETA: 63s - loss: 4.3081 - acc: 0.06 - ETA: 63s - loss: 4.3127 - acc: 0.06 - ETA: 63s - loss: 4.3115 - acc: 0.05 - ETA: 63s - loss: 4.3013 - acc: 0.05 - ETA: 62s - loss: 4.2950 - acc: 0.06 - ETA: 62s - loss: 4.3013 - acc: 0.05 - ETA: 62s - loss: 4.2860 - acc: 0.06 - ETA: 62s - loss: 4.2856 - acc: 0.06 - ETA: 62s - loss: 4.2840 - acc: 0.06 - ETA: 61s - loss: 4.2855 - acc: 0.06 - ETA: 61s - loss: 4.2916 - acc: 0.05 - ETA: 61s - loss: 4.2977 - acc: 0.05 - ETA: 61s - loss: 4.3130 - acc: 0.05 - ETA: 61s - loss: 4.3081 - acc: 0.05 - ETA: 60s - loss: 4.3050 - acc: 0.05 - ETA: 60s - loss: 4.3046 - acc: 0.05 - ETA: 60s - loss: 4.3012 - acc: 0.05 - ETA: 60s - loss: 4.2977 - acc: 0.05 - ETA: 60s - loss: 4.3046 - acc: 0.05 - ETA: 59s - loss: 4.3049 - acc: 0.05 - ETA: 59s - loss: 4.3019 - acc: 0.06 - ETA: 59s - loss: 4.3076 - acc: 0.05 - ETA: 59s - loss: 4.3073 - acc: 0.05 - ETA: 59s - loss: 4.2990 - acc: 0.05 - ETA: 58s - loss: 4.2931 - acc: 0.05 - ETA: 58s - loss: 4.2966 - acc: 0.05 - ETA: 58s - loss: 4.2928 - acc: 0.05 - ETA: 58s - loss: 4.2885 - acc: 0.06 - ETA: 58s - loss: 4.2915 - acc: 0.06 - ETA: 57s - loss: 4.3020 - acc: 0.05 - ETA: 57s - loss: 4.3070 - acc: 0.06 - ETA: 57s - loss: 4.3063 - acc: 0.06 - ETA: 57s - loss: 4.3050 - acc: 0.06 - ETA: 56s - loss: 4.3051 - acc: 0.06 - ETA: 56s - loss: 4.3057 - acc: 0.06 - ETA: 56s - loss: 4.3040 - acc: 0.06 - ETA: 56s - loss: 4.3038 - acc: 0.06 - ETA: 56s - loss: 4.3068 - acc: 0.06 - ETA: 55s - loss: 4.3061 - acc: 0.06 - ETA: 55s - loss: 4.3073 - acc: 0.06 - ETA: 55s - loss: 4.3042 - acc: 0.06 - ETA: 55s - loss: 4.3060 - acc: 0.06 - ETA: 55s - loss: 4.3081 - acc: 0.06 - ETA: 54s - loss: 4.3076 - acc: 0.06 - ETA: 54s - loss: 4.3060 - acc: 0.06 - ETA: 54s - loss: 4.3034 - acc: 0.06 - ETA: 54s - loss: 4.3033 - acc: 0.06 - ETA: 54s - loss: 4.2952 - acc: 0.06 - ETA: 53s - loss: 4.2958 - acc: 0.06 - ETA: 53s - loss: 4.2991 - acc: 0.06 - ETA: 53s - loss: 4.3047 - acc: 0.06 - ETA: 53s - loss: 4.3088 - acc: 0.06 - ETA: 53s - loss: 4.3077 - acc: 0.06 - ETA: 52s - loss: 4.3089 - acc: 0.06 - ETA: 52s - loss: 4.3078 - acc: 0.06 - ETA: 52s - loss: 4.3106 - acc: 0.06 - ETA: 52s - loss: 4.3139 - acc: 0.06 - ETA: 51s - loss: 4.3118 - acc: 0.06 - ETA: 51s - loss: 4.3142 - acc: 0.06 - ETA: 51s - loss: 4.3124 - acc: 0.06 - ETA: 51s - loss: 4.3156 - acc: 0.06 - ETA: 51s - loss: 4.3168 - acc: 0.06 - ETA: 50s - loss: 4.3167 - acc: 0.06 - ETA: 50s - loss: 4.3126 - acc: 0.06 - ETA: 50s - loss: 4.3097 - acc: 0.06 - ETA: 50s - loss: 4.3132 - acc: 0.06 - ETA: 50s - loss: 4.3131 - acc: 0.06 - ETA: 49s - loss: 4.3115 - acc: 0.06 - ETA: 49s - loss: 4.3128 - acc: 0.06 - ETA: 49s - loss: 4.3163 - acc: 0.06 - ETA: 49s - loss: 4.3180 - acc: 0.06 - ETA: 48s - loss: 4.3207 - acc: 0.06 - ETA: 48s - loss: 4.3188 - acc: 0.06 - ETA: 48s - loss: 4.3177 - acc: 0.06 - ETA: 48s - loss: 4.3162 - acc: 0.06 - ETA: 48s - loss: 4.3152 - acc: 0.06 - ETA: 47s - loss: 4.3123 - acc: 0.06 - ETA: 47s - loss: 4.3151 - acc: 0.06 - ETA: 47s - loss: 4.3139 - acc: 0.06 - ETA: 47s - loss: 4.3126 - acc: 0.06 - ETA: 47s - loss: 4.3130 - acc: 0.06 - ETA: 46s - loss: 4.3131 - acc: 0.06 - ETA: 46s - loss: 4.3123 - acc: 0.06 - ETA: 46s - loss: 4.3128 - acc: 0.06 - ETA: 46s - loss: 4.3153 - acc: 0.06 - ETA: 46s - loss: 4.3156 - acc: 0.06 - ETA: 45s - loss: 4.3180 - acc: 0.06 - ETA: 45s - loss: 4.3202 - acc: 0.06 - ETA: 45s - loss: 4.3199 - acc: 0.06 - ETA: 45s - loss: 4.3182 - acc: 0.06 - ETA: 45s - loss: 4.3199 - acc: 0.06 - ETA: 44s - loss: 4.3181 - acc: 0.06 - ETA: 44s - loss: 4.3198 - acc: 0.06 - ETA: 44s - loss: 4.3182 - acc: 0.06 - ETA: 44s - loss: 4.3181 - acc: 0.06 - ETA: 44s - loss: 4.3182 - acc: 0.06 - ETA: 43s - loss: 4.3173 - acc: 0.06 - ETA: 43s - loss: 4.3208 - acc: 0.06 - ETA: 43s - loss: 4.3190 - acc: 0.06 - ETA: 43s - loss: 4.3206 - acc: 0.06 - ETA: 42s - loss: 4.3195 - acc: 0.06 - ETA: 42s - loss: 4.3193 - acc: 0.06 - ETA: 42s - loss: 4.3197 - acc: 0.06 - ETA: 42s - loss: 4.3190 - acc: 0.06 - ETA: 42s - loss: 4.3184 - acc: 0.06 - ETA: 41s - loss: 4.3170 - acc: 0.06 - ETA: 41s - loss: 4.3151 - acc: 0.06 - ETA: 41s - loss: 4.3166 - acc: 0.06 - ETA: 41s - loss: 4.3144 - acc: 0.06 - ETA: 41s - loss: 4.3148 - acc: 0.06 - ETA: 40s - loss: 4.3143 - acc: 0.06 - ETA: 40s - loss: 4.3149 - acc: 0.06 - ETA: 40s - loss: 4.3138 - acc: 0.06 - ETA: 40s - loss: 4.3137 - acc: 0.06 - ETA: 40s - loss: 4.3130 - acc: 0.06 - ETA: 39s - loss: 4.3095 - acc: 0.06 - ETA: 39s - loss: 4.3073 - acc: 0.06 - ETA: 39s - loss: 4.3076 - acc: 0.06 - ETA: 39s - loss: 4.3053 - acc: 0.06 - ETA: 38s - loss: 4.3030 - acc: 0.06 - ETA: 38s - loss: 4.3017 - acc: 0.06 - ETA: 38s - loss: 4.2978 - acc: 0.06 - ETA: 38s - loss: 4.3008 - acc: 0.06 - ETA: 38s - loss: 4.3011 - acc: 0.06 - ETA: 37s - loss: 4.3013 - acc: 0.06 - ETA: 37s - loss: 4.3012 - acc: 0.06 - ETA: 37s - loss: 4.3012 - acc: 0.06 - ETA: 37s - loss: 4.3007 - acc: 0.06 - ETA: 37s - loss: 4.2992 - acc: 0.06 - ETA: 36s - loss: 4.2996 - acc: 0.06 - ETA: 36s - loss: 4.3001 - acc: 0.06 - ETA: 36s - loss: 4.2971 - acc: 0.06 - ETA: 36s - loss: 4.2983 - acc: 0.06 - ETA: 36s - loss: 4.2990 - acc: 0.06 - ETA: 35s - loss: 4.2989 - acc: 0.06 - ETA: 35s - loss: 4.2986 - acc: 0.06 - ETA: 35s - loss: 4.2966 - acc: 0.06 - ETA: 35s - loss: 4.2973 - acc: 0.06 - ETA: 35s - loss: 4.2956 - acc: 0.06 - ETA: 34s - loss: 4.2945 - acc: 0.06 - ETA: 34s - loss: 4.2948 - acc: 0.06 - ETA: 34s - loss: 4.2945 - acc: 0.06 - ETA: 34s - loss: 4.2926 - acc: 0.06 - ETA: 33s - loss: 4.2934 - acc: 0.06 - ETA: 33s - loss: 4.2952 - acc: 0.06 - ETA: 33s - loss: 4.2956 - acc: 0.06 - ETA: 33s - loss: 4.2974 - acc: 0.06 - ETA: 33s - loss: 4.2988 - acc: 0.06 - ETA: 32s - loss: 4.2975 - acc: 0.06 - ETA: 32s - loss: 4.3008 - acc: 0.06 - ETA: 32s - loss: 4.3022 - acc: 0.06 - ETA: 32s - loss: 4.3015 - acc: 0.06 - ETA: 32s - loss: 4.3027 - acc: 0.06 - ETA: 31s - loss: 4.3021 - acc: 0.06 - ETA: 31s - loss: 4.3024 - acc: 0.06 - ETA: 31s - loss: 4.3006 - acc: 0.06 - ETA: 31s - loss: 4.2999 - acc: 0.06 - ETA: 31s - loss: 4.2992 - acc: 0.06 - ETA: 30s - loss: 4.3008 - acc: 0.06 - ETA: 30s - loss: 4.3018 - acc: 0.06 - ETA: 30s - loss: 4.3015 - acc: 0.06 - ETA: 30s - loss: 4.3005 - acc: 0.06 - ETA: 30s - loss: 4.2990 - acc: 0.06 - ETA: 29s - loss: 4.3016 - acc: 0.06 - ETA: 29s - loss: 4.3023 - acc: 0.06 - ETA: 29s - loss: 4.3022 - acc: 0.06 - ETA: 29s - loss: 4.3024 - acc: 0.06 - ETA: 28s - loss: 4.3029 - acc: 0.06 - ETA: 28s - loss: 4.3031 - acc: 0.06 - ETA: 28s - loss: 4.3019 - acc: 0.06 - ETA: 28s - loss: 4.3022 - acc: 0.06 - ETA: 28s - loss: 4.3020 - acc: 0.06 - ETA: 27s - loss: 4.3028 - acc: 0.06 - ETA: 27s - loss: 4.3027 - acc: 0.06 - ETA: 27s - loss: 4.3039 - acc: 0.06 - ETA: 27s - loss: 4.3048 - acc: 0.06 - ETA: 27s - loss: 4.3044 - acc: 0.06 - ETA: 26s - loss: 4.3047 - acc: 0.06 - ETA: 26s - loss: 4.3040 - acc: 0.06 - ETA: 26s - loss: 4.3050 - acc: 0.06 - ETA: 26s - loss: 4.3047 - acc: 0.06 - ETA: 26s - loss: 4.3062 - acc: 0.06 - ETA: 25s - loss: 4.3059 - acc: 0.06 - ETA: 25s - loss: 4.3059 - acc: 0.06 - ETA: 25s - loss: 4.3057 - acc: 0.06 - ETA: 25s - loss: 4.3061 - acc: 0.06 - ETA: 24s - loss: 4.3085 - acc: 0.0649"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6660/6680 [============================>.] - ETA: 24s - loss: 4.3079 - acc: 0.06 - ETA: 24s - loss: 4.3074 - acc: 0.06 - ETA: 24s - loss: 4.3065 - acc: 0.06 - ETA: 24s - loss: 4.3056 - acc: 0.06 - ETA: 23s - loss: 4.3055 - acc: 0.06 - ETA: 23s - loss: 4.3050 - acc: 0.06 - ETA: 23s - loss: 4.3060 - acc: 0.06 - ETA: 23s - loss: 4.3070 - acc: 0.06 - ETA: 23s - loss: 4.3051 - acc: 0.06 - ETA: 22s - loss: 4.3035 - acc: 0.06 - ETA: 22s - loss: 4.3024 - acc: 0.06 - ETA: 22s - loss: 4.3024 - acc: 0.06 - ETA: 22s - loss: 4.3025 - acc: 0.06 - ETA: 22s - loss: 4.3039 - acc: 0.06 - ETA: 21s - loss: 4.3041 - acc: 0.06 - ETA: 21s - loss: 4.3042 - acc: 0.06 - ETA: 21s - loss: 4.3029 - acc: 0.06 - ETA: 21s - loss: 4.3043 - acc: 0.06 - ETA: 20s - loss: 4.3035 - acc: 0.06 - ETA: 20s - loss: 4.3051 - acc: 0.06 - ETA: 20s - loss: 4.3047 - acc: 0.06 - ETA: 20s - loss: 4.3042 - acc: 0.06 - ETA: 20s - loss: 4.3044 - acc: 0.06 - ETA: 19s - loss: 4.3046 - acc: 0.06 - ETA: 19s - loss: 4.3082 - acc: 0.06 - ETA: 19s - loss: 4.3088 - acc: 0.06 - ETA: 19s - loss: 4.3073 - acc: 0.06 - ETA: 19s - loss: 4.3061 - acc: 0.06 - ETA: 18s - loss: 4.3058 - acc: 0.06 - ETA: 18s - loss: 4.3061 - acc: 0.06 - ETA: 18s - loss: 4.3070 - acc: 0.06 - ETA: 18s - loss: 4.3066 - acc: 0.06 - ETA: 18s - loss: 4.3069 - acc: 0.06 - ETA: 17s - loss: 4.3053 - acc: 0.06 - ETA: 17s - loss: 4.3063 - acc: 0.06 - ETA: 17s - loss: 4.3069 - acc: 0.06 - ETA: 17s - loss: 4.3076 - acc: 0.06 - ETA: 17s - loss: 4.3069 - acc: 0.06 - ETA: 16s - loss: 4.3064 - acc: 0.06 - ETA: 16s - loss: 4.3078 - acc: 0.06 - ETA: 16s - loss: 4.3063 - acc: 0.06 - ETA: 16s - loss: 4.3069 - acc: 0.06 - ETA: 15s - loss: 4.3052 - acc: 0.06 - ETA: 15s - loss: 4.3055 - acc: 0.06 - ETA: 15s - loss: 4.3030 - acc: 0.06 - ETA: 15s - loss: 4.3015 - acc: 0.06 - ETA: 15s - loss: 4.3025 - acc: 0.06 - ETA: 14s - loss: 4.3024 - acc: 0.06 - ETA: 14s - loss: 4.3019 - acc: 0.06 - ETA: 14s - loss: 4.3015 - acc: 0.06 - ETA: 14s - loss: 4.3021 - acc: 0.06 - ETA: 14s - loss: 4.3027 - acc: 0.06 - ETA: 13s - loss: 4.3022 - acc: 0.06 - ETA: 13s - loss: 4.3015 - acc: 0.06 - ETA: 13s - loss: 4.3015 - acc: 0.06 - ETA: 13s - loss: 4.3023 - acc: 0.06 - ETA: 13s - loss: 4.3018 - acc: 0.06 - ETA: 12s - loss: 4.3010 - acc: 0.06 - ETA: 12s - loss: 4.3007 - acc: 0.06 - ETA: 12s - loss: 4.3001 - acc: 0.06 - ETA: 12s - loss: 4.2999 - acc: 0.06 - ETA: 11s - loss: 4.2997 - acc: 0.06 - ETA: 11s - loss: 4.3007 - acc: 0.06 - ETA: 11s - loss: 4.3016 - acc: 0.06 - ETA: 11s - loss: 4.3022 - acc: 0.06 - ETA: 11s - loss: 4.3047 - acc: 0.06 - ETA: 10s - loss: 4.3043 - acc: 0.06 - ETA: 10s - loss: 4.3035 - acc: 0.06 - ETA: 10s - loss: 4.3060 - acc: 0.06 - ETA: 10s - loss: 4.3063 - acc: 0.06 - ETA: 10s - loss: 4.3053 - acc: 0.06 - ETA: 9s - loss: 4.3060 - acc: 0.0669 - ETA: 9s - loss: 4.3055 - acc: 0.067 - ETA: 9s - loss: 4.3060 - acc: 0.067 - ETA: 9s - loss: 4.3062 - acc: 0.067 - ETA: 9s - loss: 4.3061 - acc: 0.067 - ETA: 8s - loss: 4.3055 - acc: 0.067 - ETA: 8s - loss: 4.3051 - acc: 0.067 - ETA: 8s - loss: 4.3052 - acc: 0.066 - ETA: 8s - loss: 4.3053 - acc: 0.066 - ETA: 7s - loss: 4.3041 - acc: 0.067 - ETA: 7s - loss: 4.3048 - acc: 0.067 - ETA: 7s - loss: 4.3049 - acc: 0.066 - ETA: 7s - loss: 4.3051 - acc: 0.066 - ETA: 7s - loss: 4.3055 - acc: 0.066 - ETA: 6s - loss: 4.3053 - acc: 0.067 - ETA: 6s - loss: 4.3065 - acc: 0.066 - ETA: 6s - loss: 4.3075 - acc: 0.066 - ETA: 6s - loss: 4.3078 - acc: 0.066 - ETA: 6s - loss: 4.3067 - acc: 0.067 - ETA: 5s - loss: 4.3070 - acc: 0.067 - ETA: 5s - loss: 4.3053 - acc: 0.067 - ETA: 5s - loss: 4.3059 - acc: 0.067 - ETA: 5s - loss: 4.3064 - acc: 0.067 - ETA: 5s - loss: 4.3056 - acc: 0.067 - ETA: 4s - loss: 4.3053 - acc: 0.067 - ETA: 4s - loss: 4.3040 - acc: 0.067 - ETA: 4s - loss: 4.3038 - acc: 0.067 - ETA: 4s - loss: 4.3041 - acc: 0.067 - ETA: 3s - loss: 4.3046 - acc: 0.067 - ETA: 3s - loss: 4.3050 - acc: 0.067 - ETA: 3s - loss: 4.3057 - acc: 0.067 - ETA: 3s - loss: 4.3048 - acc: 0.067 - ETA: 3s - loss: 4.3046 - acc: 0.067 - ETA: 2s - loss: 4.3052 - acc: 0.067 - ETA: 2s - loss: 4.3057 - acc: 0.067 - ETA: 2s - loss: 4.3057 - acc: 0.067 - ETA: 2s - loss: 4.3053 - acc: 0.067 - ETA: 2s - loss: 4.3055 - acc: 0.067 - ETA: 1s - loss: 4.3053 - acc: 0.067 - ETA: 1s - loss: 4.3060 - acc: 0.067 - ETA: 1s - loss: 4.3060 - acc: 0.067 - ETA: 1s - loss: 4.3048 - acc: 0.067 - ETA: 1s - loss: 4.3053 - acc: 0.067 - ETA: 0s - loss: 4.3056 - acc: 0.067 - ETA: 0s - loss: 4.3061 - acc: 0.067 - ETA: 0s - loss: 4.3059 - acc: 0.067 - ETA: 0s - loss: 4.3059 - acc: 0.0673Epoch 00018: val_loss improved from 4.38349 to 4.37664, saving model to saved_models/weights.best.from_scratch.hdf5\n",
      "6680/6680 [==============================] - 72s - loss: 4.3066 - acc: 0.0671 - val_loss: 4.3766 - val_acc: 0.0635\n",
      "Epoch 20/32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4300/6680 [==================>...........] - ETA: 66s - loss: 4.2253 - acc: 0.10 - ETA: 67s - loss: 4.2775 - acc: 0.07 - ETA: 68s - loss: 4.2336 - acc: 0.05 - ETA: 69s - loss: 4.1998 - acc: 0.06 - ETA: 69s - loss: 4.1580 - acc: 0.08 - ETA: 68s - loss: 4.1989 - acc: 0.07 - ETA: 68s - loss: 4.2085 - acc: 0.09 - ETA: 68s - loss: 4.2512 - acc: 0.08 - ETA: 68s - loss: 4.2226 - acc: 0.07 - ETA: 68s - loss: 4.2037 - acc: 0.09 - ETA: 68s - loss: 4.2279 - acc: 0.08 - ETA: 67s - loss: 4.2812 - acc: 0.07 - ETA: 67s - loss: 4.2617 - acc: 0.08 - ETA: 67s - loss: 4.2685 - acc: 0.07 - ETA: 66s - loss: 4.2629 - acc: 0.07 - ETA: 66s - loss: 4.2815 - acc: 0.06 - ETA: 66s - loss: 4.2876 - acc: 0.06 - ETA: 66s - loss: 4.2826 - acc: 0.06 - ETA: 66s - loss: 4.2695 - acc: 0.06 - ETA: 65s - loss: 4.2727 - acc: 0.06 - ETA: 65s - loss: 4.2708 - acc: 0.06 - ETA: 65s - loss: 4.2718 - acc: 0.06 - ETA: 65s - loss: 4.2724 - acc: 0.06 - ETA: 65s - loss: 4.2891 - acc: 0.06 - ETA: 64s - loss: 4.2708 - acc: 0.06 - ETA: 64s - loss: 4.2585 - acc: 0.06 - ETA: 64s - loss: 4.2534 - acc: 0.06 - ETA: 64s - loss: 4.2495 - acc: 0.06 - ETA: 64s - loss: 4.2450 - acc: 0.06 - ETA: 64s - loss: 4.2486 - acc: 0.07 - ETA: 63s - loss: 4.2502 - acc: 0.07 - ETA: 63s - loss: 4.2481 - acc: 0.06 - ETA: 63s - loss: 4.2482 - acc: 0.06 - ETA: 63s - loss: 4.2426 - acc: 0.06 - ETA: 62s - loss: 4.2255 - acc: 0.07 - ETA: 62s - loss: 4.2297 - acc: 0.06 - ETA: 62s - loss: 4.2376 - acc: 0.06 - ETA: 62s - loss: 4.2406 - acc: 0.06 - ETA: 62s - loss: 4.2439 - acc: 0.06 - ETA: 61s - loss: 4.2532 - acc: 0.06 - ETA: 61s - loss: 4.2515 - acc: 0.06 - ETA: 61s - loss: 4.2497 - acc: 0.06 - ETA: 61s - loss: 4.2516 - acc: 0.06 - ETA: 60s - loss: 4.2553 - acc: 0.06 - ETA: 60s - loss: 4.2606 - acc: 0.06 - ETA: 60s - loss: 4.2610 - acc: 0.06 - ETA: 60s - loss: 4.2612 - acc: 0.06 - ETA: 60s - loss: 4.2637 - acc: 0.05 - ETA: 59s - loss: 4.2625 - acc: 0.05 - ETA: 59s - loss: 4.2670 - acc: 0.05 - ETA: 59s - loss: 4.2686 - acc: 0.05 - ETA: 59s - loss: 4.2669 - acc: 0.05 - ETA: 59s - loss: 4.2678 - acc: 0.05 - ETA: 58s - loss: 4.2667 - acc: 0.06 - ETA: 58s - loss: 4.2654 - acc: 0.06 - ETA: 58s - loss: 4.2621 - acc: 0.06 - ETA: 58s - loss: 4.2518 - acc: 0.06 - ETA: 57s - loss: 4.2573 - acc: 0.06 - ETA: 57s - loss: 4.2629 - acc: 0.06 - ETA: 57s - loss: 4.2617 - acc: 0.06 - ETA: 57s - loss: 4.2605 - acc: 0.06 - ETA: 57s - loss: 4.2575 - acc: 0.06 - ETA: 56s - loss: 4.2597 - acc: 0.06 - ETA: 56s - loss: 4.2540 - acc: 0.06 - ETA: 56s - loss: 4.2521 - acc: 0.06 - ETA: 56s - loss: 4.2540 - acc: 0.06 - ETA: 55s - loss: 4.2552 - acc: 0.06 - ETA: 55s - loss: 4.2614 - acc: 0.06 - ETA: 55s - loss: 4.2629 - acc: 0.06 - ETA: 55s - loss: 4.2631 - acc: 0.06 - ETA: 55s - loss: 4.2642 - acc: 0.06 - ETA: 54s - loss: 4.2654 - acc: 0.06 - ETA: 54s - loss: 4.2625 - acc: 0.06 - ETA: 54s - loss: 4.2704 - acc: 0.06 - ETA: 54s - loss: 4.2704 - acc: 0.06 - ETA: 54s - loss: 4.2697 - acc: 0.06 - ETA: 53s - loss: 4.2663 - acc: 0.06 - ETA: 53s - loss: 4.2701 - acc: 0.06 - ETA: 53s - loss: 4.2663 - acc: 0.06 - ETA: 53s - loss: 4.2623 - acc: 0.06 - ETA: 53s - loss: 4.2601 - acc: 0.06 - ETA: 52s - loss: 4.2557 - acc: 0.06 - ETA: 52s - loss: 4.2629 - acc: 0.06 - ETA: 52s - loss: 4.2625 - acc: 0.06 - ETA: 52s - loss: 4.2669 - acc: 0.06 - ETA: 52s - loss: 4.2632 - acc: 0.06 - ETA: 51s - loss: 4.2626 - acc: 0.06 - ETA: 51s - loss: 4.2641 - acc: 0.06 - ETA: 51s - loss: 4.2630 - acc: 0.06 - ETA: 51s - loss: 4.2620 - acc: 0.06 - ETA: 51s - loss: 4.2628 - acc: 0.06 - ETA: 50s - loss: 4.2634 - acc: 0.06 - ETA: 50s - loss: 4.2638 - acc: 0.06 - ETA: 50s - loss: 4.2634 - acc: 0.06 - ETA: 50s - loss: 4.2628 - acc: 0.06 - ETA: 50s - loss: 4.2642 - acc: 0.06 - ETA: 49s - loss: 4.2656 - acc: 0.06 - ETA: 49s - loss: 4.2656 - acc: 0.06 - ETA: 49s - loss: 4.2671 - acc: 0.06 - ETA: 49s - loss: 4.2664 - acc: 0.06 - ETA: 48s - loss: 4.2659 - acc: 0.06 - ETA: 48s - loss: 4.2653 - acc: 0.06 - ETA: 48s - loss: 4.2635 - acc: 0.06 - ETA: 48s - loss: 4.2625 - acc: 0.06 - ETA: 48s - loss: 4.2567 - acc: 0.06 - ETA: 47s - loss: 4.2563 - acc: 0.06 - ETA: 47s - loss: 4.2579 - acc: 0.06 - ETA: 47s - loss: 4.2612 - acc: 0.06 - ETA: 47s - loss: 4.2622 - acc: 0.06 - ETA: 47s - loss: 4.2617 - acc: 0.06 - ETA: 46s - loss: 4.2627 - acc: 0.06 - ETA: 46s - loss: 4.2685 - acc: 0.06 - ETA: 46s - loss: 4.2669 - acc: 0.06 - ETA: 46s - loss: 4.2669 - acc: 0.06 - ETA: 45s - loss: 4.2697 - acc: 0.06 - ETA: 45s - loss: 4.2719 - acc: 0.06 - ETA: 45s - loss: 4.2730 - acc: 0.06 - ETA: 45s - loss: 4.2750 - acc: 0.06 - ETA: 45s - loss: 4.2762 - acc: 0.06 - ETA: 45s - loss: 4.2778 - acc: 0.06 - ETA: 44s - loss: 4.2783 - acc: 0.06 - ETA: 44s - loss: 4.2792 - acc: 0.06 - ETA: 44s - loss: 4.2788 - acc: 0.06 - ETA: 44s - loss: 4.2776 - acc: 0.06 - ETA: 43s - loss: 4.2767 - acc: 0.06 - ETA: 43s - loss: 4.2758 - acc: 0.06 - ETA: 43s - loss: 4.2753 - acc: 0.07 - ETA: 43s - loss: 4.2723 - acc: 0.07 - ETA: 43s - loss: 4.2764 - acc: 0.06 - ETA: 42s - loss: 4.2743 - acc: 0.07 - ETA: 42s - loss: 4.2759 - acc: 0.06 - ETA: 42s - loss: 4.2736 - acc: 0.07 - ETA: 42s - loss: 4.2743 - acc: 0.07 - ETA: 42s - loss: 4.2737 - acc: 0.06 - ETA: 41s - loss: 4.2751 - acc: 0.06 - ETA: 41s - loss: 4.2741 - acc: 0.06 - ETA: 41s - loss: 4.2715 - acc: 0.07 - ETA: 41s - loss: 4.2709 - acc: 0.07 - ETA: 41s - loss: 4.2728 - acc: 0.07 - ETA: 40s - loss: 4.2711 - acc: 0.07 - ETA: 40s - loss: 4.2730 - acc: 0.07 - ETA: 40s - loss: 4.2730 - acc: 0.07 - ETA: 40s - loss: 4.2709 - acc: 0.06 - ETA: 39s - loss: 4.2699 - acc: 0.06 - ETA: 39s - loss: 4.2713 - acc: 0.06 - ETA: 39s - loss: 4.2694 - acc: 0.07 - ETA: 39s - loss: 4.2706 - acc: 0.07 - ETA: 39s - loss: 4.2708 - acc: 0.07 - ETA: 38s - loss: 4.2726 - acc: 0.06 - ETA: 38s - loss: 4.2764 - acc: 0.06 - ETA: 38s - loss: 4.2777 - acc: 0.07 - ETA: 38s - loss: 4.2783 - acc: 0.07 - ETA: 38s - loss: 4.2760 - acc: 0.07 - ETA: 37s - loss: 4.2773 - acc: 0.07 - ETA: 37s - loss: 4.2779 - acc: 0.07 - ETA: 37s - loss: 4.2801 - acc: 0.07 - ETA: 37s - loss: 4.2826 - acc: 0.07 - ETA: 37s - loss: 4.2828 - acc: 0.07 - ETA: 36s - loss: 4.2831 - acc: 0.07 - ETA: 36s - loss: 4.2826 - acc: 0.07 - ETA: 36s - loss: 4.2814 - acc: 0.07 - ETA: 36s - loss: 4.2817 - acc: 0.07 - ETA: 35s - loss: 4.2833 - acc: 0.07 - ETA: 35s - loss: 4.2833 - acc: 0.07 - ETA: 35s - loss: 4.2844 - acc: 0.07 - ETA: 35s - loss: 4.2868 - acc: 0.07 - ETA: 35s - loss: 4.2863 - acc: 0.07 - ETA: 34s - loss: 4.2862 - acc: 0.07 - ETA: 34s - loss: 4.2852 - acc: 0.07 - ETA: 34s - loss: 4.2851 - acc: 0.07 - ETA: 34s - loss: 4.2848 - acc: 0.07 - ETA: 34s - loss: 4.2874 - acc: 0.07 - ETA: 33s - loss: 4.2877 - acc: 0.07 - ETA: 33s - loss: 4.2873 - acc: 0.07 - ETA: 33s - loss: 4.2857 - acc: 0.07 - ETA: 33s - loss: 4.2847 - acc: 0.07 - ETA: 32s - loss: 4.2854 - acc: 0.07 - ETA: 32s - loss: 4.2856 - acc: 0.07 - ETA: 32s - loss: 4.2855 - acc: 0.06 - ETA: 32s - loss: 4.2844 - acc: 0.06 - ETA: 32s - loss: 4.2849 - acc: 0.06 - ETA: 31s - loss: 4.2832 - acc: 0.06 - ETA: 31s - loss: 4.2832 - acc: 0.06 - ETA: 31s - loss: 4.2847 - acc: 0.06 - ETA: 31s - loss: 4.2836 - acc: 0.06 - ETA: 31s - loss: 4.2847 - acc: 0.06 - ETA: 30s - loss: 4.2865 - acc: 0.06 - ETA: 30s - loss: 4.2876 - acc: 0.06 - ETA: 30s - loss: 4.2869 - acc: 0.06 - ETA: 30s - loss: 4.2875 - acc: 0.06 - ETA: 30s - loss: 4.2887 - acc: 0.06 - ETA: 29s - loss: 4.2890 - acc: 0.06 - ETA: 29s - loss: 4.2881 - acc: 0.06 - ETA: 29s - loss: 4.2893 - acc: 0.06 - ETA: 29s - loss: 4.2903 - acc: 0.06 - ETA: 29s - loss: 4.2902 - acc: 0.06 - ETA: 28s - loss: 4.2897 - acc: 0.06 - ETA: 28s - loss: 4.2909 - acc: 0.06 - ETA: 28s - loss: 4.2917 - acc: 0.06 - ETA: 28s - loss: 4.2918 - acc: 0.06 - ETA: 27s - loss: 4.2921 - acc: 0.06 - ETA: 27s - loss: 4.2922 - acc: 0.06 - ETA: 27s - loss: 4.2918 - acc: 0.06 - ETA: 27s - loss: 4.2917 - acc: 0.06 - ETA: 27s - loss: 4.2905 - acc: 0.06 - ETA: 26s - loss: 4.2901 - acc: 0.06 - ETA: 26s - loss: 4.2886 - acc: 0.06 - ETA: 26s - loss: 4.2887 - acc: 0.06 - ETA: 26s - loss: 4.2898 - acc: 0.06 - ETA: 26s - loss: 4.2911 - acc: 0.06 - ETA: 25s - loss: 4.2921 - acc: 0.06 - ETA: 25s - loss: 4.2907 - acc: 0.06 - ETA: 25s - loss: 4.2921 - acc: 0.06 - ETA: 25s - loss: 4.2911 - acc: 0.06 - ETA: 25s - loss: 4.2925 - acc: 0.0667"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6660/6680 [============================>.] - ETA: 24s - loss: 4.2930 - acc: 0.06 - ETA: 24s - loss: 4.2919 - acc: 0.06 - ETA: 24s - loss: 4.2927 - acc: 0.06 - ETA: 24s - loss: 4.2924 - acc: 0.06 - ETA: 23s - loss: 4.2934 - acc: 0.06 - ETA: 23s - loss: 4.2928 - acc: 0.06 - ETA: 23s - loss: 4.2918 - acc: 0.06 - ETA: 23s - loss: 4.2929 - acc: 0.06 - ETA: 23s - loss: 4.2931 - acc: 0.06 - ETA: 22s - loss: 4.2927 - acc: 0.06 - ETA: 22s - loss: 4.2933 - acc: 0.06 - ETA: 22s - loss: 4.2922 - acc: 0.06 - ETA: 22s - loss: 4.2922 - acc: 0.06 - ETA: 22s - loss: 4.2920 - acc: 0.06 - ETA: 21s - loss: 4.2904 - acc: 0.06 - ETA: 21s - loss: 4.2893 - acc: 0.06 - ETA: 21s - loss: 4.2883 - acc: 0.06 - ETA: 21s - loss: 4.2867 - acc: 0.06 - ETA: 21s - loss: 4.2904 - acc: 0.06 - ETA: 20s - loss: 4.2893 - acc: 0.06 - ETA: 20s - loss: 4.2896 - acc: 0.06 - ETA: 20s - loss: 4.2905 - acc: 0.06 - ETA: 20s - loss: 4.2895 - acc: 0.06 - ETA: 19s - loss: 4.2878 - acc: 0.06 - ETA: 19s - loss: 4.2881 - acc: 0.06 - ETA: 19s - loss: 4.2884 - acc: 0.06 - ETA: 19s - loss: 4.2881 - acc: 0.06 - ETA: 19s - loss: 4.2888 - acc: 0.06 - ETA: 18s - loss: 4.2887 - acc: 0.06 - ETA: 18s - loss: 4.2888 - acc: 0.06 - ETA: 18s - loss: 4.2884 - acc: 0.06 - ETA: 18s - loss: 4.2874 - acc: 0.06 - ETA: 18s - loss: 4.2869 - acc: 0.06 - ETA: 17s - loss: 4.2861 - acc: 0.06 - ETA: 17s - loss: 4.2854 - acc: 0.06 - ETA: 17s - loss: 4.2867 - acc: 0.06 - ETA: 17s - loss: 4.2871 - acc: 0.06 - ETA: 17s - loss: 4.2863 - acc: 0.06 - ETA: 16s - loss: 4.2869 - acc: 0.06 - ETA: 16s - loss: 4.2882 - acc: 0.06 - ETA: 16s - loss: 4.2892 - acc: 0.06 - ETA: 16s - loss: 4.2886 - acc: 0.06 - ETA: 15s - loss: 4.2876 - acc: 0.06 - ETA: 15s - loss: 4.2872 - acc: 0.06 - ETA: 15s - loss: 4.2883 - acc: 0.06 - ETA: 15s - loss: 4.2874 - acc: 0.06 - ETA: 15s - loss: 4.2892 - acc: 0.06 - ETA: 14s - loss: 4.2888 - acc: 0.06 - ETA: 14s - loss: 4.2888 - acc: 0.06 - ETA: 14s - loss: 4.2878 - acc: 0.06 - ETA: 14s - loss: 4.2868 - acc: 0.06 - ETA: 14s - loss: 4.2857 - acc: 0.06 - ETA: 13s - loss: 4.2856 - acc: 0.06 - ETA: 13s - loss: 4.2868 - acc: 0.06 - ETA: 13s - loss: 4.2865 - acc: 0.06 - ETA: 13s - loss: 4.2864 - acc: 0.06 - ETA: 13s - loss: 4.2867 - acc: 0.06 - ETA: 12s - loss: 4.2863 - acc: 0.06 - ETA: 12s - loss: 4.2867 - acc: 0.06 - ETA: 12s - loss: 4.2867 - acc: 0.06 - ETA: 12s - loss: 4.2872 - acc: 0.06 - ETA: 11s - loss: 4.2864 - acc: 0.06 - ETA: 11s - loss: 4.2864 - acc: 0.06 - ETA: 11s - loss: 4.2865 - acc: 0.06 - ETA: 11s - loss: 4.2872 - acc: 0.06 - ETA: 11s - loss: 4.2872 - acc: 0.06 - ETA: 10s - loss: 4.2874 - acc: 0.06 - ETA: 10s - loss: 4.2880 - acc: 0.06 - ETA: 10s - loss: 4.2873 - acc: 0.06 - ETA: 10s - loss: 4.2875 - acc: 0.06 - ETA: 10s - loss: 4.2876 - acc: 0.06 - ETA: 9s - loss: 4.2883 - acc: 0.0667 - ETA: 9s - loss: 4.2890 - acc: 0.066 - ETA: 9s - loss: 4.2887 - acc: 0.067 - ETA: 9s - loss: 4.2888 - acc: 0.066 - ETA: 9s - loss: 4.2877 - acc: 0.067 - ETA: 8s - loss: 4.2874 - acc: 0.067 - ETA: 8s - loss: 4.2893 - acc: 0.066 - ETA: 8s - loss: 4.2902 - acc: 0.066 - ETA: 8s - loss: 4.2899 - acc: 0.066 - ETA: 7s - loss: 4.2907 - acc: 0.067 - ETA: 7s - loss: 4.2901 - acc: 0.067 - ETA: 7s - loss: 4.2908 - acc: 0.067 - ETA: 7s - loss: 4.2907 - acc: 0.067 - ETA: 7s - loss: 4.2905 - acc: 0.067 - ETA: 6s - loss: 4.2918 - acc: 0.066 - ETA: 6s - loss: 4.2922 - acc: 0.066 - ETA: 6s - loss: 4.2918 - acc: 0.066 - ETA: 6s - loss: 4.2918 - acc: 0.066 - ETA: 6s - loss: 4.2912 - acc: 0.066 - ETA: 5s - loss: 4.2931 - acc: 0.065 - ETA: 5s - loss: 4.2928 - acc: 0.065 - ETA: 5s - loss: 4.2934 - acc: 0.065 - ETA: 5s - loss: 4.2940 - acc: 0.065 - ETA: 5s - loss: 4.2928 - acc: 0.066 - ETA: 4s - loss: 4.2932 - acc: 0.065 - ETA: 4s - loss: 4.2913 - acc: 0.066 - ETA: 4s - loss: 4.2928 - acc: 0.066 - ETA: 4s - loss: 4.2916 - acc: 0.066 - ETA: 3s - loss: 4.2914 - acc: 0.066 - ETA: 3s - loss: 4.2913 - acc: 0.066 - ETA: 3s - loss: 4.2909 - acc: 0.066 - ETA: 3s - loss: 4.2902 - acc: 0.066 - ETA: 3s - loss: 4.2892 - acc: 0.066 - ETA: 2s - loss: 4.2904 - acc: 0.066 - ETA: 2s - loss: 4.2897 - acc: 0.066 - ETA: 2s - loss: 4.2894 - acc: 0.066 - ETA: 2s - loss: 4.2885 - acc: 0.066 - ETA: 2s - loss: 4.2879 - acc: 0.066 - ETA: 1s - loss: 4.2874 - acc: 0.066 - ETA: 1s - loss: 4.2884 - acc: 0.066 - ETA: 1s - loss: 4.2885 - acc: 0.066 - ETA: 1s - loss: 4.2875 - acc: 0.066 - ETA: 1s - loss: 4.2870 - acc: 0.067 - ETA: 0s - loss: 4.2859 - acc: 0.066 - ETA: 0s - loss: 4.2859 - acc: 0.066 - ETA: 0s - loss: 4.2871 - acc: 0.067 - ETA: 0s - loss: 4.2875 - acc: 0.0673Epoch 00019: val_loss improved from 4.37664 to 4.32070, saving model to saved_models/weights.best.from_scratch.hdf5\n",
      "6680/6680 [==============================] - 72s - loss: 4.2863 - acc: 0.0674 - val_loss: 4.3207 - val_acc: 0.0623\n",
      "Epoch 21/32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4300/6680 [==================>...........] - ETA: 64s - loss: 3.9926 - acc: 0.05 - ETA: 68s - loss: 4.0915 - acc: 0.05 - ETA: 68s - loss: 4.1474 - acc: 0.03 - ETA: 68s - loss: 4.1821 - acc: 0.05 - ETA: 68s - loss: 4.1881 - acc: 0.06 - ETA: 68s - loss: 4.1655 - acc: 0.07 - ETA: 68s - loss: 4.1867 - acc: 0.08 - ETA: 68s - loss: 4.1962 - acc: 0.08 - ETA: 67s - loss: 4.1882 - acc: 0.08 - ETA: 67s - loss: 4.1603 - acc: 0.07 - ETA: 67s - loss: 4.1598 - acc: 0.06 - ETA: 67s - loss: 4.1796 - acc: 0.07 - ETA: 67s - loss: 4.1734 - acc: 0.07 - ETA: 67s - loss: 4.1988 - acc: 0.07 - ETA: 67s - loss: 4.1710 - acc: 0.07 - ETA: 66s - loss: 4.1797 - acc: 0.07 - ETA: 66s - loss: 4.2000 - acc: 0.07 - ETA: 66s - loss: 4.2098 - acc: 0.07 - ETA: 66s - loss: 4.2271 - acc: 0.07 - ETA: 66s - loss: 4.2224 - acc: 0.07 - ETA: 66s - loss: 4.2236 - acc: 0.07 - ETA: 66s - loss: 4.2027 - acc: 0.07 - ETA: 66s - loss: 4.1868 - acc: 0.08 - ETA: 66s - loss: 4.1816 - acc: 0.08 - ETA: 66s - loss: 4.1791 - acc: 0.08 - ETA: 65s - loss: 4.1767 - acc: 0.08 - ETA: 65s - loss: 4.1938 - acc: 0.08 - ETA: 65s - loss: 4.1874 - acc: 0.07 - ETA: 65s - loss: 4.1853 - acc: 0.07 - ETA: 65s - loss: 4.1792 - acc: 0.07 - ETA: 65s - loss: 4.1560 - acc: 0.07 - ETA: 64s - loss: 4.1645 - acc: 0.07 - ETA: 64s - loss: 4.1747 - acc: 0.07 - ETA: 64s - loss: 4.1711 - acc: 0.07 - ETA: 64s - loss: 4.1728 - acc: 0.08 - ETA: 64s - loss: 4.1803 - acc: 0.07 - ETA: 63s - loss: 4.1685 - acc: 0.07 - ETA: 63s - loss: 4.1827 - acc: 0.07 - ETA: 63s - loss: 4.1885 - acc: 0.07 - ETA: 62s - loss: 4.1833 - acc: 0.07 - ETA: 62s - loss: 4.1820 - acc: 0.07 - ETA: 62s - loss: 4.1816 - acc: 0.07 - ETA: 62s - loss: 4.1855 - acc: 0.07 - ETA: 62s - loss: 4.1866 - acc: 0.07 - ETA: 61s - loss: 4.1815 - acc: 0.07 - ETA: 61s - loss: 4.1793 - acc: 0.07 - ETA: 61s - loss: 4.1869 - acc: 0.07 - ETA: 61s - loss: 4.1903 - acc: 0.07 - ETA: 60s - loss: 4.1938 - acc: 0.07 - ETA: 60s - loss: 4.1960 - acc: 0.07 - ETA: 60s - loss: 4.1969 - acc: 0.07 - ETA: 60s - loss: 4.1980 - acc: 0.07 - ETA: 59s - loss: 4.2047 - acc: 0.07 - ETA: 59s - loss: 4.2101 - acc: 0.07 - ETA: 59s - loss: 4.2138 - acc: 0.07 - ETA: 59s - loss: 4.2147 - acc: 0.07 - ETA: 58s - loss: 4.2177 - acc: 0.07 - ETA: 58s - loss: 4.2214 - acc: 0.07 - ETA: 58s - loss: 4.2210 - acc: 0.07 - ETA: 58s - loss: 4.2187 - acc: 0.07 - ETA: 58s - loss: 4.2181 - acc: 0.07 - ETA: 58s - loss: 4.2148 - acc: 0.07 - ETA: 57s - loss: 4.2228 - acc: 0.07 - ETA: 57s - loss: 4.2280 - acc: 0.07 - ETA: 57s - loss: 4.2292 - acc: 0.07 - ETA: 57s - loss: 4.2291 - acc: 0.07 - ETA: 57s - loss: 4.2331 - acc: 0.07 - ETA: 56s - loss: 4.2325 - acc: 0.07 - ETA: 56s - loss: 4.2335 - acc: 0.07 - ETA: 56s - loss: 4.2315 - acc: 0.07 - ETA: 56s - loss: 4.2330 - acc: 0.07 - ETA: 55s - loss: 4.2377 - acc: 0.07 - ETA: 55s - loss: 4.2351 - acc: 0.06 - ETA: 55s - loss: 4.2381 - acc: 0.06 - ETA: 55s - loss: 4.2404 - acc: 0.07 - ETA: 55s - loss: 4.2423 - acc: 0.06 - ETA: 54s - loss: 4.2407 - acc: 0.07 - ETA: 54s - loss: 4.2453 - acc: 0.06 - ETA: 54s - loss: 4.2494 - acc: 0.06 - ETA: 54s - loss: 4.2451 - acc: 0.06 - ETA: 53s - loss: 4.2455 - acc: 0.06 - ETA: 53s - loss: 4.2452 - acc: 0.06 - ETA: 53s - loss: 4.2473 - acc: 0.06 - ETA: 53s - loss: 4.2520 - acc: 0.06 - ETA: 53s - loss: 4.2522 - acc: 0.06 - ETA: 52s - loss: 4.2504 - acc: 0.06 - ETA: 52s - loss: 4.2494 - acc: 0.06 - ETA: 52s - loss: 4.2516 - acc: 0.06 - ETA: 52s - loss: 4.2488 - acc: 0.06 - ETA: 52s - loss: 4.2486 - acc: 0.06 - ETA: 51s - loss: 4.2489 - acc: 0.06 - ETA: 51s - loss: 4.2519 - acc: 0.06 - ETA: 51s - loss: 4.2553 - acc: 0.06 - ETA: 51s - loss: 4.2547 - acc: 0.06 - ETA: 50s - loss: 4.2538 - acc: 0.06 - ETA: 50s - loss: 4.2551 - acc: 0.06 - ETA: 50s - loss: 4.2519 - acc: 0.06 - ETA: 50s - loss: 4.2549 - acc: 0.06 - ETA: 50s - loss: 4.2555 - acc: 0.06 - ETA: 49s - loss: 4.2541 - acc: 0.06 - ETA: 49s - loss: 4.2629 - acc: 0.06 - ETA: 49s - loss: 4.2631 - acc: 0.06 - ETA: 49s - loss: 4.2603 - acc: 0.06 - ETA: 48s - loss: 4.2621 - acc: 0.06 - ETA: 48s - loss: 4.2672 - acc: 0.06 - ETA: 48s - loss: 4.2685 - acc: 0.06 - ETA: 48s - loss: 4.2695 - acc: 0.06 - ETA: 48s - loss: 4.2685 - acc: 0.06 - ETA: 47s - loss: 4.2699 - acc: 0.06 - ETA: 47s - loss: 4.2705 - acc: 0.06 - ETA: 47s - loss: 4.2730 - acc: 0.06 - ETA: 47s - loss: 4.2740 - acc: 0.06 - ETA: 47s - loss: 4.2746 - acc: 0.06 - ETA: 46s - loss: 4.2754 - acc: 0.06 - ETA: 46s - loss: 4.2747 - acc: 0.06 - ETA: 46s - loss: 4.2742 - acc: 0.06 - ETA: 46s - loss: 4.2702 - acc: 0.06 - ETA: 45s - loss: 4.2684 - acc: 0.06 - ETA: 45s - loss: 4.2690 - acc: 0.06 - ETA: 45s - loss: 4.2691 - acc: 0.06 - ETA: 45s - loss: 4.2691 - acc: 0.06 - ETA: 45s - loss: 4.2654 - acc: 0.06 - ETA: 44s - loss: 4.2652 - acc: 0.06 - ETA: 44s - loss: 4.2645 - acc: 0.06 - ETA: 44s - loss: 4.2650 - acc: 0.06 - ETA: 44s - loss: 4.2672 - acc: 0.06 - ETA: 44s - loss: 4.2689 - acc: 0.06 - ETA: 43s - loss: 4.2691 - acc: 0.06 - ETA: 43s - loss: 4.2706 - acc: 0.06 - ETA: 43s - loss: 4.2688 - acc: 0.06 - ETA: 43s - loss: 4.2676 - acc: 0.06 - ETA: 42s - loss: 4.2680 - acc: 0.06 - ETA: 42s - loss: 4.2690 - acc: 0.06 - ETA: 42s - loss: 4.2667 - acc: 0.06 - ETA: 42s - loss: 4.2673 - acc: 0.06 - ETA: 42s - loss: 4.2685 - acc: 0.06 - ETA: 41s - loss: 4.2664 - acc: 0.06 - ETA: 41s - loss: 4.2684 - acc: 0.06 - ETA: 41s - loss: 4.2670 - acc: 0.06 - ETA: 41s - loss: 4.2686 - acc: 0.06 - ETA: 41s - loss: 4.2680 - acc: 0.06 - ETA: 40s - loss: 4.2675 - acc: 0.06 - ETA: 40s - loss: 4.2682 - acc: 0.06 - ETA: 40s - loss: 4.2658 - acc: 0.06 - ETA: 40s - loss: 4.2648 - acc: 0.06 - ETA: 39s - loss: 4.2634 - acc: 0.06 - ETA: 39s - loss: 4.2623 - acc: 0.06 - ETA: 39s - loss: 4.2602 - acc: 0.06 - ETA: 39s - loss: 4.2613 - acc: 0.06 - ETA: 39s - loss: 4.2629 - acc: 0.06 - ETA: 38s - loss: 4.2626 - acc: 0.06 - ETA: 38s - loss: 4.2643 - acc: 0.06 - ETA: 38s - loss: 4.2670 - acc: 0.06 - ETA: 38s - loss: 4.2663 - acc: 0.06 - ETA: 38s - loss: 4.2660 - acc: 0.06 - ETA: 37s - loss: 4.2657 - acc: 0.06 - ETA: 37s - loss: 4.2653 - acc: 0.06 - ETA: 37s - loss: 4.2636 - acc: 0.06 - ETA: 37s - loss: 4.2623 - acc: 0.06 - ETA: 37s - loss: 4.2605 - acc: 0.06 - ETA: 36s - loss: 4.2561 - acc: 0.06 - ETA: 36s - loss: 4.2563 - acc: 0.06 - ETA: 36s - loss: 4.2550 - acc: 0.06 - ETA: 36s - loss: 4.2553 - acc: 0.06 - ETA: 35s - loss: 4.2527 - acc: 0.06 - ETA: 35s - loss: 4.2538 - acc: 0.06 - ETA: 35s - loss: 4.2557 - acc: 0.06 - ETA: 35s - loss: 4.2556 - acc: 0.06 - ETA: 35s - loss: 4.2564 - acc: 0.06 - ETA: 34s - loss: 4.2567 - acc: 0.06 - ETA: 34s - loss: 4.2551 - acc: 0.06 - ETA: 34s - loss: 4.2548 - acc: 0.06 - ETA: 34s - loss: 4.2550 - acc: 0.06 - ETA: 34s - loss: 4.2543 - acc: 0.06 - ETA: 33s - loss: 4.2556 - acc: 0.06 - ETA: 33s - loss: 4.2532 - acc: 0.06 - ETA: 33s - loss: 4.2541 - acc: 0.06 - ETA: 33s - loss: 4.2541 - acc: 0.06 - ETA: 32s - loss: 4.2534 - acc: 0.06 - ETA: 32s - loss: 4.2529 - acc: 0.06 - ETA: 32s - loss: 4.2530 - acc: 0.06 - ETA: 32s - loss: 4.2542 - acc: 0.06 - ETA: 32s - loss: 4.2553 - acc: 0.06 - ETA: 31s - loss: 4.2550 - acc: 0.06 - ETA: 31s - loss: 4.2551 - acc: 0.06 - ETA: 31s - loss: 4.2532 - acc: 0.06 - ETA: 31s - loss: 4.2532 - acc: 0.06 - ETA: 31s - loss: 4.2511 - acc: 0.06 - ETA: 30s - loss: 4.2524 - acc: 0.06 - ETA: 30s - loss: 4.2530 - acc: 0.06 - ETA: 30s - loss: 4.2533 - acc: 0.06 - ETA: 30s - loss: 4.2532 - acc: 0.06 - ETA: 29s - loss: 4.2530 - acc: 0.06 - ETA: 29s - loss: 4.2540 - acc: 0.06 - ETA: 29s - loss: 4.2540 - acc: 0.06 - ETA: 29s - loss: 4.2530 - acc: 0.06 - ETA: 29s - loss: 4.2542 - acc: 0.06 - ETA: 28s - loss: 4.2577 - acc: 0.06 - ETA: 28s - loss: 4.2588 - acc: 0.06 - ETA: 28s - loss: 4.2582 - acc: 0.06 - ETA: 28s - loss: 4.2580 - acc: 0.06 - ETA: 28s - loss: 4.2568 - acc: 0.06 - ETA: 27s - loss: 4.2571 - acc: 0.06 - ETA: 27s - loss: 4.2548 - acc: 0.06 - ETA: 27s - loss: 4.2548 - acc: 0.06 - ETA: 27s - loss: 4.2539 - acc: 0.06 - ETA: 26s - loss: 4.2560 - acc: 0.06 - ETA: 26s - loss: 4.2578 - acc: 0.06 - ETA: 26s - loss: 4.2591 - acc: 0.06 - ETA: 26s - loss: 4.2582 - acc: 0.06 - ETA: 26s - loss: 4.2576 - acc: 0.06 - ETA: 25s - loss: 4.2572 - acc: 0.06 - ETA: 25s - loss: 4.2581 - acc: 0.06 - ETA: 25s - loss: 4.2570 - acc: 0.07 - ETA: 25s - loss: 4.2567 - acc: 0.0702"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6660/6680 [============================>.] - ETA: 25s - loss: 4.2564 - acc: 0.07 - ETA: 24s - loss: 4.2567 - acc: 0.07 - ETA: 24s - loss: 4.2598 - acc: 0.07 - ETA: 24s - loss: 4.2578 - acc: 0.07 - ETA: 24s - loss: 4.2559 - acc: 0.07 - ETA: 24s - loss: 4.2585 - acc: 0.07 - ETA: 23s - loss: 4.2571 - acc: 0.07 - ETA: 23s - loss: 4.2571 - acc: 0.07 - ETA: 23s - loss: 4.2578 - acc: 0.07 - ETA: 23s - loss: 4.2569 - acc: 0.07 - ETA: 22s - loss: 4.2566 - acc: 0.07 - ETA: 22s - loss: 4.2565 - acc: 0.07 - ETA: 22s - loss: 4.2568 - acc: 0.07 - ETA: 22s - loss: 4.2575 - acc: 0.07 - ETA: 22s - loss: 4.2587 - acc: 0.07 - ETA: 21s - loss: 4.2577 - acc: 0.07 - ETA: 21s - loss: 4.2583 - acc: 0.07 - ETA: 21s - loss: 4.2592 - acc: 0.07 - ETA: 21s - loss: 4.2587 - acc: 0.07 - ETA: 21s - loss: 4.2588 - acc: 0.07 - ETA: 20s - loss: 4.2588 - acc: 0.07 - ETA: 20s - loss: 4.2584 - acc: 0.07 - ETA: 20s - loss: 4.2593 - acc: 0.07 - ETA: 20s - loss: 4.2605 - acc: 0.07 - ETA: 19s - loss: 4.2601 - acc: 0.07 - ETA: 19s - loss: 4.2603 - acc: 0.07 - ETA: 19s - loss: 4.2608 - acc: 0.07 - ETA: 19s - loss: 4.2604 - acc: 0.07 - ETA: 19s - loss: 4.2607 - acc: 0.07 - ETA: 18s - loss: 4.2591 - acc: 0.07 - ETA: 18s - loss: 4.2625 - acc: 0.07 - ETA: 18s - loss: 4.2625 - acc: 0.07 - ETA: 18s - loss: 4.2619 - acc: 0.07 - ETA: 18s - loss: 4.2624 - acc: 0.07 - ETA: 17s - loss: 4.2618 - acc: 0.07 - ETA: 17s - loss: 4.2615 - acc: 0.07 - ETA: 17s - loss: 4.2619 - acc: 0.07 - ETA: 17s - loss: 4.2598 - acc: 0.07 - ETA: 16s - loss: 4.2591 - acc: 0.07 - ETA: 16s - loss: 4.2574 - acc: 0.07 - ETA: 16s - loss: 4.2583 - acc: 0.07 - ETA: 16s - loss: 4.2582 - acc: 0.07 - ETA: 16s - loss: 4.2595 - acc: 0.07 - ETA: 15s - loss: 4.2596 - acc: 0.07 - ETA: 15s - loss: 4.2591 - acc: 0.07 - ETA: 15s - loss: 4.2613 - acc: 0.07 - ETA: 15s - loss: 4.2601 - acc: 0.07 - ETA: 15s - loss: 4.2608 - acc: 0.07 - ETA: 14s - loss: 4.2606 - acc: 0.07 - ETA: 14s - loss: 4.2613 - acc: 0.07 - ETA: 14s - loss: 4.2603 - acc: 0.07 - ETA: 14s - loss: 4.2604 - acc: 0.07 - ETA: 13s - loss: 4.2605 - acc: 0.07 - ETA: 13s - loss: 4.2614 - acc: 0.07 - ETA: 13s - loss: 4.2606 - acc: 0.07 - ETA: 13s - loss: 4.2605 - acc: 0.07 - ETA: 13s - loss: 4.2612 - acc: 0.07 - ETA: 12s - loss: 4.2624 - acc: 0.07 - ETA: 12s - loss: 4.2625 - acc: 0.07 - ETA: 12s - loss: 4.2633 - acc: 0.06 - ETA: 12s - loss: 4.2633 - acc: 0.07 - ETA: 12s - loss: 4.2617 - acc: 0.07 - ETA: 11s - loss: 4.2637 - acc: 0.07 - ETA: 11s - loss: 4.2631 - acc: 0.07 - ETA: 11s - loss: 4.2624 - acc: 0.07 - ETA: 11s - loss: 4.2624 - acc: 0.07 - ETA: 11s - loss: 4.2619 - acc: 0.07 - ETA: 10s - loss: 4.2620 - acc: 0.07 - ETA: 10s - loss: 4.2631 - acc: 0.07 - ETA: 10s - loss: 4.2629 - acc: 0.07 - ETA: 10s - loss: 4.2618 - acc: 0.07 - ETA: 9s - loss: 4.2621 - acc: 0.0700 - ETA: 9s - loss: 4.2623 - acc: 0.070 - ETA: 9s - loss: 4.2632 - acc: 0.070 - ETA: 9s - loss: 4.2628 - acc: 0.070 - ETA: 9s - loss: 4.2618 - acc: 0.070 - ETA: 8s - loss: 4.2607 - acc: 0.070 - ETA: 8s - loss: 4.2595 - acc: 0.070 - ETA: 8s - loss: 4.2591 - acc: 0.070 - ETA: 8s - loss: 4.2596 - acc: 0.070 - ETA: 8s - loss: 4.2584 - acc: 0.069 - ETA: 7s - loss: 4.2586 - acc: 0.069 - ETA: 7s - loss: 4.2604 - acc: 0.069 - ETA: 7s - loss: 4.2600 - acc: 0.069 - ETA: 7s - loss: 4.2593 - acc: 0.070 - ETA: 6s - loss: 4.2594 - acc: 0.070 - ETA: 6s - loss: 4.2581 - acc: 0.070 - ETA: 6s - loss: 4.2580 - acc: 0.070 - ETA: 6s - loss: 4.2570 - acc: 0.070 - ETA: 6s - loss: 4.2560 - acc: 0.070 - ETA: 5s - loss: 4.2591 - acc: 0.070 - ETA: 5s - loss: 4.2591 - acc: 0.070 - ETA: 5s - loss: 4.2593 - acc: 0.070 - ETA: 5s - loss: 4.2582 - acc: 0.070 - ETA: 5s - loss: 4.2579 - acc: 0.070 - ETA: 4s - loss: 4.2581 - acc: 0.070 - ETA: 4s - loss: 4.2572 - acc: 0.070 - ETA: 4s - loss: 4.2565 - acc: 0.070 - ETA: 4s - loss: 4.2565 - acc: 0.070 - ETA: 4s - loss: 4.2577 - acc: 0.070 - ETA: 3s - loss: 4.2578 - acc: 0.069 - ETA: 3s - loss: 4.2589 - acc: 0.069 - ETA: 3s - loss: 4.2594 - acc: 0.069 - ETA: 3s - loss: 4.2588 - acc: 0.069 - ETA: 2s - loss: 4.2569 - acc: 0.069 - ETA: 2s - loss: 4.2600 - acc: 0.069 - ETA: 2s - loss: 4.2606 - acc: 0.069 - ETA: 2s - loss: 4.2606 - acc: 0.069 - ETA: 2s - loss: 4.2606 - acc: 0.069 - ETA: 1s - loss: 4.2610 - acc: 0.069 - ETA: 1s - loss: 4.2607 - acc: 0.069 - ETA: 1s - loss: 4.2601 - acc: 0.069 - ETA: 1s - loss: 4.2607 - acc: 0.069 - ETA: 1s - loss: 4.2598 - acc: 0.069 - ETA: 0s - loss: 4.2604 - acc: 0.069 - ETA: 0s - loss: 4.2617 - acc: 0.069 - ETA: 0s - loss: 4.2613 - acc: 0.069 - ETA: 0s - loss: 4.2616 - acc: 0.0692Epoch 00020: val_loss did not improve\n",
      "6680/6680 [==============================] - 73s - loss: 4.2603 - acc: 0.0692 - val_loss: 4.3490 - val_acc: 0.0623\n",
      "Epoch 22/32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4300/6680 [==================>...........] - ETA: 69s - loss: 3.7662 - acc: 0.15 - ETA: 70s - loss: 4.1157 - acc: 0.12 - ETA: 71s - loss: 4.3155 - acc: 0.08 - ETA: 69s - loss: 4.2995 - acc: 0.08 - ETA: 68s - loss: 4.3287 - acc: 0.07 - ETA: 69s - loss: 4.2996 - acc: 0.06 - ETA: 69s - loss: 4.2901 - acc: 0.05 - ETA: 68s - loss: 4.2758 - acc: 0.06 - ETA: 68s - loss: 4.2659 - acc: 0.07 - ETA: 67s - loss: 4.2449 - acc: 0.07 - ETA: 67s - loss: 4.2696 - acc: 0.07 - ETA: 67s - loss: 4.2692 - acc: 0.08 - ETA: 67s - loss: 4.2603 - acc: 0.07 - ETA: 67s - loss: 4.2478 - acc: 0.07 - ETA: 67s - loss: 4.2520 - acc: 0.07 - ETA: 66s - loss: 4.2487 - acc: 0.07 - ETA: 66s - loss: 4.2021 - acc: 0.08 - ETA: 66s - loss: 4.2160 - acc: 0.08 - ETA: 65s - loss: 4.2152 - acc: 0.08 - ETA: 65s - loss: 4.2339 - acc: 0.08 - ETA: 65s - loss: 4.2163 - acc: 0.08 - ETA: 65s - loss: 4.2308 - acc: 0.08 - ETA: 65s - loss: 4.2208 - acc: 0.08 - ETA: 65s - loss: 4.2432 - acc: 0.07 - ETA: 64s - loss: 4.2414 - acc: 0.08 - ETA: 64s - loss: 4.2465 - acc: 0.07 - ETA: 64s - loss: 4.2319 - acc: 0.07 - ETA: 64s - loss: 4.2160 - acc: 0.07 - ETA: 64s - loss: 4.2235 - acc: 0.08 - ETA: 63s - loss: 4.2152 - acc: 0.08 - ETA: 63s - loss: 4.2312 - acc: 0.08 - ETA: 63s - loss: 4.2261 - acc: 0.07 - ETA: 63s - loss: 4.2275 - acc: 0.07 - ETA: 63s - loss: 4.2245 - acc: 0.07 - ETA: 62s - loss: 4.2180 - acc: 0.07 - ETA: 62s - loss: 4.2202 - acc: 0.07 - ETA: 62s - loss: 4.2336 - acc: 0.07 - ETA: 62s - loss: 4.2329 - acc: 0.07 - ETA: 62s - loss: 4.2314 - acc: 0.07 - ETA: 62s - loss: 4.2382 - acc: 0.07 - ETA: 61s - loss: 4.2367 - acc: 0.07 - ETA: 61s - loss: 4.2408 - acc: 0.07 - ETA: 61s - loss: 4.2373 - acc: 0.07 - ETA: 61s - loss: 4.2427 - acc: 0.06 - ETA: 61s - loss: 4.2473 - acc: 0.07 - ETA: 61s - loss: 4.2451 - acc: 0.07 - ETA: 60s - loss: 4.2441 - acc: 0.07 - ETA: 60s - loss: 4.2507 - acc: 0.07 - ETA: 60s - loss: 4.2486 - acc: 0.07 - ETA: 60s - loss: 4.2492 - acc: 0.07 - ETA: 60s - loss: 4.2491 - acc: 0.07 - ETA: 59s - loss: 4.2500 - acc: 0.07 - ETA: 59s - loss: 4.2438 - acc: 0.07 - ETA: 59s - loss: 4.2416 - acc: 0.07 - ETA: 59s - loss: 4.2444 - acc: 0.07 - ETA: 58s - loss: 4.2449 - acc: 0.07 - ETA: 58s - loss: 4.2416 - acc: 0.07 - ETA: 58s - loss: 4.2445 - acc: 0.07 - ETA: 58s - loss: 4.2437 - acc: 0.07 - ETA: 58s - loss: 4.2452 - acc: 0.07 - ETA: 57s - loss: 4.2483 - acc: 0.06 - ETA: 57s - loss: 4.2517 - acc: 0.06 - ETA: 57s - loss: 4.2456 - acc: 0.06 - ETA: 57s - loss: 4.2486 - acc: 0.06 - ETA: 56s - loss: 4.2495 - acc: 0.07 - ETA: 56s - loss: 4.2420 - acc: 0.07 - ETA: 56s - loss: 4.2344 - acc: 0.07 - ETA: 56s - loss: 4.2335 - acc: 0.07 - ETA: 56s - loss: 4.2339 - acc: 0.07 - ETA: 55s - loss: 4.2349 - acc: 0.07 - ETA: 55s - loss: 4.2337 - acc: 0.07 - ETA: 55s - loss: 4.2312 - acc: 0.07 - ETA: 55s - loss: 4.2294 - acc: 0.07 - ETA: 55s - loss: 4.2326 - acc: 0.07 - ETA: 54s - loss: 4.2339 - acc: 0.07 - ETA: 54s - loss: 4.2280 - acc: 0.07 - ETA: 54s - loss: 4.2246 - acc: 0.07 - ETA: 54s - loss: 4.2265 - acc: 0.07 - ETA: 53s - loss: 4.2252 - acc: 0.07 - ETA: 53s - loss: 4.2237 - acc: 0.07 - ETA: 53s - loss: 4.2203 - acc: 0.07 - ETA: 53s - loss: 4.2178 - acc: 0.07 - ETA: 53s - loss: 4.2268 - acc: 0.07 - ETA: 52s - loss: 4.2279 - acc: 0.07 - ETA: 52s - loss: 4.2333 - acc: 0.07 - ETA: 52s - loss: 4.2307 - acc: 0.07 - ETA: 52s - loss: 4.2334 - acc: 0.07 - ETA: 52s - loss: 4.2326 - acc: 0.07 - ETA: 51s - loss: 4.2373 - acc: 0.07 - ETA: 51s - loss: 4.2376 - acc: 0.07 - ETA: 51s - loss: 4.2339 - acc: 0.07 - ETA: 51s - loss: 4.2345 - acc: 0.07 - ETA: 50s - loss: 4.2370 - acc: 0.07 - ETA: 50s - loss: 4.2387 - acc: 0.07 - ETA: 50s - loss: 4.2367 - acc: 0.07 - ETA: 50s - loss: 4.2320 - acc: 0.07 - ETA: 50s - loss: 4.2269 - acc: 0.07 - ETA: 49s - loss: 4.2243 - acc: 0.07 - ETA: 49s - loss: 4.2253 - acc: 0.07 - ETA: 49s - loss: 4.2254 - acc: 0.07 - ETA: 49s - loss: 4.2250 - acc: 0.07 - ETA: 48s - loss: 4.2245 - acc: 0.07 - ETA: 48s - loss: 4.2280 - acc: 0.07 - ETA: 48s - loss: 4.2270 - acc: 0.07 - ETA: 48s - loss: 4.2295 - acc: 0.07 - ETA: 48s - loss: 4.2289 - acc: 0.07 - ETA: 47s - loss: 4.2260 - acc: 0.07 - ETA: 47s - loss: 4.2245 - acc: 0.07 - ETA: 47s - loss: 4.2231 - acc: 0.07 - ETA: 47s - loss: 4.2231 - acc: 0.07 - ETA: 47s - loss: 4.2227 - acc: 0.07 - ETA: 46s - loss: 4.2255 - acc: 0.07 - ETA: 46s - loss: 4.2276 - acc: 0.07 - ETA: 46s - loss: 4.2291 - acc: 0.07 - ETA: 46s - loss: 4.2297 - acc: 0.07 - ETA: 45s - loss: 4.2307 - acc: 0.07 - ETA: 45s - loss: 4.2327 - acc: 0.07 - ETA: 45s - loss: 4.2306 - acc: 0.07 - ETA: 45s - loss: 4.2313 - acc: 0.07 - ETA: 45s - loss: 4.2325 - acc: 0.07 - ETA: 44s - loss: 4.2326 - acc: 0.07 - ETA: 44s - loss: 4.2314 - acc: 0.07 - ETA: 44s - loss: 4.2297 - acc: 0.07 - ETA: 44s - loss: 4.2272 - acc: 0.07 - ETA: 44s - loss: 4.2250 - acc: 0.07 - ETA: 43s - loss: 4.2213 - acc: 0.07 - ETA: 43s - loss: 4.2245 - acc: 0.07 - ETA: 43s - loss: 4.2244 - acc: 0.07 - ETA: 43s - loss: 4.2214 - acc: 0.07 - ETA: 43s - loss: 4.2228 - acc: 0.07 - ETA: 42s - loss: 4.2254 - acc: 0.07 - ETA: 42s - loss: 4.2246 - acc: 0.07 - ETA: 42s - loss: 4.2283 - acc: 0.07 - ETA: 42s - loss: 4.2285 - acc: 0.07 - ETA: 41s - loss: 4.2284 - acc: 0.07 - ETA: 41s - loss: 4.2260 - acc: 0.07 - ETA: 41s - loss: 4.2275 - acc: 0.07 - ETA: 41s - loss: 4.2295 - acc: 0.07 - ETA: 41s - loss: 4.2263 - acc: 0.07 - ETA: 40s - loss: 4.2282 - acc: 0.07 - ETA: 40s - loss: 4.2273 - acc: 0.07 - ETA: 40s - loss: 4.2283 - acc: 0.07 - ETA: 40s - loss: 4.2300 - acc: 0.07 - ETA: 40s - loss: 4.2288 - acc: 0.07 - ETA: 39s - loss: 4.2297 - acc: 0.07 - ETA: 39s - loss: 4.2309 - acc: 0.07 - ETA: 39s - loss: 4.2312 - acc: 0.07 - ETA: 39s - loss: 4.2305 - acc: 0.07 - ETA: 38s - loss: 4.2334 - acc: 0.07 - ETA: 38s - loss: 4.2332 - acc: 0.07 - ETA: 38s - loss: 4.2352 - acc: 0.07 - ETA: 38s - loss: 4.2347 - acc: 0.07 - ETA: 38s - loss: 4.2373 - acc: 0.07 - ETA: 37s - loss: 4.2374 - acc: 0.07 - ETA: 37s - loss: 4.2368 - acc: 0.07 - ETA: 37s - loss: 4.2357 - acc: 0.07 - ETA: 37s - loss: 4.2357 - acc: 0.07 - ETA: 37s - loss: 4.2348 - acc: 0.07 - ETA: 36s - loss: 4.2345 - acc: 0.07 - ETA: 36s - loss: 4.2340 - acc: 0.07 - ETA: 36s - loss: 4.2382 - acc: 0.07 - ETA: 36s - loss: 4.2366 - acc: 0.07 - ETA: 36s - loss: 4.2333 - acc: 0.07 - ETA: 35s - loss: 4.2368 - acc: 0.07 - ETA: 35s - loss: 4.2353 - acc: 0.07 - ETA: 35s - loss: 4.2371 - acc: 0.07 - ETA: 35s - loss: 4.2384 - acc: 0.07 - ETA: 34s - loss: 4.2373 - acc: 0.07 - ETA: 34s - loss: 4.2364 - acc: 0.07 - ETA: 34s - loss: 4.2414 - acc: 0.07 - ETA: 34s - loss: 4.2418 - acc: 0.07 - ETA: 34s - loss: 4.2411 - acc: 0.07 - ETA: 33s - loss: 4.2426 - acc: 0.07 - ETA: 33s - loss: 4.2423 - acc: 0.07 - ETA: 33s - loss: 4.2415 - acc: 0.07 - ETA: 33s - loss: 4.2419 - acc: 0.07 - ETA: 33s - loss: 4.2425 - acc: 0.07 - ETA: 32s - loss: 4.2426 - acc: 0.07 - ETA: 32s - loss: 4.2385 - acc: 0.07 - ETA: 32s - loss: 4.2395 - acc: 0.07 - ETA: 32s - loss: 4.2379 - acc: 0.07 - ETA: 31s - loss: 4.2370 - acc: 0.07 - ETA: 31s - loss: 4.2366 - acc: 0.07 - ETA: 31s - loss: 4.2381 - acc: 0.07 - ETA: 31s - loss: 4.2370 - acc: 0.07 - ETA: 31s - loss: 4.2380 - acc: 0.07 - ETA: 30s - loss: 4.2374 - acc: 0.07 - ETA: 30s - loss: 4.2376 - acc: 0.07 - ETA: 30s - loss: 4.2386 - acc: 0.07 - ETA: 30s - loss: 4.2390 - acc: 0.07 - ETA: 30s - loss: 4.2381 - acc: 0.07 - ETA: 29s - loss: 4.2384 - acc: 0.07 - ETA: 29s - loss: 4.2378 - acc: 0.07 - ETA: 29s - loss: 4.2375 - acc: 0.07 - ETA: 29s - loss: 4.2378 - acc: 0.07 - ETA: 29s - loss: 4.2364 - acc: 0.07 - ETA: 28s - loss: 4.2363 - acc: 0.07 - ETA: 28s - loss: 4.2356 - acc: 0.07 - ETA: 28s - loss: 4.2357 - acc: 0.07 - ETA: 28s - loss: 4.2340 - acc: 0.07 - ETA: 27s - loss: 4.2342 - acc: 0.07 - ETA: 27s - loss: 4.2322 - acc: 0.07 - ETA: 27s - loss: 4.2321 - acc: 0.07 - ETA: 27s - loss: 4.2316 - acc: 0.07 - ETA: 27s - loss: 4.2320 - acc: 0.07 - ETA: 26s - loss: 4.2312 - acc: 0.07 - ETA: 26s - loss: 4.2329 - acc: 0.07 - ETA: 26s - loss: 4.2337 - acc: 0.07 - ETA: 26s - loss: 4.2328 - acc: 0.07 - ETA: 26s - loss: 4.2328 - acc: 0.07 - ETA: 25s - loss: 4.2319 - acc: 0.07 - ETA: 25s - loss: 4.2324 - acc: 0.07 - ETA: 25s - loss: 4.2323 - acc: 0.07 - ETA: 25s - loss: 4.2314 - acc: 0.07 - ETA: 25s - loss: 4.2324 - acc: 0.0767"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6660/6680 [============================>.] - ETA: 24s - loss: 4.2331 - acc: 0.07 - ETA: 24s - loss: 4.2324 - acc: 0.07 - ETA: 24s - loss: 4.2307 - acc: 0.07 - ETA: 24s - loss: 4.2290 - acc: 0.07 - ETA: 23s - loss: 4.2291 - acc: 0.07 - ETA: 23s - loss: 4.2293 - acc: 0.07 - ETA: 23s - loss: 4.2295 - acc: 0.07 - ETA: 23s - loss: 4.2319 - acc: 0.07 - ETA: 23s - loss: 4.2330 - acc: 0.07 - ETA: 22s - loss: 4.2351 - acc: 0.07 - ETA: 22s - loss: 4.2364 - acc: 0.07 - ETA: 22s - loss: 4.2359 - acc: 0.07 - ETA: 22s - loss: 4.2351 - acc: 0.07 - ETA: 22s - loss: 4.2355 - acc: 0.07 - ETA: 21s - loss: 4.2355 - acc: 0.07 - ETA: 21s - loss: 4.2349 - acc: 0.07 - ETA: 21s - loss: 4.2344 - acc: 0.07 - ETA: 21s - loss: 4.2359 - acc: 0.07 - ETA: 21s - loss: 4.2369 - acc: 0.07 - ETA: 20s - loss: 4.2365 - acc: 0.07 - ETA: 20s - loss: 4.2340 - acc: 0.07 - ETA: 20s - loss: 4.2345 - acc: 0.07 - ETA: 20s - loss: 4.2334 - acc: 0.07 - ETA: 19s - loss: 4.2368 - acc: 0.07 - ETA: 19s - loss: 4.2367 - acc: 0.07 - ETA: 19s - loss: 4.2358 - acc: 0.07 - ETA: 19s - loss: 4.2361 - acc: 0.07 - ETA: 19s - loss: 4.2358 - acc: 0.07 - ETA: 18s - loss: 4.2353 - acc: 0.07 - ETA: 18s - loss: 4.2358 - acc: 0.07 - ETA: 18s - loss: 4.2356 - acc: 0.07 - ETA: 18s - loss: 4.2364 - acc: 0.07 - ETA: 18s - loss: 4.2361 - acc: 0.07 - ETA: 17s - loss: 4.2361 - acc: 0.07 - ETA: 17s - loss: 4.2348 - acc: 0.07 - ETA: 17s - loss: 4.2340 - acc: 0.07 - ETA: 17s - loss: 4.2339 - acc: 0.07 - ETA: 17s - loss: 4.2347 - acc: 0.07 - ETA: 16s - loss: 4.2336 - acc: 0.07 - ETA: 16s - loss: 4.2348 - acc: 0.07 - ETA: 16s - loss: 4.2344 - acc: 0.07 - ETA: 16s - loss: 4.2345 - acc: 0.07 - ETA: 15s - loss: 4.2334 - acc: 0.07 - ETA: 15s - loss: 4.2350 - acc: 0.07 - ETA: 15s - loss: 4.2342 - acc: 0.07 - ETA: 15s - loss: 4.2346 - acc: 0.07 - ETA: 15s - loss: 4.2356 - acc: 0.07 - ETA: 14s - loss: 4.2348 - acc: 0.07 - ETA: 14s - loss: 4.2342 - acc: 0.07 - ETA: 14s - loss: 4.2366 - acc: 0.07 - ETA: 14s - loss: 4.2374 - acc: 0.07 - ETA: 14s - loss: 4.2383 - acc: 0.07 - ETA: 13s - loss: 4.2375 - acc: 0.07 - ETA: 13s - loss: 4.2388 - acc: 0.07 - ETA: 13s - loss: 4.2390 - acc: 0.07 - ETA: 13s - loss: 4.2385 - acc: 0.07 - ETA: 13s - loss: 4.2380 - acc: 0.07 - ETA: 12s - loss: 4.2392 - acc: 0.07 - ETA: 12s - loss: 4.2398 - acc: 0.07 - ETA: 12s - loss: 4.2403 - acc: 0.07 - ETA: 12s - loss: 4.2407 - acc: 0.07 - ETA: 11s - loss: 4.2410 - acc: 0.07 - ETA: 11s - loss: 4.2403 - acc: 0.07 - ETA: 11s - loss: 4.2393 - acc: 0.07 - ETA: 11s - loss: 4.2400 - acc: 0.07 - ETA: 11s - loss: 4.2391 - acc: 0.07 - ETA: 10s - loss: 4.2396 - acc: 0.07 - ETA: 10s - loss: 4.2402 - acc: 0.07 - ETA: 10s - loss: 4.2404 - acc: 0.07 - ETA: 10s - loss: 4.2408 - acc: 0.07 - ETA: 10s - loss: 4.2395 - acc: 0.07 - ETA: 9s - loss: 4.2404 - acc: 0.0782 - ETA: 9s - loss: 4.2408 - acc: 0.078 - ETA: 9s - loss: 4.2407 - acc: 0.078 - ETA: 9s - loss: 4.2402 - acc: 0.077 - ETA: 9s - loss: 4.2399 - acc: 0.078 - ETA: 8s - loss: 4.2386 - acc: 0.078 - ETA: 8s - loss: 4.2398 - acc: 0.079 - ETA: 8s - loss: 4.2390 - acc: 0.079 - ETA: 8s - loss: 4.2384 - acc: 0.079 - ETA: 7s - loss: 4.2409 - acc: 0.079 - ETA: 7s - loss: 4.2407 - acc: 0.079 - ETA: 7s - loss: 4.2414 - acc: 0.079 - ETA: 7s - loss: 4.2404 - acc: 0.079 - ETA: 7s - loss: 4.2409 - acc: 0.079 - ETA: 6s - loss: 4.2393 - acc: 0.079 - ETA: 6s - loss: 4.2384 - acc: 0.079 - ETA: 6s - loss: 4.2383 - acc: 0.079 - ETA: 6s - loss: 4.2386 - acc: 0.079 - ETA: 6s - loss: 4.2371 - acc: 0.079 - ETA: 5s - loss: 4.2366 - acc: 0.079 - ETA: 5s - loss: 4.2371 - acc: 0.079 - ETA: 5s - loss: 4.2378 - acc: 0.079 - ETA: 5s - loss: 4.2375 - acc: 0.079 - ETA: 5s - loss: 4.2378 - acc: 0.079 - ETA: 4s - loss: 4.2381 - acc: 0.079 - ETA: 4s - loss: 4.2381 - acc: 0.079 - ETA: 4s - loss: 4.2386 - acc: 0.078 - ETA: 4s - loss: 4.2385 - acc: 0.078 - ETA: 3s - loss: 4.2386 - acc: 0.078 - ETA: 3s - loss: 4.2390 - acc: 0.078 - ETA: 3s - loss: 4.2393 - acc: 0.078 - ETA: 3s - loss: 4.2401 - acc: 0.078 - ETA: 3s - loss: 4.2400 - acc: 0.077 - ETA: 2s - loss: 4.2401 - acc: 0.077 - ETA: 2s - loss: 4.2389 - acc: 0.077 - ETA: 2s - loss: 4.2395 - acc: 0.077 - ETA: 2s - loss: 4.2399 - acc: 0.077 - ETA: 2s - loss: 4.2395 - acc: 0.077 - ETA: 1s - loss: 4.2405 - acc: 0.077 - ETA: 1s - loss: 4.2401 - acc: 0.077 - ETA: 1s - loss: 4.2399 - acc: 0.077 - ETA: 1s - loss: 4.2397 - acc: 0.077 - ETA: 1s - loss: 4.2412 - acc: 0.076 - ETA: 0s - loss: 4.2405 - acc: 0.076 - ETA: 0s - loss: 4.2392 - acc: 0.077 - ETA: 0s - loss: 4.2397 - acc: 0.077 - ETA: 0s - loss: 4.2384 - acc: 0.0772Epoch 00021: val_loss did not improve\n",
      "6680/6680 [==============================] - 72s - loss: 4.2383 - acc: 0.0771 - val_loss: 4.3425 - val_acc: 0.0611\n",
      "Epoch 23/32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4300/6680 [==================>...........] - ETA: 69s - loss: 4.4833 - acc: 0.0000e+ - ETA: 67s - loss: 4.2025 - acc: 0.0250   - ETA: 69s - loss: 4.2116 - acc: 0.03 - ETA: 69s - loss: 4.2689 - acc: 0.06 - ETA: 69s - loss: 4.2048 - acc: 0.06 - ETA: 68s - loss: 4.2991 - acc: 0.05 - ETA: 68s - loss: 4.3426 - acc: 0.04 - ETA: 68s - loss: 4.3538 - acc: 0.03 - ETA: 68s - loss: 4.3606 - acc: 0.04 - ETA: 67s - loss: 4.3206 - acc: 0.05 - ETA: 67s - loss: 4.3052 - acc: 0.05 - ETA: 67s - loss: 4.2901 - acc: 0.06 - ETA: 67s - loss: 4.3014 - acc: 0.06 - ETA: 67s - loss: 4.2975 - acc: 0.07 - ETA: 66s - loss: 4.3095 - acc: 0.07 - ETA: 66s - loss: 4.2932 - acc: 0.07 - ETA: 66s - loss: 4.2759 - acc: 0.07 - ETA: 66s - loss: 4.2795 - acc: 0.07 - ETA: 66s - loss: 4.2781 - acc: 0.07 - ETA: 65s - loss: 4.2773 - acc: 0.07 - ETA: 65s - loss: 4.2734 - acc: 0.08 - ETA: 65s - loss: 4.2790 - acc: 0.08 - ETA: 65s - loss: 4.2865 - acc: 0.08 - ETA: 65s - loss: 4.2675 - acc: 0.08 - ETA: 64s - loss: 4.2804 - acc: 0.08 - ETA: 64s - loss: 4.2726 - acc: 0.07 - ETA: 64s - loss: 4.2770 - acc: 0.07 - ETA: 64s - loss: 4.2766 - acc: 0.07 - ETA: 64s - loss: 4.2748 - acc: 0.07 - ETA: 63s - loss: 4.2827 - acc: 0.07 - ETA: 63s - loss: 4.2841 - acc: 0.07 - ETA: 63s - loss: 4.2949 - acc: 0.07 - ETA: 63s - loss: 4.2983 - acc: 0.07 - ETA: 63s - loss: 4.2876 - acc: 0.07 - ETA: 62s - loss: 4.2901 - acc: 0.07 - ETA: 62s - loss: 4.2873 - acc: 0.07 - ETA: 62s - loss: 4.2830 - acc: 0.07 - ETA: 62s - loss: 4.2809 - acc: 0.07 - ETA: 61s - loss: 4.2844 - acc: 0.07 - ETA: 61s - loss: 4.2786 - acc: 0.07 - ETA: 61s - loss: 4.2736 - acc: 0.07 - ETA: 61s - loss: 4.2721 - acc: 0.07 - ETA: 61s - loss: 4.2747 - acc: 0.07 - ETA: 60s - loss: 4.2720 - acc: 0.07 - ETA: 60s - loss: 4.2757 - acc: 0.07 - ETA: 60s - loss: 4.2760 - acc: 0.07 - ETA: 60s - loss: 4.2734 - acc: 0.07 - ETA: 59s - loss: 4.2728 - acc: 0.07 - ETA: 59s - loss: 4.2683 - acc: 0.07 - ETA: 59s - loss: 4.2618 - acc: 0.07 - ETA: 59s - loss: 4.2581 - acc: 0.07 - ETA: 59s - loss: 4.2519 - acc: 0.07 - ETA: 58s - loss: 4.2543 - acc: 0.07 - ETA: 58s - loss: 4.2461 - acc: 0.07 - ETA: 58s - loss: 4.2401 - acc: 0.07 - ETA: 58s - loss: 4.2395 - acc: 0.07 - ETA: 58s - loss: 4.2436 - acc: 0.07 - ETA: 57s - loss: 4.2440 - acc: 0.07 - ETA: 57s - loss: 4.2379 - acc: 0.07 - ETA: 57s - loss: 4.2389 - acc: 0.07 - ETA: 57s - loss: 4.2335 - acc: 0.07 - ETA: 56s - loss: 4.2375 - acc: 0.07 - ETA: 56s - loss: 4.2371 - acc: 0.07 - ETA: 56s - loss: 4.2384 - acc: 0.07 - ETA: 56s - loss: 4.2371 - acc: 0.07 - ETA: 56s - loss: 4.2361 - acc: 0.07 - ETA: 55s - loss: 4.2378 - acc: 0.07 - ETA: 55s - loss: 4.2358 - acc: 0.07 - ETA: 55s - loss: 4.2379 - acc: 0.07 - ETA: 55s - loss: 4.2419 - acc: 0.07 - ETA: 55s - loss: 4.2414 - acc: 0.07 - ETA: 54s - loss: 4.2418 - acc: 0.07 - ETA: 54s - loss: 4.2381 - acc: 0.07 - ETA: 54s - loss: 4.2397 - acc: 0.07 - ETA: 54s - loss: 4.2347 - acc: 0.07 - ETA: 54s - loss: 4.2302 - acc: 0.07 - ETA: 53s - loss: 4.2307 - acc: 0.07 - ETA: 53s - loss: 4.2329 - acc: 0.07 - ETA: 53s - loss: 4.2336 - acc: 0.07 - ETA: 53s - loss: 4.2324 - acc: 0.07 - ETA: 53s - loss: 4.2286 - acc: 0.07 - ETA: 52s - loss: 4.2244 - acc: 0.07 - ETA: 52s - loss: 4.2281 - acc: 0.07 - ETA: 52s - loss: 4.2302 - acc: 0.07 - ETA: 52s - loss: 4.2313 - acc: 0.07 - ETA: 51s - loss: 4.2294 - acc: 0.07 - ETA: 51s - loss: 4.2301 - acc: 0.07 - ETA: 51s - loss: 4.2349 - acc: 0.07 - ETA: 51s - loss: 4.2336 - acc: 0.07 - ETA: 51s - loss: 4.2372 - acc: 0.07 - ETA: 50s - loss: 4.2369 - acc: 0.07 - ETA: 50s - loss: 4.2360 - acc: 0.07 - ETA: 50s - loss: 4.2430 - acc: 0.07 - ETA: 50s - loss: 4.2443 - acc: 0.07 - ETA: 50s - loss: 4.2413 - acc: 0.07 - ETA: 49s - loss: 4.2393 - acc: 0.07 - ETA: 49s - loss: 4.2410 - acc: 0.07 - ETA: 49s - loss: 4.2392 - acc: 0.07 - ETA: 49s - loss: 4.2428 - acc: 0.07 - ETA: 49s - loss: 4.2477 - acc: 0.07 - ETA: 48s - loss: 4.2481 - acc: 0.07 - ETA: 48s - loss: 4.2499 - acc: 0.07 - ETA: 48s - loss: 4.2468 - acc: 0.07 - ETA: 48s - loss: 4.2494 - acc: 0.07 - ETA: 48s - loss: 4.2503 - acc: 0.07 - ETA: 47s - loss: 4.2480 - acc: 0.07 - ETA: 47s - loss: 4.2482 - acc: 0.07 - ETA: 47s - loss: 4.2480 - acc: 0.07 - ETA: 47s - loss: 4.2480 - acc: 0.07 - ETA: 46s - loss: 4.2502 - acc: 0.07 - ETA: 46s - loss: 4.2491 - acc: 0.07 - ETA: 46s - loss: 4.2493 - acc: 0.07 - ETA: 46s - loss: 4.2496 - acc: 0.07 - ETA: 46s - loss: 4.2498 - acc: 0.07 - ETA: 45s - loss: 4.2489 - acc: 0.07 - ETA: 45s - loss: 4.2476 - acc: 0.07 - ETA: 45s - loss: 4.2489 - acc: 0.07 - ETA: 45s - loss: 4.2460 - acc: 0.07 - ETA: 45s - loss: 4.2484 - acc: 0.07 - ETA: 44s - loss: 4.2508 - acc: 0.07 - ETA: 44s - loss: 4.2490 - acc: 0.07 - ETA: 44s - loss: 4.2493 - acc: 0.07 - ETA: 44s - loss: 4.2455 - acc: 0.07 - ETA: 44s - loss: 4.2469 - acc: 0.07 - ETA: 43s - loss: 4.2469 - acc: 0.07 - ETA: 43s - loss: 4.2451 - acc: 0.07 - ETA: 43s - loss: 4.2449 - acc: 0.07 - ETA: 43s - loss: 4.2454 - acc: 0.07 - ETA: 42s - loss: 4.2438 - acc: 0.07 - ETA: 42s - loss: 4.2433 - acc: 0.07 - ETA: 42s - loss: 4.2446 - acc: 0.07 - ETA: 42s - loss: 4.2423 - acc: 0.07 - ETA: 42s - loss: 4.2403 - acc: 0.07 - ETA: 41s - loss: 4.2411 - acc: 0.07 - ETA: 41s - loss: 4.2398 - acc: 0.07 - ETA: 41s - loss: 4.2423 - acc: 0.07 - ETA: 41s - loss: 4.2416 - acc: 0.07 - ETA: 41s - loss: 4.2393 - acc: 0.07 - ETA: 40s - loss: 4.2397 - acc: 0.07 - ETA: 40s - loss: 4.2383 - acc: 0.07 - ETA: 40s - loss: 4.2357 - acc: 0.07 - ETA: 40s - loss: 4.2416 - acc: 0.07 - ETA: 40s - loss: 4.2425 - acc: 0.07 - ETA: 39s - loss: 4.2424 - acc: 0.07 - ETA: 39s - loss: 4.2408 - acc: 0.07 - ETA: 39s - loss: 4.2401 - acc: 0.07 - ETA: 39s - loss: 4.2391 - acc: 0.07 - ETA: 39s - loss: 4.2375 - acc: 0.07 - ETA: 38s - loss: 4.2390 - acc: 0.07 - ETA: 38s - loss: 4.2365 - acc: 0.07 - ETA: 38s - loss: 4.2379 - acc: 0.07 - ETA: 38s - loss: 4.2357 - acc: 0.07 - ETA: 37s - loss: 4.2338 - acc: 0.07 - ETA: 37s - loss: 4.2353 - acc: 0.07 - ETA: 37s - loss: 4.2362 - acc: 0.07 - ETA: 37s - loss: 4.2384 - acc: 0.07 - ETA: 37s - loss: 4.2399 - acc: 0.07 - ETA: 36s - loss: 4.2429 - acc: 0.07 - ETA: 36s - loss: 4.2411 - acc: 0.07 - ETA: 36s - loss: 4.2413 - acc: 0.07 - ETA: 36s - loss: 4.2386 - acc: 0.07 - ETA: 36s - loss: 4.2396 - acc: 0.07 - ETA: 35s - loss: 4.2418 - acc: 0.07 - ETA: 35s - loss: 4.2428 - acc: 0.07 - ETA: 35s - loss: 4.2420 - acc: 0.07 - ETA: 35s - loss: 4.2408 - acc: 0.07 - ETA: 35s - loss: 4.2397 - acc: 0.07 - ETA: 34s - loss: 4.2392 - acc: 0.07 - ETA: 34s - loss: 4.2394 - acc: 0.07 - ETA: 34s - loss: 4.2378 - acc: 0.07 - ETA: 34s - loss: 4.2371 - acc: 0.07 - ETA: 33s - loss: 4.2393 - acc: 0.07 - ETA: 33s - loss: 4.2380 - acc: 0.07 - ETA: 33s - loss: 4.2406 - acc: 0.07 - ETA: 33s - loss: 4.2393 - acc: 0.07 - ETA: 33s - loss: 4.2385 - acc: 0.07 - ETA: 32s - loss: 4.2372 - acc: 0.07 - ETA: 32s - loss: 4.2380 - acc: 0.07 - ETA: 32s - loss: 4.2369 - acc: 0.07 - ETA: 32s - loss: 4.2364 - acc: 0.07 - ETA: 32s - loss: 4.2375 - acc: 0.07 - ETA: 31s - loss: 4.2374 - acc: 0.07 - ETA: 31s - loss: 4.2364 - acc: 0.07 - ETA: 31s - loss: 4.2361 - acc: 0.07 - ETA: 31s - loss: 4.2370 - acc: 0.07 - ETA: 31s - loss: 4.2367 - acc: 0.07 - ETA: 30s - loss: 4.2352 - acc: 0.07 - ETA: 30s - loss: 4.2343 - acc: 0.07 - ETA: 30s - loss: 4.2336 - acc: 0.07 - ETA: 30s - loss: 4.2339 - acc: 0.07 - ETA: 29s - loss: 4.2363 - acc: 0.07 - ETA: 29s - loss: 4.2356 - acc: 0.07 - ETA: 29s - loss: 4.2361 - acc: 0.07 - ETA: 29s - loss: 4.2368 - acc: 0.07 - ETA: 29s - loss: 4.2370 - acc: 0.07 - ETA: 28s - loss: 4.2372 - acc: 0.07 - ETA: 28s - loss: 4.2372 - acc: 0.07 - ETA: 28s - loss: 4.2376 - acc: 0.07 - ETA: 28s - loss: 4.2361 - acc: 0.07 - ETA: 28s - loss: 4.2346 - acc: 0.07 - ETA: 27s - loss: 4.2338 - acc: 0.07 - ETA: 27s - loss: 4.2324 - acc: 0.07 - ETA: 27s - loss: 4.2351 - acc: 0.07 - ETA: 27s - loss: 4.2356 - acc: 0.07 - ETA: 27s - loss: 4.2345 - acc: 0.07 - ETA: 26s - loss: 4.2352 - acc: 0.07 - ETA: 26s - loss: 4.2358 - acc: 0.07 - ETA: 26s - loss: 4.2360 - acc: 0.07 - ETA: 26s - loss: 4.2358 - acc: 0.07 - ETA: 26s - loss: 4.2367 - acc: 0.07 - ETA: 25s - loss: 4.2354 - acc: 0.07 - ETA: 25s - loss: 4.2361 - acc: 0.07 - ETA: 25s - loss: 4.2364 - acc: 0.07 - ETA: 25s - loss: 4.2371 - acc: 0.07 - ETA: 24s - loss: 4.2368 - acc: 0.0737"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6660/6680 [============================>.] - ETA: 24s - loss: 4.2363 - acc: 0.07 - ETA: 24s - loss: 4.2354 - acc: 0.07 - ETA: 24s - loss: 4.2392 - acc: 0.07 - ETA: 24s - loss: 4.2405 - acc: 0.07 - ETA: 23s - loss: 4.2398 - acc: 0.07 - ETA: 23s - loss: 4.2410 - acc: 0.07 - ETA: 23s - loss: 4.2414 - acc: 0.07 - ETA: 23s - loss: 4.2410 - acc: 0.07 - ETA: 23s - loss: 4.2405 - acc: 0.07 - ETA: 22s - loss: 4.2405 - acc: 0.07 - ETA: 22s - loss: 4.2414 - acc: 0.07 - ETA: 22s - loss: 4.2405 - acc: 0.07 - ETA: 22s - loss: 4.2397 - acc: 0.07 - ETA: 22s - loss: 4.2401 - acc: 0.07 - ETA: 21s - loss: 4.2386 - acc: 0.07 - ETA: 21s - loss: 4.2351 - acc: 0.07 - ETA: 21s - loss: 4.2337 - acc: 0.07 - ETA: 21s - loss: 4.2342 - acc: 0.07 - ETA: 20s - loss: 4.2340 - acc: 0.07 - ETA: 20s - loss: 4.2341 - acc: 0.07 - ETA: 20s - loss: 4.2350 - acc: 0.07 - ETA: 20s - loss: 4.2363 - acc: 0.07 - ETA: 20s - loss: 4.2348 - acc: 0.07 - ETA: 19s - loss: 4.2350 - acc: 0.07 - ETA: 19s - loss: 4.2365 - acc: 0.07 - ETA: 19s - loss: 4.2360 - acc: 0.07 - ETA: 19s - loss: 4.2347 - acc: 0.07 - ETA: 19s - loss: 4.2341 - acc: 0.07 - ETA: 18s - loss: 4.2336 - acc: 0.07 - ETA: 18s - loss: 4.2335 - acc: 0.07 - ETA: 18s - loss: 4.2320 - acc: 0.07 - ETA: 18s - loss: 4.2336 - acc: 0.07 - ETA: 18s - loss: 4.2336 - acc: 0.07 - ETA: 17s - loss: 4.2330 - acc: 0.07 - ETA: 17s - loss: 4.2338 - acc: 0.07 - ETA: 17s - loss: 4.2345 - acc: 0.07 - ETA: 17s - loss: 4.2349 - acc: 0.07 - ETA: 16s - loss: 4.2347 - acc: 0.07 - ETA: 16s - loss: 4.2343 - acc: 0.07 - ETA: 16s - loss: 4.2339 - acc: 0.07 - ETA: 16s - loss: 4.2333 - acc: 0.07 - ETA: 16s - loss: 4.2335 - acc: 0.07 - ETA: 15s - loss: 4.2323 - acc: 0.07 - ETA: 15s - loss: 4.2311 - acc: 0.07 - ETA: 15s - loss: 4.2309 - acc: 0.07 - ETA: 15s - loss: 4.2310 - acc: 0.07 - ETA: 15s - loss: 4.2297 - acc: 0.07 - ETA: 14s - loss: 4.2276 - acc: 0.07 - ETA: 14s - loss: 4.2270 - acc: 0.07 - ETA: 14s - loss: 4.2272 - acc: 0.07 - ETA: 14s - loss: 4.2278 - acc: 0.07 - ETA: 14s - loss: 4.2277 - acc: 0.07 - ETA: 13s - loss: 4.2266 - acc: 0.07 - ETA: 13s - loss: 4.2270 - acc: 0.07 - ETA: 13s - loss: 4.2258 - acc: 0.07 - ETA: 13s - loss: 4.2258 - acc: 0.07 - ETA: 13s - loss: 4.2266 - acc: 0.07 - ETA: 12s - loss: 4.2267 - acc: 0.07 - ETA: 12s - loss: 4.2279 - acc: 0.07 - ETA: 12s - loss: 4.2281 - acc: 0.07 - ETA: 12s - loss: 4.2277 - acc: 0.07 - ETA: 11s - loss: 4.2269 - acc: 0.07 - ETA: 11s - loss: 4.2261 - acc: 0.07 - ETA: 11s - loss: 4.2244 - acc: 0.07 - ETA: 11s - loss: 4.2252 - acc: 0.07 - ETA: 11s - loss: 4.2256 - acc: 0.07 - ETA: 10s - loss: 4.2251 - acc: 0.07 - ETA: 10s - loss: 4.2244 - acc: 0.07 - ETA: 10s - loss: 4.2234 - acc: 0.07 - ETA: 10s - loss: 4.2225 - acc: 0.07 - ETA: 10s - loss: 4.2221 - acc: 0.07 - ETA: 9s - loss: 4.2217 - acc: 0.0730 - ETA: 9s - loss: 4.2211 - acc: 0.073 - ETA: 9s - loss: 4.2198 - acc: 0.072 - ETA: 9s - loss: 4.2208 - acc: 0.072 - ETA: 9s - loss: 4.2207 - acc: 0.072 - ETA: 8s - loss: 4.2209 - acc: 0.072 - ETA: 8s - loss: 4.2206 - acc: 0.072 - ETA: 8s - loss: 4.2218 - acc: 0.072 - ETA: 8s - loss: 4.2211 - acc: 0.072 - ETA: 7s - loss: 4.2210 - acc: 0.072 - ETA: 7s - loss: 4.2207 - acc: 0.072 - ETA: 7s - loss: 4.2196 - acc: 0.073 - ETA: 7s - loss: 4.2218 - acc: 0.073 - ETA: 7s - loss: 4.2215 - acc: 0.073 - ETA: 6s - loss: 4.2240 - acc: 0.072 - ETA: 6s - loss: 4.2235 - acc: 0.072 - ETA: 6s - loss: 4.2242 - acc: 0.072 - ETA: 6s - loss: 4.2232 - acc: 0.073 - ETA: 6s - loss: 4.2223 - acc: 0.073 - ETA: 5s - loss: 4.2227 - acc: 0.072 - ETA: 5s - loss: 4.2217 - acc: 0.073 - ETA: 5s - loss: 4.2216 - acc: 0.073 - ETA: 5s - loss: 4.2202 - acc: 0.073 - ETA: 5s - loss: 4.2197 - acc: 0.072 - ETA: 4s - loss: 4.2205 - acc: 0.072 - ETA: 4s - loss: 4.2205 - acc: 0.072 - ETA: 4s - loss: 4.2210 - acc: 0.073 - ETA: 4s - loss: 4.2208 - acc: 0.072 - ETA: 3s - loss: 4.2209 - acc: 0.073 - ETA: 3s - loss: 4.2202 - acc: 0.072 - ETA: 3s - loss: 4.2195 - acc: 0.073 - ETA: 3s - loss: 4.2177 - acc: 0.073 - ETA: 3s - loss: 4.2172 - acc: 0.073 - ETA: 2s - loss: 4.2172 - acc: 0.073 - ETA: 2s - loss: 4.2168 - acc: 0.073 - ETA: 2s - loss: 4.2163 - acc: 0.073 - ETA: 2s - loss: 4.2178 - acc: 0.073 - ETA: 2s - loss: 4.2186 - acc: 0.073 - ETA: 1s - loss: 4.2195 - acc: 0.073 - ETA: 1s - loss: 4.2197 - acc: 0.073 - ETA: 1s - loss: 4.2204 - acc: 0.073 - ETA: 1s - loss: 4.2196 - acc: 0.073 - ETA: 1s - loss: 4.2194 - acc: 0.073 - ETA: 0s - loss: 4.2196 - acc: 0.073 - ETA: 0s - loss: 4.2202 - acc: 0.073 - ETA: 0s - loss: 4.2201 - acc: 0.073 - ETA: 0s - loss: 4.2205 - acc: 0.0734Epoch 00022: val_loss improved from 4.32070 to 4.27061, saving model to saved_models/weights.best.from_scratch.hdf5\n",
      "6680/6680 [==============================] - 72s - loss: 4.2186 - acc: 0.0738 - val_loss: 4.2706 - val_acc: 0.0683\n",
      "Epoch 24/32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4300/6680 [==================>...........] - ETA: 67s - loss: 3.9800 - acc: 0.05 - ETA: 67s - loss: 4.0598 - acc: 0.05 - ETA: 68s - loss: 4.0405 - acc: 0.10 - ETA: 68s - loss: 4.0663 - acc: 0.08 - ETA: 68s - loss: 4.0545 - acc: 0.09 - ETA: 68s - loss: 4.0415 - acc: 0.08 - ETA: 67s - loss: 4.0396 - acc: 0.07 - ETA: 68s - loss: 4.0846 - acc: 0.08 - ETA: 67s - loss: 4.0990 - acc: 0.07 - ETA: 67s - loss: 4.0686 - acc: 0.07 - ETA: 67s - loss: 4.0819 - acc: 0.07 - ETA: 67s - loss: 4.1092 - acc: 0.07 - ETA: 67s - loss: 4.0871 - acc: 0.07 - ETA: 67s - loss: 4.0988 - acc: 0.06 - ETA: 66s - loss: 4.1357 - acc: 0.06 - ETA: 66s - loss: 4.1602 - acc: 0.06 - ETA: 66s - loss: 4.1375 - acc: 0.07 - ETA: 66s - loss: 4.1463 - acc: 0.07 - ETA: 65s - loss: 4.1385 - acc: 0.07 - ETA: 65s - loss: 4.1405 - acc: 0.07 - ETA: 65s - loss: 4.1385 - acc: 0.06 - ETA: 65s - loss: 4.1462 - acc: 0.06 - ETA: 65s - loss: 4.1314 - acc: 0.06 - ETA: 64s - loss: 4.1331 - acc: 0.06 - ETA: 64s - loss: 4.1301 - acc: 0.06 - ETA: 64s - loss: 4.1369 - acc: 0.06 - ETA: 64s - loss: 4.1382 - acc: 0.06 - ETA: 64s - loss: 4.1384 - acc: 0.05 - ETA: 64s - loss: 4.1326 - acc: 0.06 - ETA: 63s - loss: 4.1414 - acc: 0.06 - ETA: 63s - loss: 4.1276 - acc: 0.06 - ETA: 63s - loss: 4.1171 - acc: 0.06 - ETA: 63s - loss: 4.1237 - acc: 0.06 - ETA: 62s - loss: 4.1314 - acc: 0.06 - ETA: 62s - loss: 4.1191 - acc: 0.06 - ETA: 62s - loss: 4.1320 - acc: 0.06 - ETA: 62s - loss: 4.1316 - acc: 0.06 - ETA: 62s - loss: 4.1367 - acc: 0.06 - ETA: 61s - loss: 4.1439 - acc: 0.06 - ETA: 61s - loss: 4.1436 - acc: 0.06 - ETA: 61s - loss: 4.1381 - acc: 0.06 - ETA: 61s - loss: 4.1477 - acc: 0.06 - ETA: 61s - loss: 4.1438 - acc: 0.06 - ETA: 60s - loss: 4.1641 - acc: 0.06 - ETA: 60s - loss: 4.1582 - acc: 0.07 - ETA: 60s - loss: 4.1646 - acc: 0.06 - ETA: 60s - loss: 4.1614 - acc: 0.06 - ETA: 60s - loss: 4.1628 - acc: 0.06 - ETA: 59s - loss: 4.1584 - acc: 0.06 - ETA: 59s - loss: 4.1525 - acc: 0.06 - ETA: 59s - loss: 4.1632 - acc: 0.06 - ETA: 59s - loss: 4.1715 - acc: 0.06 - ETA: 58s - loss: 4.1666 - acc: 0.06 - ETA: 58s - loss: 4.1721 - acc: 0.06 - ETA: 58s - loss: 4.1744 - acc: 0.06 - ETA: 58s - loss: 4.1694 - acc: 0.06 - ETA: 58s - loss: 4.1679 - acc: 0.06 - ETA: 57s - loss: 4.1630 - acc: 0.06 - ETA: 57s - loss: 4.1651 - acc: 0.06 - ETA: 57s - loss: 4.1694 - acc: 0.06 - ETA: 57s - loss: 4.1636 - acc: 0.06 - ETA: 57s - loss: 4.1632 - acc: 0.06 - ETA: 56s - loss: 4.1603 - acc: 0.06 - ETA: 56s - loss: 4.1639 - acc: 0.06 - ETA: 56s - loss: 4.1641 - acc: 0.06 - ETA: 56s - loss: 4.1647 - acc: 0.06 - ETA: 56s - loss: 4.1614 - acc: 0.06 - ETA: 55s - loss: 4.1652 - acc: 0.06 - ETA: 55s - loss: 4.1673 - acc: 0.06 - ETA: 55s - loss: 4.1660 - acc: 0.06 - ETA: 55s - loss: 4.1687 - acc: 0.06 - ETA: 55s - loss: 4.1714 - acc: 0.06 - ETA: 54s - loss: 4.1681 - acc: 0.06 - ETA: 54s - loss: 4.1671 - acc: 0.06 - ETA: 54s - loss: 4.1634 - acc: 0.06 - ETA: 54s - loss: 4.1594 - acc: 0.06 - ETA: 54s - loss: 4.1599 - acc: 0.06 - ETA: 53s - loss: 4.1590 - acc: 0.06 - ETA: 53s - loss: 4.1539 - acc: 0.06 - ETA: 53s - loss: 4.1540 - acc: 0.06 - ETA: 53s - loss: 4.1527 - acc: 0.06 - ETA: 52s - loss: 4.1531 - acc: 0.06 - ETA: 52s - loss: 4.1510 - acc: 0.06 - ETA: 52s - loss: 4.1557 - acc: 0.06 - ETA: 52s - loss: 4.1575 - acc: 0.06 - ETA: 52s - loss: 4.1573 - acc: 0.06 - ETA: 51s - loss: 4.1598 - acc: 0.06 - ETA: 51s - loss: 4.1578 - acc: 0.06 - ETA: 51s - loss: 4.1580 - acc: 0.06 - ETA: 51s - loss: 4.1610 - acc: 0.06 - ETA: 51s - loss: 4.1571 - acc: 0.06 - ETA: 50s - loss: 4.1539 - acc: 0.06 - ETA: 50s - loss: 4.1549 - acc: 0.06 - ETA: 50s - loss: 4.1579 - acc: 0.06 - ETA: 50s - loss: 4.1592 - acc: 0.06 - ETA: 50s - loss: 4.1543 - acc: 0.06 - ETA: 49s - loss: 4.1572 - acc: 0.06 - ETA: 49s - loss: 4.1546 - acc: 0.06 - ETA: 49s - loss: 4.1537 - acc: 0.06 - ETA: 49s - loss: 4.1539 - acc: 0.06 - ETA: 49s - loss: 4.1581 - acc: 0.06 - ETA: 48s - loss: 4.1597 - acc: 0.06 - ETA: 48s - loss: 4.1643 - acc: 0.06 - ETA: 48s - loss: 4.1674 - acc: 0.06 - ETA: 48s - loss: 4.1631 - acc: 0.06 - ETA: 47s - loss: 4.1596 - acc: 0.06 - ETA: 47s - loss: 4.1572 - acc: 0.06 - ETA: 47s - loss: 4.1589 - acc: 0.07 - ETA: 47s - loss: 4.1581 - acc: 0.07 - ETA: 47s - loss: 4.1601 - acc: 0.07 - ETA: 46s - loss: 4.1605 - acc: 0.07 - ETA: 46s - loss: 4.1598 - acc: 0.07 - ETA: 46s - loss: 4.1574 - acc: 0.06 - ETA: 46s - loss: 4.1579 - acc: 0.07 - ETA: 46s - loss: 4.1571 - acc: 0.06 - ETA: 45s - loss: 4.1563 - acc: 0.06 - ETA: 45s - loss: 4.1556 - acc: 0.07 - ETA: 45s - loss: 4.1557 - acc: 0.07 - ETA: 45s - loss: 4.1573 - acc: 0.07 - ETA: 45s - loss: 4.1548 - acc: 0.07 - ETA: 44s - loss: 4.1570 - acc: 0.07 - ETA: 44s - loss: 4.1580 - acc: 0.07 - ETA: 44s - loss: 4.1582 - acc: 0.07 - ETA: 44s - loss: 4.1614 - acc: 0.07 - ETA: 44s - loss: 4.1635 - acc: 0.07 - ETA: 43s - loss: 4.1621 - acc: 0.07 - ETA: 43s - loss: 4.1627 - acc: 0.07 - ETA: 43s - loss: 4.1600 - acc: 0.07 - ETA: 43s - loss: 4.1615 - acc: 0.07 - ETA: 42s - loss: 4.1597 - acc: 0.07 - ETA: 42s - loss: 4.1594 - acc: 0.07 - ETA: 42s - loss: 4.1601 - acc: 0.07 - ETA: 42s - loss: 4.1594 - acc: 0.07 - ETA: 42s - loss: 4.1609 - acc: 0.07 - ETA: 41s - loss: 4.1615 - acc: 0.07 - ETA: 41s - loss: 4.1673 - acc: 0.07 - ETA: 41s - loss: 4.1677 - acc: 0.07 - ETA: 41s - loss: 4.1695 - acc: 0.07 - ETA: 41s - loss: 4.1707 - acc: 0.07 - ETA: 40s - loss: 4.1705 - acc: 0.07 - ETA: 40s - loss: 4.1723 - acc: 0.07 - ETA: 40s - loss: 4.1730 - acc: 0.07 - ETA: 40s - loss: 4.1721 - acc: 0.07 - ETA: 40s - loss: 4.1725 - acc: 0.07 - ETA: 39s - loss: 4.1725 - acc: 0.07 - ETA: 39s - loss: 4.1723 - acc: 0.07 - ETA: 39s - loss: 4.1742 - acc: 0.07 - ETA: 39s - loss: 4.1730 - acc: 0.07 - ETA: 39s - loss: 4.1747 - acc: 0.07 - ETA: 38s - loss: 4.1773 - acc: 0.07 - ETA: 38s - loss: 4.1761 - acc: 0.07 - ETA: 38s - loss: 4.1758 - acc: 0.07 - ETA: 38s - loss: 4.1757 - acc: 0.07 - ETA: 37s - loss: 4.1783 - acc: 0.07 - ETA: 37s - loss: 4.1783 - acc: 0.07 - ETA: 37s - loss: 4.1778 - acc: 0.07 - ETA: 37s - loss: 4.1772 - acc: 0.07 - ETA: 37s - loss: 4.1779 - acc: 0.07 - ETA: 36s - loss: 4.1775 - acc: 0.07 - ETA: 36s - loss: 4.1791 - acc: 0.07 - ETA: 36s - loss: 4.1777 - acc: 0.07 - ETA: 36s - loss: 4.1751 - acc: 0.07 - ETA: 36s - loss: 4.1747 - acc: 0.07 - ETA: 35s - loss: 4.1741 - acc: 0.07 - ETA: 35s - loss: 4.1741 - acc: 0.07 - ETA: 35s - loss: 4.1764 - acc: 0.07 - ETA: 35s - loss: 4.1767 - acc: 0.07 - ETA: 34s - loss: 4.1790 - acc: 0.07 - ETA: 34s - loss: 4.1787 - acc: 0.07 - ETA: 34s - loss: 4.1782 - acc: 0.07 - ETA: 34s - loss: 4.1776 - acc: 0.07 - ETA: 34s - loss: 4.1805 - acc: 0.07 - ETA: 33s - loss: 4.1801 - acc: 0.07 - ETA: 33s - loss: 4.1803 - acc: 0.07 - ETA: 33s - loss: 4.1828 - acc: 0.07 - ETA: 33s - loss: 4.1828 - acc: 0.07 - ETA: 33s - loss: 4.1812 - acc: 0.07 - ETA: 32s - loss: 4.1807 - acc: 0.07 - ETA: 32s - loss: 4.1809 - acc: 0.07 - ETA: 32s - loss: 4.1796 - acc: 0.07 - ETA: 32s - loss: 4.1803 - acc: 0.07 - ETA: 32s - loss: 4.1802 - acc: 0.07 - ETA: 31s - loss: 4.1802 - acc: 0.07 - ETA: 31s - loss: 4.1810 - acc: 0.07 - ETA: 31s - loss: 4.1810 - acc: 0.07 - ETA: 31s - loss: 4.1804 - acc: 0.07 - ETA: 31s - loss: 4.1797 - acc: 0.07 - ETA: 30s - loss: 4.1777 - acc: 0.07 - ETA: 30s - loss: 4.1779 - acc: 0.07 - ETA: 30s - loss: 4.1786 - acc: 0.07 - ETA: 30s - loss: 4.1802 - acc: 0.07 - ETA: 29s - loss: 4.1805 - acc: 0.07 - ETA: 29s - loss: 4.1790 - acc: 0.07 - ETA: 29s - loss: 4.1802 - acc: 0.07 - ETA: 29s - loss: 4.1801 - acc: 0.07 - ETA: 29s - loss: 4.1801 - acc: 0.07 - ETA: 28s - loss: 4.1808 - acc: 0.07 - ETA: 28s - loss: 4.1819 - acc: 0.07 - ETA: 28s - loss: 4.1812 - acc: 0.07 - ETA: 28s - loss: 4.1810 - acc: 0.07 - ETA: 28s - loss: 4.1819 - acc: 0.07 - ETA: 27s - loss: 4.1811 - acc: 0.07 - ETA: 27s - loss: 4.1831 - acc: 0.07 - ETA: 27s - loss: 4.1822 - acc: 0.07 - ETA: 27s - loss: 4.1838 - acc: 0.07 - ETA: 27s - loss: 4.1847 - acc: 0.07 - ETA: 26s - loss: 4.1852 - acc: 0.07 - ETA: 26s - loss: 4.1843 - acc: 0.07 - ETA: 26s - loss: 4.1864 - acc: 0.07 - ETA: 26s - loss: 4.1864 - acc: 0.07 - ETA: 25s - loss: 4.1868 - acc: 0.07 - ETA: 25s - loss: 4.1874 - acc: 0.07 - ETA: 25s - loss: 4.1875 - acc: 0.07 - ETA: 25s - loss: 4.1882 - acc: 0.07 - ETA: 25s - loss: 4.1875 - acc: 0.0730"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6660/6680 [============================>.] - ETA: 24s - loss: 4.1902 - acc: 0.07 - ETA: 24s - loss: 4.1909 - acc: 0.07 - ETA: 24s - loss: 4.1912 - acc: 0.07 - ETA: 24s - loss: 4.1898 - acc: 0.07 - ETA: 24s - loss: 4.1894 - acc: 0.07 - ETA: 23s - loss: 4.1882 - acc: 0.07 - ETA: 23s - loss: 4.1917 - acc: 0.07 - ETA: 23s - loss: 4.1952 - acc: 0.07 - ETA: 23s - loss: 4.1956 - acc: 0.07 - ETA: 22s - loss: 4.1965 - acc: 0.07 - ETA: 22s - loss: 4.1964 - acc: 0.07 - ETA: 22s - loss: 4.1958 - acc: 0.07 - ETA: 22s - loss: 4.1961 - acc: 0.07 - ETA: 22s - loss: 4.1961 - acc: 0.07 - ETA: 21s - loss: 4.1971 - acc: 0.07 - ETA: 21s - loss: 4.1966 - acc: 0.07 - ETA: 21s - loss: 4.1962 - acc: 0.07 - ETA: 21s - loss: 4.1953 - acc: 0.07 - ETA: 21s - loss: 4.1957 - acc: 0.07 - ETA: 20s - loss: 4.1963 - acc: 0.07 - ETA: 20s - loss: 4.1958 - acc: 0.07 - ETA: 20s - loss: 4.1953 - acc: 0.07 - ETA: 20s - loss: 4.1942 - acc: 0.07 - ETA: 20s - loss: 4.1939 - acc: 0.07 - ETA: 19s - loss: 4.1962 - acc: 0.07 - ETA: 19s - loss: 4.1956 - acc: 0.07 - ETA: 19s - loss: 4.1942 - acc: 0.07 - ETA: 19s - loss: 4.1953 - acc: 0.07 - ETA: 18s - loss: 4.1963 - acc: 0.07 - ETA: 18s - loss: 4.1960 - acc: 0.07 - ETA: 18s - loss: 4.1951 - acc: 0.07 - ETA: 18s - loss: 4.1967 - acc: 0.07 - ETA: 18s - loss: 4.1966 - acc: 0.07 - ETA: 17s - loss: 4.1952 - acc: 0.07 - ETA: 17s - loss: 4.1943 - acc: 0.07 - ETA: 17s - loss: 4.1930 - acc: 0.07 - ETA: 17s - loss: 4.1910 - acc: 0.07 - ETA: 17s - loss: 4.1936 - acc: 0.07 - ETA: 16s - loss: 4.1959 - acc: 0.07 - ETA: 16s - loss: 4.1975 - acc: 0.07 - ETA: 16s - loss: 4.1977 - acc: 0.07 - ETA: 16s - loss: 4.1968 - acc: 0.07 - ETA: 16s - loss: 4.1957 - acc: 0.07 - ETA: 15s - loss: 4.1963 - acc: 0.07 - ETA: 15s - loss: 4.1947 - acc: 0.07 - ETA: 15s - loss: 4.1959 - acc: 0.07 - ETA: 15s - loss: 4.1957 - acc: 0.07 - ETA: 14s - loss: 4.1962 - acc: 0.07 - ETA: 14s - loss: 4.1962 - acc: 0.07 - ETA: 14s - loss: 4.1952 - acc: 0.07 - ETA: 14s - loss: 4.1953 - acc: 0.07 - ETA: 14s - loss: 4.1953 - acc: 0.07 - ETA: 13s - loss: 4.1965 - acc: 0.07 - ETA: 13s - loss: 4.1988 - acc: 0.07 - ETA: 13s - loss: 4.1978 - acc: 0.07 - ETA: 13s - loss: 4.1968 - acc: 0.07 - ETA: 13s - loss: 4.1965 - acc: 0.07 - ETA: 12s - loss: 4.1971 - acc: 0.07 - ETA: 12s - loss: 4.1964 - acc: 0.07 - ETA: 12s - loss: 4.1946 - acc: 0.07 - ETA: 12s - loss: 4.1940 - acc: 0.07 - ETA: 12s - loss: 4.1951 - acc: 0.07 - ETA: 11s - loss: 4.1950 - acc: 0.07 - ETA: 11s - loss: 4.1951 - acc: 0.07 - ETA: 11s - loss: 4.1954 - acc: 0.07 - ETA: 11s - loss: 4.1934 - acc: 0.07 - ETA: 10s - loss: 4.1930 - acc: 0.07 - ETA: 10s - loss: 4.1929 - acc: 0.07 - ETA: 10s - loss: 4.1920 - acc: 0.07 - ETA: 10s - loss: 4.1933 - acc: 0.07 - ETA: 10s - loss: 4.1931 - acc: 0.07 - ETA: 9s - loss: 4.1941 - acc: 0.0767 - ETA: 9s - loss: 4.1937 - acc: 0.076 - ETA: 9s - loss: 4.1943 - acc: 0.076 - ETA: 9s - loss: 4.1927 - acc: 0.077 - ETA: 9s - loss: 4.1927 - acc: 0.077 - ETA: 8s - loss: 4.1926 - acc: 0.077 - ETA: 8s - loss: 4.1924 - acc: 0.077 - ETA: 8s - loss: 4.1921 - acc: 0.077 - ETA: 8s - loss: 4.1937 - acc: 0.077 - ETA: 8s - loss: 4.1940 - acc: 0.077 - ETA: 7s - loss: 4.1945 - acc: 0.077 - ETA: 7s - loss: 4.1949 - acc: 0.077 - ETA: 7s - loss: 4.1937 - acc: 0.077 - ETA: 7s - loss: 4.1936 - acc: 0.077 - ETA: 6s - loss: 4.1933 - acc: 0.077 - ETA: 6s - loss: 4.1931 - acc: 0.077 - ETA: 6s - loss: 4.1932 - acc: 0.077 - ETA: 6s - loss: 4.1918 - acc: 0.078 - ETA: 6s - loss: 4.1914 - acc: 0.078 - ETA: 5s - loss: 4.1919 - acc: 0.078 - ETA: 5s - loss: 4.1918 - acc: 0.078 - ETA: 5s - loss: 4.1927 - acc: 0.078 - ETA: 5s - loss: 4.1925 - acc: 0.078 - ETA: 5s - loss: 4.1919 - acc: 0.078 - ETA: 4s - loss: 4.1908 - acc: 0.078 - ETA: 4s - loss: 4.1907 - acc: 0.078 - ETA: 4s - loss: 4.1906 - acc: 0.078 - ETA: 4s - loss: 4.1908 - acc: 0.078 - ETA: 4s - loss: 4.1901 - acc: 0.078 - ETA: 3s - loss: 4.1895 - acc: 0.078 - ETA: 3s - loss: 4.1910 - acc: 0.078 - ETA: 3s - loss: 4.1925 - acc: 0.078 - ETA: 3s - loss: 4.1930 - acc: 0.078 - ETA: 2s - loss: 4.1949 - acc: 0.078 - ETA: 2s - loss: 4.1963 - acc: 0.078 - ETA: 2s - loss: 4.1953 - acc: 0.078 - ETA: 2s - loss: 4.1952 - acc: 0.078 - ETA: 2s - loss: 4.1956 - acc: 0.078 - ETA: 1s - loss: 4.1953 - acc: 0.079 - ETA: 1s - loss: 4.1954 - acc: 0.079 - ETA: 1s - loss: 4.1950 - acc: 0.079 - ETA: 1s - loss: 4.1953 - acc: 0.079 - ETA: 1s - loss: 4.1947 - acc: 0.079 - ETA: 0s - loss: 4.1963 - acc: 0.079 - ETA: 0s - loss: 4.1970 - acc: 0.079 - ETA: 0s - loss: 4.1979 - acc: 0.078 - ETA: 0s - loss: 4.1975 - acc: 0.0787Epoch 00023: val_loss improved from 4.27061 to 4.24373, saving model to saved_models/weights.best.from_scratch.hdf5\n",
      "6680/6680 [==============================] - 73s - loss: 4.1971 - acc: 0.0786 - val_loss: 4.2437 - val_acc: 0.0647\n",
      "Epoch 25/32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4300/6680 [==================>...........] - ETA: 69s - loss: 4.3701 - acc: 0.0000e+ - ETA: 70s - loss: 4.2861 - acc: 0.0250   - ETA: 69s - loss: 4.2773 - acc: 0.03 - ETA: 69s - loss: 4.1566 - acc: 0.05 - ETA: 69s - loss: 4.1629 - acc: 0.06 - ETA: 68s - loss: 4.1323 - acc: 0.06 - ETA: 68s - loss: 4.1517 - acc: 0.06 - ETA: 68s - loss: 4.1228 - acc: 0.06 - ETA: 68s - loss: 4.1426 - acc: 0.06 - ETA: 68s - loss: 4.1262 - acc: 0.07 - ETA: 67s - loss: 4.1403 - acc: 0.07 - ETA: 68s - loss: 4.1257 - acc: 0.08 - ETA: 67s - loss: 4.1162 - acc: 0.08 - ETA: 67s - loss: 4.1120 - acc: 0.08 - ETA: 67s - loss: 4.0949 - acc: 0.09 - ETA: 66s - loss: 4.0982 - acc: 0.09 - ETA: 66s - loss: 4.0869 - acc: 0.09 - ETA: 66s - loss: 4.1095 - acc: 0.09 - ETA: 66s - loss: 4.1134 - acc: 0.09 - ETA: 66s - loss: 4.1135 - acc: 0.10 - ETA: 66s - loss: 4.0986 - acc: 0.10 - ETA: 65s - loss: 4.1004 - acc: 0.10 - ETA: 65s - loss: 4.1169 - acc: 0.09 - ETA: 65s - loss: 4.1163 - acc: 0.09 - ETA: 65s - loss: 4.1178 - acc: 0.09 - ETA: 65s - loss: 4.1172 - acc: 0.09 - ETA: 64s - loss: 4.1115 - acc: 0.09 - ETA: 64s - loss: 4.1271 - acc: 0.09 - ETA: 64s - loss: 4.1202 - acc: 0.10 - ETA: 64s - loss: 4.1090 - acc: 0.09 - ETA: 64s - loss: 4.0933 - acc: 0.10 - ETA: 63s - loss: 4.0976 - acc: 0.09 - ETA: 63s - loss: 4.0988 - acc: 0.09 - ETA: 63s - loss: 4.0973 - acc: 0.09 - ETA: 63s - loss: 4.1050 - acc: 0.09 - ETA: 62s - loss: 4.1126 - acc: 0.08 - ETA: 62s - loss: 4.1179 - acc: 0.08 - ETA: 62s - loss: 4.1176 - acc: 0.08 - ETA: 62s - loss: 4.1164 - acc: 0.08 - ETA: 62s - loss: 4.1158 - acc: 0.08 - ETA: 61s - loss: 4.1187 - acc: 0.08 - ETA: 61s - loss: 4.1135 - acc: 0.08 - ETA: 61s - loss: 4.1131 - acc: 0.08 - ETA: 61s - loss: 4.1142 - acc: 0.08 - ETA: 61s - loss: 4.1128 - acc: 0.08 - ETA: 60s - loss: 4.1114 - acc: 0.08 - ETA: 60s - loss: 4.1072 - acc: 0.08 - ETA: 60s - loss: 4.1038 - acc: 0.08 - ETA: 60s - loss: 4.1044 - acc: 0.08 - ETA: 60s - loss: 4.1048 - acc: 0.08 - ETA: 59s - loss: 4.1050 - acc: 0.08 - ETA: 59s - loss: 4.1027 - acc: 0.08 - ETA: 59s - loss: 4.1046 - acc: 0.08 - ETA: 59s - loss: 4.1050 - acc: 0.07 - ETA: 58s - loss: 4.1049 - acc: 0.07 - ETA: 58s - loss: 4.1103 - acc: 0.07 - ETA: 58s - loss: 4.1121 - acc: 0.07 - ETA: 58s - loss: 4.1085 - acc: 0.07 - ETA: 58s - loss: 4.1140 - acc: 0.07 - ETA: 57s - loss: 4.1186 - acc: 0.07 - ETA: 57s - loss: 4.1207 - acc: 0.07 - ETA: 57s - loss: 4.1181 - acc: 0.07 - ETA: 57s - loss: 4.1175 - acc: 0.07 - ETA: 57s - loss: 4.1182 - acc: 0.07 - ETA: 56s - loss: 4.1220 - acc: 0.07 - ETA: 56s - loss: 4.1253 - acc: 0.07 - ETA: 56s - loss: 4.1280 - acc: 0.07 - ETA: 56s - loss: 4.1247 - acc: 0.07 - ETA: 56s - loss: 4.1262 - acc: 0.07 - ETA: 55s - loss: 4.1267 - acc: 0.07 - ETA: 55s - loss: 4.1274 - acc: 0.07 - ETA: 55s - loss: 4.1277 - acc: 0.07 - ETA: 55s - loss: 4.1316 - acc: 0.07 - ETA: 55s - loss: 4.1335 - acc: 0.07 - ETA: 54s - loss: 4.1378 - acc: 0.07 - ETA: 54s - loss: 4.1378 - acc: 0.07 - ETA: 54s - loss: 4.1432 - acc: 0.07 - ETA: 54s - loss: 4.1475 - acc: 0.07 - ETA: 53s - loss: 4.1489 - acc: 0.07 - ETA: 53s - loss: 4.1502 - acc: 0.07 - ETA: 53s - loss: 4.1538 - acc: 0.07 - ETA: 53s - loss: 4.1504 - acc: 0.07 - ETA: 53s - loss: 4.1463 - acc: 0.07 - ETA: 52s - loss: 4.1474 - acc: 0.07 - ETA: 52s - loss: 4.1454 - acc: 0.07 - ETA: 52s - loss: 4.1456 - acc: 0.07 - ETA: 52s - loss: 4.1520 - acc: 0.07 - ETA: 52s - loss: 4.1554 - acc: 0.07 - ETA: 51s - loss: 4.1533 - acc: 0.07 - ETA: 51s - loss: 4.1581 - acc: 0.07 - ETA: 51s - loss: 4.1590 - acc: 0.07 - ETA: 51s - loss: 4.1572 - acc: 0.07 - ETA: 51s - loss: 4.1567 - acc: 0.07 - ETA: 50s - loss: 4.1556 - acc: 0.07 - ETA: 50s - loss: 4.1561 - acc: 0.07 - ETA: 50s - loss: 4.1569 - acc: 0.07 - ETA: 50s - loss: 4.1580 - acc: 0.07 - ETA: 50s - loss: 4.1539 - acc: 0.07 - ETA: 49s - loss: 4.1497 - acc: 0.07 - ETA: 49s - loss: 4.1476 - acc: 0.07 - ETA: 49s - loss: 4.1502 - acc: 0.07 - ETA: 49s - loss: 4.1533 - acc: 0.07 - ETA: 49s - loss: 4.1540 - acc: 0.07 - ETA: 48s - loss: 4.1561 - acc: 0.07 - ETA: 48s - loss: 4.1599 - acc: 0.07 - ETA: 48s - loss: 4.1607 - acc: 0.07 - ETA: 48s - loss: 4.1587 - acc: 0.07 - ETA: 47s - loss: 4.1619 - acc: 0.07 - ETA: 47s - loss: 4.1624 - acc: 0.07 - ETA: 47s - loss: 4.1648 - acc: 0.07 - ETA: 47s - loss: 4.1688 - acc: 0.07 - ETA: 47s - loss: 4.1667 - acc: 0.07 - ETA: 46s - loss: 4.1663 - acc: 0.07 - ETA: 46s - loss: 4.1658 - acc: 0.07 - ETA: 46s - loss: 4.1642 - acc: 0.07 - ETA: 46s - loss: 4.1666 - acc: 0.07 - ETA: 46s - loss: 4.1638 - acc: 0.07 - ETA: 45s - loss: 4.1659 - acc: 0.07 - ETA: 45s - loss: 4.1646 - acc: 0.07 - ETA: 45s - loss: 4.1631 - acc: 0.07 - ETA: 45s - loss: 4.1603 - acc: 0.07 - ETA: 45s - loss: 4.1640 - acc: 0.07 - ETA: 44s - loss: 4.1641 - acc: 0.07 - ETA: 44s - loss: 4.1621 - acc: 0.07 - ETA: 44s - loss: 4.1660 - acc: 0.07 - ETA: 44s - loss: 4.1632 - acc: 0.08 - ETA: 44s - loss: 4.1641 - acc: 0.08 - ETA: 43s - loss: 4.1635 - acc: 0.08 - ETA: 43s - loss: 4.1668 - acc: 0.08 - ETA: 43s - loss: 4.1693 - acc: 0.08 - ETA: 43s - loss: 4.1709 - acc: 0.07 - ETA: 42s - loss: 4.1711 - acc: 0.08 - ETA: 42s - loss: 4.1692 - acc: 0.08 - ETA: 42s - loss: 4.1671 - acc: 0.08 - ETA: 42s - loss: 4.1694 - acc: 0.08 - ETA: 42s - loss: 4.1698 - acc: 0.08 - ETA: 41s - loss: 4.1706 - acc: 0.08 - ETA: 41s - loss: 4.1705 - acc: 0.08 - ETA: 41s - loss: 4.1698 - acc: 0.08 - ETA: 41s - loss: 4.1720 - acc: 0.08 - ETA: 41s - loss: 4.1720 - acc: 0.08 - ETA: 40s - loss: 4.1744 - acc: 0.08 - ETA: 40s - loss: 4.1752 - acc: 0.08 - ETA: 40s - loss: 4.1758 - acc: 0.08 - ETA: 40s - loss: 4.1739 - acc: 0.08 - ETA: 39s - loss: 4.1757 - acc: 0.08 - ETA: 39s - loss: 4.1749 - acc: 0.08 - ETA: 39s - loss: 4.1746 - acc: 0.08 - ETA: 39s - loss: 4.1737 - acc: 0.08 - ETA: 39s - loss: 4.1748 - acc: 0.08 - ETA: 38s - loss: 4.1743 - acc: 0.08 - ETA: 38s - loss: 4.1749 - acc: 0.08 - ETA: 38s - loss: 4.1746 - acc: 0.08 - ETA: 38s - loss: 4.1756 - acc: 0.08 - ETA: 38s - loss: 4.1784 - acc: 0.08 - ETA: 37s - loss: 4.1787 - acc: 0.08 - ETA: 37s - loss: 4.1760 - acc: 0.08 - ETA: 37s - loss: 4.1779 - acc: 0.08 - ETA: 37s - loss: 4.1805 - acc: 0.08 - ETA: 36s - loss: 4.1811 - acc: 0.08 - ETA: 36s - loss: 4.1808 - acc: 0.08 - ETA: 36s - loss: 4.1809 - acc: 0.08 - ETA: 36s - loss: 4.1827 - acc: 0.08 - ETA: 36s - loss: 4.1809 - acc: 0.08 - ETA: 35s - loss: 4.1811 - acc: 0.08 - ETA: 35s - loss: 4.1822 - acc: 0.08 - ETA: 35s - loss: 4.1820 - acc: 0.08 - ETA: 35s - loss: 4.1808 - acc: 0.08 - ETA: 35s - loss: 4.1811 - acc: 0.08 - ETA: 34s - loss: 4.1802 - acc: 0.08 - ETA: 34s - loss: 4.1793 - acc: 0.08 - ETA: 34s - loss: 4.1772 - acc: 0.08 - ETA: 34s - loss: 4.1773 - acc: 0.08 - ETA: 33s - loss: 4.1767 - acc: 0.08 - ETA: 33s - loss: 4.1796 - acc: 0.08 - ETA: 33s - loss: 4.1801 - acc: 0.08 - ETA: 33s - loss: 4.1801 - acc: 0.08 - ETA: 33s - loss: 4.1796 - acc: 0.08 - ETA: 32s - loss: 4.1811 - acc: 0.08 - ETA: 32s - loss: 4.1813 - acc: 0.08 - ETA: 32s - loss: 4.1817 - acc: 0.08 - ETA: 32s - loss: 4.1824 - acc: 0.08 - ETA: 32s - loss: 4.1810 - acc: 0.08 - ETA: 31s - loss: 4.1802 - acc: 0.07 - ETA: 31s - loss: 4.1811 - acc: 0.08 - ETA: 31s - loss: 4.1822 - acc: 0.08 - ETA: 31s - loss: 4.1815 - acc: 0.08 - ETA: 30s - loss: 4.1831 - acc: 0.08 - ETA: 30s - loss: 4.1815 - acc: 0.08 - ETA: 30s - loss: 4.1822 - acc: 0.08 - ETA: 30s - loss: 4.1812 - acc: 0.08 - ETA: 30s - loss: 4.1830 - acc: 0.08 - ETA: 29s - loss: 4.1826 - acc: 0.08 - ETA: 29s - loss: 4.1831 - acc: 0.08 - ETA: 29s - loss: 4.1833 - acc: 0.08 - ETA: 29s - loss: 4.1826 - acc: 0.08 - ETA: 29s - loss: 4.1826 - acc: 0.08 - ETA: 28s - loss: 4.1813 - acc: 0.08 - ETA: 28s - loss: 4.1816 - acc: 0.08 - ETA: 28s - loss: 4.1826 - acc: 0.08 - ETA: 28s - loss: 4.1810 - acc: 0.08 - ETA: 27s - loss: 4.1806 - acc: 0.08 - ETA: 27s - loss: 4.1818 - acc: 0.08 - ETA: 27s - loss: 4.1821 - acc: 0.08 - ETA: 27s - loss: 4.1814 - acc: 0.08 - ETA: 27s - loss: 4.1813 - acc: 0.08 - ETA: 26s - loss: 4.1816 - acc: 0.08 - ETA: 26s - loss: 4.1815 - acc: 0.08 - ETA: 26s - loss: 4.1806 - acc: 0.08 - ETA: 26s - loss: 4.1797 - acc: 0.08 - ETA: 26s - loss: 4.1787 - acc: 0.08 - ETA: 25s - loss: 4.1782 - acc: 0.08 - ETA: 25s - loss: 4.1779 - acc: 0.08 - ETA: 25s - loss: 4.1774 - acc: 0.08 - ETA: 25s - loss: 4.1765 - acc: 0.0807"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6660/6680 [============================>.] - ETA: 25s - loss: 4.1802 - acc: 0.08 - ETA: 24s - loss: 4.1804 - acc: 0.08 - ETA: 24s - loss: 4.1813 - acc: 0.08 - ETA: 24s - loss: 4.1821 - acc: 0.07 - ETA: 24s - loss: 4.1804 - acc: 0.08 - ETA: 23s - loss: 4.1808 - acc: 0.08 - ETA: 23s - loss: 4.1815 - acc: 0.08 - ETA: 23s - loss: 4.1814 - acc: 0.08 - ETA: 23s - loss: 4.1822 - acc: 0.08 - ETA: 23s - loss: 4.1829 - acc: 0.08 - ETA: 22s - loss: 4.1830 - acc: 0.08 - ETA: 22s - loss: 4.1815 - acc: 0.08 - ETA: 22s - loss: 4.1832 - acc: 0.08 - ETA: 22s - loss: 4.1856 - acc: 0.08 - ETA: 22s - loss: 4.1847 - acc: 0.08 - ETA: 21s - loss: 4.1839 - acc: 0.08 - ETA: 21s - loss: 4.1820 - acc: 0.08 - ETA: 21s - loss: 4.1806 - acc: 0.08 - ETA: 21s - loss: 4.1823 - acc: 0.08 - ETA: 20s - loss: 4.1824 - acc: 0.08 - ETA: 20s - loss: 4.1823 - acc: 0.08 - ETA: 20s - loss: 4.1801 - acc: 0.08 - ETA: 20s - loss: 4.1770 - acc: 0.08 - ETA: 20s - loss: 4.1771 - acc: 0.08 - ETA: 19s - loss: 4.1786 - acc: 0.08 - ETA: 19s - loss: 4.1785 - acc: 0.08 - ETA: 19s - loss: 4.1772 - acc: 0.08 - ETA: 19s - loss: 4.1761 - acc: 0.08 - ETA: 19s - loss: 4.1748 - acc: 0.08 - ETA: 18s - loss: 4.1744 - acc: 0.08 - ETA: 18s - loss: 4.1722 - acc: 0.08 - ETA: 18s - loss: 4.1714 - acc: 0.08 - ETA: 18s - loss: 4.1722 - acc: 0.08 - ETA: 18s - loss: 4.1733 - acc: 0.08 - ETA: 17s - loss: 4.1734 - acc: 0.08 - ETA: 17s - loss: 4.1717 - acc: 0.08 - ETA: 17s - loss: 4.1714 - acc: 0.08 - ETA: 17s - loss: 4.1712 - acc: 0.08 - ETA: 16s - loss: 4.1714 - acc: 0.08 - ETA: 16s - loss: 4.1723 - acc: 0.08 - ETA: 16s - loss: 4.1719 - acc: 0.08 - ETA: 16s - loss: 4.1712 - acc: 0.08 - ETA: 16s - loss: 4.1699 - acc: 0.08 - ETA: 15s - loss: 4.1707 - acc: 0.08 - ETA: 15s - loss: 4.1717 - acc: 0.08 - ETA: 15s - loss: 4.1713 - acc: 0.08 - ETA: 15s - loss: 4.1711 - acc: 0.08 - ETA: 15s - loss: 4.1735 - acc: 0.08 - ETA: 14s - loss: 4.1746 - acc: 0.08 - ETA: 14s - loss: 4.1739 - acc: 0.08 - ETA: 14s - loss: 4.1724 - acc: 0.08 - ETA: 14s - loss: 4.1734 - acc: 0.08 - ETA: 13s - loss: 4.1743 - acc: 0.08 - ETA: 13s - loss: 4.1739 - acc: 0.08 - ETA: 13s - loss: 4.1738 - acc: 0.08 - ETA: 13s - loss: 4.1737 - acc: 0.08 - ETA: 13s - loss: 4.1734 - acc: 0.08 - ETA: 12s - loss: 4.1727 - acc: 0.08 - ETA: 12s - loss: 4.1747 - acc: 0.08 - ETA: 12s - loss: 4.1760 - acc: 0.08 - ETA: 12s - loss: 4.1764 - acc: 0.08 - ETA: 12s - loss: 4.1748 - acc: 0.08 - ETA: 11s - loss: 4.1744 - acc: 0.08 - ETA: 11s - loss: 4.1742 - acc: 0.08 - ETA: 11s - loss: 4.1732 - acc: 0.08 - ETA: 11s - loss: 4.1742 - acc: 0.08 - ETA: 11s - loss: 4.1745 - acc: 0.08 - ETA: 10s - loss: 4.1757 - acc: 0.08 - ETA: 10s - loss: 4.1756 - acc: 0.08 - ETA: 10s - loss: 4.1760 - acc: 0.08 - ETA: 10s - loss: 4.1749 - acc: 0.08 - ETA: 9s - loss: 4.1744 - acc: 0.0812 - ETA: 9s - loss: 4.1741 - acc: 0.080 - ETA: 9s - loss: 4.1753 - acc: 0.080 - ETA: 9s - loss: 4.1758 - acc: 0.080 - ETA: 9s - loss: 4.1763 - acc: 0.080 - ETA: 8s - loss: 4.1789 - acc: 0.080 - ETA: 8s - loss: 4.1802 - acc: 0.080 - ETA: 8s - loss: 4.1799 - acc: 0.080 - ETA: 8s - loss: 4.1796 - acc: 0.080 - ETA: 8s - loss: 4.1798 - acc: 0.080 - ETA: 7s - loss: 4.1806 - acc: 0.080 - ETA: 7s - loss: 4.1799 - acc: 0.080 - ETA: 7s - loss: 4.1787 - acc: 0.080 - ETA: 7s - loss: 4.1777 - acc: 0.080 - ETA: 6s - loss: 4.1781 - acc: 0.080 - ETA: 6s - loss: 4.1758 - acc: 0.080 - ETA: 6s - loss: 4.1766 - acc: 0.080 - ETA: 6s - loss: 4.1775 - acc: 0.079 - ETA: 6s - loss: 4.1765 - acc: 0.080 - ETA: 5s - loss: 4.1769 - acc: 0.080 - ETA: 5s - loss: 4.1765 - acc: 0.080 - ETA: 5s - loss: 4.1752 - acc: 0.081 - ETA: 5s - loss: 4.1743 - acc: 0.081 - ETA: 5s - loss: 4.1739 - acc: 0.081 - ETA: 4s - loss: 4.1747 - acc: 0.081 - ETA: 4s - loss: 4.1750 - acc: 0.081 - ETA: 4s - loss: 4.1740 - acc: 0.081 - ETA: 4s - loss: 4.1757 - acc: 0.081 - ETA: 4s - loss: 4.1754 - acc: 0.081 - ETA: 3s - loss: 4.1748 - acc: 0.081 - ETA: 3s - loss: 4.1745 - acc: 0.081 - ETA: 3s - loss: 4.1741 - acc: 0.081 - ETA: 3s - loss: 4.1743 - acc: 0.081 - ETA: 2s - loss: 4.1760 - acc: 0.081 - ETA: 2s - loss: 4.1754 - acc: 0.081 - ETA: 2s - loss: 4.1761 - acc: 0.081 - ETA: 2s - loss: 4.1757 - acc: 0.081 - ETA: 2s - loss: 4.1758 - acc: 0.081 - ETA: 1s - loss: 4.1753 - acc: 0.081 - ETA: 1s - loss: 4.1772 - acc: 0.081 - ETA: 1s - loss: 4.1762 - acc: 0.081 - ETA: 1s - loss: 4.1761 - acc: 0.081 - ETA: 1s - loss: 4.1767 - acc: 0.081 - ETA: 0s - loss: 4.1759 - acc: 0.080 - ETA: 0s - loss: 4.1759 - acc: 0.080 - ETA: 0s - loss: 4.1767 - acc: 0.080 - ETA: 0s - loss: 4.1768 - acc: 0.0806Epoch 00024: val_loss improved from 4.24373 to 4.24149, saving model to saved_models/weights.best.from_scratch.hdf5\n",
      "6680/6680 [==============================] - 73s - loss: 4.1770 - acc: 0.0808 - val_loss: 4.2415 - val_acc: 0.0659\n",
      "Epoch 26/32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4300/6680 [==================>...........] - ETA: 68s - loss: 4.1356 - acc: 0.15 - ETA: 67s - loss: 4.0229 - acc: 0.10 - ETA: 67s - loss: 4.0107 - acc: 0.08 - ETA: 68s - loss: 4.0732 - acc: 0.07 - ETA: 68s - loss: 4.0592 - acc: 0.08 - ETA: 68s - loss: 4.0478 - acc: 0.08 - ETA: 68s - loss: 4.0504 - acc: 0.07 - ETA: 67s - loss: 4.0995 - acc: 0.06 - ETA: 67s - loss: 4.1295 - acc: 0.06 - ETA: 67s - loss: 4.1023 - acc: 0.06 - ETA: 67s - loss: 4.1272 - acc: 0.05 - ETA: 67s - loss: 4.1108 - acc: 0.06 - ETA: 67s - loss: 4.0884 - acc: 0.06 - ETA: 66s - loss: 4.0839 - acc: 0.06 - ETA: 66s - loss: 4.0610 - acc: 0.07 - ETA: 66s - loss: 4.0534 - acc: 0.07 - ETA: 66s - loss: 4.0454 - acc: 0.07 - ETA: 66s - loss: 4.0474 - acc: 0.06 - ETA: 66s - loss: 4.0516 - acc: 0.06 - ETA: 65s - loss: 4.0643 - acc: 0.06 - ETA: 65s - loss: 4.0620 - acc: 0.06 - ETA: 65s - loss: 4.0821 - acc: 0.06 - ETA: 65s - loss: 4.0902 - acc: 0.06 - ETA: 64s - loss: 4.0713 - acc: 0.06 - ETA: 64s - loss: 4.0673 - acc: 0.07 - ETA: 64s - loss: 4.0641 - acc: 0.07 - ETA: 64s - loss: 4.0513 - acc: 0.07 - ETA: 64s - loss: 4.0680 - acc: 0.07 - ETA: 64s - loss: 4.0730 - acc: 0.07 - ETA: 63s - loss: 4.0804 - acc: 0.07 - ETA: 63s - loss: 4.0799 - acc: 0.06 - ETA: 63s - loss: 4.0717 - acc: 0.07 - ETA: 63s - loss: 4.0612 - acc: 0.07 - ETA: 62s - loss: 4.0568 - acc: 0.07 - ETA: 62s - loss: 4.0580 - acc: 0.07 - ETA: 62s - loss: 4.0593 - acc: 0.07 - ETA: 62s - loss: 4.0526 - acc: 0.07 - ETA: 62s - loss: 4.0566 - acc: 0.07 - ETA: 61s - loss: 4.0470 - acc: 0.07 - ETA: 61s - loss: 4.0441 - acc: 0.08 - ETA: 61s - loss: 4.0412 - acc: 0.08 - ETA: 61s - loss: 4.0451 - acc: 0.07 - ETA: 61s - loss: 4.0424 - acc: 0.07 - ETA: 60s - loss: 4.0493 - acc: 0.07 - ETA: 60s - loss: 4.0603 - acc: 0.07 - ETA: 60s - loss: 4.0606 - acc: 0.07 - ETA: 60s - loss: 4.0597 - acc: 0.08 - ETA: 60s - loss: 4.0643 - acc: 0.08 - ETA: 59s - loss: 4.0620 - acc: 0.08 - ETA: 59s - loss: 4.0607 - acc: 0.08 - ETA: 59s - loss: 4.0595 - acc: 0.08 - ETA: 59s - loss: 4.0648 - acc: 0.08 - ETA: 59s - loss: 4.0646 - acc: 0.07 - ETA: 58s - loss: 4.0685 - acc: 0.08 - ETA: 58s - loss: 4.0662 - acc: 0.08 - ETA: 58s - loss: 4.0624 - acc: 0.08 - ETA: 58s - loss: 4.0639 - acc: 0.08 - ETA: 58s - loss: 4.0574 - acc: 0.08 - ETA: 57s - loss: 4.0587 - acc: 0.08 - ETA: 57s - loss: 4.0559 - acc: 0.08 - ETA: 57s - loss: 4.0481 - acc: 0.08 - ETA: 57s - loss: 4.0547 - acc: 0.08 - ETA: 57s - loss: 4.0606 - acc: 0.08 - ETA: 56s - loss: 4.0681 - acc: 0.08 - ETA: 56s - loss: 4.0782 - acc: 0.08 - ETA: 56s - loss: 4.0753 - acc: 0.08 - ETA: 56s - loss: 4.0783 - acc: 0.08 - ETA: 56s - loss: 4.0770 - acc: 0.08 - ETA: 55s - loss: 4.0779 - acc: 0.08 - ETA: 55s - loss: 4.0795 - acc: 0.08 - ETA: 55s - loss: 4.0878 - acc: 0.08 - ETA: 55s - loss: 4.0896 - acc: 0.08 - ETA: 54s - loss: 4.0907 - acc: 0.08 - ETA: 54s - loss: 4.0946 - acc: 0.08 - ETA: 54s - loss: 4.0920 - acc: 0.08 - ETA: 54s - loss: 4.0867 - acc: 0.08 - ETA: 54s - loss: 4.0838 - acc: 0.08 - ETA: 53s - loss: 4.0842 - acc: 0.08 - ETA: 53s - loss: 4.0889 - acc: 0.08 - ETA: 53s - loss: 4.0969 - acc: 0.08 - ETA: 53s - loss: 4.0965 - acc: 0.08 - ETA: 53s - loss: 4.0997 - acc: 0.08 - ETA: 52s - loss: 4.0961 - acc: 0.08 - ETA: 52s - loss: 4.0900 - acc: 0.08 - ETA: 52s - loss: 4.0986 - acc: 0.08 - ETA: 52s - loss: 4.1065 - acc: 0.08 - ETA: 51s - loss: 4.1082 - acc: 0.08 - ETA: 51s - loss: 4.1124 - acc: 0.08 - ETA: 51s - loss: 4.1113 - acc: 0.08 - ETA: 51s - loss: 4.1094 - acc: 0.08 - ETA: 51s - loss: 4.1119 - acc: 0.08 - ETA: 50s - loss: 4.1139 - acc: 0.08 - ETA: 50s - loss: 4.1151 - acc: 0.08 - ETA: 50s - loss: 4.1164 - acc: 0.08 - ETA: 50s - loss: 4.1138 - acc: 0.08 - ETA: 50s - loss: 4.1139 - acc: 0.08 - ETA: 49s - loss: 4.1138 - acc: 0.08 - ETA: 49s - loss: 4.1149 - acc: 0.08 - ETA: 49s - loss: 4.1171 - acc: 0.08 - ETA: 49s - loss: 4.1165 - acc: 0.08 - ETA: 49s - loss: 4.1170 - acc: 0.07 - ETA: 48s - loss: 4.1153 - acc: 0.07 - ETA: 48s - loss: 4.1169 - acc: 0.08 - ETA: 48s - loss: 4.1147 - acc: 0.08 - ETA: 48s - loss: 4.1146 - acc: 0.08 - ETA: 47s - loss: 4.1109 - acc: 0.08 - ETA: 47s - loss: 4.1141 - acc: 0.08 - ETA: 47s - loss: 4.1145 - acc: 0.08 - ETA: 47s - loss: 4.1123 - acc: 0.08 - ETA: 47s - loss: 4.1146 - acc: 0.08 - ETA: 46s - loss: 4.1142 - acc: 0.08 - ETA: 46s - loss: 4.1161 - acc: 0.08 - ETA: 46s - loss: 4.1141 - acc: 0.08 - ETA: 46s - loss: 4.1122 - acc: 0.08 - ETA: 46s - loss: 4.1166 - acc: 0.08 - ETA: 45s - loss: 4.1157 - acc: 0.08 - ETA: 45s - loss: 4.1127 - acc: 0.08 - ETA: 45s - loss: 4.1139 - acc: 0.08 - ETA: 45s - loss: 4.1181 - acc: 0.08 - ETA: 44s - loss: 4.1171 - acc: 0.08 - ETA: 44s - loss: 4.1175 - acc: 0.07 - ETA: 44s - loss: 4.1167 - acc: 0.08 - ETA: 44s - loss: 4.1197 - acc: 0.08 - ETA: 44s - loss: 4.1192 - acc: 0.08 - ETA: 43s - loss: 4.1193 - acc: 0.08 - ETA: 43s - loss: 4.1189 - acc: 0.08 - ETA: 43s - loss: 4.1255 - acc: 0.08 - ETA: 43s - loss: 4.1256 - acc: 0.08 - ETA: 43s - loss: 4.1268 - acc: 0.08 - ETA: 42s - loss: 4.1307 - acc: 0.07 - ETA: 42s - loss: 4.1324 - acc: 0.07 - ETA: 42s - loss: 4.1350 - acc: 0.07 - ETA: 42s - loss: 4.1353 - acc: 0.07 - ETA: 42s - loss: 4.1347 - acc: 0.07 - ETA: 41s - loss: 4.1356 - acc: 0.07 - ETA: 41s - loss: 4.1390 - acc: 0.07 - ETA: 41s - loss: 4.1375 - acc: 0.07 - ETA: 41s - loss: 4.1341 - acc: 0.07 - ETA: 40s - loss: 4.1316 - acc: 0.07 - ETA: 40s - loss: 4.1336 - acc: 0.07 - ETA: 40s - loss: 4.1317 - acc: 0.07 - ETA: 40s - loss: 4.1316 - acc: 0.07 - ETA: 40s - loss: 4.1324 - acc: 0.07 - ETA: 39s - loss: 4.1307 - acc: 0.07 - ETA: 39s - loss: 4.1292 - acc: 0.07 - ETA: 39s - loss: 4.1308 - acc: 0.07 - ETA: 39s - loss: 4.1306 - acc: 0.07 - ETA: 39s - loss: 4.1297 - acc: 0.07 - ETA: 38s - loss: 4.1266 - acc: 0.08 - ETA: 38s - loss: 4.1304 - acc: 0.08 - ETA: 38s - loss: 4.1316 - acc: 0.08 - ETA: 38s - loss: 4.1307 - acc: 0.08 - ETA: 37s - loss: 4.1308 - acc: 0.08 - ETA: 37s - loss: 4.1329 - acc: 0.07 - ETA: 37s - loss: 4.1336 - acc: 0.08 - ETA: 37s - loss: 4.1314 - acc: 0.08 - ETA: 37s - loss: 4.1321 - acc: 0.08 - ETA: 36s - loss: 4.1345 - acc: 0.08 - ETA: 36s - loss: 4.1318 - acc: 0.08 - ETA: 36s - loss: 4.1328 - acc: 0.08 - ETA: 36s - loss: 4.1330 - acc: 0.08 - ETA: 36s - loss: 4.1357 - acc: 0.07 - ETA: 35s - loss: 4.1352 - acc: 0.08 - ETA: 35s - loss: 4.1363 - acc: 0.07 - ETA: 35s - loss: 4.1354 - acc: 0.08 - ETA: 35s - loss: 4.1348 - acc: 0.08 - ETA: 35s - loss: 4.1363 - acc: 0.08 - ETA: 34s - loss: 4.1367 - acc: 0.08 - ETA: 34s - loss: 4.1378 - acc: 0.08 - ETA: 34s - loss: 4.1363 - acc: 0.08 - ETA: 34s - loss: 4.1354 - acc: 0.08 - ETA: 34s - loss: 4.1335 - acc: 0.08 - ETA: 33s - loss: 4.1322 - acc: 0.08 - ETA: 33s - loss: 4.1329 - acc: 0.08 - ETA: 33s - loss: 4.1323 - acc: 0.08 - ETA: 33s - loss: 4.1343 - acc: 0.08 - ETA: 32s - loss: 4.1355 - acc: 0.08 - ETA: 32s - loss: 4.1365 - acc: 0.08 - ETA: 32s - loss: 4.1373 - acc: 0.08 - ETA: 32s - loss: 4.1353 - acc: 0.08 - ETA: 32s - loss: 4.1355 - acc: 0.08 - ETA: 31s - loss: 4.1381 - acc: 0.08 - ETA: 31s - loss: 4.1389 - acc: 0.08 - ETA: 31s - loss: 4.1384 - acc: 0.08 - ETA: 31s - loss: 4.1380 - acc: 0.08 - ETA: 31s - loss: 4.1364 - acc: 0.08 - ETA: 30s - loss: 4.1391 - acc: 0.08 - ETA: 30s - loss: 4.1380 - acc: 0.08 - ETA: 30s - loss: 4.1370 - acc: 0.08 - ETA: 30s - loss: 4.1353 - acc: 0.08 - ETA: 30s - loss: 4.1344 - acc: 0.08 - ETA: 29s - loss: 4.1349 - acc: 0.08 - ETA: 29s - loss: 4.1340 - acc: 0.08 - ETA: 29s - loss: 4.1320 - acc: 0.08 - ETA: 29s - loss: 4.1337 - acc: 0.08 - ETA: 28s - loss: 4.1332 - acc: 0.08 - ETA: 28s - loss: 4.1331 - acc: 0.08 - ETA: 28s - loss: 4.1321 - acc: 0.08 - ETA: 28s - loss: 4.1314 - acc: 0.08 - ETA: 28s - loss: 4.1318 - acc: 0.08 - ETA: 27s - loss: 4.1331 - acc: 0.08 - ETA: 27s - loss: 4.1341 - acc: 0.08 - ETA: 27s - loss: 4.1345 - acc: 0.08 - ETA: 27s - loss: 4.1318 - acc: 0.08 - ETA: 27s - loss: 4.1338 - acc: 0.08 - ETA: 26s - loss: 4.1349 - acc: 0.08 - ETA: 26s - loss: 4.1355 - acc: 0.08 - ETA: 26s - loss: 4.1365 - acc: 0.08 - ETA: 26s - loss: 4.1384 - acc: 0.08 - ETA: 26s - loss: 4.1400 - acc: 0.08 - ETA: 25s - loss: 4.1403 - acc: 0.08 - ETA: 25s - loss: 4.1398 - acc: 0.08 - ETA: 25s - loss: 4.1407 - acc: 0.08 - ETA: 25s - loss: 4.1405 - acc: 0.08 - ETA: 24s - loss: 4.1405 - acc: 0.0830"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6660/6680 [============================>.] - ETA: 24s - loss: 4.1401 - acc: 0.08 - ETA: 24s - loss: 4.1414 - acc: 0.08 - ETA: 24s - loss: 4.1408 - acc: 0.08 - ETA: 24s - loss: 4.1410 - acc: 0.08 - ETA: 23s - loss: 4.1433 - acc: 0.08 - ETA: 23s - loss: 4.1433 - acc: 0.08 - ETA: 23s - loss: 4.1440 - acc: 0.08 - ETA: 23s - loss: 4.1443 - acc: 0.08 - ETA: 23s - loss: 4.1442 - acc: 0.08 - ETA: 22s - loss: 4.1443 - acc: 0.08 - ETA: 22s - loss: 4.1440 - acc: 0.08 - ETA: 22s - loss: 4.1434 - acc: 0.08 - ETA: 22s - loss: 4.1451 - acc: 0.08 - ETA: 22s - loss: 4.1454 - acc: 0.08 - ETA: 21s - loss: 4.1455 - acc: 0.08 - ETA: 21s - loss: 4.1448 - acc: 0.08 - ETA: 21s - loss: 4.1432 - acc: 0.08 - ETA: 21s - loss: 4.1435 - acc: 0.08 - ETA: 20s - loss: 4.1436 - acc: 0.08 - ETA: 20s - loss: 4.1429 - acc: 0.08 - ETA: 20s - loss: 4.1436 - acc: 0.08 - ETA: 20s - loss: 4.1414 - acc: 0.08 - ETA: 20s - loss: 4.1409 - acc: 0.08 - ETA: 19s - loss: 4.1402 - acc: 0.08 - ETA: 19s - loss: 4.1401 - acc: 0.08 - ETA: 19s - loss: 4.1400 - acc: 0.08 - ETA: 19s - loss: 4.1403 - acc: 0.08 - ETA: 19s - loss: 4.1406 - acc: 0.08 - ETA: 18s - loss: 4.1404 - acc: 0.08 - ETA: 18s - loss: 4.1406 - acc: 0.08 - ETA: 18s - loss: 4.1409 - acc: 0.08 - ETA: 18s - loss: 4.1399 - acc: 0.08 - ETA: 18s - loss: 4.1398 - acc: 0.08 - ETA: 17s - loss: 4.1407 - acc: 0.08 - ETA: 17s - loss: 4.1415 - acc: 0.08 - ETA: 17s - loss: 4.1426 - acc: 0.08 - ETA: 17s - loss: 4.1429 - acc: 0.08 - ETA: 17s - loss: 4.1448 - acc: 0.08 - ETA: 16s - loss: 4.1437 - acc: 0.08 - ETA: 16s - loss: 4.1438 - acc: 0.08 - ETA: 16s - loss: 4.1436 - acc: 0.08 - ETA: 16s - loss: 4.1454 - acc: 0.08 - ETA: 15s - loss: 4.1444 - acc: 0.08 - ETA: 15s - loss: 4.1437 - acc: 0.08 - ETA: 15s - loss: 4.1431 - acc: 0.08 - ETA: 15s - loss: 4.1435 - acc: 0.08 - ETA: 15s - loss: 4.1435 - acc: 0.08 - ETA: 14s - loss: 4.1432 - acc: 0.08 - ETA: 14s - loss: 4.1442 - acc: 0.08 - ETA: 14s - loss: 4.1441 - acc: 0.08 - ETA: 14s - loss: 4.1467 - acc: 0.08 - ETA: 14s - loss: 4.1472 - acc: 0.08 - ETA: 13s - loss: 4.1485 - acc: 0.08 - ETA: 13s - loss: 4.1482 - acc: 0.08 - ETA: 13s - loss: 4.1488 - acc: 0.08 - ETA: 13s - loss: 4.1483 - acc: 0.08 - ETA: 13s - loss: 4.1480 - acc: 0.08 - ETA: 12s - loss: 4.1478 - acc: 0.08 - ETA: 12s - loss: 4.1482 - acc: 0.08 - ETA: 12s - loss: 4.1470 - acc: 0.08 - ETA: 12s - loss: 4.1462 - acc: 0.08 - ETA: 11s - loss: 4.1459 - acc: 0.08 - ETA: 11s - loss: 4.1475 - acc: 0.08 - ETA: 11s - loss: 4.1477 - acc: 0.08 - ETA: 11s - loss: 4.1474 - acc: 0.08 - ETA: 11s - loss: 4.1466 - acc: 0.08 - ETA: 10s - loss: 4.1467 - acc: 0.08 - ETA: 10s - loss: 4.1468 - acc: 0.08 - ETA: 10s - loss: 4.1464 - acc: 0.08 - ETA: 10s - loss: 4.1465 - acc: 0.08 - ETA: 10s - loss: 4.1469 - acc: 0.08 - ETA: 9s - loss: 4.1472 - acc: 0.0836 - ETA: 9s - loss: 4.1464 - acc: 0.083 - ETA: 9s - loss: 4.1459 - acc: 0.083 - ETA: 9s - loss: 4.1460 - acc: 0.084 - ETA: 9s - loss: 4.1466 - acc: 0.084 - ETA: 8s - loss: 4.1490 - acc: 0.084 - ETA: 8s - loss: 4.1485 - acc: 0.084 - ETA: 8s - loss: 4.1471 - acc: 0.084 - ETA: 8s - loss: 4.1468 - acc: 0.084 - ETA: 7s - loss: 4.1468 - acc: 0.084 - ETA: 7s - loss: 4.1458 - acc: 0.084 - ETA: 7s - loss: 4.1456 - acc: 0.084 - ETA: 7s - loss: 4.1439 - acc: 0.086 - ETA: 7s - loss: 4.1429 - acc: 0.086 - ETA: 6s - loss: 4.1448 - acc: 0.085 - ETA: 6s - loss: 4.1442 - acc: 0.086 - ETA: 6s - loss: 4.1432 - acc: 0.085 - ETA: 6s - loss: 4.1450 - acc: 0.085 - ETA: 6s - loss: 4.1453 - acc: 0.085 - ETA: 5s - loss: 4.1439 - acc: 0.085 - ETA: 5s - loss: 4.1422 - acc: 0.085 - ETA: 5s - loss: 4.1416 - acc: 0.085 - ETA: 5s - loss: 4.1411 - acc: 0.085 - ETA: 5s - loss: 4.1406 - acc: 0.085 - ETA: 4s - loss: 4.1438 - acc: 0.085 - ETA: 4s - loss: 4.1434 - acc: 0.085 - ETA: 4s - loss: 4.1441 - acc: 0.085 - ETA: 4s - loss: 4.1445 - acc: 0.085 - ETA: 3s - loss: 4.1449 - acc: 0.085 - ETA: 3s - loss: 4.1458 - acc: 0.085 - ETA: 3s - loss: 4.1461 - acc: 0.085 - ETA: 3s - loss: 4.1478 - acc: 0.084 - ETA: 3s - loss: 4.1470 - acc: 0.085 - ETA: 2s - loss: 4.1462 - acc: 0.085 - ETA: 2s - loss: 4.1477 - acc: 0.085 - ETA: 2s - loss: 4.1488 - acc: 0.085 - ETA: 2s - loss: 4.1493 - acc: 0.086 - ETA: 2s - loss: 4.1480 - acc: 0.086 - ETA: 1s - loss: 4.1491 - acc: 0.085 - ETA: 1s - loss: 4.1491 - acc: 0.085 - ETA: 1s - loss: 4.1494 - acc: 0.085 - ETA: 1s - loss: 4.1492 - acc: 0.085 - ETA: 1s - loss: 4.1491 - acc: 0.085 - ETA: 0s - loss: 4.1488 - acc: 0.085 - ETA: 0s - loss: 4.1489 - acc: 0.085 - ETA: 0s - loss: 4.1490 - acc: 0.085 - ETA: 0s - loss: 4.1488 - acc: 0.0853Epoch 00025: val_loss did not improve\n",
      "6680/6680 [==============================] - 72s - loss: 4.1478 - acc: 0.0855 - val_loss: 4.2423 - val_acc: 0.0623\n",
      "Epoch 27/32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4300/6680 [==================>...........] - ETA: 70s - loss: 4.0527 - acc: 0.20 - ETA: 67s - loss: 3.9923 - acc: 0.15 - ETA: 68s - loss: 4.1824 - acc: 0.10 - ETA: 68s - loss: 4.2416 - acc: 0.08 - ETA: 68s - loss: 4.3136 - acc: 0.07 - ETA: 68s - loss: 4.3163 - acc: 0.07 - ETA: 68s - loss: 4.3448 - acc: 0.07 - ETA: 67s - loss: 4.3569 - acc: 0.06 - ETA: 67s - loss: 4.3427 - acc: 0.07 - ETA: 67s - loss: 4.3181 - acc: 0.06 - ETA: 67s - loss: 4.2914 - acc: 0.07 - ETA: 67s - loss: 4.2980 - acc: 0.07 - ETA: 66s - loss: 4.2740 - acc: 0.07 - ETA: 66s - loss: 4.2515 - acc: 0.06 - ETA: 66s - loss: 4.2140 - acc: 0.07 - ETA: 66s - loss: 4.2098 - acc: 0.08 - ETA: 66s - loss: 4.2077 - acc: 0.07 - ETA: 66s - loss: 4.2061 - acc: 0.07 - ETA: 66s - loss: 4.2043 - acc: 0.07 - ETA: 65s - loss: 4.1934 - acc: 0.07 - ETA: 65s - loss: 4.1846 - acc: 0.07 - ETA: 65s - loss: 4.1725 - acc: 0.07 - ETA: 65s - loss: 4.1718 - acc: 0.07 - ETA: 65s - loss: 4.1633 - acc: 0.07 - ETA: 64s - loss: 4.1541 - acc: 0.07 - ETA: 64s - loss: 4.1597 - acc: 0.07 - ETA: 64s - loss: 4.1428 - acc: 0.07 - ETA: 64s - loss: 4.1388 - acc: 0.07 - ETA: 63s - loss: 4.1491 - acc: 0.07 - ETA: 63s - loss: 4.1582 - acc: 0.07 - ETA: 63s - loss: 4.1523 - acc: 0.06 - ETA: 63s - loss: 4.1608 - acc: 0.06 - ETA: 63s - loss: 4.1614 - acc: 0.06 - ETA: 63s - loss: 4.1590 - acc: 0.06 - ETA: 62s - loss: 4.1586 - acc: 0.06 - ETA: 62s - loss: 4.1588 - acc: 0.06 - ETA: 62s - loss: 4.1604 - acc: 0.06 - ETA: 62s - loss: 4.1596 - acc: 0.06 - ETA: 62s - loss: 4.1701 - acc: 0.06 - ETA: 61s - loss: 4.1758 - acc: 0.06 - ETA: 61s - loss: 4.1798 - acc: 0.06 - ETA: 61s - loss: 4.1702 - acc: 0.06 - ETA: 61s - loss: 4.1684 - acc: 0.06 - ETA: 60s - loss: 4.1586 - acc: 0.07 - ETA: 60s - loss: 4.1676 - acc: 0.07 - ETA: 60s - loss: 4.1720 - acc: 0.07 - ETA: 60s - loss: 4.1555 - acc: 0.07 - ETA: 60s - loss: 4.1610 - acc: 0.07 - ETA: 59s - loss: 4.1567 - acc: 0.07 - ETA: 59s - loss: 4.1498 - acc: 0.08 - ETA: 59s - loss: 4.1438 - acc: 0.08 - ETA: 59s - loss: 4.1464 - acc: 0.07 - ETA: 59s - loss: 4.1358 - acc: 0.08 - ETA: 58s - loss: 4.1347 - acc: 0.08 - ETA: 58s - loss: 4.1256 - acc: 0.08 - ETA: 58s - loss: 4.1375 - acc: 0.08 - ETA: 58s - loss: 4.1347 - acc: 0.08 - ETA: 58s - loss: 4.1305 - acc: 0.08 - ETA: 57s - loss: 4.1218 - acc: 0.08 - ETA: 57s - loss: 4.1216 - acc: 0.08 - ETA: 57s - loss: 4.1247 - acc: 0.08 - ETA: 57s - loss: 4.1322 - acc: 0.08 - ETA: 56s - loss: 4.1277 - acc: 0.08 - ETA: 56s - loss: 4.1229 - acc: 0.08 - ETA: 56s - loss: 4.1262 - acc: 0.08 - ETA: 56s - loss: 4.1319 - acc: 0.08 - ETA: 56s - loss: 4.1308 - acc: 0.08 - ETA: 55s - loss: 4.1257 - acc: 0.08 - ETA: 55s - loss: 4.1261 - acc: 0.08 - ETA: 55s - loss: 4.1222 - acc: 0.08 - ETA: 55s - loss: 4.1228 - acc: 0.08 - ETA: 55s - loss: 4.1248 - acc: 0.08 - ETA: 54s - loss: 4.1234 - acc: 0.08 - ETA: 54s - loss: 4.1287 - acc: 0.08 - ETA: 54s - loss: 4.1290 - acc: 0.08 - ETA: 54s - loss: 4.1307 - acc: 0.08 - ETA: 54s - loss: 4.1302 - acc: 0.08 - ETA: 53s - loss: 4.1289 - acc: 0.08 - ETA: 53s - loss: 4.1315 - acc: 0.08 - ETA: 53s - loss: 4.1331 - acc: 0.08 - ETA: 53s - loss: 4.1350 - acc: 0.08 - ETA: 52s - loss: 4.1369 - acc: 0.08 - ETA: 52s - loss: 4.1394 - acc: 0.08 - ETA: 52s - loss: 4.1348 - acc: 0.08 - ETA: 52s - loss: 4.1371 - acc: 0.08 - ETA: 52s - loss: 4.1384 - acc: 0.08 - ETA: 51s - loss: 4.1361 - acc: 0.08 - ETA: 51s - loss: 4.1376 - acc: 0.08 - ETA: 51s - loss: 4.1390 - acc: 0.08 - ETA: 51s - loss: 4.1393 - acc: 0.08 - ETA: 51s - loss: 4.1390 - acc: 0.08 - ETA: 50s - loss: 4.1449 - acc: 0.08 - ETA: 50s - loss: 4.1434 - acc: 0.08 - ETA: 50s - loss: 4.1409 - acc: 0.08 - ETA: 50s - loss: 4.1364 - acc: 0.08 - ETA: 50s - loss: 4.1390 - acc: 0.08 - ETA: 49s - loss: 4.1375 - acc: 0.08 - ETA: 49s - loss: 4.1369 - acc: 0.08 - ETA: 49s - loss: 4.1336 - acc: 0.08 - ETA: 49s - loss: 4.1294 - acc: 0.08 - ETA: 49s - loss: 4.1276 - acc: 0.08 - ETA: 48s - loss: 4.1285 - acc: 0.08 - ETA: 48s - loss: 4.1296 - acc: 0.08 - ETA: 48s - loss: 4.1293 - acc: 0.08 - ETA: 48s - loss: 4.1292 - acc: 0.08 - ETA: 47s - loss: 4.1263 - acc: 0.08 - ETA: 47s - loss: 4.1257 - acc: 0.08 - ETA: 47s - loss: 4.1266 - acc: 0.07 - ETA: 47s - loss: 4.1268 - acc: 0.07 - ETA: 47s - loss: 4.1249 - acc: 0.07 - ETA: 46s - loss: 4.1238 - acc: 0.08 - ETA: 46s - loss: 4.1230 - acc: 0.08 - ETA: 46s - loss: 4.1251 - acc: 0.08 - ETA: 46s - loss: 4.1272 - acc: 0.08 - ETA: 46s - loss: 4.1314 - acc: 0.08 - ETA: 45s - loss: 4.1352 - acc: 0.07 - ETA: 45s - loss: 4.1347 - acc: 0.07 - ETA: 45s - loss: 4.1352 - acc: 0.07 - ETA: 45s - loss: 4.1366 - acc: 0.07 - ETA: 45s - loss: 4.1365 - acc: 0.07 - ETA: 44s - loss: 4.1337 - acc: 0.08 - ETA: 44s - loss: 4.1337 - acc: 0.07 - ETA: 44s - loss: 4.1318 - acc: 0.07 - ETA: 44s - loss: 4.1325 - acc: 0.07 - ETA: 43s - loss: 4.1288 - acc: 0.08 - ETA: 43s - loss: 4.1319 - acc: 0.08 - ETA: 43s - loss: 4.1323 - acc: 0.08 - ETA: 43s - loss: 4.1339 - acc: 0.08 - ETA: 43s - loss: 4.1343 - acc: 0.08 - ETA: 42s - loss: 4.1324 - acc: 0.08 - ETA: 42s - loss: 4.1300 - acc: 0.08 - ETA: 42s - loss: 4.1292 - acc: 0.08 - ETA: 42s - loss: 4.1288 - acc: 0.08 - ETA: 42s - loss: 4.1290 - acc: 0.08 - ETA: 41s - loss: 4.1279 - acc: 0.08 - ETA: 41s - loss: 4.1284 - acc: 0.08 - ETA: 41s - loss: 4.1317 - acc: 0.07 - ETA: 41s - loss: 4.1296 - acc: 0.08 - ETA: 41s - loss: 4.1325 - acc: 0.07 - ETA: 40s - loss: 4.1336 - acc: 0.07 - ETA: 40s - loss: 4.1367 - acc: 0.07 - ETA: 40s - loss: 4.1381 - acc: 0.07 - ETA: 40s - loss: 4.1355 - acc: 0.08 - ETA: 39s - loss: 4.1349 - acc: 0.08 - ETA: 39s - loss: 4.1332 - acc: 0.08 - ETA: 39s - loss: 4.1331 - acc: 0.08 - ETA: 39s - loss: 4.1335 - acc: 0.07 - ETA: 39s - loss: 4.1315 - acc: 0.08 - ETA: 38s - loss: 4.1296 - acc: 0.08 - ETA: 38s - loss: 4.1339 - acc: 0.07 - ETA: 38s - loss: 4.1325 - acc: 0.08 - ETA: 38s - loss: 4.1345 - acc: 0.08 - ETA: 38s - loss: 4.1351 - acc: 0.08 - ETA: 37s - loss: 4.1352 - acc: 0.08 - ETA: 37s - loss: 4.1397 - acc: 0.08 - ETA: 37s - loss: 4.1381 - acc: 0.08 - ETA: 37s - loss: 4.1383 - acc: 0.08 - ETA: 37s - loss: 4.1388 - acc: 0.08 - ETA: 36s - loss: 4.1356 - acc: 0.08 - ETA: 36s - loss: 4.1362 - acc: 0.08 - ETA: 36s - loss: 4.1337 - acc: 0.08 - ETA: 36s - loss: 4.1320 - acc: 0.08 - ETA: 35s - loss: 4.1289 - acc: 0.08 - ETA: 35s - loss: 4.1264 - acc: 0.08 - ETA: 35s - loss: 4.1277 - acc: 0.08 - ETA: 35s - loss: 4.1287 - acc: 0.08 - ETA: 35s - loss: 4.1293 - acc: 0.08 - ETA: 34s - loss: 4.1296 - acc: 0.08 - ETA: 34s - loss: 4.1297 - acc: 0.08 - ETA: 34s - loss: 4.1298 - acc: 0.08 - ETA: 34s - loss: 4.1293 - acc: 0.08 - ETA: 34s - loss: 4.1299 - acc: 0.08 - ETA: 33s - loss: 4.1281 - acc: 0.08 - ETA: 33s - loss: 4.1272 - acc: 0.08 - ETA: 33s - loss: 4.1275 - acc: 0.08 - ETA: 33s - loss: 4.1289 - acc: 0.08 - ETA: 33s - loss: 4.1287 - acc: 0.08 - ETA: 32s - loss: 4.1281 - acc: 0.08 - ETA: 32s - loss: 4.1268 - acc: 0.08 - ETA: 32s - loss: 4.1272 - acc: 0.08 - ETA: 32s - loss: 4.1247 - acc: 0.08 - ETA: 31s - loss: 4.1264 - acc: 0.08 - ETA: 31s - loss: 4.1231 - acc: 0.08 - ETA: 31s - loss: 4.1236 - acc: 0.08 - ETA: 31s - loss: 4.1236 - acc: 0.08 - ETA: 31s - loss: 4.1245 - acc: 0.08 - ETA: 30s - loss: 4.1224 - acc: 0.08 - ETA: 30s - loss: 4.1253 - acc: 0.08 - ETA: 30s - loss: 4.1275 - acc: 0.08 - ETA: 30s - loss: 4.1254 - acc: 0.08 - ETA: 30s - loss: 4.1229 - acc: 0.08 - ETA: 29s - loss: 4.1236 - acc: 0.08 - ETA: 29s - loss: 4.1235 - acc: 0.08 - ETA: 29s - loss: 4.1265 - acc: 0.08 - ETA: 29s - loss: 4.1263 - acc: 0.08 - ETA: 29s - loss: 4.1249 - acc: 0.08 - ETA: 28s - loss: 4.1249 - acc: 0.08 - ETA: 28s - loss: 4.1226 - acc: 0.08 - ETA: 28s - loss: 4.1218 - acc: 0.08 - ETA: 28s - loss: 4.1200 - acc: 0.08 - ETA: 28s - loss: 4.1200 - acc: 0.08 - ETA: 27s - loss: 4.1216 - acc: 0.08 - ETA: 27s - loss: 4.1206 - acc: 0.08 - ETA: 27s - loss: 4.1224 - acc: 0.08 - ETA: 27s - loss: 4.1215 - acc: 0.08 - ETA: 26s - loss: 4.1205 - acc: 0.08 - ETA: 26s - loss: 4.1207 - acc: 0.08 - ETA: 26s - loss: 4.1190 - acc: 0.08 - ETA: 26s - loss: 4.1202 - acc: 0.08 - ETA: 26s - loss: 4.1215 - acc: 0.08 - ETA: 25s - loss: 4.1202 - acc: 0.08 - ETA: 25s - loss: 4.1204 - acc: 0.08 - ETA: 25s - loss: 4.1202 - acc: 0.08 - ETA: 25s - loss: 4.1203 - acc: 0.08 - ETA: 25s - loss: 4.1197 - acc: 0.0858"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6660/6680 [============================>.] - ETA: 24s - loss: 4.1195 - acc: 0.08 - ETA: 24s - loss: 4.1203 - acc: 0.08 - ETA: 24s - loss: 4.1217 - acc: 0.08 - ETA: 24s - loss: 4.1209 - acc: 0.08 - ETA: 24s - loss: 4.1227 - acc: 0.08 - ETA: 23s - loss: 4.1223 - acc: 0.08 - ETA: 23s - loss: 4.1232 - acc: 0.08 - ETA: 23s - loss: 4.1244 - acc: 0.08 - ETA: 23s - loss: 4.1239 - acc: 0.08 - ETA: 22s - loss: 4.1232 - acc: 0.08 - ETA: 22s - loss: 4.1227 - acc: 0.08 - ETA: 22s - loss: 4.1223 - acc: 0.08 - ETA: 22s - loss: 4.1246 - acc: 0.08 - ETA: 22s - loss: 4.1257 - acc: 0.08 - ETA: 21s - loss: 4.1265 - acc: 0.08 - ETA: 21s - loss: 4.1254 - acc: 0.08 - ETA: 21s - loss: 4.1258 - acc: 0.08 - ETA: 21s - loss: 4.1300 - acc: 0.08 - ETA: 21s - loss: 4.1307 - acc: 0.08 - ETA: 20s - loss: 4.1323 - acc: 0.08 - ETA: 20s - loss: 4.1321 - acc: 0.08 - ETA: 20s - loss: 4.1331 - acc: 0.08 - ETA: 20s - loss: 4.1342 - acc: 0.08 - ETA: 19s - loss: 4.1344 - acc: 0.08 - ETA: 19s - loss: 4.1355 - acc: 0.08 - ETA: 19s - loss: 4.1342 - acc: 0.08 - ETA: 19s - loss: 4.1330 - acc: 0.08 - ETA: 19s - loss: 4.1332 - acc: 0.08 - ETA: 18s - loss: 4.1327 - acc: 0.08 - ETA: 18s - loss: 4.1306 - acc: 0.08 - ETA: 18s - loss: 4.1303 - acc: 0.08 - ETA: 18s - loss: 4.1298 - acc: 0.08 - ETA: 18s - loss: 4.1298 - acc: 0.08 - ETA: 17s - loss: 4.1297 - acc: 0.08 - ETA: 17s - loss: 4.1297 - acc: 0.08 - ETA: 17s - loss: 4.1300 - acc: 0.08 - ETA: 17s - loss: 4.1305 - acc: 0.08 - ETA: 17s - loss: 4.1322 - acc: 0.08 - ETA: 16s - loss: 4.1317 - acc: 0.08 - ETA: 16s - loss: 4.1319 - acc: 0.08 - ETA: 16s - loss: 4.1320 - acc: 0.08 - ETA: 16s - loss: 4.1307 - acc: 0.08 - ETA: 15s - loss: 4.1315 - acc: 0.08 - ETA: 15s - loss: 4.1329 - acc: 0.08 - ETA: 15s - loss: 4.1324 - acc: 0.08 - ETA: 15s - loss: 4.1323 - acc: 0.08 - ETA: 15s - loss: 4.1317 - acc: 0.08 - ETA: 14s - loss: 4.1296 - acc: 0.08 - ETA: 14s - loss: 4.1294 - acc: 0.08 - ETA: 14s - loss: 4.1304 - acc: 0.08 - ETA: 14s - loss: 4.1303 - acc: 0.08 - ETA: 14s - loss: 4.1305 - acc: 0.08 - ETA: 13s - loss: 4.1292 - acc: 0.08 - ETA: 13s - loss: 4.1308 - acc: 0.08 - ETA: 13s - loss: 4.1309 - acc: 0.08 - ETA: 13s - loss: 4.1298 - acc: 0.08 - ETA: 13s - loss: 4.1307 - acc: 0.08 - ETA: 12s - loss: 4.1297 - acc: 0.08 - ETA: 12s - loss: 4.1291 - acc: 0.08 - ETA: 12s - loss: 4.1287 - acc: 0.08 - ETA: 12s - loss: 4.1286 - acc: 0.08 - ETA: 11s - loss: 4.1277 - acc: 0.08 - ETA: 11s - loss: 4.1280 - acc: 0.08 - ETA: 11s - loss: 4.1300 - acc: 0.08 - ETA: 11s - loss: 4.1298 - acc: 0.08 - ETA: 11s - loss: 4.1297 - acc: 0.08 - ETA: 10s - loss: 4.1273 - acc: 0.08 - ETA: 10s - loss: 4.1280 - acc: 0.08 - ETA: 10s - loss: 4.1271 - acc: 0.08 - ETA: 10s - loss: 4.1274 - acc: 0.08 - ETA: 10s - loss: 4.1265 - acc: 0.08 - ETA: 9s - loss: 4.1261 - acc: 0.0854 - ETA: 9s - loss: 4.1265 - acc: 0.085 - ETA: 9s - loss: 4.1274 - acc: 0.085 - ETA: 9s - loss: 4.1262 - acc: 0.085 - ETA: 9s - loss: 4.1264 - acc: 0.085 - ETA: 8s - loss: 4.1266 - acc: 0.085 - ETA: 8s - loss: 4.1268 - acc: 0.085 - ETA: 8s - loss: 4.1258 - acc: 0.084 - ETA: 8s - loss: 4.1276 - acc: 0.084 - ETA: 7s - loss: 4.1287 - acc: 0.084 - ETA: 7s - loss: 4.1306 - acc: 0.084 - ETA: 7s - loss: 4.1309 - acc: 0.084 - ETA: 7s - loss: 4.1296 - acc: 0.084 - ETA: 7s - loss: 4.1305 - acc: 0.084 - ETA: 6s - loss: 4.1303 - acc: 0.083 - ETA: 6s - loss: 4.1324 - acc: 0.083 - ETA: 6s - loss: 4.1324 - acc: 0.083 - ETA: 6s - loss: 4.1329 - acc: 0.083 - ETA: 6s - loss: 4.1330 - acc: 0.084 - ETA: 5s - loss: 4.1349 - acc: 0.084 - ETA: 5s - loss: 4.1351 - acc: 0.084 - ETA: 5s - loss: 4.1352 - acc: 0.084 - ETA: 5s - loss: 4.1355 - acc: 0.084 - ETA: 5s - loss: 4.1355 - acc: 0.083 - ETA: 4s - loss: 4.1359 - acc: 0.083 - ETA: 4s - loss: 4.1367 - acc: 0.083 - ETA: 4s - loss: 4.1369 - acc: 0.084 - ETA: 4s - loss: 4.1377 - acc: 0.083 - ETA: 3s - loss: 4.1369 - acc: 0.083 - ETA: 3s - loss: 4.1367 - acc: 0.083 - ETA: 3s - loss: 4.1368 - acc: 0.083 - ETA: 3s - loss: 4.1387 - acc: 0.083 - ETA: 3s - loss: 4.1389 - acc: 0.083 - ETA: 2s - loss: 4.1381 - acc: 0.083 - ETA: 2s - loss: 4.1381 - acc: 0.083 - ETA: 2s - loss: 4.1372 - acc: 0.083 - ETA: 2s - loss: 4.1372 - acc: 0.083 - ETA: 2s - loss: 4.1368 - acc: 0.083 - ETA: 1s - loss: 4.1362 - acc: 0.084 - ETA: 1s - loss: 4.1376 - acc: 0.084 - ETA: 1s - loss: 4.1370 - acc: 0.083 - ETA: 1s - loss: 4.1378 - acc: 0.083 - ETA: 1s - loss: 4.1391 - acc: 0.083 - ETA: 0s - loss: 4.1392 - acc: 0.083 - ETA: 0s - loss: 4.1393 - acc: 0.083 - ETA: 0s - loss: 4.1402 - acc: 0.083 - ETA: 0s - loss: 4.1410 - acc: 0.0838Epoch 00026: val_loss did not improve\n",
      "6680/6680 [==============================] - 73s - loss: 4.1409 - acc: 0.0841 - val_loss: 4.2456 - val_acc: 0.0695\n",
      "Epoch 28/32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4300/6680 [==================>...........] - ETA: 68s - loss: 4.0703 - acc: 0.05 - ETA: 68s - loss: 4.0646 - acc: 0.10 - ETA: 67s - loss: 3.9436 - acc: 0.08 - ETA: 68s - loss: 3.9859 - acc: 0.10 - ETA: 68s - loss: 3.9716 - acc: 0.09 - ETA: 68s - loss: 4.0046 - acc: 0.09 - ETA: 67s - loss: 4.0390 - acc: 0.09 - ETA: 67s - loss: 4.0574 - acc: 0.08 - ETA: 67s - loss: 4.0419 - acc: 0.10 - ETA: 68s - loss: 4.0201 - acc: 0.09 - ETA: 67s - loss: 3.9985 - acc: 0.10 - ETA: 67s - loss: 4.0244 - acc: 0.10 - ETA: 67s - loss: 4.0242 - acc: 0.10 - ETA: 66s - loss: 4.0568 - acc: 0.10 - ETA: 66s - loss: 4.0681 - acc: 0.10 - ETA: 66s - loss: 4.1062 - acc: 0.09 - ETA: 66s - loss: 4.1041 - acc: 0.09 - ETA: 66s - loss: 4.0781 - acc: 0.10 - ETA: 66s - loss: 4.0713 - acc: 0.09 - ETA: 65s - loss: 4.0417 - acc: 0.10 - ETA: 65s - loss: 4.0227 - acc: 0.10 - ETA: 65s - loss: 4.0342 - acc: 0.10 - ETA: 65s - loss: 4.0464 - acc: 0.10 - ETA: 64s - loss: 4.0500 - acc: 0.10 - ETA: 64s - loss: 4.0571 - acc: 0.10 - ETA: 64s - loss: 4.0369 - acc: 0.10 - ETA: 64s - loss: 4.0281 - acc: 0.10 - ETA: 64s - loss: 4.0118 - acc: 0.11 - ETA: 63s - loss: 3.9959 - acc: 0.11 - ETA: 63s - loss: 3.9975 - acc: 0.11 - ETA: 63s - loss: 3.9910 - acc: 0.11 - ETA: 63s - loss: 3.9885 - acc: 0.11 - ETA: 63s - loss: 4.0074 - acc: 0.11 - ETA: 62s - loss: 4.0195 - acc: 0.11 - ETA: 62s - loss: 4.0231 - acc: 0.11 - ETA: 62s - loss: 4.0315 - acc: 0.11 - ETA: 62s - loss: 4.0351 - acc: 0.11 - ETA: 62s - loss: 4.0369 - acc: 0.11 - ETA: 61s - loss: 4.0400 - acc: 0.11 - ETA: 61s - loss: 4.0388 - acc: 0.11 - ETA: 61s - loss: 4.0505 - acc: 0.10 - ETA: 61s - loss: 4.0473 - acc: 0.10 - ETA: 60s - loss: 4.0561 - acc: 0.10 - ETA: 60s - loss: 4.0656 - acc: 0.10 - ETA: 60s - loss: 4.0621 - acc: 0.11 - ETA: 60s - loss: 4.0701 - acc: 0.10 - ETA: 60s - loss: 4.0652 - acc: 0.10 - ETA: 59s - loss: 4.0666 - acc: 0.10 - ETA: 59s - loss: 4.0533 - acc: 0.11 - ETA: 59s - loss: 4.0639 - acc: 0.11 - ETA: 59s - loss: 4.0629 - acc: 0.10 - ETA: 58s - loss: 4.0633 - acc: 0.11 - ETA: 58s - loss: 4.0709 - acc: 0.11 - ETA: 58s - loss: 4.0683 - acc: 0.11 - ETA: 58s - loss: 4.0618 - acc: 0.11 - ETA: 58s - loss: 4.0685 - acc: 0.11 - ETA: 57s - loss: 4.0660 - acc: 0.11 - ETA: 57s - loss: 4.0727 - acc: 0.11 - ETA: 57s - loss: 4.0747 - acc: 0.11 - ETA: 57s - loss: 4.0743 - acc: 0.11 - ETA: 57s - loss: 4.0776 - acc: 0.11 - ETA: 56s - loss: 4.0736 - acc: 0.11 - ETA: 56s - loss: 4.0703 - acc: 0.11 - ETA: 56s - loss: 4.0723 - acc: 0.11 - ETA: 56s - loss: 4.0727 - acc: 0.11 - ETA: 56s - loss: 4.0785 - acc: 0.11 - ETA: 55s - loss: 4.0835 - acc: 0.10 - ETA: 55s - loss: 4.0846 - acc: 0.10 - ETA: 55s - loss: 4.0857 - acc: 0.10 - ETA: 55s - loss: 4.0909 - acc: 0.10 - ETA: 55s - loss: 4.0891 - acc: 0.10 - ETA: 54s - loss: 4.0867 - acc: 0.10 - ETA: 54s - loss: 4.0941 - acc: 0.10 - ETA: 54s - loss: 4.0982 - acc: 0.10 - ETA: 54s - loss: 4.0981 - acc: 0.10 - ETA: 54s - loss: 4.0912 - acc: 0.10 - ETA: 53s - loss: 4.0926 - acc: 0.10 - ETA: 53s - loss: 4.0939 - acc: 0.10 - ETA: 53s - loss: 4.0934 - acc: 0.10 - ETA: 53s - loss: 4.0921 - acc: 0.10 - ETA: 52s - loss: 4.0869 - acc: 0.10 - ETA: 52s - loss: 4.0882 - acc: 0.10 - ETA: 52s - loss: 4.0908 - acc: 0.10 - ETA: 52s - loss: 4.0922 - acc: 0.10 - ETA: 52s - loss: 4.0862 - acc: 0.10 - ETA: 51s - loss: 4.0857 - acc: 0.10 - ETA: 51s - loss: 4.0832 - acc: 0.10 - ETA: 51s - loss: 4.0784 - acc: 0.10 - ETA: 51s - loss: 4.0711 - acc: 0.10 - ETA: 51s - loss: 4.0764 - acc: 0.10 - ETA: 50s - loss: 4.0780 - acc: 0.10 - ETA: 50s - loss: 4.0781 - acc: 0.10 - ETA: 50s - loss: 4.0821 - acc: 0.10 - ETA: 50s - loss: 4.0805 - acc: 0.10 - ETA: 50s - loss: 4.0846 - acc: 0.10 - ETA: 49s - loss: 4.0855 - acc: 0.10 - ETA: 49s - loss: 4.0824 - acc: 0.10 - ETA: 49s - loss: 4.0856 - acc: 0.10 - ETA: 49s - loss: 4.0821 - acc: 0.10 - ETA: 49s - loss: 4.0803 - acc: 0.10 - ETA: 48s - loss: 4.0800 - acc: 0.10 - ETA: 48s - loss: 4.0846 - acc: 0.10 - ETA: 48s - loss: 4.0876 - acc: 0.10 - ETA: 48s - loss: 4.0900 - acc: 0.10 - ETA: 48s - loss: 4.0904 - acc: 0.10 - ETA: 47s - loss: 4.0893 - acc: 0.10 - ETA: 47s - loss: 4.0865 - acc: 0.10 - ETA: 47s - loss: 4.0873 - acc: 0.10 - ETA: 47s - loss: 4.0876 - acc: 0.10 - ETA: 46s - loss: 4.0905 - acc: 0.10 - ETA: 46s - loss: 4.0907 - acc: 0.10 - ETA: 46s - loss: 4.0938 - acc: 0.10 - ETA: 46s - loss: 4.0946 - acc: 0.10 - ETA: 46s - loss: 4.0935 - acc: 0.10 - ETA: 45s - loss: 4.0957 - acc: 0.09 - ETA: 45s - loss: 4.0956 - acc: 0.09 - ETA: 45s - loss: 4.0978 - acc: 0.09 - ETA: 45s - loss: 4.1019 - acc: 0.09 - ETA: 45s - loss: 4.0983 - acc: 0.09 - ETA: 44s - loss: 4.0976 - acc: 0.09 - ETA: 44s - loss: 4.0941 - acc: 0.09 - ETA: 44s - loss: 4.0953 - acc: 0.09 - ETA: 44s - loss: 4.1024 - acc: 0.09 - ETA: 44s - loss: 4.1044 - acc: 0.09 - ETA: 43s - loss: 4.1042 - acc: 0.09 - ETA: 43s - loss: 4.1083 - acc: 0.09 - ETA: 43s - loss: 4.1083 - acc: 0.09 - ETA: 43s - loss: 4.1075 - acc: 0.09 - ETA: 42s - loss: 4.1040 - acc: 0.09 - ETA: 42s - loss: 4.1055 - acc: 0.09 - ETA: 42s - loss: 4.1063 - acc: 0.09 - ETA: 42s - loss: 4.1048 - acc: 0.09 - ETA: 42s - loss: 4.1019 - acc: 0.09 - ETA: 41s - loss: 4.1035 - acc: 0.09 - ETA: 41s - loss: 4.1059 - acc: 0.09 - ETA: 41s - loss: 4.1067 - acc: 0.09 - ETA: 41s - loss: 4.1013 - acc: 0.09 - ETA: 41s - loss: 4.1017 - acc: 0.09 - ETA: 40s - loss: 4.1054 - acc: 0.09 - ETA: 40s - loss: 4.1054 - acc: 0.09 - ETA: 40s - loss: 4.1070 - acc: 0.09 - ETA: 40s - loss: 4.1084 - acc: 0.09 - ETA: 40s - loss: 4.1077 - acc: 0.09 - ETA: 39s - loss: 4.1066 - acc: 0.09 - ETA: 39s - loss: 4.1069 - acc: 0.09 - ETA: 39s - loss: 4.1069 - acc: 0.09 - ETA: 39s - loss: 4.1066 - acc: 0.09 - ETA: 38s - loss: 4.1048 - acc: 0.09 - ETA: 38s - loss: 4.1052 - acc: 0.09 - ETA: 38s - loss: 4.1054 - acc: 0.09 - ETA: 38s - loss: 4.1080 - acc: 0.09 - ETA: 38s - loss: 4.1077 - acc: 0.09 - ETA: 37s - loss: 4.1085 - acc: 0.09 - ETA: 37s - loss: 4.1077 - acc: 0.09 - ETA: 37s - loss: 4.1072 - acc: 0.09 - ETA: 37s - loss: 4.1074 - acc: 0.09 - ETA: 37s - loss: 4.1064 - acc: 0.09 - ETA: 36s - loss: 4.1058 - acc: 0.09 - ETA: 36s - loss: 4.1085 - acc: 0.09 - ETA: 36s - loss: 4.1078 - acc: 0.09 - ETA: 36s - loss: 4.1061 - acc: 0.09 - ETA: 36s - loss: 4.1063 - acc: 0.09 - ETA: 35s - loss: 4.1077 - acc: 0.09 - ETA: 35s - loss: 4.1086 - acc: 0.09 - ETA: 35s - loss: 4.1110 - acc: 0.09 - ETA: 35s - loss: 4.1117 - acc: 0.09 - ETA: 35s - loss: 4.1100 - acc: 0.09 - ETA: 34s - loss: 4.1079 - acc: 0.09 - ETA: 34s - loss: 4.1076 - acc: 0.09 - ETA: 34s - loss: 4.1105 - acc: 0.09 - ETA: 34s - loss: 4.1107 - acc: 0.09 - ETA: 33s - loss: 4.1107 - acc: 0.09 - ETA: 33s - loss: 4.1096 - acc: 0.09 - ETA: 33s - loss: 4.1107 - acc: 0.09 - ETA: 33s - loss: 4.1098 - acc: 0.09 - ETA: 33s - loss: 4.1107 - acc: 0.09 - ETA: 32s - loss: 4.1122 - acc: 0.09 - ETA: 32s - loss: 4.1128 - acc: 0.09 - ETA: 32s - loss: 4.1118 - acc: 0.09 - ETA: 32s - loss: 4.1125 - acc: 0.09 - ETA: 32s - loss: 4.1133 - acc: 0.09 - ETA: 31s - loss: 4.1121 - acc: 0.09 - ETA: 31s - loss: 4.1110 - acc: 0.09 - ETA: 31s - loss: 4.1140 - acc: 0.09 - ETA: 31s - loss: 4.1136 - acc: 0.09 - ETA: 31s - loss: 4.1126 - acc: 0.09 - ETA: 30s - loss: 4.1103 - acc: 0.09 - ETA: 30s - loss: 4.1093 - acc: 0.09 - ETA: 30s - loss: 4.1108 - acc: 0.09 - ETA: 30s - loss: 4.1133 - acc: 0.09 - ETA: 29s - loss: 4.1147 - acc: 0.09 - ETA: 29s - loss: 4.1131 - acc: 0.09 - ETA: 29s - loss: 4.1140 - acc: 0.09 - ETA: 29s - loss: 4.1136 - acc: 0.09 - ETA: 29s - loss: 4.1149 - acc: 0.09 - ETA: 28s - loss: 4.1150 - acc: 0.09 - ETA: 28s - loss: 4.1144 - acc: 0.09 - ETA: 28s - loss: 4.1161 - acc: 0.09 - ETA: 28s - loss: 4.1162 - acc: 0.09 - ETA: 28s - loss: 4.1165 - acc: 0.09 - ETA: 27s - loss: 4.1164 - acc: 0.09 - ETA: 27s - loss: 4.1161 - acc: 0.09 - ETA: 27s - loss: 4.1160 - acc: 0.09 - ETA: 27s - loss: 4.1140 - acc: 0.09 - ETA: 27s - loss: 4.1165 - acc: 0.09 - ETA: 26s - loss: 4.1183 - acc: 0.09 - ETA: 26s - loss: 4.1170 - acc: 0.09 - ETA: 26s - loss: 4.1130 - acc: 0.09 - ETA: 26s - loss: 4.1116 - acc: 0.09 - ETA: 26s - loss: 4.1132 - acc: 0.09 - ETA: 25s - loss: 4.1136 - acc: 0.09 - ETA: 25s - loss: 4.1143 - acc: 0.09 - ETA: 25s - loss: 4.1142 - acc: 0.09 - ETA: 25s - loss: 4.1145 - acc: 0.09 - ETA: 24s - loss: 4.1140 - acc: 0.0947"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6660/6680 [============================>.] - ETA: 24s - loss: 4.1135 - acc: 0.09 - ETA: 24s - loss: 4.1133 - acc: 0.09 - ETA: 24s - loss: 4.1127 - acc: 0.09 - ETA: 24s - loss: 4.1144 - acc: 0.09 - ETA: 23s - loss: 4.1137 - acc: 0.09 - ETA: 23s - loss: 4.1156 - acc: 0.09 - ETA: 23s - loss: 4.1155 - acc: 0.09 - ETA: 23s - loss: 4.1169 - acc: 0.09 - ETA: 23s - loss: 4.1163 - acc: 0.09 - ETA: 22s - loss: 4.1173 - acc: 0.09 - ETA: 22s - loss: 4.1161 - acc: 0.09 - ETA: 22s - loss: 4.1146 - acc: 0.09 - ETA: 22s - loss: 4.1153 - acc: 0.09 - ETA: 22s - loss: 4.1146 - acc: 0.09 - ETA: 21s - loss: 4.1160 - acc: 0.09 - ETA: 21s - loss: 4.1169 - acc: 0.09 - ETA: 21s - loss: 4.1175 - acc: 0.09 - ETA: 21s - loss: 4.1172 - acc: 0.09 - ETA: 20s - loss: 4.1162 - acc: 0.09 - ETA: 20s - loss: 4.1171 - acc: 0.09 - ETA: 20s - loss: 4.1172 - acc: 0.09 - ETA: 20s - loss: 4.1163 - acc: 0.09 - ETA: 20s - loss: 4.1170 - acc: 0.09 - ETA: 19s - loss: 4.1171 - acc: 0.09 - ETA: 19s - loss: 4.1159 - acc: 0.09 - ETA: 19s - loss: 4.1152 - acc: 0.09 - ETA: 19s - loss: 4.1139 - acc: 0.09 - ETA: 19s - loss: 4.1133 - acc: 0.09 - ETA: 18s - loss: 4.1151 - acc: 0.09 - ETA: 18s - loss: 4.1161 - acc: 0.09 - ETA: 18s - loss: 4.1166 - acc: 0.09 - ETA: 18s - loss: 4.1152 - acc: 0.09 - ETA: 18s - loss: 4.1167 - acc: 0.09 - ETA: 17s - loss: 4.1169 - acc: 0.09 - ETA: 17s - loss: 4.1157 - acc: 0.09 - ETA: 17s - loss: 4.1124 - acc: 0.09 - ETA: 17s - loss: 4.1141 - acc: 0.09 - ETA: 16s - loss: 4.1132 - acc: 0.09 - ETA: 16s - loss: 4.1158 - acc: 0.09 - ETA: 16s - loss: 4.1160 - acc: 0.09 - ETA: 16s - loss: 4.1166 - acc: 0.09 - ETA: 16s - loss: 4.1172 - acc: 0.09 - ETA: 15s - loss: 4.1172 - acc: 0.09 - ETA: 15s - loss: 4.1169 - acc: 0.09 - ETA: 15s - loss: 4.1175 - acc: 0.09 - ETA: 15s - loss: 4.1169 - acc: 0.09 - ETA: 15s - loss: 4.1147 - acc: 0.09 - ETA: 14s - loss: 4.1147 - acc: 0.09 - ETA: 14s - loss: 4.1145 - acc: 0.09 - ETA: 14s - loss: 4.1131 - acc: 0.09 - ETA: 14s - loss: 4.1145 - acc: 0.09 - ETA: 14s - loss: 4.1144 - acc: 0.09 - ETA: 13s - loss: 4.1136 - acc: 0.09 - ETA: 13s - loss: 4.1140 - acc: 0.09 - ETA: 13s - loss: 4.1149 - acc: 0.09 - ETA: 13s - loss: 4.1151 - acc: 0.09 - ETA: 13s - loss: 4.1166 - acc: 0.09 - ETA: 12s - loss: 4.1161 - acc: 0.09 - ETA: 12s - loss: 4.1154 - acc: 0.09 - ETA: 12s - loss: 4.1168 - acc: 0.09 - ETA: 12s - loss: 4.1170 - acc: 0.09 - ETA: 11s - loss: 4.1162 - acc: 0.09 - ETA: 11s - loss: 4.1165 - acc: 0.09 - ETA: 11s - loss: 4.1163 - acc: 0.09 - ETA: 11s - loss: 4.1167 - acc: 0.09 - ETA: 11s - loss: 4.1173 - acc: 0.09 - ETA: 10s - loss: 4.1179 - acc: 0.09 - ETA: 10s - loss: 4.1165 - acc: 0.09 - ETA: 10s - loss: 4.1168 - acc: 0.09 - ETA: 10s - loss: 4.1164 - acc: 0.09 - ETA: 10s - loss: 4.1155 - acc: 0.09 - ETA: 9s - loss: 4.1185 - acc: 0.0922 - ETA: 9s - loss: 4.1180 - acc: 0.092 - ETA: 9s - loss: 4.1180 - acc: 0.091 - ETA: 9s - loss: 4.1182 - acc: 0.091 - ETA: 9s - loss: 4.1187 - acc: 0.091 - ETA: 8s - loss: 4.1182 - acc: 0.092 - ETA: 8s - loss: 4.1171 - acc: 0.091 - ETA: 8s - loss: 4.1175 - acc: 0.091 - ETA: 8s - loss: 4.1183 - acc: 0.091 - ETA: 7s - loss: 4.1179 - acc: 0.091 - ETA: 7s - loss: 4.1184 - acc: 0.091 - ETA: 7s - loss: 4.1181 - acc: 0.091 - ETA: 7s - loss: 4.1195 - acc: 0.091 - ETA: 7s - loss: 4.1214 - acc: 0.090 - ETA: 6s - loss: 4.1211 - acc: 0.090 - ETA: 6s - loss: 4.1212 - acc: 0.090 - ETA: 6s - loss: 4.1235 - acc: 0.090 - ETA: 6s - loss: 4.1223 - acc: 0.090 - ETA: 6s - loss: 4.1230 - acc: 0.090 - ETA: 5s - loss: 4.1235 - acc: 0.090 - ETA: 5s - loss: 4.1227 - acc: 0.090 - ETA: 5s - loss: 4.1227 - acc: 0.090 - ETA: 5s - loss: 4.1229 - acc: 0.090 - ETA: 5s - loss: 4.1243 - acc: 0.090 - ETA: 4s - loss: 4.1243 - acc: 0.089 - ETA: 4s - loss: 4.1241 - acc: 0.089 - ETA: 4s - loss: 4.1255 - acc: 0.089 - ETA: 4s - loss: 4.1260 - acc: 0.089 - ETA: 3s - loss: 4.1248 - acc: 0.090 - ETA: 3s - loss: 4.1246 - acc: 0.090 - ETA: 3s - loss: 4.1239 - acc: 0.090 - ETA: 3s - loss: 4.1238 - acc: 0.089 - ETA: 3s - loss: 4.1240 - acc: 0.089 - ETA: 2s - loss: 4.1235 - acc: 0.089 - ETA: 2s - loss: 4.1240 - acc: 0.089 - ETA: 2s - loss: 4.1247 - acc: 0.089 - ETA: 2s - loss: 4.1262 - acc: 0.089 - ETA: 2s - loss: 4.1257 - acc: 0.089 - ETA: 1s - loss: 4.1264 - acc: 0.089 - ETA: 1s - loss: 4.1254 - acc: 0.089 - ETA: 1s - loss: 4.1242 - acc: 0.089 - ETA: 1s - loss: 4.1231 - acc: 0.089 - ETA: 1s - loss: 4.1228 - acc: 0.089 - ETA: 0s - loss: 4.1222 - acc: 0.089 - ETA: 0s - loss: 4.1229 - acc: 0.089 - ETA: 0s - loss: 4.1228 - acc: 0.089 - ETA: 0s - loss: 4.1224 - acc: 0.0899Epoch 00027: val_loss improved from 4.24149 to 4.18566, saving model to saved_models/weights.best.from_scratch.hdf5\n",
      "6680/6680 [==============================] - 72s - loss: 4.1218 - acc: 0.0901 - val_loss: 4.1857 - val_acc: 0.0814\n",
      "Epoch 29/32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4300/6680 [==================>...........] - ETA: 66s - loss: 3.9595 - acc: 0.10 - ETA: 69s - loss: 4.2298 - acc: 0.07 - ETA: 68s - loss: 4.2100 - acc: 0.06 - ETA: 69s - loss: 4.1829 - acc: 0.06 - ETA: 68s - loss: 4.1979 - acc: 0.06 - ETA: 68s - loss: 4.2102 - acc: 0.06 - ETA: 68s - loss: 4.1790 - acc: 0.07 - ETA: 68s - loss: 4.1918 - acc: 0.06 - ETA: 68s - loss: 4.1546 - acc: 0.06 - ETA: 67s - loss: 4.1634 - acc: 0.07 - ETA: 67s - loss: 4.1736 - acc: 0.06 - ETA: 67s - loss: 4.1401 - acc: 0.06 - ETA: 67s - loss: 4.1393 - acc: 0.06 - ETA: 67s - loss: 4.1182 - acc: 0.06 - ETA: 67s - loss: 4.0932 - acc: 0.08 - ETA: 66s - loss: 4.0748 - acc: 0.08 - ETA: 66s - loss: 4.1053 - acc: 0.08 - ETA: 66s - loss: 4.0994 - acc: 0.08 - ETA: 66s - loss: 4.0906 - acc: 0.08 - ETA: 65s - loss: 4.0916 - acc: 0.08 - ETA: 65s - loss: 4.0831 - acc: 0.08 - ETA: 65s - loss: 4.0637 - acc: 0.08 - ETA: 65s - loss: 4.0604 - acc: 0.09 - ETA: 65s - loss: 4.0651 - acc: 0.08 - ETA: 65s - loss: 4.0388 - acc: 0.09 - ETA: 64s - loss: 4.0294 - acc: 0.09 - ETA: 64s - loss: 4.0315 - acc: 0.09 - ETA: 64s - loss: 4.0288 - acc: 0.09 - ETA: 64s - loss: 4.0154 - acc: 0.09 - ETA: 63s - loss: 4.0065 - acc: 0.09 - ETA: 63s - loss: 4.0032 - acc: 0.09 - ETA: 63s - loss: 4.0113 - acc: 0.09 - ETA: 63s - loss: 4.0122 - acc: 0.09 - ETA: 63s - loss: 4.0125 - acc: 0.09 - ETA: 62s - loss: 4.0120 - acc: 0.09 - ETA: 62s - loss: 4.0137 - acc: 0.09 - ETA: 62s - loss: 4.0101 - acc: 0.09 - ETA: 62s - loss: 4.0144 - acc: 0.09 - ETA: 62s - loss: 4.0223 - acc: 0.09 - ETA: 61s - loss: 4.0272 - acc: 0.09 - ETA: 61s - loss: 4.0325 - acc: 0.09 - ETA: 61s - loss: 4.0264 - acc: 0.09 - ETA: 61s - loss: 4.0381 - acc: 0.08 - ETA: 61s - loss: 4.0406 - acc: 0.08 - ETA: 60s - loss: 4.0429 - acc: 0.08 - ETA: 60s - loss: 4.0491 - acc: 0.08 - ETA: 60s - loss: 4.0507 - acc: 0.08 - ETA: 60s - loss: 4.0639 - acc: 0.08 - ETA: 59s - loss: 4.0706 - acc: 0.08 - ETA: 59s - loss: 4.0705 - acc: 0.08 - ETA: 59s - loss: 4.0668 - acc: 0.08 - ETA: 59s - loss: 4.0633 - acc: 0.08 - ETA: 59s - loss: 4.0584 - acc: 0.08 - ETA: 58s - loss: 4.0630 - acc: 0.08 - ETA: 58s - loss: 4.0638 - acc: 0.08 - ETA: 58s - loss: 4.0584 - acc: 0.08 - ETA: 58s - loss: 4.0586 - acc: 0.08 - ETA: 58s - loss: 4.0575 - acc: 0.08 - ETA: 57s - loss: 4.0568 - acc: 0.08 - ETA: 57s - loss: 4.0580 - acc: 0.08 - ETA: 57s - loss: 4.0576 - acc: 0.08 - ETA: 57s - loss: 4.0536 - acc: 0.08 - ETA: 56s - loss: 4.0441 - acc: 0.08 - ETA: 56s - loss: 4.0458 - acc: 0.08 - ETA: 56s - loss: 4.0479 - acc: 0.08 - ETA: 56s - loss: 4.0430 - acc: 0.08 - ETA: 56s - loss: 4.0384 - acc: 0.08 - ETA: 55s - loss: 4.0417 - acc: 0.08 - ETA: 55s - loss: 4.0397 - acc: 0.08 - ETA: 55s - loss: 4.0343 - acc: 0.08 - ETA: 55s - loss: 4.0338 - acc: 0.08 - ETA: 55s - loss: 4.0362 - acc: 0.09 - ETA: 54s - loss: 4.0373 - acc: 0.09 - ETA: 54s - loss: 4.0371 - acc: 0.09 - ETA: 54s - loss: 4.0282 - acc: 0.09 - ETA: 54s - loss: 4.0304 - acc: 0.09 - ETA: 54s - loss: 4.0317 - acc: 0.09 - ETA: 53s - loss: 4.0315 - acc: 0.09 - ETA: 53s - loss: 4.0272 - acc: 0.09 - ETA: 53s - loss: 4.0224 - acc: 0.09 - ETA: 53s - loss: 4.0243 - acc: 0.09 - ETA: 52s - loss: 4.0302 - acc: 0.09 - ETA: 52s - loss: 4.0324 - acc: 0.09 - ETA: 52s - loss: 4.0333 - acc: 0.09 - ETA: 52s - loss: 4.0326 - acc: 0.09 - ETA: 52s - loss: 4.0304 - acc: 0.09 - ETA: 51s - loss: 4.0351 - acc: 0.09 - ETA: 51s - loss: 4.0338 - acc: 0.09 - ETA: 51s - loss: 4.0366 - acc: 0.09 - ETA: 51s - loss: 4.0370 - acc: 0.09 - ETA: 51s - loss: 4.0374 - acc: 0.09 - ETA: 50s - loss: 4.0414 - acc: 0.09 - ETA: 50s - loss: 4.0437 - acc: 0.09 - ETA: 50s - loss: 4.0483 - acc: 0.09 - ETA: 50s - loss: 4.0482 - acc: 0.09 - ETA: 50s - loss: 4.0458 - acc: 0.09 - ETA: 49s - loss: 4.0428 - acc: 0.09 - ETA: 49s - loss: 4.0423 - acc: 0.09 - ETA: 49s - loss: 4.0443 - acc: 0.09 - ETA: 49s - loss: 4.0533 - acc: 0.09 - ETA: 49s - loss: 4.0516 - acc: 0.09 - ETA: 48s - loss: 4.0520 - acc: 0.09 - ETA: 48s - loss: 4.0531 - acc: 0.09 - ETA: 48s - loss: 4.0502 - acc: 0.09 - ETA: 48s - loss: 4.0600 - acc: 0.09 - ETA: 47s - loss: 4.0584 - acc: 0.09 - ETA: 47s - loss: 4.0584 - acc: 0.09 - ETA: 47s - loss: 4.0589 - acc: 0.09 - ETA: 47s - loss: 4.0573 - acc: 0.09 - ETA: 47s - loss: 4.0564 - acc: 0.09 - ETA: 46s - loss: 4.0549 - acc: 0.09 - ETA: 46s - loss: 4.0571 - acc: 0.09 - ETA: 46s - loss: 4.0575 - acc: 0.09 - ETA: 46s - loss: 4.0583 - acc: 0.09 - ETA: 46s - loss: 4.0601 - acc: 0.09 - ETA: 45s - loss: 4.0612 - acc: 0.09 - ETA: 45s - loss: 4.0637 - acc: 0.09 - ETA: 45s - loss: 4.0644 - acc: 0.09 - ETA: 45s - loss: 4.0663 - acc: 0.09 - ETA: 44s - loss: 4.0683 - acc: 0.09 - ETA: 44s - loss: 4.0697 - acc: 0.09 - ETA: 44s - loss: 4.0671 - acc: 0.09 - ETA: 44s - loss: 4.0692 - acc: 0.09 - ETA: 44s - loss: 4.0654 - acc: 0.09 - ETA: 43s - loss: 4.0631 - acc: 0.09 - ETA: 43s - loss: 4.0636 - acc: 0.09 - ETA: 43s - loss: 4.0644 - acc: 0.09 - ETA: 43s - loss: 4.0662 - acc: 0.09 - ETA: 43s - loss: 4.0677 - acc: 0.09 - ETA: 42s - loss: 4.0680 - acc: 0.09 - ETA: 42s - loss: 4.0662 - acc: 0.09 - ETA: 42s - loss: 4.0673 - acc: 0.09 - ETA: 42s - loss: 4.0664 - acc: 0.09 - ETA: 42s - loss: 4.0677 - acc: 0.09 - ETA: 41s - loss: 4.0709 - acc: 0.09 - ETA: 41s - loss: 4.0699 - acc: 0.09 - ETA: 41s - loss: 4.0699 - acc: 0.09 - ETA: 41s - loss: 4.0685 - acc: 0.09 - ETA: 40s - loss: 4.0656 - acc: 0.09 - ETA: 40s - loss: 4.0676 - acc: 0.09 - ETA: 40s - loss: 4.0658 - acc: 0.09 - ETA: 40s - loss: 4.0686 - acc: 0.08 - ETA: 40s - loss: 4.0663 - acc: 0.09 - ETA: 39s - loss: 4.0686 - acc: 0.08 - ETA: 39s - loss: 4.0689 - acc: 0.09 - ETA: 39s - loss: 4.0662 - acc: 0.09 - ETA: 39s - loss: 4.0658 - acc: 0.08 - ETA: 39s - loss: 4.0667 - acc: 0.08 - ETA: 38s - loss: 4.0670 - acc: 0.08 - ETA: 38s - loss: 4.0653 - acc: 0.08 - ETA: 38s - loss: 4.0686 - acc: 0.08 - ETA: 38s - loss: 4.0707 - acc: 0.08 - ETA: 38s - loss: 4.0708 - acc: 0.08 - ETA: 37s - loss: 4.0719 - acc: 0.08 - ETA: 37s - loss: 4.0694 - acc: 0.08 - ETA: 37s - loss: 4.0749 - acc: 0.08 - ETA: 37s - loss: 4.0768 - acc: 0.08 - ETA: 36s - loss: 4.0779 - acc: 0.08 - ETA: 36s - loss: 4.0782 - acc: 0.08 - ETA: 36s - loss: 4.0797 - acc: 0.08 - ETA: 36s - loss: 4.0772 - acc: 0.08 - ETA: 36s - loss: 4.0781 - acc: 0.08 - ETA: 35s - loss: 4.0787 - acc: 0.08 - ETA: 35s - loss: 4.0791 - acc: 0.08 - ETA: 35s - loss: 4.0784 - acc: 0.09 - ETA: 35s - loss: 4.0822 - acc: 0.08 - ETA: 35s - loss: 4.0831 - acc: 0.08 - ETA: 34s - loss: 4.0843 - acc: 0.08 - ETA: 34s - loss: 4.0837 - acc: 0.08 - ETA: 34s - loss: 4.0836 - acc: 0.08 - ETA: 34s - loss: 4.0854 - acc: 0.08 - ETA: 34s - loss: 4.0844 - acc: 0.08 - ETA: 33s - loss: 4.0854 - acc: 0.08 - ETA: 33s - loss: 4.0840 - acc: 0.08 - ETA: 33s - loss: 4.0840 - acc: 0.08 - ETA: 33s - loss: 4.0824 - acc: 0.08 - ETA: 33s - loss: 4.0833 - acc: 0.08 - ETA: 32s - loss: 4.0827 - acc: 0.08 - ETA: 32s - loss: 4.0819 - acc: 0.08 - ETA: 32s - loss: 4.0826 - acc: 0.08 - ETA: 32s - loss: 4.0816 - acc: 0.08 - ETA: 31s - loss: 4.0828 - acc: 0.08 - ETA: 31s - loss: 4.0823 - acc: 0.08 - ETA: 31s - loss: 4.0802 - acc: 0.08 - ETA: 31s - loss: 4.0794 - acc: 0.08 - ETA: 31s - loss: 4.0791 - acc: 0.08 - ETA: 30s - loss: 4.0793 - acc: 0.08 - ETA: 30s - loss: 4.0773 - acc: 0.08 - ETA: 30s - loss: 4.0765 - acc: 0.08 - ETA: 30s - loss: 4.0788 - acc: 0.08 - ETA: 30s - loss: 4.0812 - acc: 0.08 - ETA: 29s - loss: 4.0787 - acc: 0.08 - ETA: 29s - loss: 4.0780 - acc: 0.08 - ETA: 29s - loss: 4.0772 - acc: 0.08 - ETA: 29s - loss: 4.0787 - acc: 0.08 - ETA: 29s - loss: 4.0779 - acc: 0.08 - ETA: 28s - loss: 4.0783 - acc: 0.08 - ETA: 28s - loss: 4.0811 - acc: 0.08 - ETA: 28s - loss: 4.0808 - acc: 0.08 - ETA: 28s - loss: 4.0815 - acc: 0.08 - ETA: 27s - loss: 4.0808 - acc: 0.08 - ETA: 27s - loss: 4.0812 - acc: 0.08 - ETA: 27s - loss: 4.0814 - acc: 0.08 - ETA: 27s - loss: 4.0821 - acc: 0.08 - ETA: 27s - loss: 4.0800 - acc: 0.08 - ETA: 26s - loss: 4.0805 - acc: 0.08 - ETA: 26s - loss: 4.0805 - acc: 0.08 - ETA: 26s - loss: 4.0830 - acc: 0.08 - ETA: 26s - loss: 4.0837 - acc: 0.08 - ETA: 26s - loss: 4.0837 - acc: 0.08 - ETA: 25s - loss: 4.0823 - acc: 0.08 - ETA: 25s - loss: 4.0818 - acc: 0.08 - ETA: 25s - loss: 4.0831 - acc: 0.08 - ETA: 25s - loss: 4.0841 - acc: 0.08 - ETA: 25s - loss: 4.0835 - acc: 0.0891"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6660/6680 [============================>.] - ETA: 24s - loss: 4.0814 - acc: 0.08 - ETA: 24s - loss: 4.0829 - acc: 0.08 - ETA: 24s - loss: 4.0835 - acc: 0.08 - ETA: 24s - loss: 4.0860 - acc: 0.08 - ETA: 23s - loss: 4.0861 - acc: 0.08 - ETA: 23s - loss: 4.0871 - acc: 0.08 - ETA: 23s - loss: 4.0860 - acc: 0.08 - ETA: 23s - loss: 4.0842 - acc: 0.09 - ETA: 23s - loss: 4.0837 - acc: 0.09 - ETA: 22s - loss: 4.0799 - acc: 0.09 - ETA: 22s - loss: 4.0808 - acc: 0.09 - ETA: 22s - loss: 4.0799 - acc: 0.09 - ETA: 22s - loss: 4.0808 - acc: 0.09 - ETA: 22s - loss: 4.0793 - acc: 0.09 - ETA: 21s - loss: 4.0798 - acc: 0.09 - ETA: 21s - loss: 4.0810 - acc: 0.09 - ETA: 21s - loss: 4.0826 - acc: 0.09 - ETA: 21s - loss: 4.0834 - acc: 0.09 - ETA: 21s - loss: 4.0827 - acc: 0.09 - ETA: 20s - loss: 4.0843 - acc: 0.09 - ETA: 20s - loss: 4.0839 - acc: 0.09 - ETA: 20s - loss: 4.0840 - acc: 0.09 - ETA: 20s - loss: 4.0851 - acc: 0.09 - ETA: 19s - loss: 4.0846 - acc: 0.09 - ETA: 19s - loss: 4.0840 - acc: 0.09 - ETA: 19s - loss: 4.0836 - acc: 0.09 - ETA: 19s - loss: 4.0819 - acc: 0.09 - ETA: 19s - loss: 4.0820 - acc: 0.09 - ETA: 18s - loss: 4.0845 - acc: 0.09 - ETA: 18s - loss: 4.0855 - acc: 0.09 - ETA: 18s - loss: 4.0871 - acc: 0.09 - ETA: 18s - loss: 4.0859 - acc: 0.09 - ETA: 18s - loss: 4.0860 - acc: 0.09 - ETA: 17s - loss: 4.0857 - acc: 0.09 - ETA: 17s - loss: 4.0875 - acc: 0.09 - ETA: 17s - loss: 4.0877 - acc: 0.09 - ETA: 17s - loss: 4.0860 - acc: 0.09 - ETA: 17s - loss: 4.0863 - acc: 0.09 - ETA: 16s - loss: 4.0848 - acc: 0.09 - ETA: 16s - loss: 4.0850 - acc: 0.09 - ETA: 16s - loss: 4.0851 - acc: 0.09 - ETA: 16s - loss: 4.0843 - acc: 0.09 - ETA: 15s - loss: 4.0867 - acc: 0.09 - ETA: 15s - loss: 4.0880 - acc: 0.09 - ETA: 15s - loss: 4.0880 - acc: 0.09 - ETA: 15s - loss: 4.0878 - acc: 0.09 - ETA: 15s - loss: 4.0872 - acc: 0.09 - ETA: 14s - loss: 4.0871 - acc: 0.09 - ETA: 14s - loss: 4.0878 - acc: 0.09 - ETA: 14s - loss: 4.0898 - acc: 0.09 - ETA: 14s - loss: 4.0901 - acc: 0.09 - ETA: 14s - loss: 4.0891 - acc: 0.09 - ETA: 13s - loss: 4.0900 - acc: 0.09 - ETA: 13s - loss: 4.0900 - acc: 0.09 - ETA: 13s - loss: 4.0907 - acc: 0.09 - ETA: 13s - loss: 4.0906 - acc: 0.09 - ETA: 13s - loss: 4.0910 - acc: 0.09 - ETA: 12s - loss: 4.0903 - acc: 0.09 - ETA: 12s - loss: 4.0902 - acc: 0.09 - ETA: 12s - loss: 4.0888 - acc: 0.09 - ETA: 12s - loss: 4.0890 - acc: 0.09 - ETA: 11s - loss: 4.0917 - acc: 0.09 - ETA: 11s - loss: 4.0918 - acc: 0.09 - ETA: 11s - loss: 4.0918 - acc: 0.09 - ETA: 11s - loss: 4.0913 - acc: 0.09 - ETA: 11s - loss: 4.0898 - acc: 0.09 - ETA: 10s - loss: 4.0909 - acc: 0.09 - ETA: 10s - loss: 4.0908 - acc: 0.09 - ETA: 10s - loss: 4.0934 - acc: 0.09 - ETA: 10s - loss: 4.0932 - acc: 0.09 - ETA: 10s - loss: 4.0931 - acc: 0.09 - ETA: 9s - loss: 4.0930 - acc: 0.0911 - ETA: 9s - loss: 4.0925 - acc: 0.091 - ETA: 9s - loss: 4.0916 - acc: 0.091 - ETA: 9s - loss: 4.0922 - acc: 0.091 - ETA: 9s - loss: 4.0934 - acc: 0.090 - ETA: 8s - loss: 4.0936 - acc: 0.090 - ETA: 8s - loss: 4.0922 - acc: 0.091 - ETA: 8s - loss: 4.0924 - acc: 0.091 - ETA: 8s - loss: 4.0921 - acc: 0.091 - ETA: 7s - loss: 4.0920 - acc: 0.091 - ETA: 7s - loss: 4.0935 - acc: 0.091 - ETA: 7s - loss: 4.0950 - acc: 0.091 - ETA: 7s - loss: 4.0950 - acc: 0.091 - ETA: 7s - loss: 4.0951 - acc: 0.091 - ETA: 6s - loss: 4.0968 - acc: 0.091 - ETA: 6s - loss: 4.0965 - acc: 0.091 - ETA: 6s - loss: 4.0967 - acc: 0.091 - ETA: 6s - loss: 4.0967 - acc: 0.091 - ETA: 6s - loss: 4.0973 - acc: 0.091 - ETA: 5s - loss: 4.0979 - acc: 0.091 - ETA: 5s - loss: 4.0984 - acc: 0.091 - ETA: 5s - loss: 4.0984 - acc: 0.091 - ETA: 5s - loss: 4.0987 - acc: 0.091 - ETA: 5s - loss: 4.0985 - acc: 0.090 - ETA: 4s - loss: 4.0987 - acc: 0.091 - ETA: 4s - loss: 4.0993 - acc: 0.091 - ETA: 4s - loss: 4.0996 - acc: 0.090 - ETA: 4s - loss: 4.0997 - acc: 0.091 - ETA: 3s - loss: 4.0991 - acc: 0.091 - ETA: 3s - loss: 4.0996 - acc: 0.090 - ETA: 3s - loss: 4.0992 - acc: 0.090 - ETA: 3s - loss: 4.0981 - acc: 0.090 - ETA: 3s - loss: 4.0964 - acc: 0.090 - ETA: 2s - loss: 4.0983 - acc: 0.090 - ETA: 2s - loss: 4.0981 - acc: 0.090 - ETA: 2s - loss: 4.0983 - acc: 0.090 - ETA: 2s - loss: 4.0969 - acc: 0.090 - ETA: 2s - loss: 4.0955 - acc: 0.090 - ETA: 1s - loss: 4.0958 - acc: 0.090 - ETA: 1s - loss: 4.0960 - acc: 0.090 - ETA: 1s - loss: 4.0960 - acc: 0.090 - ETA: 1s - loss: 4.0954 - acc: 0.090 - ETA: 1s - loss: 4.0958 - acc: 0.090 - ETA: 0s - loss: 4.0955 - acc: 0.090 - ETA: 0s - loss: 4.0951 - acc: 0.090 - ETA: 0s - loss: 4.0960 - acc: 0.090 - ETA: 0s - loss: 4.0959 - acc: 0.0902Epoch 00028: val_loss improved from 4.18566 to 4.16506, saving model to saved_models/weights.best.from_scratch.hdf5\n",
      "6680/6680 [==============================] - 73s - loss: 4.0966 - acc: 0.0903 - val_loss: 4.1651 - val_acc: 0.0731\n",
      "Epoch 30/32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4300/6680 [==================>...........] - ETA: 70s - loss: 4.2588 - acc: 0.05 - ETA: 68s - loss: 4.1226 - acc: 0.10 - ETA: 67s - loss: 3.9814 - acc: 0.11 - ETA: 68s - loss: 3.9209 - acc: 0.12 - ETA: 69s - loss: 3.9909 - acc: 0.10 - ETA: 68s - loss: 3.9873 - acc: 0.10 - ETA: 67s - loss: 3.9739 - acc: 0.10 - ETA: 67s - loss: 3.9450 - acc: 0.10 - ETA: 67s - loss: 3.9618 - acc: 0.11 - ETA: 67s - loss: 4.0102 - acc: 0.11 - ETA: 67s - loss: 3.9951 - acc: 0.11 - ETA: 66s - loss: 3.9808 - acc: 0.11 - ETA: 66s - loss: 3.9693 - acc: 0.12 - ETA: 66s - loss: 3.9694 - acc: 0.11 - ETA: 66s - loss: 3.9627 - acc: 0.11 - ETA: 66s - loss: 3.9990 - acc: 0.11 - ETA: 66s - loss: 4.0024 - acc: 0.11 - ETA: 65s - loss: 4.0150 - acc: 0.11 - ETA: 65s - loss: 4.0159 - acc: 0.11 - ETA: 65s - loss: 4.0086 - acc: 0.11 - ETA: 65s - loss: 4.0052 - acc: 0.12 - ETA: 65s - loss: 4.0138 - acc: 0.11 - ETA: 64s - loss: 4.0131 - acc: 0.11 - ETA: 64s - loss: 4.0229 - acc: 0.12 - ETA: 64s - loss: 4.0251 - acc: 0.12 - ETA: 64s - loss: 4.0213 - acc: 0.11 - ETA: 64s - loss: 4.0059 - acc: 0.11 - ETA: 63s - loss: 4.0041 - acc: 0.11 - ETA: 63s - loss: 4.0214 - acc: 0.11 - ETA: 63s - loss: 4.0240 - acc: 0.11 - ETA: 63s - loss: 4.0170 - acc: 0.11 - ETA: 63s - loss: 4.0149 - acc: 0.10 - ETA: 63s - loss: 4.0162 - acc: 0.10 - ETA: 62s - loss: 4.0208 - acc: 0.10 - ETA: 62s - loss: 4.0285 - acc: 0.10 - ETA: 62s - loss: 4.0369 - acc: 0.10 - ETA: 62s - loss: 4.0441 - acc: 0.10 - ETA: 62s - loss: 4.0535 - acc: 0.10 - ETA: 61s - loss: 4.0578 - acc: 0.10 - ETA: 61s - loss: 4.0520 - acc: 0.10 - ETA: 61s - loss: 4.0389 - acc: 0.10 - ETA: 61s - loss: 4.0406 - acc: 0.10 - ETA: 60s - loss: 4.0371 - acc: 0.10 - ETA: 60s - loss: 4.0337 - acc: 0.10 - ETA: 60s - loss: 4.0394 - acc: 0.10 - ETA: 60s - loss: 4.0371 - acc: 0.09 - ETA: 60s - loss: 4.0409 - acc: 0.10 - ETA: 59s - loss: 4.0436 - acc: 0.10 - ETA: 59s - loss: 4.0392 - acc: 0.10 - ETA: 59s - loss: 4.0376 - acc: 0.10 - ETA: 59s - loss: 4.0367 - acc: 0.10 - ETA: 59s - loss: 4.0409 - acc: 0.09 - ETA: 58s - loss: 4.0456 - acc: 0.09 - ETA: 58s - loss: 4.0451 - acc: 0.09 - ETA: 58s - loss: 4.0483 - acc: 0.09 - ETA: 58s - loss: 4.0587 - acc: 0.09 - ETA: 58s - loss: 4.0606 - acc: 0.09 - ETA: 57s - loss: 4.0648 - acc: 0.09 - ETA: 57s - loss: 4.0632 - acc: 0.09 - ETA: 57s - loss: 4.0661 - acc: 0.09 - ETA: 57s - loss: 4.0602 - acc: 0.09 - ETA: 57s - loss: 4.0554 - acc: 0.09 - ETA: 56s - loss: 4.0631 - acc: 0.09 - ETA: 56s - loss: 4.0701 - acc: 0.08 - ETA: 56s - loss: 4.0709 - acc: 0.09 - ETA: 56s - loss: 4.0730 - acc: 0.08 - ETA: 56s - loss: 4.0661 - acc: 0.08 - ETA: 55s - loss: 4.0609 - acc: 0.08 - ETA: 55s - loss: 4.0648 - acc: 0.08 - ETA: 55s - loss: 4.0653 - acc: 0.08 - ETA: 55s - loss: 4.0631 - acc: 0.08 - ETA: 55s - loss: 4.0709 - acc: 0.08 - ETA: 54s - loss: 4.0678 - acc: 0.08 - ETA: 54s - loss: 4.0639 - acc: 0.08 - ETA: 54s - loss: 4.0593 - acc: 0.08 - ETA: 54s - loss: 4.0600 - acc: 0.08 - ETA: 54s - loss: 4.0577 - acc: 0.09 - ETA: 53s - loss: 4.0559 - acc: 0.08 - ETA: 53s - loss: 4.0524 - acc: 0.09 - ETA: 53s - loss: 4.0529 - acc: 0.09 - ETA: 53s - loss: 4.0560 - acc: 0.09 - ETA: 52s - loss: 4.0548 - acc: 0.09 - ETA: 52s - loss: 4.0546 - acc: 0.09 - ETA: 52s - loss: 4.0580 - acc: 0.09 - ETA: 52s - loss: 4.0607 - acc: 0.09 - ETA: 52s - loss: 4.0629 - acc: 0.09 - ETA: 51s - loss: 4.0667 - acc: 0.09 - ETA: 51s - loss: 4.0664 - acc: 0.09 - ETA: 51s - loss: 4.0670 - acc: 0.09 - ETA: 51s - loss: 4.0663 - acc: 0.09 - ETA: 51s - loss: 4.0667 - acc: 0.09 - ETA: 50s - loss: 4.0664 - acc: 0.09 - ETA: 50s - loss: 4.0676 - acc: 0.09 - ETA: 50s - loss: 4.0699 - acc: 0.09 - ETA: 50s - loss: 4.0683 - acc: 0.09 - ETA: 50s - loss: 4.0646 - acc: 0.09 - ETA: 49s - loss: 4.0685 - acc: 0.09 - ETA: 49s - loss: 4.0666 - acc: 0.09 - ETA: 49s - loss: 4.0658 - acc: 0.09 - ETA: 49s - loss: 4.0614 - acc: 0.09 - ETA: 48s - loss: 4.0617 - acc: 0.09 - ETA: 48s - loss: 4.0650 - acc: 0.09 - ETA: 48s - loss: 4.0637 - acc: 0.09 - ETA: 48s - loss: 4.0628 - acc: 0.09 - ETA: 48s - loss: 4.0644 - acc: 0.09 - ETA: 47s - loss: 4.0653 - acc: 0.09 - ETA: 47s - loss: 4.0649 - acc: 0.09 - ETA: 47s - loss: 4.0617 - acc: 0.09 - ETA: 47s - loss: 4.0629 - acc: 0.09 - ETA: 47s - loss: 4.0658 - acc: 0.09 - ETA: 46s - loss: 4.0664 - acc: 0.09 - ETA: 46s - loss: 4.0677 - acc: 0.08 - ETA: 46s - loss: 4.0663 - acc: 0.08 - ETA: 46s - loss: 4.0663 - acc: 0.08 - ETA: 46s - loss: 4.0668 - acc: 0.08 - ETA: 45s - loss: 4.0653 - acc: 0.08 - ETA: 45s - loss: 4.0664 - acc: 0.08 - ETA: 45s - loss: 4.0644 - acc: 0.08 - ETA: 45s - loss: 4.0630 - acc: 0.08 - ETA: 45s - loss: 4.0653 - acc: 0.08 - ETA: 44s - loss: 4.0635 - acc: 0.08 - ETA: 44s - loss: 4.0650 - acc: 0.08 - ETA: 44s - loss: 4.0661 - acc: 0.08 - ETA: 44s - loss: 4.0613 - acc: 0.08 - ETA: 43s - loss: 4.0620 - acc: 0.08 - ETA: 43s - loss: 4.0631 - acc: 0.08 - ETA: 43s - loss: 4.0621 - acc: 0.08 - ETA: 43s - loss: 4.0641 - acc: 0.08 - ETA: 43s - loss: 4.0630 - acc: 0.08 - ETA: 42s - loss: 4.0621 - acc: 0.08 - ETA: 42s - loss: 4.0633 - acc: 0.08 - ETA: 42s - loss: 4.0632 - acc: 0.08 - ETA: 42s - loss: 4.0590 - acc: 0.08 - ETA: 42s - loss: 4.0560 - acc: 0.08 - ETA: 41s - loss: 4.0600 - acc: 0.08 - ETA: 41s - loss: 4.0589 - acc: 0.08 - ETA: 41s - loss: 4.0615 - acc: 0.08 - ETA: 41s - loss: 4.0651 - acc: 0.08 - ETA: 41s - loss: 4.0622 - acc: 0.08 - ETA: 40s - loss: 4.0644 - acc: 0.08 - ETA: 40s - loss: 4.0622 - acc: 0.08 - ETA: 40s - loss: 4.0634 - acc: 0.08 - ETA: 40s - loss: 4.0597 - acc: 0.08 - ETA: 39s - loss: 4.0601 - acc: 0.08 - ETA: 39s - loss: 4.0591 - acc: 0.08 - ETA: 39s - loss: 4.0610 - acc: 0.08 - ETA: 39s - loss: 4.0613 - acc: 0.08 - ETA: 39s - loss: 4.0625 - acc: 0.08 - ETA: 38s - loss: 4.0587 - acc: 0.08 - ETA: 38s - loss: 4.0554 - acc: 0.09 - ETA: 38s - loss: 4.0588 - acc: 0.08 - ETA: 38s - loss: 4.0588 - acc: 0.08 - ETA: 38s - loss: 4.0569 - acc: 0.08 - ETA: 37s - loss: 4.0601 - acc: 0.08 - ETA: 37s - loss: 4.0607 - acc: 0.08 - ETA: 37s - loss: 4.0622 - acc: 0.08 - ETA: 37s - loss: 4.0609 - acc: 0.09 - ETA: 37s - loss: 4.0613 - acc: 0.09 - ETA: 36s - loss: 4.0620 - acc: 0.09 - ETA: 36s - loss: 4.0621 - acc: 0.09 - ETA: 36s - loss: 4.0630 - acc: 0.09 - ETA: 36s - loss: 4.0634 - acc: 0.08 - ETA: 35s - loss: 4.0614 - acc: 0.08 - ETA: 35s - loss: 4.0610 - acc: 0.08 - ETA: 35s - loss: 4.0611 - acc: 0.08 - ETA: 35s - loss: 4.0618 - acc: 0.08 - ETA: 35s - loss: 4.0655 - acc: 0.08 - ETA: 34s - loss: 4.0659 - acc: 0.08 - ETA: 34s - loss: 4.0668 - acc: 0.08 - ETA: 34s - loss: 4.0675 - acc: 0.08 - ETA: 34s - loss: 4.0736 - acc: 0.08 - ETA: 34s - loss: 4.0760 - acc: 0.08 - ETA: 33s - loss: 4.0756 - acc: 0.08 - ETA: 33s - loss: 4.0760 - acc: 0.08 - ETA: 33s - loss: 4.0773 - acc: 0.08 - ETA: 33s - loss: 4.0785 - acc: 0.08 - ETA: 33s - loss: 4.0774 - acc: 0.08 - ETA: 32s - loss: 4.0774 - acc: 0.08 - ETA: 32s - loss: 4.0744 - acc: 0.08 - ETA: 32s - loss: 4.0743 - acc: 0.08 - ETA: 32s - loss: 4.0735 - acc: 0.08 - ETA: 31s - loss: 4.0721 - acc: 0.08 - ETA: 31s - loss: 4.0725 - acc: 0.08 - ETA: 31s - loss: 4.0741 - acc: 0.08 - ETA: 31s - loss: 4.0735 - acc: 0.08 - ETA: 31s - loss: 4.0762 - acc: 0.08 - ETA: 30s - loss: 4.0753 - acc: 0.08 - ETA: 30s - loss: 4.0755 - acc: 0.08 - ETA: 30s - loss: 4.0751 - acc: 0.08 - ETA: 30s - loss: 4.0777 - acc: 0.08 - ETA: 30s - loss: 4.0796 - acc: 0.08 - ETA: 29s - loss: 4.0805 - acc: 0.08 - ETA: 29s - loss: 4.0790 - acc: 0.08 - ETA: 29s - loss: 4.0796 - acc: 0.08 - ETA: 29s - loss: 4.0796 - acc: 0.08 - ETA: 29s - loss: 4.0791 - acc: 0.08 - ETA: 28s - loss: 4.0778 - acc: 0.08 - ETA: 28s - loss: 4.0801 - acc: 0.08 - ETA: 28s - loss: 4.0812 - acc: 0.08 - ETA: 28s - loss: 4.0812 - acc: 0.08 - ETA: 27s - loss: 4.0800 - acc: 0.08 - ETA: 27s - loss: 4.0807 - acc: 0.08 - ETA: 27s - loss: 4.0825 - acc: 0.08 - ETA: 27s - loss: 4.0810 - acc: 0.08 - ETA: 27s - loss: 4.0804 - acc: 0.08 - ETA: 26s - loss: 4.0815 - acc: 0.08 - ETA: 26s - loss: 4.0813 - acc: 0.08 - ETA: 26s - loss: 4.0805 - acc: 0.08 - ETA: 26s - loss: 4.0799 - acc: 0.08 - ETA: 26s - loss: 4.0781 - acc: 0.08 - ETA: 25s - loss: 4.0771 - acc: 0.08 - ETA: 25s - loss: 4.0784 - acc: 0.08 - ETA: 25s - loss: 4.0796 - acc: 0.08 - ETA: 25s - loss: 4.0808 - acc: 0.08 - ETA: 25s - loss: 4.0794 - acc: 0.0863"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6660/6680 [============================>.] - ETA: 24s - loss: 4.0784 - acc: 0.08 - ETA: 24s - loss: 4.0794 - acc: 0.08 - ETA: 24s - loss: 4.0805 - acc: 0.08 - ETA: 24s - loss: 4.0828 - acc: 0.08 - ETA: 23s - loss: 4.0820 - acc: 0.08 - ETA: 23s - loss: 4.0816 - acc: 0.08 - ETA: 23s - loss: 4.0821 - acc: 0.08 - ETA: 23s - loss: 4.0837 - acc: 0.08 - ETA: 23s - loss: 4.0850 - acc: 0.08 - ETA: 22s - loss: 4.0851 - acc: 0.08 - ETA: 22s - loss: 4.0842 - acc: 0.08 - ETA: 22s - loss: 4.0836 - acc: 0.08 - ETA: 22s - loss: 4.0830 - acc: 0.08 - ETA: 22s - loss: 4.0820 - acc: 0.08 - ETA: 21s - loss: 4.0829 - acc: 0.08 - ETA: 21s - loss: 4.0832 - acc: 0.08 - ETA: 21s - loss: 4.0822 - acc: 0.08 - ETA: 21s - loss: 4.0818 - acc: 0.08 - ETA: 21s - loss: 4.0828 - acc: 0.08 - ETA: 20s - loss: 4.0821 - acc: 0.08 - ETA: 20s - loss: 4.0820 - acc: 0.08 - ETA: 20s - loss: 4.0831 - acc: 0.08 - ETA: 20s - loss: 4.0835 - acc: 0.08 - ETA: 19s - loss: 4.0824 - acc: 0.08 - ETA: 19s - loss: 4.0822 - acc: 0.08 - ETA: 19s - loss: 4.0827 - acc: 0.08 - ETA: 19s - loss: 4.0815 - acc: 0.08 - ETA: 19s - loss: 4.0810 - acc: 0.08 - ETA: 18s - loss: 4.0796 - acc: 0.08 - ETA: 18s - loss: 4.0803 - acc: 0.08 - ETA: 18s - loss: 4.0800 - acc: 0.08 - ETA: 18s - loss: 4.0814 - acc: 0.08 - ETA: 18s - loss: 4.0830 - acc: 0.08 - ETA: 17s - loss: 4.0810 - acc: 0.08 - ETA: 17s - loss: 4.0807 - acc: 0.08 - ETA: 17s - loss: 4.0811 - acc: 0.08 - ETA: 17s - loss: 4.0795 - acc: 0.08 - ETA: 17s - loss: 4.0797 - acc: 0.08 - ETA: 16s - loss: 4.0805 - acc: 0.08 - ETA: 16s - loss: 4.0807 - acc: 0.08 - ETA: 16s - loss: 4.0802 - acc: 0.08 - ETA: 16s - loss: 4.0811 - acc: 0.08 - ETA: 15s - loss: 4.0811 - acc: 0.08 - ETA: 15s - loss: 4.0805 - acc: 0.08 - ETA: 15s - loss: 4.0796 - acc: 0.08 - ETA: 15s - loss: 4.0781 - acc: 0.08 - ETA: 15s - loss: 4.0778 - acc: 0.08 - ETA: 14s - loss: 4.0780 - acc: 0.08 - ETA: 14s - loss: 4.0782 - acc: 0.08 - ETA: 14s - loss: 4.0790 - acc: 0.08 - ETA: 14s - loss: 4.0788 - acc: 0.08 - ETA: 14s - loss: 4.0789 - acc: 0.08 - ETA: 13s - loss: 4.0801 - acc: 0.08 - ETA: 13s - loss: 4.0792 - acc: 0.08 - ETA: 13s - loss: 4.0796 - acc: 0.08 - ETA: 13s - loss: 4.0792 - acc: 0.08 - ETA: 13s - loss: 4.0792 - acc: 0.08 - ETA: 12s - loss: 4.0797 - acc: 0.08 - ETA: 12s - loss: 4.0800 - acc: 0.08 - ETA: 12s - loss: 4.0803 - acc: 0.08 - ETA: 12s - loss: 4.0815 - acc: 0.08 - ETA: 11s - loss: 4.0821 - acc: 0.08 - ETA: 11s - loss: 4.0816 - acc: 0.08 - ETA: 11s - loss: 4.0808 - acc: 0.08 - ETA: 11s - loss: 4.0797 - acc: 0.08 - ETA: 11s - loss: 4.0817 - acc: 0.08 - ETA: 10s - loss: 4.0816 - acc: 0.08 - ETA: 10s - loss: 4.0807 - acc: 0.08 - ETA: 10s - loss: 4.0799 - acc: 0.08 - ETA: 10s - loss: 4.0793 - acc: 0.08 - ETA: 10s - loss: 4.0799 - acc: 0.08 - ETA: 9s - loss: 4.0817 - acc: 0.0894 - ETA: 9s - loss: 4.0813 - acc: 0.089 - ETA: 9s - loss: 4.0822 - acc: 0.089 - ETA: 9s - loss: 4.0816 - acc: 0.089 - ETA: 9s - loss: 4.0822 - acc: 0.088 - ETA: 8s - loss: 4.0824 - acc: 0.089 - ETA: 8s - loss: 4.0827 - acc: 0.089 - ETA: 8s - loss: 4.0819 - acc: 0.089 - ETA: 8s - loss: 4.0814 - acc: 0.089 - ETA: 7s - loss: 4.0823 - acc: 0.089 - ETA: 7s - loss: 4.0825 - acc: 0.089 - ETA: 7s - loss: 4.0821 - acc: 0.089 - ETA: 7s - loss: 4.0837 - acc: 0.090 - ETA: 7s - loss: 4.0838 - acc: 0.089 - ETA: 6s - loss: 4.0829 - acc: 0.090 - ETA: 6s - loss: 4.0816 - acc: 0.090 - ETA: 6s - loss: 4.0803 - acc: 0.090 - ETA: 6s - loss: 4.0805 - acc: 0.090 - ETA: 6s - loss: 4.0800 - acc: 0.090 - ETA: 5s - loss: 4.0797 - acc: 0.090 - ETA: 5s - loss: 4.0797 - acc: 0.090 - ETA: 5s - loss: 4.0826 - acc: 0.090 - ETA: 5s - loss: 4.0835 - acc: 0.090 - ETA: 5s - loss: 4.0839 - acc: 0.090 - ETA: 4s - loss: 4.0853 - acc: 0.090 - ETA: 4s - loss: 4.0850 - acc: 0.089 - ETA: 4s - loss: 4.0841 - acc: 0.089 - ETA: 4s - loss: 4.0827 - acc: 0.090 - ETA: 3s - loss: 4.0832 - acc: 0.090 - ETA: 3s - loss: 4.0827 - acc: 0.089 - ETA: 3s - loss: 4.0820 - acc: 0.089 - ETA: 3s - loss: 4.0821 - acc: 0.089 - ETA: 3s - loss: 4.0826 - acc: 0.089 - ETA: 2s - loss: 4.0825 - acc: 0.089 - ETA: 2s - loss: 4.0826 - acc: 0.089 - ETA: 2s - loss: 4.0820 - acc: 0.089 - ETA: 2s - loss: 4.0820 - acc: 0.089 - ETA: 2s - loss: 4.0829 - acc: 0.089 - ETA: 1s - loss: 4.0830 - acc: 0.089 - ETA: 1s - loss: 4.0837 - acc: 0.089 - ETA: 1s - loss: 4.0836 - acc: 0.089 - ETA: 1s - loss: 4.0842 - acc: 0.089 - ETA: 1s - loss: 4.0850 - acc: 0.088 - ETA: 0s - loss: 4.0839 - acc: 0.089 - ETA: 0s - loss: 4.0840 - acc: 0.089 - ETA: 0s - loss: 4.0842 - acc: 0.089 - ETA: 0s - loss: 4.0833 - acc: 0.0892Epoch 00029: val_loss did not improve\n",
      "6680/6680 [==============================] - 72s - loss: 4.0840 - acc: 0.0891 - val_loss: 4.2462 - val_acc: 0.0707\n",
      "Epoch 31/32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4300/6680 [==================>...........] - ETA: 67s - loss: 4.6960 - acc: 0.05 - ETA: 68s - loss: 4.2439 - acc: 0.10 - ETA: 68s - loss: 4.2416 - acc: 0.06 - ETA: 68s - loss: 4.1739 - acc: 0.06 - ETA: 68s - loss: 4.1351 - acc: 0.06 - ETA: 68s - loss: 4.1804 - acc: 0.05 - ETA: 67s - loss: 4.1941 - acc: 0.05 - ETA: 67s - loss: 4.2286 - acc: 0.06 - ETA: 67s - loss: 4.2045 - acc: 0.06 - ETA: 67s - loss: 4.1629 - acc: 0.07 - ETA: 67s - loss: 4.1784 - acc: 0.06 - ETA: 67s - loss: 4.1792 - acc: 0.06 - ETA: 66s - loss: 4.1985 - acc: 0.06 - ETA: 66s - loss: 4.1767 - acc: 0.07 - ETA: 66s - loss: 4.1518 - acc: 0.07 - ETA: 66s - loss: 4.1471 - acc: 0.06 - ETA: 66s - loss: 4.1531 - acc: 0.06 - ETA: 66s - loss: 4.1661 - acc: 0.07 - ETA: 65s - loss: 4.1453 - acc: 0.08 - ETA: 65s - loss: 4.1323 - acc: 0.08 - ETA: 65s - loss: 4.1110 - acc: 0.09 - ETA: 65s - loss: 4.0832 - acc: 0.09 - ETA: 64s - loss: 4.0591 - acc: 0.09 - ETA: 64s - loss: 4.0825 - acc: 0.09 - ETA: 64s - loss: 4.0846 - acc: 0.09 - ETA: 64s - loss: 4.0839 - acc: 0.09 - ETA: 64s - loss: 4.0600 - acc: 0.09 - ETA: 64s - loss: 4.0790 - acc: 0.09 - ETA: 63s - loss: 4.0878 - acc: 0.09 - ETA: 63s - loss: 4.0863 - acc: 0.09 - ETA: 63s - loss: 4.0864 - acc: 0.09 - ETA: 63s - loss: 4.0859 - acc: 0.09 - ETA: 63s - loss: 4.1013 - acc: 0.09 - ETA: 62s - loss: 4.0971 - acc: 0.09 - ETA: 62s - loss: 4.0961 - acc: 0.09 - ETA: 62s - loss: 4.0924 - acc: 0.09 - ETA: 62s - loss: 4.0928 - acc: 0.09 - ETA: 61s - loss: 4.0919 - acc: 0.09 - ETA: 61s - loss: 4.0874 - acc: 0.09 - ETA: 61s - loss: 4.0900 - acc: 0.09 - ETA: 61s - loss: 4.0801 - acc: 0.09 - ETA: 61s - loss: 4.0696 - acc: 0.09 - ETA: 60s - loss: 4.0779 - acc: 0.09 - ETA: 60s - loss: 4.0683 - acc: 0.09 - ETA: 60s - loss: 4.0676 - acc: 0.09 - ETA: 60s - loss: 4.0625 - acc: 0.09 - ETA: 60s - loss: 4.0641 - acc: 0.09 - ETA: 59s - loss: 4.0657 - acc: 0.09 - ETA: 59s - loss: 4.0627 - acc: 0.09 - ETA: 59s - loss: 4.0617 - acc: 0.09 - ETA: 59s - loss: 4.0635 - acc: 0.09 - ETA: 58s - loss: 4.0631 - acc: 0.09 - ETA: 58s - loss: 4.0600 - acc: 0.09 - ETA: 58s - loss: 4.0660 - acc: 0.09 - ETA: 58s - loss: 4.0669 - acc: 0.09 - ETA: 58s - loss: 4.0651 - acc: 0.09 - ETA: 58s - loss: 4.0575 - acc: 0.09 - ETA: 58s - loss: 4.0570 - acc: 0.09 - ETA: 57s - loss: 4.0506 - acc: 0.09 - ETA: 57s - loss: 4.0472 - acc: 0.09 - ETA: 57s - loss: 4.0492 - acc: 0.09 - ETA: 57s - loss: 4.0449 - acc: 0.09 - ETA: 56s - loss: 4.0441 - acc: 0.09 - ETA: 56s - loss: 4.0429 - acc: 0.09 - ETA: 56s - loss: 4.0414 - acc: 0.09 - ETA: 56s - loss: 4.0445 - acc: 0.09 - ETA: 56s - loss: 4.0439 - acc: 0.09 - ETA: 55s - loss: 4.0453 - acc: 0.09 - ETA: 55s - loss: 4.0439 - acc: 0.09 - ETA: 55s - loss: 4.0444 - acc: 0.09 - ETA: 55s - loss: 4.0461 - acc: 0.09 - ETA: 54s - loss: 4.0509 - acc: 0.09 - ETA: 54s - loss: 4.0538 - acc: 0.09 - ETA: 54s - loss: 4.0520 - acc: 0.09 - ETA: 54s - loss: 4.0486 - acc: 0.09 - ETA: 54s - loss: 4.0492 - acc: 0.09 - ETA: 53s - loss: 4.0533 - acc: 0.09 - ETA: 53s - loss: 4.0498 - acc: 0.09 - ETA: 53s - loss: 4.0472 - acc: 0.09 - ETA: 53s - loss: 4.0457 - acc: 0.09 - ETA: 53s - loss: 4.0422 - acc: 0.09 - ETA: 52s - loss: 4.0406 - acc: 0.09 - ETA: 52s - loss: 4.0497 - acc: 0.09 - ETA: 52s - loss: 4.0528 - acc: 0.09 - ETA: 52s - loss: 4.0537 - acc: 0.09 - ETA: 52s - loss: 4.0504 - acc: 0.09 - ETA: 51s - loss: 4.0544 - acc: 0.09 - ETA: 51s - loss: 4.0502 - acc: 0.09 - ETA: 51s - loss: 4.0535 - acc: 0.09 - ETA: 51s - loss: 4.0532 - acc: 0.09 - ETA: 51s - loss: 4.0533 - acc: 0.09 - ETA: 50s - loss: 4.0517 - acc: 0.09 - ETA: 50s - loss: 4.0535 - acc: 0.09 - ETA: 50s - loss: 4.0522 - acc: 0.09 - ETA: 50s - loss: 4.0605 - acc: 0.09 - ETA: 50s - loss: 4.0579 - acc: 0.09 - ETA: 49s - loss: 4.0541 - acc: 0.09 - ETA: 49s - loss: 4.0543 - acc: 0.09 - ETA: 49s - loss: 4.0585 - acc: 0.09 - ETA: 49s - loss: 4.0565 - acc: 0.09 - ETA: 48s - loss: 4.0549 - acc: 0.09 - ETA: 48s - loss: 4.0601 - acc: 0.09 - ETA: 48s - loss: 4.0622 - acc: 0.09 - ETA: 48s - loss: 4.0650 - acc: 0.09 - ETA: 48s - loss: 4.0679 - acc: 0.09 - ETA: 47s - loss: 4.0656 - acc: 0.09 - ETA: 47s - loss: 4.0654 - acc: 0.09 - ETA: 47s - loss: 4.0627 - acc: 0.09 - ETA: 47s - loss: 4.0605 - acc: 0.09 - ETA: 47s - loss: 4.0586 - acc: 0.09 - ETA: 46s - loss: 4.0546 - acc: 0.09 - ETA: 46s - loss: 4.0581 - acc: 0.09 - ETA: 46s - loss: 4.0604 - acc: 0.09 - ETA: 46s - loss: 4.0625 - acc: 0.09 - ETA: 45s - loss: 4.0580 - acc: 0.09 - ETA: 45s - loss: 4.0519 - acc: 0.09 - ETA: 45s - loss: 4.0516 - acc: 0.09 - ETA: 45s - loss: 4.0532 - acc: 0.09 - ETA: 45s - loss: 4.0537 - acc: 0.09 - ETA: 44s - loss: 4.0491 - acc: 0.09 - ETA: 44s - loss: 4.0492 - acc: 0.09 - ETA: 44s - loss: 4.0476 - acc: 0.09 - ETA: 44s - loss: 4.0458 - acc: 0.09 - ETA: 44s - loss: 4.0438 - acc: 0.09 - ETA: 43s - loss: 4.0492 - acc: 0.09 - ETA: 43s - loss: 4.0519 - acc: 0.09 - ETA: 43s - loss: 4.0483 - acc: 0.09 - ETA: 43s - loss: 4.0472 - acc: 0.09 - ETA: 43s - loss: 4.0464 - acc: 0.09 - ETA: 42s - loss: 4.0473 - acc: 0.09 - ETA: 42s - loss: 4.0488 - acc: 0.09 - ETA: 42s - loss: 4.0487 - acc: 0.09 - ETA: 42s - loss: 4.0498 - acc: 0.09 - ETA: 41s - loss: 4.0549 - acc: 0.09 - ETA: 41s - loss: 4.0566 - acc: 0.09 - ETA: 41s - loss: 4.0583 - acc: 0.09 - ETA: 41s - loss: 4.0574 - acc: 0.09 - ETA: 41s - loss: 4.0575 - acc: 0.09 - ETA: 40s - loss: 4.0579 - acc: 0.09 - ETA: 40s - loss: 4.0559 - acc: 0.09 - ETA: 40s - loss: 4.0564 - acc: 0.09 - ETA: 40s - loss: 4.0574 - acc: 0.09 - ETA: 40s - loss: 4.0629 - acc: 0.09 - ETA: 39s - loss: 4.0657 - acc: 0.09 - ETA: 39s - loss: 4.0650 - acc: 0.09 - ETA: 39s - loss: 4.0633 - acc: 0.09 - ETA: 39s - loss: 4.0646 - acc: 0.09 - ETA: 39s - loss: 4.0653 - acc: 0.09 - ETA: 38s - loss: 4.0653 - acc: 0.09 - ETA: 38s - loss: 4.0645 - acc: 0.09 - ETA: 38s - loss: 4.0675 - acc: 0.09 - ETA: 38s - loss: 4.0668 - acc: 0.09 - ETA: 37s - loss: 4.0683 - acc: 0.09 - ETA: 37s - loss: 4.0680 - acc: 0.09 - ETA: 37s - loss: 4.0681 - acc: 0.09 - ETA: 37s - loss: 4.0667 - acc: 0.10 - ETA: 37s - loss: 4.0654 - acc: 0.10 - ETA: 36s - loss: 4.0660 - acc: 0.10 - ETA: 36s - loss: 4.0656 - acc: 0.10 - ETA: 36s - loss: 4.0661 - acc: 0.10 - ETA: 36s - loss: 4.0700 - acc: 0.09 - ETA: 36s - loss: 4.0698 - acc: 0.10 - ETA: 35s - loss: 4.0721 - acc: 0.10 - ETA: 35s - loss: 4.0709 - acc: 0.10 - ETA: 35s - loss: 4.0721 - acc: 0.10 - ETA: 35s - loss: 4.0723 - acc: 0.10 - ETA: 35s - loss: 4.0715 - acc: 0.10 - ETA: 34s - loss: 4.0714 - acc: 0.10 - ETA: 34s - loss: 4.0717 - acc: 0.09 - ETA: 34s - loss: 4.0709 - acc: 0.09 - ETA: 34s - loss: 4.0720 - acc: 0.09 - ETA: 33s - loss: 4.0707 - acc: 0.09 - ETA: 33s - loss: 4.0698 - acc: 0.09 - ETA: 33s - loss: 4.0684 - acc: 0.09 - ETA: 33s - loss: 4.0712 - acc: 0.09 - ETA: 33s - loss: 4.0711 - acc: 0.09 - ETA: 32s - loss: 4.0722 - acc: 0.09 - ETA: 32s - loss: 4.0722 - acc: 0.09 - ETA: 32s - loss: 4.0738 - acc: 0.10 - ETA: 32s - loss: 4.0744 - acc: 0.09 - ETA: 32s - loss: 4.0724 - acc: 0.10 - ETA: 31s - loss: 4.0719 - acc: 0.10 - ETA: 31s - loss: 4.0727 - acc: 0.10 - ETA: 31s - loss: 4.0737 - acc: 0.10 - ETA: 31s - loss: 4.0767 - acc: 0.10 - ETA: 31s - loss: 4.0776 - acc: 0.10 - ETA: 30s - loss: 4.0772 - acc: 0.10 - ETA: 30s - loss: 4.0782 - acc: 0.10 - ETA: 30s - loss: 4.0773 - acc: 0.10 - ETA: 30s - loss: 4.0762 - acc: 0.10 - ETA: 30s - loss: 4.0763 - acc: 0.10 - ETA: 29s - loss: 4.0765 - acc: 0.10 - ETA: 29s - loss: 4.0743 - acc: 0.10 - ETA: 29s - loss: 4.0754 - acc: 0.10 - ETA: 29s - loss: 4.0746 - acc: 0.10 - ETA: 28s - loss: 4.0776 - acc: 0.10 - ETA: 28s - loss: 4.0789 - acc: 0.10 - ETA: 28s - loss: 4.0779 - acc: 0.09 - ETA: 28s - loss: 4.0779 - acc: 0.09 - ETA: 28s - loss: 4.0793 - acc: 0.09 - ETA: 27s - loss: 4.0791 - acc: 0.09 - ETA: 27s - loss: 4.0793 - acc: 0.09 - ETA: 27s - loss: 4.0787 - acc: 0.09 - ETA: 27s - loss: 4.0779 - acc: 0.09 - ETA: 27s - loss: 4.0797 - acc: 0.09 - ETA: 26s - loss: 4.0806 - acc: 0.09 - ETA: 26s - loss: 4.0788 - acc: 0.09 - ETA: 26s - loss: 4.0796 - acc: 0.09 - ETA: 26s - loss: 4.0778 - acc: 0.09 - ETA: 26s - loss: 4.0787 - acc: 0.09 - ETA: 25s - loss: 4.0775 - acc: 0.09 - ETA: 25s - loss: 4.0777 - acc: 0.09 - ETA: 25s - loss: 4.0771 - acc: 0.09 - ETA: 25s - loss: 4.0766 - acc: 0.09 - ETA: 24s - loss: 4.0772 - acc: 0.0981"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6660/6680 [============================>.] - ETA: 24s - loss: 4.0773 - acc: 0.09 - ETA: 24s - loss: 4.0768 - acc: 0.09 - ETA: 24s - loss: 4.0759 - acc: 0.09 - ETA: 24s - loss: 4.0779 - acc: 0.09 - ETA: 23s - loss: 4.0786 - acc: 0.09 - ETA: 23s - loss: 4.0800 - acc: 0.09 - ETA: 23s - loss: 4.0782 - acc: 0.09 - ETA: 23s - loss: 4.0779 - acc: 0.09 - ETA: 23s - loss: 4.0793 - acc: 0.09 - ETA: 22s - loss: 4.0793 - acc: 0.09 - ETA: 22s - loss: 4.0796 - acc: 0.09 - ETA: 22s - loss: 4.0783 - acc: 0.09 - ETA: 22s - loss: 4.0772 - acc: 0.09 - ETA: 22s - loss: 4.0779 - acc: 0.09 - ETA: 21s - loss: 4.0781 - acc: 0.09 - ETA: 21s - loss: 4.0793 - acc: 0.09 - ETA: 21s - loss: 4.0788 - acc: 0.09 - ETA: 21s - loss: 4.0796 - acc: 0.09 - ETA: 20s - loss: 4.0772 - acc: 0.09 - ETA: 20s - loss: 4.0764 - acc: 0.09 - ETA: 20s - loss: 4.0754 - acc: 0.09 - ETA: 20s - loss: 4.0775 - acc: 0.09 - ETA: 20s - loss: 4.0776 - acc: 0.09 - ETA: 19s - loss: 4.0772 - acc: 0.09 - ETA: 19s - loss: 4.0775 - acc: 0.09 - ETA: 19s - loss: 4.0785 - acc: 0.09 - ETA: 19s - loss: 4.0788 - acc: 0.09 - ETA: 19s - loss: 4.0779 - acc: 0.09 - ETA: 18s - loss: 4.0785 - acc: 0.09 - ETA: 18s - loss: 4.0797 - acc: 0.09 - ETA: 18s - loss: 4.0798 - acc: 0.09 - ETA: 18s - loss: 4.0803 - acc: 0.09 - ETA: 18s - loss: 4.0801 - acc: 0.09 - ETA: 17s - loss: 4.0819 - acc: 0.09 - ETA: 17s - loss: 4.0807 - acc: 0.09 - ETA: 17s - loss: 4.0797 - acc: 0.09 - ETA: 17s - loss: 4.0808 - acc: 0.09 - ETA: 16s - loss: 4.0804 - acc: 0.09 - ETA: 16s - loss: 4.0810 - acc: 0.09 - ETA: 16s - loss: 4.0797 - acc: 0.09 - ETA: 16s - loss: 4.0807 - acc: 0.09 - ETA: 16s - loss: 4.0801 - acc: 0.09 - ETA: 15s - loss: 4.0818 - acc: 0.09 - ETA: 15s - loss: 4.0827 - acc: 0.09 - ETA: 15s - loss: 4.0828 - acc: 0.09 - ETA: 15s - loss: 4.0823 - acc: 0.09 - ETA: 15s - loss: 4.0823 - acc: 0.09 - ETA: 14s - loss: 4.0816 - acc: 0.09 - ETA: 14s - loss: 4.0806 - acc: 0.09 - ETA: 14s - loss: 4.0784 - acc: 0.09 - ETA: 14s - loss: 4.0772 - acc: 0.09 - ETA: 14s - loss: 4.0774 - acc: 0.09 - ETA: 13s - loss: 4.0788 - acc: 0.09 - ETA: 13s - loss: 4.0777 - acc: 0.09 - ETA: 13s - loss: 4.0771 - acc: 0.09 - ETA: 13s - loss: 4.0785 - acc: 0.09 - ETA: 13s - loss: 4.0787 - acc: 0.09 - ETA: 12s - loss: 4.0805 - acc: 0.09 - ETA: 12s - loss: 4.0803 - acc: 0.09 - ETA: 12s - loss: 4.0806 - acc: 0.09 - ETA: 12s - loss: 4.0811 - acc: 0.09 - ETA: 11s - loss: 4.0809 - acc: 0.09 - ETA: 11s - loss: 4.0810 - acc: 0.09 - ETA: 11s - loss: 4.0804 - acc: 0.09 - ETA: 11s - loss: 4.0799 - acc: 0.09 - ETA: 11s - loss: 4.0803 - acc: 0.09 - ETA: 10s - loss: 4.0791 - acc: 0.09 - ETA: 10s - loss: 4.0785 - acc: 0.09 - ETA: 10s - loss: 4.0786 - acc: 0.09 - ETA: 10s - loss: 4.0771 - acc: 0.09 - ETA: 10s - loss: 4.0780 - acc: 0.09 - ETA: 9s - loss: 4.0788 - acc: 0.0974 - ETA: 9s - loss: 4.0773 - acc: 0.097 - ETA: 9s - loss: 4.0784 - acc: 0.097 - ETA: 9s - loss: 4.0781 - acc: 0.097 - ETA: 9s - loss: 4.0783 - acc: 0.096 - ETA: 8s - loss: 4.0798 - acc: 0.096 - ETA: 8s - loss: 4.0794 - acc: 0.096 - ETA: 8s - loss: 4.0788 - acc: 0.096 - ETA: 8s - loss: 4.0784 - acc: 0.096 - ETA: 7s - loss: 4.0799 - acc: 0.096 - ETA: 7s - loss: 4.0793 - acc: 0.096 - ETA: 7s - loss: 4.0788 - acc: 0.095 - ETA: 7s - loss: 4.0797 - acc: 0.095 - ETA: 7s - loss: 4.0807 - acc: 0.096 - ETA: 6s - loss: 4.0807 - acc: 0.096 - ETA: 6s - loss: 4.0798 - acc: 0.095 - ETA: 6s - loss: 4.0804 - acc: 0.095 - ETA: 6s - loss: 4.0799 - acc: 0.096 - ETA: 6s - loss: 4.0782 - acc: 0.096 - ETA: 5s - loss: 4.0778 - acc: 0.096 - ETA: 5s - loss: 4.0769 - acc: 0.097 - ETA: 5s - loss: 4.0765 - acc: 0.096 - ETA: 5s - loss: 4.0763 - acc: 0.096 - ETA: 5s - loss: 4.0760 - acc: 0.096 - ETA: 4s - loss: 4.0756 - acc: 0.096 - ETA: 4s - loss: 4.0753 - acc: 0.096 - ETA: 4s - loss: 4.0760 - acc: 0.096 - ETA: 4s - loss: 4.0774 - acc: 0.096 - ETA: 3s - loss: 4.0776 - acc: 0.096 - ETA: 3s - loss: 4.0780 - acc: 0.096 - ETA: 3s - loss: 4.0768 - acc: 0.097 - ETA: 3s - loss: 4.0759 - acc: 0.096 - ETA: 3s - loss: 4.0760 - acc: 0.096 - ETA: 2s - loss: 4.0768 - acc: 0.096 - ETA: 2s - loss: 4.0764 - acc: 0.096 - ETA: 2s - loss: 4.0762 - acc: 0.096 - ETA: 2s - loss: 4.0761 - acc: 0.096 - ETA: 2s - loss: 4.0759 - acc: 0.096 - ETA: 1s - loss: 4.0749 - acc: 0.096 - ETA: 1s - loss: 4.0770 - acc: 0.096 - ETA: 1s - loss: 4.0772 - acc: 0.096 - ETA: 1s - loss: 4.0769 - acc: 0.096 - ETA: 1s - loss: 4.0769 - acc: 0.096 - ETA: 0s - loss: 4.0763 - acc: 0.096 - ETA: 0s - loss: 4.0779 - acc: 0.096 - ETA: 0s - loss: 4.0774 - acc: 0.096 - ETA: 0s - loss: 4.0783 - acc: 0.0965Epoch 00030: val_loss improved from 4.16506 to 4.15619, saving model to saved_models/weights.best.from_scratch.hdf5\n",
      "6680/6680 [==============================] - 72s - loss: 4.0779 - acc: 0.0967 - val_loss: 4.1562 - val_acc: 0.0850\n",
      "Epoch 32/32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4300/6680 [==================>...........] - ETA: 68s - loss: 3.5901 - acc: 0.20 - ETA: 70s - loss: 3.6268 - acc: 0.17 - ETA: 69s - loss: 3.9039 - acc: 0.18 - ETA: 69s - loss: 3.8845 - acc: 0.17 - ETA: 68s - loss: 3.8950 - acc: 0.15 - ETA: 69s - loss: 3.9226 - acc: 0.12 - ETA: 68s - loss: 3.9301 - acc: 0.13 - ETA: 68s - loss: 3.9428 - acc: 0.13 - ETA: 68s - loss: 3.9249 - acc: 0.13 - ETA: 68s - loss: 3.9467 - acc: 0.12 - ETA: 68s - loss: 3.9551 - acc: 0.11 - ETA: 67s - loss: 4.0034 - acc: 0.11 - ETA: 67s - loss: 3.9949 - acc: 0.11 - ETA: 67s - loss: 3.9801 - acc: 0.10 - ETA: 67s - loss: 3.9753 - acc: 0.11 - ETA: 66s - loss: 3.9772 - acc: 0.11 - ETA: 66s - loss: 3.9562 - acc: 0.11 - ETA: 66s - loss: 3.9231 - acc: 0.11 - ETA: 66s - loss: 3.9029 - acc: 0.12 - ETA: 66s - loss: 3.9340 - acc: 0.11 - ETA: 65s - loss: 3.9661 - acc: 0.11 - ETA: 65s - loss: 3.9517 - acc: 0.11 - ETA: 65s - loss: 3.9477 - acc: 0.10 - ETA: 65s - loss: 3.9410 - acc: 0.10 - ETA: 65s - loss: 3.9525 - acc: 0.10 - ETA: 65s - loss: 3.9499 - acc: 0.10 - ETA: 64s - loss: 3.9735 - acc: 0.09 - ETA: 64s - loss: 3.9825 - acc: 0.10 - ETA: 64s - loss: 3.9818 - acc: 0.10 - ETA: 64s - loss: 3.9871 - acc: 0.10 - ETA: 64s - loss: 3.9936 - acc: 0.09 - ETA: 63s - loss: 3.9879 - acc: 0.09 - ETA: 63s - loss: 3.9919 - acc: 0.09 - ETA: 63s - loss: 3.9941 - acc: 0.09 - ETA: 63s - loss: 3.9980 - acc: 0.09 - ETA: 62s - loss: 3.9916 - acc: 0.09 - ETA: 62s - loss: 3.9941 - acc: 0.09 - ETA: 62s - loss: 3.9863 - acc: 0.09 - ETA: 62s - loss: 3.9973 - acc: 0.09 - ETA: 62s - loss: 4.0076 - acc: 0.09 - ETA: 61s - loss: 4.0114 - acc: 0.09 - ETA: 61s - loss: 4.0115 - acc: 0.09 - ETA: 61s - loss: 4.0022 - acc: 0.09 - ETA: 61s - loss: 4.0151 - acc: 0.09 - ETA: 60s - loss: 4.0171 - acc: 0.09 - ETA: 60s - loss: 4.0167 - acc: 0.09 - ETA: 60s - loss: 4.0238 - acc: 0.09 - ETA: 60s - loss: 4.0185 - acc: 0.09 - ETA: 60s - loss: 4.0154 - acc: 0.09 - ETA: 60s - loss: 4.0234 - acc: 0.09 - ETA: 59s - loss: 4.0253 - acc: 0.09 - ETA: 59s - loss: 4.0305 - acc: 0.09 - ETA: 59s - loss: 4.0315 - acc: 0.09 - ETA: 59s - loss: 4.0389 - acc: 0.09 - ETA: 58s - loss: 4.0419 - acc: 0.09 - ETA: 58s - loss: 4.0380 - acc: 0.09 - ETA: 58s - loss: 4.0451 - acc: 0.09 - ETA: 58s - loss: 4.0473 - acc: 0.09 - ETA: 58s - loss: 4.0428 - acc: 0.09 - ETA: 57s - loss: 4.0443 - acc: 0.09 - ETA: 57s - loss: 4.0429 - acc: 0.09 - ETA: 57s - loss: 4.0390 - acc: 0.09 - ETA: 57s - loss: 4.0340 - acc: 0.09 - ETA: 57s - loss: 4.0443 - acc: 0.09 - ETA: 56s - loss: 4.0460 - acc: 0.09 - ETA: 56s - loss: 4.0418 - acc: 0.09 - ETA: 56s - loss: 4.0435 - acc: 0.09 - ETA: 56s - loss: 4.0449 - acc: 0.09 - ETA: 55s - loss: 4.0452 - acc: 0.09 - ETA: 55s - loss: 4.0412 - acc: 0.09 - ETA: 55s - loss: 4.0402 - acc: 0.09 - ETA: 55s - loss: 4.0401 - acc: 0.09 - ETA: 55s - loss: 4.0364 - acc: 0.09 - ETA: 54s - loss: 4.0370 - acc: 0.09 - ETA: 54s - loss: 4.0370 - acc: 0.09 - ETA: 54s - loss: 4.0358 - acc: 0.09 - ETA: 54s - loss: 4.0375 - acc: 0.09 - ETA: 53s - loss: 4.0306 - acc: 0.09 - ETA: 53s - loss: 4.0278 - acc: 0.09 - ETA: 53s - loss: 4.0283 - acc: 0.09 - ETA: 53s - loss: 4.0274 - acc: 0.09 - ETA: 53s - loss: 4.0221 - acc: 0.09 - ETA: 52s - loss: 4.0183 - acc: 0.09 - ETA: 52s - loss: 4.0162 - acc: 0.09 - ETA: 52s - loss: 4.0202 - acc: 0.09 - ETA: 52s - loss: 4.0149 - acc: 0.09 - ETA: 52s - loss: 4.0120 - acc: 0.09 - ETA: 51s - loss: 4.0102 - acc: 0.09 - ETA: 51s - loss: 4.0100 - acc: 0.09 - ETA: 51s - loss: 4.0114 - acc: 0.09 - ETA: 51s - loss: 4.0154 - acc: 0.09 - ETA: 51s - loss: 4.0170 - acc: 0.09 - ETA: 50s - loss: 4.0176 - acc: 0.10 - ETA: 50s - loss: 4.0179 - acc: 0.10 - ETA: 50s - loss: 4.0152 - acc: 0.10 - ETA: 50s - loss: 4.0117 - acc: 0.10 - ETA: 49s - loss: 4.0082 - acc: 0.10 - ETA: 49s - loss: 4.0084 - acc: 0.10 - ETA: 49s - loss: 4.0113 - acc: 0.09 - ETA: 49s - loss: 4.0130 - acc: 0.09 - ETA: 49s - loss: 4.0105 - acc: 0.09 - ETA: 48s - loss: 4.0069 - acc: 0.09 - ETA: 48s - loss: 4.0098 - acc: 0.09 - ETA: 48s - loss: 4.0119 - acc: 0.09 - ETA: 48s - loss: 4.0100 - acc: 0.09 - ETA: 48s - loss: 4.0068 - acc: 0.09 - ETA: 47s - loss: 4.0044 - acc: 0.09 - ETA: 47s - loss: 4.0045 - acc: 0.09 - ETA: 47s - loss: 4.0022 - acc: 0.09 - ETA: 47s - loss: 4.0044 - acc: 0.09 - ETA: 46s - loss: 4.0038 - acc: 0.09 - ETA: 46s - loss: 4.0051 - acc: 0.09 - ETA: 46s - loss: 4.0035 - acc: 0.09 - ETA: 46s - loss: 4.0071 - acc: 0.09 - ETA: 46s - loss: 4.0089 - acc: 0.09 - ETA: 45s - loss: 4.0095 - acc: 0.09 - ETA: 45s - loss: 4.0103 - acc: 0.09 - ETA: 45s - loss: 4.0134 - acc: 0.09 - ETA: 45s - loss: 4.0098 - acc: 0.09 - ETA: 45s - loss: 4.0131 - acc: 0.09 - ETA: 44s - loss: 4.0127 - acc: 0.09 - ETA: 44s - loss: 4.0173 - acc: 0.09 - ETA: 44s - loss: 4.0161 - acc: 0.09 - ETA: 44s - loss: 4.0131 - acc: 0.09 - ETA: 44s - loss: 4.0168 - acc: 0.09 - ETA: 43s - loss: 4.0162 - acc: 0.09 - ETA: 43s - loss: 4.0175 - acc: 0.09 - ETA: 43s - loss: 4.0175 - acc: 0.09 - ETA: 43s - loss: 4.0190 - acc: 0.09 - ETA: 42s - loss: 4.0198 - acc: 0.09 - ETA: 42s - loss: 4.0208 - acc: 0.09 - ETA: 42s - loss: 4.0221 - acc: 0.09 - ETA: 42s - loss: 4.0200 - acc: 0.09 - ETA: 42s - loss: 4.0184 - acc: 0.09 - ETA: 41s - loss: 4.0156 - acc: 0.09 - ETA: 41s - loss: 4.0092 - acc: 0.10 - ETA: 41s - loss: 4.0100 - acc: 0.10 - ETA: 41s - loss: 4.0083 - acc: 0.10 - ETA: 41s - loss: 4.0110 - acc: 0.10 - ETA: 40s - loss: 4.0117 - acc: 0.09 - ETA: 40s - loss: 4.0105 - acc: 0.09 - ETA: 40s - loss: 4.0100 - acc: 0.09 - ETA: 40s - loss: 4.0096 - acc: 0.09 - ETA: 40s - loss: 4.0089 - acc: 0.09 - ETA: 39s - loss: 4.0078 - acc: 0.09 - ETA: 39s - loss: 4.0107 - acc: 0.09 - ETA: 39s - loss: 4.0095 - acc: 0.09 - ETA: 39s - loss: 4.0121 - acc: 0.09 - ETA: 38s - loss: 4.0109 - acc: 0.09 - ETA: 38s - loss: 4.0108 - acc: 0.09 - ETA: 38s - loss: 4.0086 - acc: 0.09 - ETA: 38s - loss: 4.0085 - acc: 0.09 - ETA: 38s - loss: 4.0108 - acc: 0.09 - ETA: 37s - loss: 4.0092 - acc: 0.09 - ETA: 37s - loss: 4.0113 - acc: 0.09 - ETA: 37s - loss: 4.0111 - acc: 0.09 - ETA: 37s - loss: 4.0111 - acc: 0.09 - ETA: 37s - loss: 4.0111 - acc: 0.09 - ETA: 36s - loss: 4.0088 - acc: 0.09 - ETA: 36s - loss: 4.0097 - acc: 0.09 - ETA: 36s - loss: 4.0122 - acc: 0.09 - ETA: 36s - loss: 4.0122 - acc: 0.09 - ETA: 36s - loss: 4.0134 - acc: 0.09 - ETA: 35s - loss: 4.0126 - acc: 0.09 - ETA: 35s - loss: 4.0121 - acc: 0.09 - ETA: 35s - loss: 4.0128 - acc: 0.09 - ETA: 35s - loss: 4.0150 - acc: 0.09 - ETA: 34s - loss: 4.0155 - acc: 0.09 - ETA: 34s - loss: 4.0177 - acc: 0.09 - ETA: 34s - loss: 4.0156 - acc: 0.09 - ETA: 34s - loss: 4.0134 - acc: 0.09 - ETA: 34s - loss: 4.0161 - acc: 0.09 - ETA: 33s - loss: 4.0129 - acc: 0.09 - ETA: 33s - loss: 4.0134 - acc: 0.09 - ETA: 33s - loss: 4.0142 - acc: 0.09 - ETA: 33s - loss: 4.0160 - acc: 0.09 - ETA: 33s - loss: 4.0154 - acc: 0.09 - ETA: 32s - loss: 4.0134 - acc: 0.09 - ETA: 32s - loss: 4.0125 - acc: 0.09 - ETA: 32s - loss: 4.0134 - acc: 0.09 - ETA: 32s - loss: 4.0114 - acc: 0.09 - ETA: 31s - loss: 4.0109 - acc: 0.09 - ETA: 31s - loss: 4.0118 - acc: 0.09 - ETA: 31s - loss: 4.0134 - acc: 0.09 - ETA: 31s - loss: 4.0127 - acc: 0.09 - ETA: 31s - loss: 4.0163 - acc: 0.09 - ETA: 30s - loss: 4.0177 - acc: 0.09 - ETA: 30s - loss: 4.0165 - acc: 0.09 - ETA: 30s - loss: 4.0163 - acc: 0.09 - ETA: 30s - loss: 4.0188 - acc: 0.09 - ETA: 30s - loss: 4.0172 - acc: 0.09 - ETA: 29s - loss: 4.0170 - acc: 0.09 - ETA: 29s - loss: 4.0145 - acc: 0.09 - ETA: 29s - loss: 4.0124 - acc: 0.09 - ETA: 29s - loss: 4.0130 - acc: 0.09 - ETA: 29s - loss: 4.0112 - acc: 0.09 - ETA: 28s - loss: 4.0108 - acc: 0.09 - ETA: 28s - loss: 4.0124 - acc: 0.09 - ETA: 28s - loss: 4.0118 - acc: 0.09 - ETA: 28s - loss: 4.0145 - acc: 0.09 - ETA: 27s - loss: 4.0152 - acc: 0.09 - ETA: 27s - loss: 4.0149 - acc: 0.09 - ETA: 27s - loss: 4.0155 - acc: 0.09 - ETA: 27s - loss: 4.0142 - acc: 0.09 - ETA: 27s - loss: 4.0165 - acc: 0.09 - ETA: 26s - loss: 4.0162 - acc: 0.09 - ETA: 26s - loss: 4.0176 - acc: 0.09 - ETA: 26s - loss: 4.0173 - acc: 0.09 - ETA: 26s - loss: 4.0187 - acc: 0.09 - ETA: 26s - loss: 4.0193 - acc: 0.09 - ETA: 25s - loss: 4.0182 - acc: 0.09 - ETA: 25s - loss: 4.0177 - acc: 0.09 - ETA: 25s - loss: 4.0188 - acc: 0.09 - ETA: 25s - loss: 4.0194 - acc: 0.09 - ETA: 25s - loss: 4.0227 - acc: 0.0965"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6660/6680 [============================>.] - ETA: 24s - loss: 4.0221 - acc: 0.09 - ETA: 24s - loss: 4.0227 - acc: 0.09 - ETA: 24s - loss: 4.0233 - acc: 0.09 - ETA: 24s - loss: 4.0237 - acc: 0.09 - ETA: 23s - loss: 4.0262 - acc: 0.09 - ETA: 23s - loss: 4.0249 - acc: 0.09 - ETA: 23s - loss: 4.0225 - acc: 0.09 - ETA: 23s - loss: 4.0236 - acc: 0.09 - ETA: 23s - loss: 4.0241 - acc: 0.09 - ETA: 22s - loss: 4.0241 - acc: 0.09 - ETA: 22s - loss: 4.0232 - acc: 0.09 - ETA: 22s - loss: 4.0235 - acc: 0.09 - ETA: 22s - loss: 4.0228 - acc: 0.09 - ETA: 22s - loss: 4.0243 - acc: 0.09 - ETA: 21s - loss: 4.0243 - acc: 0.09 - ETA: 21s - loss: 4.0239 - acc: 0.09 - ETA: 21s - loss: 4.0227 - acc: 0.09 - ETA: 21s - loss: 4.0227 - acc: 0.09 - ETA: 21s - loss: 4.0241 - acc: 0.09 - ETA: 20s - loss: 4.0259 - acc: 0.09 - ETA: 20s - loss: 4.0273 - acc: 0.09 - ETA: 20s - loss: 4.0266 - acc: 0.09 - ETA: 20s - loss: 4.0276 - acc: 0.09 - ETA: 20s - loss: 4.0281 - acc: 0.09 - ETA: 19s - loss: 4.0281 - acc: 0.09 - ETA: 19s - loss: 4.0289 - acc: 0.09 - ETA: 19s - loss: 4.0293 - acc: 0.09 - ETA: 19s - loss: 4.0293 - acc: 0.09 - ETA: 18s - loss: 4.0312 - acc: 0.09 - ETA: 18s - loss: 4.0310 - acc: 0.09 - ETA: 18s - loss: 4.0321 - acc: 0.09 - ETA: 18s - loss: 4.0319 - acc: 0.09 - ETA: 18s - loss: 4.0322 - acc: 0.09 - ETA: 17s - loss: 4.0330 - acc: 0.09 - ETA: 17s - loss: 4.0333 - acc: 0.09 - ETA: 17s - loss: 4.0351 - acc: 0.09 - ETA: 17s - loss: 4.0341 - acc: 0.09 - ETA: 17s - loss: 4.0344 - acc: 0.09 - ETA: 16s - loss: 4.0351 - acc: 0.09 - ETA: 16s - loss: 4.0362 - acc: 0.09 - ETA: 16s - loss: 4.0358 - acc: 0.09 - ETA: 16s - loss: 4.0363 - acc: 0.09 - ETA: 16s - loss: 4.0359 - acc: 0.09 - ETA: 15s - loss: 4.0373 - acc: 0.09 - ETA: 15s - loss: 4.0375 - acc: 0.09 - ETA: 15s - loss: 4.0378 - acc: 0.09 - ETA: 15s - loss: 4.0393 - acc: 0.09 - ETA: 14s - loss: 4.0401 - acc: 0.09 - ETA: 14s - loss: 4.0392 - acc: 0.09 - ETA: 14s - loss: 4.0406 - acc: 0.09 - ETA: 14s - loss: 4.0417 - acc: 0.09 - ETA: 14s - loss: 4.0413 - acc: 0.09 - ETA: 13s - loss: 4.0418 - acc: 0.09 - ETA: 13s - loss: 4.0416 - acc: 0.09 - ETA: 13s - loss: 4.0422 - acc: 0.09 - ETA: 13s - loss: 4.0415 - acc: 0.09 - ETA: 13s - loss: 4.0424 - acc: 0.09 - ETA: 12s - loss: 4.0424 - acc: 0.09 - ETA: 12s - loss: 4.0424 - acc: 0.09 - ETA: 12s - loss: 4.0420 - acc: 0.09 - ETA: 12s - loss: 4.0406 - acc: 0.09 - ETA: 11s - loss: 4.0416 - acc: 0.09 - ETA: 11s - loss: 4.0430 - acc: 0.09 - ETA: 11s - loss: 4.0435 - acc: 0.09 - ETA: 11s - loss: 4.0437 - acc: 0.09 - ETA: 11s - loss: 4.0436 - acc: 0.09 - ETA: 10s - loss: 4.0434 - acc: 0.09 - ETA: 10s - loss: 4.0433 - acc: 0.09 - ETA: 10s - loss: 4.0440 - acc: 0.09 - ETA: 10s - loss: 4.0439 - acc: 0.09 - ETA: 10s - loss: 4.0430 - acc: 0.09 - ETA: 9s - loss: 4.0435 - acc: 0.0948 - ETA: 9s - loss: 4.0430 - acc: 0.094 - ETA: 9s - loss: 4.0417 - acc: 0.095 - ETA: 9s - loss: 4.0421 - acc: 0.094 - ETA: 9s - loss: 4.0422 - acc: 0.094 - ETA: 8s - loss: 4.0416 - acc: 0.094 - ETA: 8s - loss: 4.0400 - acc: 0.095 - ETA: 8s - loss: 4.0420 - acc: 0.095 - ETA: 8s - loss: 4.0440 - acc: 0.095 - ETA: 7s - loss: 4.0446 - acc: 0.095 - ETA: 7s - loss: 4.0431 - acc: 0.095 - ETA: 7s - loss: 4.0408 - acc: 0.096 - ETA: 7s - loss: 4.0421 - acc: 0.095 - ETA: 7s - loss: 4.0418 - acc: 0.096 - ETA: 6s - loss: 4.0411 - acc: 0.095 - ETA: 6s - loss: 4.0407 - acc: 0.095 - ETA: 6s - loss: 4.0403 - acc: 0.095 - ETA: 6s - loss: 4.0408 - acc: 0.095 - ETA: 6s - loss: 4.0404 - acc: 0.095 - ETA: 5s - loss: 4.0412 - acc: 0.095 - ETA: 5s - loss: 4.0402 - acc: 0.095 - ETA: 5s - loss: 4.0401 - acc: 0.095 - ETA: 5s - loss: 4.0394 - acc: 0.095 - ETA: 5s - loss: 4.0384 - acc: 0.095 - ETA: 4s - loss: 4.0384 - acc: 0.095 - ETA: 4s - loss: 4.0401 - acc: 0.095 - ETA: 4s - loss: 4.0405 - acc: 0.095 - ETA: 4s - loss: 4.0408 - acc: 0.095 - ETA: 3s - loss: 4.0404 - acc: 0.095 - ETA: 3s - loss: 4.0421 - acc: 0.095 - ETA: 3s - loss: 4.0424 - acc: 0.095 - ETA: 3s - loss: 4.0417 - acc: 0.095 - ETA: 3s - loss: 4.0416 - acc: 0.095 - ETA: 2s - loss: 4.0429 - acc: 0.095 - ETA: 2s - loss: 4.0442 - acc: 0.094 - ETA: 2s - loss: 4.0425 - acc: 0.095 - ETA: 2s - loss: 4.0444 - acc: 0.094 - ETA: 2s - loss: 4.0447 - acc: 0.094 - ETA: 1s - loss: 4.0451 - acc: 0.094 - ETA: 1s - loss: 4.0458 - acc: 0.094 - ETA: 1s - loss: 4.0464 - acc: 0.094 - ETA: 1s - loss: 4.0458 - acc: 0.094 - ETA: 1s - loss: 4.0453 - acc: 0.094 - ETA: 0s - loss: 4.0457 - acc: 0.094 - ETA: 0s - loss: 4.0438 - acc: 0.095 - ETA: 0s - loss: 4.0437 - acc: 0.095 - ETA: 0s - loss: 4.0434 - acc: 0.0955Epoch 00031: val_loss improved from 4.15619 to 4.14830, saving model to saved_models/weights.best.from_scratch.hdf5\n",
      "6680/6680 [==============================] - 73s - loss: 4.0436 - acc: 0.0955 - val_loss: 4.1483 - val_acc: 0.0910\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x19aa52a29b0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint  \n",
    "\n",
    "### TODO: specify the number of epochs that you would like to use to train the model.\n",
    "\n",
    "epochs = 32\n",
    "\n",
    "### Do NOT modify the code below this line.\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='saved_models/weights.best.from_scratch.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "\n",
    "model.fit(train_tensors, train_targets, \n",
    "          validation_data=(valid_tensors, valid_targets),\n",
    "          epochs=epochs, batch_size=20, callbacks=[checkpointer], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Model with the Best Validation Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.load_weights('saved_models/weights.best.from_scratch.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the Model\n",
    "\n",
    "Try out your model on the test dataset of dog images.  Ensure that your test accuracy is greater than 1%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 11.7225%\n"
     ]
    }
   ],
   "source": [
    "# get index of predicted dog breed for each image in test set\n",
    "dog_breed_predictions = [np.argmax(model.predict(np.expand_dims(tensor, axis=0))) for tensor in test_tensors]\n",
    "\n",
    "# report test accuracy\n",
    "test_accuracy = 100*np.sum(np.array(dog_breed_predictions)==np.argmax(test_targets, axis=1))/len(dog_breed_predictions)\n",
    "print('Test accuracy: %.4f%%' % test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='step4'></a>\n",
    "## Step 4: Use a CNN to Classify Dog Breeds\n",
    "\n",
    "To reduce training time without sacrificing accuracy, we show you how to train a CNN using transfer learning.  In the following step, you will get a chance to use transfer learning to train your own CNN.\n",
    "\n",
    "### Obtain Bottleneck Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bottleneck_features = np.load('bottleneck_features/DogVGG16Data.npz')\n",
    "train_VGG16 = bottleneck_features['train']\n",
    "valid_VGG16 = bottleneck_features['valid']\n",
    "test_VGG16 = bottleneck_features['test']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Architecture\n",
    "\n",
    "The model uses the the pre-trained VGG-16 model as a fixed feature extractor, where the last convolutional output of VGG-16 is fed as input to our model.  We only add a global average pooling layer and a fully connected layer, where the latter contains one node for each dog category and is equipped with a softmax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "global_average_pooling2d_2 ( (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 133)               68229     \n",
      "=================================================================\n",
      "Total params: 68,229\n",
      "Trainable params: 68,229\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "VGG16_model = Sequential()\n",
    "VGG16_model.add(GlobalAveragePooling2D(input_shape=train_VGG16.shape[1:]))\n",
    "VGG16_model.add(Dense(133, activation='softmax'))\n",
    "\n",
    "VGG16_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "VGG16_model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6680 samples, validate on 835 samples\n",
      "Epoch 1/20\n",
      "6600/6680 [============================>.] - ETA: 72s - loss: 15.2673 - acc: 0.0000e+0 - ETA: 6s - loss: 14.7803 - acc: 0.0231    - ETA: 3s - loss: 14.3478 - acc: 0.02 - ETA: 2s - loss: 14.1539 - acc: 0.03 - ETA: 2s - loss: 14.2384 - acc: 0.02 - ETA: 1s - loss: 14.1169 - acc: 0.03 - ETA: 1s - loss: 13.8931 - acc: 0.03 - ETA: 1s - loss: 13.6962 - acc: 0.04 - ETA: 1s - loss: 13.5611 - acc: 0.04 - ETA: 1s - loss: 13.4599 - acc: 0.05 - ETA: 0s - loss: 13.3327 - acc: 0.05 - ETA: 0s - loss: 13.2347 - acc: 0.06 - ETA: 0s - loss: 13.1128 - acc: 0.06 - ETA: 0s - loss: 13.0148 - acc: 0.07 - ETA: 0s - loss: 12.9030 - acc: 0.07 - ETA: 0s - loss: 12.7354 - acc: 0.08 - ETA: 0s - loss: 12.6182 - acc: 0.08 - ETA: 0s - loss: 12.4861 - acc: 0.09 - ETA: 0s - loss: 12.3820 - acc: 0.09 - ETA: 0s - loss: 12.2758 - acc: 0.10 - ETA: 0s - loss: 12.2066 - acc: 0.10 - ETA: 0s - loss: 12.1651 - acc: 0.10 - ETA: 0s - loss: 12.0646 - acc: 0.11 - ETA: 0s - loss: 11.9846 - acc: 0.1156Epoch 00000: val_loss improved from inf to 10.25502, saving model to saved_models/weights.best.VGG16.hdf5\n",
      "6680/6680 [==============================] - 1s - loss: 11.9709 - acc: 0.1165 - val_loss: 10.2550 - val_acc: 0.2060\n",
      "Epoch 2/20\n",
      "6440/6680 [===========================>..] - ETA: 1s - loss: 10.2620 - acc: 0.25 - ETA: 1s - loss: 10.0809 - acc: 0.24 - ETA: 1s - loss: 9.9483 - acc: 0.2484 - ETA: 1s - loss: 9.8422 - acc: 0.253 - ETA: 0s - loss: 9.5551 - acc: 0.265 - ETA: 0s - loss: 9.5299 - acc: 0.269 - ETA: 0s - loss: 9.4753 - acc: 0.279 - ETA: 0s - loss: 9.3222 - acc: 0.286 - ETA: 0s - loss: 9.3164 - acc: 0.287 - ETA: 0s - loss: 9.3349 - acc: 0.287 - ETA: 0s - loss: 9.3057 - acc: 0.290 - ETA: 0s - loss: 9.3051 - acc: 0.293 - ETA: 0s - loss: 9.3288 - acc: 0.293 - ETA: 0s - loss: 9.3189 - acc: 0.295 - ETA: 0s - loss: 9.3137 - acc: 0.297 - ETA: 0s - loss: 9.3447 - acc: 0.295 - ETA: 0s - loss: 9.2782 - acc: 0.299 - ETA: 0s - loss: 9.2659 - acc: 0.301 - ETA: 0s - loss: 9.2770 - acc: 0.302 - ETA: 0s - loss: 9.2583 - acc: 0.303 - ETA: 0s - loss: 9.2432 - acc: 0.304 - ETA: 0s - loss: 9.2549 - acc: 0.305 - ETA: 0s - loss: 9.2506 - acc: 0.3048Epoch 00001: val_loss improved from 10.25502 to 9.17342, saving model to saved_models/weights.best.VGG16.hdf5\n",
      "6680/6680 [==============================] - 1s - loss: 9.2288 - acc: 0.3072 - val_loss: 9.1734 - val_acc: 0.3066\n",
      "Epoch 3/20\n",
      "6460/6680 [============================>.] - ETA: 1s - loss: 5.9668 - acc: 0.550 - ETA: 1s - loss: 8.1419 - acc: 0.412 - ETA: 1s - loss: 8.2572 - acc: 0.396 - ETA: 1s - loss: 8.1931 - acc: 0.401 - ETA: 0s - loss: 8.2717 - acc: 0.399 - ETA: 0s - loss: 8.4531 - acc: 0.390 - ETA: 0s - loss: 8.5194 - acc: 0.382 - ETA: 0s - loss: 8.5118 - acc: 0.382 - ETA: 0s - loss: 8.4982 - acc: 0.385 - ETA: 0s - loss: 8.5323 - acc: 0.384 - ETA: 0s - loss: 8.5243 - acc: 0.386 - ETA: 0s - loss: 8.4841 - acc: 0.388 - ETA: 0s - loss: 8.5732 - acc: 0.385 - ETA: 0s - loss: 8.5174 - acc: 0.390 - ETA: 0s - loss: 8.5216 - acc: 0.390 - ETA: 0s - loss: 8.5285 - acc: 0.390 - ETA: 0s - loss: 8.5344 - acc: 0.389 - ETA: 0s - loss: 8.5413 - acc: 0.389 - ETA: 0s - loss: 8.5451 - acc: 0.389 - ETA: 0s - loss: 8.5303 - acc: 0.389 - ETA: 0s - loss: 8.5246 - acc: 0.389 - ETA: 0s - loss: 8.5230 - acc: 0.390 - ETA: 0s - loss: 8.5417 - acc: 0.3899Epoch 00002: val_loss improved from 9.17342 to 8.87977, saving model to saved_models/weights.best.VGG16.hdf5\n",
      "6680/6680 [==============================] - 1s - loss: 8.5419 - acc: 0.3900 - val_loss: 8.8798 - val_acc: 0.3569\n",
      "Epoch 4/20\n",
      "6640/6680 [============================>.] - ETA: 1s - loss: 7.5581 - acc: 0.500 - ETA: 1s - loss: 8.3204 - acc: 0.421 - ETA: 1s - loss: 8.3019 - acc: 0.430 - ETA: 1s - loss: 8.1290 - acc: 0.444 - ETA: 0s - loss: 8.2590 - acc: 0.437 - ETA: 0s - loss: 8.4344 - acc: 0.429 - ETA: 0s - loss: 8.4896 - acc: 0.421 - ETA: 0s - loss: 8.3852 - acc: 0.428 - ETA: 0s - loss: 8.3990 - acc: 0.428 - ETA: 0s - loss: 8.3864 - acc: 0.427 - ETA: 0s - loss: 8.3320 - acc: 0.429 - ETA: 0s - loss: 8.3403 - acc: 0.428 - ETA: 0s - loss: 8.3262 - acc: 0.429 - ETA: 0s - loss: 8.3462 - acc: 0.427 - ETA: 0s - loss: 8.3219 - acc: 0.427 - ETA: 0s - loss: 8.3371 - acc: 0.426 - ETA: 0s - loss: 8.4097 - acc: 0.421 - ETA: 0s - loss: 8.4041 - acc: 0.422 - ETA: 0s - loss: 8.4019 - acc: 0.422 - ETA: 0s - loss: 8.3712 - acc: 0.424 - ETA: 0s - loss: 8.3767 - acc: 0.424 - ETA: 0s - loss: 8.3521 - acc: 0.425 - ETA: 0s - loss: 8.3265 - acc: 0.425 - ETA: 0s - loss: 8.3134 - acc: 0.4258Epoch 00003: val_loss improved from 8.87977 to 8.82536, saving model to saved_models/weights.best.VGG16.hdf5\n",
      "6680/6680 [==============================] - 1s - loss: 8.3052 - acc: 0.4260 - val_loss: 8.8254 - val_acc: 0.3521\n",
      "Epoch 5/20\n",
      "6400/6680 [===========================>..] - ETA: 1s - loss: 9.1891 - acc: 0.400 - ETA: 1s - loss: 7.6948 - acc: 0.486 - ETA: 1s - loss: 8.0501 - acc: 0.466 - ETA: 1s - loss: 7.9288 - acc: 0.468 - ETA: 0s - loss: 7.9615 - acc: 0.455 - ETA: 0s - loss: 7.9380 - acc: 0.459 - ETA: 0s - loss: 8.0396 - acc: 0.453 - ETA: 0s - loss: 8.0518 - acc: 0.453 - ETA: 0s - loss: 8.0139 - acc: 0.455 - ETA: 0s - loss: 7.9658 - acc: 0.457 - ETA: 0s - loss: 7.9300 - acc: 0.460 - ETA: 0s - loss: 7.9567 - acc: 0.457 - ETA: 0s - loss: 7.9509 - acc: 0.456 - ETA: 0s - loss: 7.9279 - acc: 0.458 - ETA: 0s - loss: 7.9544 - acc: 0.456 - ETA: 0s - loss: 7.9503 - acc: 0.456 - ETA: 0s - loss: 7.9927 - acc: 0.454 - ETA: 0s - loss: 8.0327 - acc: 0.451 - ETA: 0s - loss: 7.9945 - acc: 0.454 - ETA: 0s - loss: 8.0193 - acc: 0.452 - ETA: 0s - loss: 8.0037 - acc: 0.454 - ETA: 0s - loss: 8.0266 - acc: 0.452 - ETA: 0s - loss: 8.0135 - acc: 0.4534Epoch 00004: val_loss improved from 8.82536 to 8.56313, saving model to saved_models/weights.best.VGG16.hdf5\n",
      "6680/6680 [==============================] - 1s - loss: 8.0527 - acc: 0.4512 - val_loss: 8.5631 - val_acc: 0.3713\n",
      "Epoch 6/20\n",
      "6420/6680 [===========================>..] - ETA: 0s - loss: 8.8687 - acc: 0.450 - ETA: 1s - loss: 8.1449 - acc: 0.465 - ETA: 1s - loss: 8.0679 - acc: 0.458 - ETA: 1s - loss: 7.9890 - acc: 0.467 - ETA: 0s - loss: 8.1001 - acc: 0.454 - ETA: 0s - loss: 8.1059 - acc: 0.456 - ETA: 0s - loss: 8.0509 - acc: 0.461 - ETA: 0s - loss: 8.0808 - acc: 0.459 - ETA: 0s - loss: 7.9660 - acc: 0.468 - ETA: 0s - loss: 7.8786 - acc: 0.472 - ETA: 0s - loss: 7.9709 - acc: 0.468 - ETA: 0s - loss: 7.9691 - acc: 0.467 - ETA: 0s - loss: 8.0026 - acc: 0.467 - ETA: 0s - loss: 7.9754 - acc: 0.468 - ETA: 0s - loss: 7.9308 - acc: 0.471 - ETA: 0s - loss: 7.8658 - acc: 0.474 - ETA: 0s - loss: 7.8548 - acc: 0.475 - ETA: 0s - loss: 7.8400 - acc: 0.475 - ETA: 0s - loss: 7.8908 - acc: 0.473 - ETA: 0s - loss: 7.8808 - acc: 0.473 - ETA: 0s - loss: 7.8976 - acc: 0.471 - ETA: 0s - loss: 7.8943 - acc: 0.471 - ETA: 0s - loss: 7.8853 - acc: 0.4715Epoch 00005: val_loss improved from 8.56313 to 8.47503, saving model to saved_models/weights.best.VGG16.hdf5\n",
      "6680/6680 [==============================] - 1s - loss: 7.8830 - acc: 0.4723 - val_loss: 8.4750 - val_acc: 0.3916\n",
      "Epoch 7/20\n",
      "6440/6680 [===========================>..] - ETA: 0s - loss: 7.3742 - acc: 0.500 - ETA: 1s - loss: 8.0052 - acc: 0.478 - ETA: 1s - loss: 7.8113 - acc: 0.496 - ETA: 1s - loss: 7.6508 - acc: 0.502 - ETA: 0s - loss: 7.4807 - acc: 0.509 - ETA: 0s - loss: 7.5494 - acc: 0.505 - ETA: 0s - loss: 7.6407 - acc: 0.500 - ETA: 0s - loss: 7.6177 - acc: 0.499 - ETA: 0s - loss: 7.6908 - acc: 0.495 - ETA: 0s - loss: 7.6520 - acc: 0.498 - ETA: 0s - loss: 7.6715 - acc: 0.496 - ETA: 0s - loss: 7.7216 - acc: 0.493 - ETA: 0s - loss: 7.7765 - acc: 0.489 - ETA: 0s - loss: 7.8512 - acc: 0.485 - ETA: 0s - loss: 7.8862 - acc: 0.482 - ETA: 0s - loss: 7.8858 - acc: 0.483 - ETA: 0s - loss: 7.8815 - acc: 0.483 - ETA: 0s - loss: 7.8378 - acc: 0.486 - ETA: 0s - loss: 7.8170 - acc: 0.487 - ETA: 0s - loss: 7.8187 - acc: 0.487 - ETA: 0s - loss: 7.8184 - acc: 0.487 - ETA: 0s - loss: 7.7916 - acc: 0.488 - ETA: 0s - loss: 7.7955 - acc: 0.4882Epoch 00006: val_loss improved from 8.47503 to 8.43913, saving model to saved_models/weights.best.VGG16.hdf5\n",
      "6680/6680 [==============================] - 1s - loss: 7.8174 - acc: 0.4865 - val_loss: 8.4391 - val_acc: 0.3832\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20\n",
      "6620/6680 [============================>.] - ETA: 1s - loss: 6.4528 - acc: 0.600 - ETA: 1s - loss: 7.3998 - acc: 0.531 - ETA: 1s - loss: 7.7341 - acc: 0.508 - ETA: 0s - loss: 7.5494 - acc: 0.516 - ETA: 0s - loss: 7.5448 - acc: 0.517 - ETA: 0s - loss: 7.5957 - acc: 0.513 - ETA: 0s - loss: 7.6249 - acc: 0.512 - ETA: 0s - loss: 7.5982 - acc: 0.514 - ETA: 0s - loss: 7.6983 - acc: 0.507 - ETA: 0s - loss: 7.6415 - acc: 0.510 - ETA: 0s - loss: 7.6575 - acc: 0.510 - ETA: 0s - loss: 7.6561 - acc: 0.509 - ETA: 0s - loss: 7.6707 - acc: 0.506 - ETA: 0s - loss: 7.6915 - acc: 0.506 - ETA: 0s - loss: 7.7103 - acc: 0.505 - ETA: 0s - loss: 7.7271 - acc: 0.504 - ETA: 0s - loss: 7.7457 - acc: 0.502 - ETA: 0s - loss: 7.6974 - acc: 0.504 - ETA: 0s - loss: 7.7103 - acc: 0.503 - ETA: 0s - loss: 7.7616 - acc: 0.500 - ETA: 0s - loss: 7.7391 - acc: 0.501 - ETA: 0s - loss: 7.7339 - acc: 0.500 - ETA: 0s - loss: 7.7470 - acc: 0.4994Epoch 00007: val_loss improved from 8.43913 to 8.39022, saving model to saved_models/weights.best.VGG16.hdf5\n",
      "6680/6680 [==============================] - 1s - loss: 7.7500 - acc: 0.4990 - val_loss: 8.3902 - val_acc: 0.3844\n",
      "Epoch 9/20\n",
      "6580/6680 [============================>.] - ETA: 1s - loss: 6.4478 - acc: 0.600 - ETA: 1s - loss: 7.3569 - acc: 0.520 - ETA: 1s - loss: 7.4055 - acc: 0.511 - ETA: 1s - loss: 7.4790 - acc: 0.515 - ETA: 0s - loss: 7.4673 - acc: 0.517 - ETA: 0s - loss: 7.4569 - acc: 0.520 - ETA: 0s - loss: 7.4925 - acc: 0.516 - ETA: 0s - loss: 7.5743 - acc: 0.510 - ETA: 0s - loss: 7.6201 - acc: 0.508 - ETA: 0s - loss: 7.4530 - acc: 0.516 - ETA: 0s - loss: 7.5252 - acc: 0.511 - ETA: 0s - loss: 7.4772 - acc: 0.515 - ETA: 0s - loss: 7.4806 - acc: 0.515 - ETA: 0s - loss: 7.4904 - acc: 0.514 - ETA: 0s - loss: 7.5348 - acc: 0.511 - ETA: 0s - loss: 7.5857 - acc: 0.509 - ETA: 0s - loss: 7.5939 - acc: 0.509 - ETA: 0s - loss: 7.5534 - acc: 0.511 - ETA: 0s - loss: 7.5414 - acc: 0.512 - ETA: 0s - loss: 7.5455 - acc: 0.511 - ETA: 0s - loss: 7.5423 - acc: 0.511 - ETA: 0s - loss: 7.5696 - acc: 0.509 - ETA: 0s - loss: 7.5736 - acc: 0.5093Epoch 00008: val_loss improved from 8.39022 to 8.37244, saving model to saved_models/weights.best.VGG16.hdf5\n",
      "6680/6680 [==============================] - 1s - loss: 7.5813 - acc: 0.5088 - val_loss: 8.3724 - val_acc: 0.3904\n",
      "Epoch 10/20\n",
      "6580/6680 [============================>.] - ETA: 0s - loss: 7.2626 - acc: 0.550 - ETA: 1s - loss: 6.8732 - acc: 0.559 - ETA: 1s - loss: 7.2866 - acc: 0.536 - ETA: 1s - loss: 7.5361 - acc: 0.517 - ETA: 0s - loss: 7.6599 - acc: 0.509 - ETA: 0s - loss: 7.7179 - acc: 0.507 - ETA: 0s - loss: 7.5926 - acc: 0.513 - ETA: 0s - loss: 7.6890 - acc: 0.507 - ETA: 0s - loss: 7.6936 - acc: 0.507 - ETA: 0s - loss: 7.6890 - acc: 0.508 - ETA: 0s - loss: 7.6432 - acc: 0.511 - ETA: 0s - loss: 7.6568 - acc: 0.511 - ETA: 0s - loss: 7.6360 - acc: 0.512 - ETA: 0s - loss: 7.5714 - acc: 0.516 - ETA: 0s - loss: 7.5683 - acc: 0.517 - ETA: 0s - loss: 7.5497 - acc: 0.517 - ETA: 0s - loss: 7.5285 - acc: 0.519 - ETA: 0s - loss: 7.5152 - acc: 0.520 - ETA: 0s - loss: 7.5250 - acc: 0.519 - ETA: 0s - loss: 7.5566 - acc: 0.517 - ETA: 0s - loss: 7.4941 - acc: 0.521 - ETA: 0s - loss: 7.5441 - acc: 0.518 - ETA: 0s - loss: 7.5509 - acc: 0.5176Epoch 00009: val_loss improved from 8.37244 to 8.28751, saving model to saved_models/weights.best.VGG16.hdf5\n",
      "6680/6680 [==============================] - 1s - loss: 7.5380 - acc: 0.5184 - val_loss: 8.2875 - val_acc: 0.4048\n",
      "Epoch 11/20\n",
      "6620/6680 [============================>.] - ETA: 0s - loss: 5.6419 - acc: 0.650 - ETA: 1s - loss: 7.6376 - acc: 0.518 - ETA: 1s - loss: 7.5438 - acc: 0.525 - ETA: 0s - loss: 7.3676 - acc: 0.537 - ETA: 0s - loss: 7.3703 - acc: 0.536 - ETA: 0s - loss: 7.3036 - acc: 0.539 - ETA: 0s - loss: 7.3105 - acc: 0.538 - ETA: 0s - loss: 7.3660 - acc: 0.535 - ETA: 0s - loss: 7.3336 - acc: 0.537 - ETA: 0s - loss: 7.3799 - acc: 0.534 - ETA: 0s - loss: 7.4474 - acc: 0.529 - ETA: 0s - loss: 7.4210 - acc: 0.531 - ETA: 0s - loss: 7.4825 - acc: 0.527 - ETA: 0s - loss: 7.4764 - acc: 0.527 - ETA: 0s - loss: 7.4432 - acc: 0.529 - ETA: 0s - loss: 7.4327 - acc: 0.530 - ETA: 0s - loss: 7.4269 - acc: 0.530 - ETA: 0s - loss: 7.4514 - acc: 0.528 - ETA: 0s - loss: 7.4762 - acc: 0.527 - ETA: 0s - loss: 7.5093 - acc: 0.525 - ETA: 0s - loss: 7.5250 - acc: 0.524 - ETA: 0s - loss: 7.5086 - acc: 0.524 - ETA: 0s - loss: 7.5170 - acc: 0.5240Epoch 00010: val_loss improved from 8.28751 to 8.21927, saving model to saved_models/weights.best.VGG16.hdf5\n",
      "6680/6680 [==============================] - 1s - loss: 7.5176 - acc: 0.5240 - val_loss: 8.2193 - val_acc: 0.4263\n",
      "Epoch 12/20\n",
      "6500/6680 [============================>.] - ETA: 1s - loss: 8.0653 - acc: 0.500 - ETA: 1s - loss: 7.8197 - acc: 0.513 - ETA: 1s - loss: 7.5942 - acc: 0.524 - ETA: 1s - loss: 7.5709 - acc: 0.521 - ETA: 0s - loss: 7.6927 - acc: 0.514 - ETA: 0s - loss: 7.6116 - acc: 0.520 - ETA: 0s - loss: 7.6692 - acc: 0.517 - ETA: 0s - loss: 7.6516 - acc: 0.518 - ETA: 0s - loss: 7.6384 - acc: 0.518 - ETA: 0s - loss: 7.5624 - acc: 0.522 - ETA: 0s - loss: 7.5353 - acc: 0.524 - ETA: 0s - loss: 7.4770 - acc: 0.527 - ETA: 0s - loss: 7.4446 - acc: 0.529 - ETA: 0s - loss: 7.4465 - acc: 0.529 - ETA: 0s - loss: 7.4361 - acc: 0.530 - ETA: 0s - loss: 7.4393 - acc: 0.530 - ETA: 0s - loss: 7.4438 - acc: 0.529 - ETA: 0s - loss: 7.4764 - acc: 0.526 - ETA: 0s - loss: 7.4700 - acc: 0.526 - ETA: 0s - loss: 7.4759 - acc: 0.525 - ETA: 0s - loss: 7.4782 - acc: 0.525 - ETA: 0s - loss: 7.4809 - acc: 0.525 - ETA: 0s - loss: 7.4798 - acc: 0.5260Epoch 00011: val_loss improved from 8.21927 to 8.19401, saving model to saved_models/weights.best.VGG16.hdf5\n",
      "6680/6680 [==============================] - 1s - loss: 7.4832 - acc: 0.5257 - val_loss: 8.1940 - val_acc: 0.4192\n",
      "Epoch 13/20\n",
      "6600/6680 [============================>.] - ETA: 1s - loss: 7.2534 - acc: 0.550 - ETA: 1s - loss: 7.2671 - acc: 0.543 - ETA: 1s - loss: 7.2708 - acc: 0.541 - ETA: 0s - loss: 7.2192 - acc: 0.543 - ETA: 0s - loss: 7.3844 - acc: 0.532 - ETA: 0s - loss: 7.3552 - acc: 0.530 - ETA: 0s - loss: 7.4331 - acc: 0.525 - ETA: 0s - loss: 7.3596 - acc: 0.530 - ETA: 0s - loss: 7.4078 - acc: 0.527 - ETA: 0s - loss: 7.4843 - acc: 0.522 - ETA: 0s - loss: 7.4575 - acc: 0.524 - ETA: 0s - loss: 7.4404 - acc: 0.526 - ETA: 0s - loss: 7.4264 - acc: 0.526 - ETA: 0s - loss: 7.4789 - acc: 0.523 - ETA: 0s - loss: 7.4755 - acc: 0.524 - ETA: 0s - loss: 7.4457 - acc: 0.526 - ETA: 0s - loss: 7.4254 - acc: 0.527 - ETA: 0s - loss: 7.4320 - acc: 0.527 - ETA: 0s - loss: 7.4494 - acc: 0.526 - ETA: 0s - loss: 7.4336 - acc: 0.527 - ETA: 0s - loss: 7.4042 - acc: 0.529 - ETA: 0s - loss: 7.4222 - acc: 0.528 - ETA: 0s - loss: 7.4085 - acc: 0.5291Epoch 00012: val_loss improved from 8.19401 to 8.15386, saving model to saved_models/weights.best.VGG16.hdf5\n",
      "6680/6680 [==============================] - 1s - loss: 7.4117 - acc: 0.5289 - val_loss: 8.1539 - val_acc: 0.4156\n",
      "Epoch 14/20\n",
      "6660/6680 [============================>.] - ETA: 1s - loss: 10.4768 - acc: 0.35 - ETA: 1s - loss: 9.4815 - acc: 0.4094 - ETA: 1s - loss: 8.2956 - acc: 0.477 - ETA: 0s - loss: 7.8533 - acc: 0.506 - ETA: 0s - loss: 7.8033 - acc: 0.511 - ETA: 0s - loss: 7.7461 - acc: 0.513 - ETA: 0s - loss: 7.6673 - acc: 0.519 - ETA: 0s - loss: 7.6580 - acc: 0.519 - ETA: 0s - loss: 7.6062 - acc: 0.522 - ETA: 0s - loss: 7.5626 - acc: 0.524 - ETA: 0s - loss: 7.5343 - acc: 0.525 - ETA: 0s - loss: 7.5486 - acc: 0.523 - ETA: 0s - loss: 7.5257 - acc: 0.525 - ETA: 0s - loss: 7.5191 - acc: 0.525 - ETA: 0s - loss: 7.4835 - acc: 0.527 - ETA: 0s - loss: 7.4524 - acc: 0.530 - ETA: 0s - loss: 7.4075 - acc: 0.532 - ETA: 0s - loss: 7.4313 - acc: 0.531 - ETA: 0s - loss: 7.4120 - acc: 0.532 - ETA: 0s - loss: 7.4189 - acc: 0.532 - ETA: 0s - loss: 7.4012 - acc: 0.533 - ETA: 0s - loss: 7.3814 - acc: 0.534 - ETA: 0s - loss: 7.3813 - acc: 0.5342Epoch 00013: val_loss did not improve\n",
      "6680/6680 [==============================] - 1s - loss: 7.3881 - acc: 0.5338 - val_loss: 8.1953 - val_acc: 0.4144\n",
      "Epoch 15/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6380/6680 [===========================>..] - ETA: 1s - loss: 9.6709 - acc: 0.400 - ETA: 1s - loss: 6.1676 - acc: 0.609 - ETA: 1s - loss: 6.7207 - acc: 0.579 - ETA: 0s - loss: 6.8686 - acc: 0.568 - ETA: 0s - loss: 7.0382 - acc: 0.559 - ETA: 0s - loss: 7.2854 - acc: 0.542 - ETA: 0s - loss: 7.3318 - acc: 0.537 - ETA: 0s - loss: 7.3669 - acc: 0.534 - ETA: 0s - loss: 7.3824 - acc: 0.532 - ETA: 0s - loss: 7.3402 - acc: 0.535 - ETA: 0s - loss: 7.2821 - acc: 0.538 - ETA: 0s - loss: 7.3183 - acc: 0.536 - ETA: 0s - loss: 7.2819 - acc: 0.536 - ETA: 0s - loss: 7.2857 - acc: 0.536 - ETA: 0s - loss: 7.2791 - acc: 0.536 - ETA: 0s - loss: 7.3120 - acc: 0.534 - ETA: 0s - loss: 7.2967 - acc: 0.535 - ETA: 0s - loss: 7.2933 - acc: 0.536 - ETA: 0s - loss: 7.2613 - acc: 0.538 - ETA: 0s - loss: 7.3015 - acc: 0.536 - ETA: 0s - loss: 7.3337 - acc: 0.534 - ETA: 0s - loss: 7.3347 - acc: 0.5337Epoch 00014: val_loss improved from 8.15386 to 8.06791, saving model to saved_models/weights.best.VGG16.hdf5\n",
      "6680/6680 [==============================] - 1s - loss: 7.3028 - acc: 0.5358 - val_loss: 8.0679 - val_acc: 0.4263\n",
      "Epoch 16/20\n",
      "6380/6680 [===========================>..] - ETA: 1s - loss: 5.6417 - acc: 0.650 - ETA: 1s - loss: 7.1590 - acc: 0.546 - ETA: 1s - loss: 7.2789 - acc: 0.540 - ETA: 0s - loss: 7.4312 - acc: 0.531 - ETA: 0s - loss: 7.2897 - acc: 0.540 - ETA: 0s - loss: 7.2582 - acc: 0.540 - ETA: 0s - loss: 7.3526 - acc: 0.534 - ETA: 0s - loss: 7.3593 - acc: 0.533 - ETA: 0s - loss: 7.3155 - acc: 0.536 - ETA: 0s - loss: 7.3645 - acc: 0.533 - ETA: 0s - loss: 7.3817 - acc: 0.532 - ETA: 0s - loss: 7.3859 - acc: 0.532 - ETA: 0s - loss: 7.3340 - acc: 0.535 - ETA: 0s - loss: 7.3040 - acc: 0.537 - ETA: 0s - loss: 7.2630 - acc: 0.540 - ETA: 0s - loss: 7.1983 - acc: 0.544 - ETA: 0s - loss: 7.2582 - acc: 0.540 - ETA: 0s - loss: 7.2854 - acc: 0.539 - ETA: 0s - loss: 7.2475 - acc: 0.541 - ETA: 0s - loss: 7.2235 - acc: 0.542 - ETA: 0s - loss: 7.2379 - acc: 0.540 - ETA: 0s - loss: 7.2311 - acc: 0.5411Epoch 00015: val_loss improved from 8.06791 to 7.95287, saving model to saved_models/weights.best.VGG16.hdf5\n",
      "6680/6680 [==============================] - 1s - loss: 7.2303 - acc: 0.5412 - val_loss: 7.9529 - val_acc: 0.4359\n",
      "Epoch 17/20\n",
      "6660/6680 [============================>.] - ETA: 0s - loss: 4.8358 - acc: 0.700 - ETA: 1s - loss: 6.9022 - acc: 0.565 - ETA: 1s - loss: 7.3488 - acc: 0.538 - ETA: 0s - loss: 7.4390 - acc: 0.533 - ETA: 0s - loss: 7.2492 - acc: 0.545 - ETA: 0s - loss: 7.2588 - acc: 0.545 - ETA: 0s - loss: 7.3197 - acc: 0.541 - ETA: 0s - loss: 7.2833 - acc: 0.542 - ETA: 0s - loss: 7.2803 - acc: 0.542 - ETA: 0s - loss: 7.2805 - acc: 0.542 - ETA: 0s - loss: 7.3037 - acc: 0.540 - ETA: 0s - loss: 7.3266 - acc: 0.538 - ETA: 0s - loss: 7.3081 - acc: 0.539 - ETA: 0s - loss: 7.2364 - acc: 0.542 - ETA: 0s - loss: 7.2014 - acc: 0.544 - ETA: 0s - loss: 7.2279 - acc: 0.542 - ETA: 0s - loss: 7.2266 - acc: 0.541 - ETA: 0s - loss: 7.2327 - acc: 0.541 - ETA: 0s - loss: 7.2963 - acc: 0.537 - ETA: 0s - loss: 7.2863 - acc: 0.537 - ETA: 0s - loss: 7.2376 - acc: 0.539 - ETA: 0s - loss: 7.2119 - acc: 0.541 - ETA: 0s - loss: 7.1775 - acc: 0.5440Epoch 00016: val_loss did not improve\n",
      "6680/6680 [==============================] - 1s - loss: 7.1599 - acc: 0.5451 - val_loss: 8.0071 - val_acc: 0.4120\n",
      "Epoch 18/20\n",
      "6640/6680 [============================>.] - ETA: 1s - loss: 4.1102 - acc: 0.700 - ETA: 1s - loss: 7.3633 - acc: 0.535 - ETA: 1s - loss: 7.1677 - acc: 0.548 - ETA: 0s - loss: 7.0433 - acc: 0.555 - ETA: 0s - loss: 7.0817 - acc: 0.549 - ETA: 0s - loss: 7.1869 - acc: 0.540 - ETA: 0s - loss: 7.0811 - acc: 0.546 - ETA: 0s - loss: 7.1113 - acc: 0.542 - ETA: 0s - loss: 7.0601 - acc: 0.547 - ETA: 0s - loss: 7.0319 - acc: 0.548 - ETA: 0s - loss: 6.9999 - acc: 0.549 - ETA: 0s - loss: 7.0674 - acc: 0.545 - ETA: 0s - loss: 7.0544 - acc: 0.546 - ETA: 0s - loss: 7.0681 - acc: 0.545 - ETA: 0s - loss: 7.0786 - acc: 0.544 - ETA: 0s - loss: 7.0717 - acc: 0.544 - ETA: 0s - loss: 7.0217 - acc: 0.547 - ETA: 0s - loss: 6.9804 - acc: 0.550 - ETA: 0s - loss: 6.9720 - acc: 0.550 - ETA: 0s - loss: 6.9625 - acc: 0.551 - ETA: 0s - loss: 6.9953 - acc: 0.549 - ETA: 0s - loss: 7.0337 - acc: 0.546 - ETA: 0s - loss: 7.0251 - acc: 0.5476Epoch 00017: val_loss improved from 7.95287 to 7.81279, saving model to saved_models/weights.best.VGG16.hdf5\n",
      "6680/6680 [==============================] - 1s - loss: 7.0192 - acc: 0.5481 - val_loss: 7.8128 - val_acc: 0.4479\n",
      "Epoch 19/20\n",
      "6380/6680 [===========================>..] - ETA: 0s - loss: 5.6762 - acc: 0.600 - ETA: 1s - loss: 6.5510 - acc: 0.584 - ETA: 1s - loss: 6.7699 - acc: 0.571 - ETA: 0s - loss: 6.7919 - acc: 0.570 - ETA: 0s - loss: 6.7773 - acc: 0.570 - ETA: 0s - loss: 6.7474 - acc: 0.571 - ETA: 0s - loss: 6.7291 - acc: 0.572 - ETA: 0s - loss: 6.8018 - acc: 0.568 - ETA: 0s - loss: 6.8289 - acc: 0.566 - ETA: 0s - loss: 6.7523 - acc: 0.572 - ETA: 0s - loss: 6.8199 - acc: 0.568 - ETA: 0s - loss: 6.8402 - acc: 0.566 - ETA: 0s - loss: 6.8768 - acc: 0.563 - ETA: 0s - loss: 6.8880 - acc: 0.563 - ETA: 0s - loss: 6.9118 - acc: 0.561 - ETA: 0s - loss: 6.9120 - acc: 0.560 - ETA: 0s - loss: 6.9021 - acc: 0.561 - ETA: 0s - loss: 6.8809 - acc: 0.562 - ETA: 0s - loss: 6.8811 - acc: 0.563 - ETA: 0s - loss: 6.9129 - acc: 0.560 - ETA: 0s - loss: 6.9350 - acc: 0.558 - ETA: 0s - loss: 6.9536 - acc: 0.5577Epoch 00018: val_loss improved from 7.81279 to 7.79231, saving model to saved_models/weights.best.VGG16.hdf5\n",
      "6680/6680 [==============================] - 1s - loss: 6.9626 - acc: 0.5572 - val_loss: 7.7923 - val_acc: 0.4407\n",
      "Epoch 20/20\n",
      "6620/6680 [============================>.] - ETA: 1s - loss: 9.6713 - acc: 0.400 - ETA: 1s - loss: 7.2266 - acc: 0.550 - ETA: 1s - loss: 7.2942 - acc: 0.545 - ETA: 0s - loss: 6.7681 - acc: 0.576 - ETA: 0s - loss: 6.7599 - acc: 0.577 - ETA: 0s - loss: 6.7666 - acc: 0.577 - ETA: 0s - loss: 6.7971 - acc: 0.573 - ETA: 0s - loss: 6.7826 - acc: 0.573 - ETA: 0s - loss: 6.7380 - acc: 0.575 - ETA: 0s - loss: 6.7139 - acc: 0.577 - ETA: 0s - loss: 6.7284 - acc: 0.576 - ETA: 0s - loss: 6.7570 - acc: 0.574 - ETA: 0s - loss: 6.7772 - acc: 0.572 - ETA: 0s - loss: 6.8491 - acc: 0.567 - ETA: 0s - loss: 6.8848 - acc: 0.564 - ETA: 0s - loss: 6.9139 - acc: 0.563 - ETA: 0s - loss: 6.9376 - acc: 0.561 - ETA: 0s - loss: 6.9635 - acc: 0.559 - ETA: 0s - loss: 6.8925 - acc: 0.564 - ETA: 0s - loss: 6.9126 - acc: 0.562 - ETA: 0s - loss: 6.9598 - acc: 0.560 - ETA: 0s - loss: 6.9784 - acc: 0.558 - ETA: 0s - loss: 6.9516 - acc: 0.5603Epoch 00019: val_loss did not improve\n",
      "6680/6680 [==============================] - 1s - loss: 6.9446 - acc: 0.5608 - val_loss: 7.7947 - val_acc: 0.4323\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x19aa5528eb8>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpointer = ModelCheckpoint(filepath='saved_models/weights.best.VGG16.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "\n",
    "VGG16_model.fit(train_VGG16, train_targets, \n",
    "          validation_data=(valid_VGG16, valid_targets),\n",
    "          epochs=20, batch_size=20, callbacks=[checkpointer], verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Model with the Best Validation Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "VGG16_model.load_weights('saved_models/weights.best.VGG16.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the Model\n",
    "\n",
    "Now, we can use the CNN to test how well it identifies breed within our test dataset of dog images.  We print the test accuracy below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 44.3780%\n"
     ]
    }
   ],
   "source": [
    "# get index of predicted dog breed for each image in test set\n",
    "VGG16_predictions = [np.argmax(VGG16_model.predict(np.expand_dims(feature, axis=0))) for feature in test_VGG16]\n",
    "\n",
    "# report test accuracy\n",
    "test_accuracy = 100*np.sum(np.array(VGG16_predictions)==np.argmax(test_targets, axis=1))/len(VGG16_predictions)\n",
    "print('Test accuracy: %.4f%%' % test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict Dog Breed with the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from extract_bottleneck_features import *\n",
    "\n",
    "def VGG16_predict_breed(img_path):\n",
    "    # extract bottleneck features\n",
    "    bottleneck_feature = extract_VGG16(path_to_tensor(img_path))\n",
    "    # obtain predicted vector\n",
    "    predicted_vector = VGG16_model.predict(bottleneck_feature)\n",
    "    # return dog breed that is predicted by the model\n",
    "    return dog_names[np.argmax(predicted_vector)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='step5'></a>\n",
    "## Step 5: Create a CNN to Classify Dog Breeds (using Transfer Learning)\n",
    "\n",
    "You will now use transfer learning to create a CNN that can identify dog breed from images.  Your CNN must attain at least 60% accuracy on the test set.\n",
    "\n",
    "In Step 4, we used transfer learning to create a CNN using VGG-16 bottleneck features.  In this section, you must use the bottleneck features from a different pre-trained model.  To make things easier for you, we have pre-computed the features for all of the networks that are currently available in Keras:\n",
    "- [VGG-19](https://s3-us-west-1.amazonaws.com/udacity-aind/dog-project/DogVGG19Data.npz) bottleneck features\n",
    "- [ResNet-50](https://s3-us-west-1.amazonaws.com/udacity-aind/dog-project/DogResnet50Data.npz) bottleneck features\n",
    "- [Inception](https://s3-us-west-1.amazonaws.com/udacity-aind/dog-project/DogInceptionV3Data.npz) bottleneck features\n",
    "- [Xception](https://s3-us-west-1.amazonaws.com/udacity-aind/dog-project/DogXceptionData.npz) bottleneck features\n",
    "\n",
    "The files are encoded as such:\n",
    "\n",
    "    Dog{network}Data.npz\n",
    "    \n",
    "where `{network}`, in the above filename, can be one of `VGG19`, `Resnet50`, `InceptionV3`, or `Xception`.  Pick one of the above architectures, download the corresponding bottleneck features, and store the downloaded file in the `bottleneck_features/` folder in the repository.\n",
    "\n",
    "### (IMPLEMENTATION) Obtain Bottleneck Features\n",
    "\n",
    "In the code block below, extract the bottleneck features corresponding to the train, test, and validation sets by running the following:\n",
    "\n",
    "    bottleneck_features = np.load('bottleneck_features/Dog{network}Data.npz')\n",
    "    train_{network} = bottleneck_features['train']\n",
    "    valid_{network} = bottleneck_features['valid']\n",
    "    test_{network} = bottleneck_features['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### TODO: Obtain bottleneck features from another pre-trained CNN.\n",
    "bottlneck_features = np.load('bottleneck_features/DogXceptionData.npz')\n",
    "train_Xception = bottleneck_features['train']\n",
    "valid_Xception = bottleneck_features['valid']\n",
    "test_Xception = bottleneck_features['test']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (IMPLEMENTATION) Model Architecture\n",
    "\n",
    "Create a CNN to classify dog breed.  At the end of your code cell block, summarize the layers of your model by executing the line:\n",
    "    \n",
    "        <your model's name>.summary()\n",
    "   \n",
    "__Question 5:__ Outline the steps you took to get to your final CNN architecture and your reasoning at each step.  Describe why you think the architecture is suitable for the current problem.\n",
    "\n",
    "__Answer:__ \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "global_average_pooling2d_3 ( (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 133)               68229     \n",
      "=================================================================\n",
      "Total params: 330,885\n",
      "Trainable params: 330,885\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "### TODO: Define your architecture.\n",
    "# Using the Xception network\n",
    "tf_Xception_model = Sequential()\n",
    "\n",
    "# Adding a Global Pooling layer to the network\n",
    "tf_Xception_model.add(GlobalAveragePooling2D(input_shape=train_Xception.shape[1:]))\n",
    "\n",
    "# Add a fully connected layer\n",
    "tf_Xception_model.add(Dense(512, activation='relu'))\n",
    "tf_Xception_model.add(Dropout(0.5))\n",
    "\n",
    "# Add a full connected layer with 133 outputs\n",
    "tf_Xception_model.add(Dense(133, activation='softmax'))\n",
    "\n",
    "tf_Xception_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (IMPLEMENTATION) Compile the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### TODO: Compile the model.\n",
    "tf_Xception_model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (IMPLEMENTATION) Train the Model\n",
    "\n",
    "Train your model in the code cell below.  Use model checkpointing to save the model that attains the best validation loss.  \n",
    "\n",
    "You are welcome to [augment the training data](https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html), but this is not a requirement. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6680 samples, validate on 835 samples\n",
      "Epoch 1/32\n",
      "6640/6680 [============================>.] - ETA: 88s - loss: 14.7067 - acc: 0.0000e+0 - ETA: 13s - loss: 14.8820 - acc: 0.0250    - ETA: 7s - loss: 14.9418 - acc: 0.025 - ETA: 5s - loss: 14.9425 - acc: 0.02 - ETA: 4s - loss: 14.8792 - acc: 0.02 - ETA: 3s - loss: 14.7558 - acc: 0.02 - ETA: 3s - loss: 14.6381 - acc: 0.02 - ETA: 3s - loss: 14.5528 - acc: 0.03 - ETA: 2s - loss: 14.4478 - acc: 0.03 - ETA: 2s - loss: 14.4089 - acc: 0.04 - ETA: 2s - loss: 14.2922 - acc: 0.04 - ETA: 2s - loss: 14.1652 - acc: 0.04 - ETA: 2s - loss: 14.0296 - acc: 0.05 - ETA: 1s - loss: 13.9334 - acc: 0.05 - ETA: 1s - loss: 13.8324 - acc: 0.05 - ETA: 1s - loss: 13.6238 - acc: 0.05 - ETA: 1s - loss: 13.5129 - acc: 0.06 - ETA: 1s - loss: 13.3237 - acc: 0.06 - ETA: 1s - loss: 13.0311 - acc: 0.07 - ETA: 1s - loss: 12.7905 - acc: 0.07 - ETA: 1s - loss: 12.4548 - acc: 0.07 - ETA: 1s - loss: 12.0933 - acc: 0.08 - ETA: 1s - loss: 11.7959 - acc: 0.08 - ETA: 1s - loss: 11.4687 - acc: 0.08 - ETA: 0s - loss: 11.2062 - acc: 0.08 - ETA: 0s - loss: 10.9127 - acc: 0.08 - ETA: 0s - loss: 10.6399 - acc: 0.09 - ETA: 0s - loss: 10.4371 - acc: 0.09 - ETA: 0s - loss: 10.2319 - acc: 0.09 - ETA: 0s - loss: 10.0334 - acc: 0.09 - ETA: 0s - loss: 9.8280 - acc: 0.0972 - ETA: 0s - loss: 9.6491 - acc: 0.099 - ETA: 0s - loss: 9.4696 - acc: 0.101 - ETA: 0s - loss: 9.2835 - acc: 0.106 - ETA: 0s - loss: 9.1105 - acc: 0.110 - ETA: 0s - loss: 8.9382 - acc: 0.114 - ETA: 0s - loss: 8.7982 - acc: 0.118 - ETA: 0s - loss: 8.6525 - acc: 0.122 - ETA: 0s - loss: 8.5078 - acc: 0.125 - ETA: 0s - loss: 8.3854 - acc: 0.1282Epoch 00000: val_loss improved from inf to 2.39422, saving model to saved_models/weights.best.tf_Xception.hdf5\n",
      "6680/6680 [==============================] - 2s - loss: 8.3581 - acc: 0.1286 - val_loss: 2.3942 - val_acc: 0.4287\n",
      "Epoch 2/32\n",
      "6500/6680 [============================>.] - ETA: 1s - loss: 3.1241 - acc: 0.250 - ETA: 2s - loss: 3.0196 - acc: 0.333 - ETA: 1s - loss: 2.9904 - acc: 0.322 - ETA: 1s - loss: 3.0392 - acc: 0.316 - ETA: 1s - loss: 2.9872 - acc: 0.315 - ETA: 1s - loss: 2.9657 - acc: 0.317 - ETA: 1s - loss: 2.8910 - acc: 0.333 - ETA: 1s - loss: 2.9178 - acc: 0.331 - ETA: 1s - loss: 2.9118 - acc: 0.334 - ETA: 1s - loss: 2.8828 - acc: 0.338 - ETA: 1s - loss: 2.9088 - acc: 0.340 - ETA: 1s - loss: 2.9013 - acc: 0.343 - ETA: 1s - loss: 2.8806 - acc: 0.346 - ETA: 1s - loss: 2.8678 - acc: 0.352 - ETA: 1s - loss: 2.8623 - acc: 0.355 - ETA: 1s - loss: 2.8290 - acc: 0.359 - ETA: 1s - loss: 2.8213 - acc: 0.357 - ETA: 1s - loss: 2.8097 - acc: 0.359 - ETA: 1s - loss: 2.7927 - acc: 0.363 - ETA: 1s - loss: 2.7853 - acc: 0.363 - ETA: 1s - loss: 2.7671 - acc: 0.365 - ETA: 0s - loss: 2.7626 - acc: 0.367 - ETA: 0s - loss: 2.7343 - acc: 0.371 - ETA: 0s - loss: 2.7319 - acc: 0.373 - ETA: 0s - loss: 2.7147 - acc: 0.374 - ETA: 0s - loss: 2.6986 - acc: 0.376 - ETA: 0s - loss: 2.6815 - acc: 0.379 - ETA: 0s - loss: 2.6785 - acc: 0.379 - ETA: 0s - loss: 2.6769 - acc: 0.382 - ETA: 0s - loss: 2.6692 - acc: 0.383 - ETA: 0s - loss: 2.6642 - acc: 0.385 - ETA: 0s - loss: 2.6624 - acc: 0.386 - ETA: 0s - loss: 2.6564 - acc: 0.387 - ETA: 0s - loss: 2.6456 - acc: 0.389 - ETA: 0s - loss: 2.6318 - acc: 0.392 - ETA: 0s - loss: 2.6173 - acc: 0.395 - ETA: 0s - loss: 2.6055 - acc: 0.397 - ETA: 0s - loss: 2.5909 - acc: 0.400 - ETA: 0s - loss: 2.5824 - acc: 0.4020Epoch 00001: val_loss improved from 2.39422 to 1.33658, saving model to saved_models/weights.best.tf_Xception.hdf5\n",
      "6680/6680 [==============================] - 2s - loss: 2.5702 - acc: 0.4043 - val_loss: 1.3366 - val_acc: 0.6335\n",
      "Epoch 3/32\n",
      "6660/6680 [============================>.] - ETA: 2s - loss: 2.0926 - acc: 0.400 - ETA: 2s - loss: 2.0548 - acc: 0.490 - ETA: 1s - loss: 2.1607 - acc: 0.483 - ETA: 1s - loss: 2.0938 - acc: 0.486 - ETA: 1s - loss: 2.0254 - acc: 0.486 - ETA: 1s - loss: 1.9805 - acc: 0.486 - ETA: 1s - loss: 1.9730 - acc: 0.484 - ETA: 1s - loss: 2.0000 - acc: 0.491 - ETA: 1s - loss: 2.0014 - acc: 0.497 - ETA: 1s - loss: 1.9541 - acc: 0.505 - ETA: 1s - loss: 1.9606 - acc: 0.508 - ETA: 1s - loss: 1.9381 - acc: 0.515 - ETA: 1s - loss: 1.9242 - acc: 0.517 - ETA: 1s - loss: 1.9190 - acc: 0.520 - ETA: 1s - loss: 1.9245 - acc: 0.521 - ETA: 1s - loss: 1.9158 - acc: 0.524 - ETA: 1s - loss: 1.9158 - acc: 0.525 - ETA: 1s - loss: 1.9139 - acc: 0.523 - ETA: 1s - loss: 1.9180 - acc: 0.526 - ETA: 1s - loss: 1.9297 - acc: 0.524 - ETA: 1s - loss: 1.9147 - acc: 0.525 - ETA: 0s - loss: 1.9152 - acc: 0.525 - ETA: 0s - loss: 1.9124 - acc: 0.523 - ETA: 0s - loss: 1.9154 - acc: 0.522 - ETA: 0s - loss: 1.9226 - acc: 0.521 - ETA: 0s - loss: 1.9203 - acc: 0.523 - ETA: 0s - loss: 1.9055 - acc: 0.527 - ETA: 0s - loss: 1.9036 - acc: 0.527 - ETA: 0s - loss: 1.8971 - acc: 0.529 - ETA: 0s - loss: 1.8883 - acc: 0.529 - ETA: 0s - loss: 1.8849 - acc: 0.531 - ETA: 0s - loss: 1.8811 - acc: 0.533 - ETA: 0s - loss: 1.8656 - acc: 0.535 - ETA: 0s - loss: 1.8697 - acc: 0.535 - ETA: 0s - loss: 1.8629 - acc: 0.535 - ETA: 0s - loss: 1.8619 - acc: 0.535 - ETA: 0s - loss: 1.8624 - acc: 0.535 - ETA: 0s - loss: 1.8615 - acc: 0.537 - ETA: 0s - loss: 1.8516 - acc: 0.539 - ETA: 0s - loss: 1.8459 - acc: 0.5407Epoch 00002: val_loss improved from 1.33658 to 1.18522, saving model to saved_models/weights.best.tf_Xception.hdf5\n",
      "6680/6680 [==============================] - 2s - loss: 1.8460 - acc: 0.5401 - val_loss: 1.1852 - val_acc: 0.6635\n",
      "Epoch 4/32\n",
      "6520/6680 [============================>.] - ETA: 2s - loss: 1.9557 - acc: 0.450 - ETA: 1s - loss: 1.5654 - acc: 0.590 - ETA: 1s - loss: 1.3879 - acc: 0.628 - ETA: 1s - loss: 1.5019 - acc: 0.613 - ETA: 1s - loss: 1.5378 - acc: 0.611 - ETA: 1s - loss: 1.5607 - acc: 0.602 - ETA: 1s - loss: 1.5621 - acc: 0.609 - ETA: 1s - loss: 1.5554 - acc: 0.607 - ETA: 1s - loss: 1.5330 - acc: 0.610 - ETA: 1s - loss: 1.5276 - acc: 0.611 - ETA: 1s - loss: 1.5548 - acc: 0.607 - ETA: 1s - loss: 1.5482 - acc: 0.608 - ETA: 1s - loss: 1.5439 - acc: 0.606 - ETA: 1s - loss: 1.5367 - acc: 0.609 - ETA: 1s - loss: 1.5431 - acc: 0.611 - ETA: 1s - loss: 1.5320 - acc: 0.610 - ETA: 1s - loss: 1.5436 - acc: 0.609 - ETA: 1s - loss: 1.5558 - acc: 0.611 - ETA: 1s - loss: 1.5606 - acc: 0.612 - ETA: 1s - loss: 1.5810 - acc: 0.611 - ETA: 1s - loss: 1.5777 - acc: 0.611 - ETA: 0s - loss: 1.5596 - acc: 0.614 - ETA: 0s - loss: 1.5637 - acc: 0.614 - ETA: 0s - loss: 1.5662 - acc: 0.613 - ETA: 0s - loss: 1.5572 - acc: 0.613 - ETA: 0s - loss: 1.5643 - acc: 0.612 - ETA: 0s - loss: 1.5518 - acc: 0.614 - ETA: 0s - loss: 1.5684 - acc: 0.611 - ETA: 0s - loss: 1.5712 - acc: 0.610 - ETA: 0s - loss: 1.5671 - acc: 0.609 - ETA: 0s - loss: 1.5677 - acc: 0.609 - ETA: 0s - loss: 1.5703 - acc: 0.607 - ETA: 0s - loss: 1.5649 - acc: 0.610 - ETA: 0s - loss: 1.5676 - acc: 0.611 - ETA: 0s - loss: 1.5640 - acc: 0.613 - ETA: 0s - loss: 1.5638 - acc: 0.613 - ETA: 0s - loss: 1.5559 - acc: 0.614 - ETA: 0s - loss: 1.5587 - acc: 0.615 - ETA: 0s - loss: 1.5614 - acc: 0.6150Epoch 00003: val_loss improved from 1.18522 to 0.98784, saving model to saved_models/weights.best.tf_Xception.hdf5\n",
      "6680/6680 [==============================] - 2s - loss: 1.5774 - acc: 0.6129 - val_loss: 0.9878 - val_acc: 0.7293\n",
      "Epoch 5/32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6620/6680 [============================>.] - ETA: 1s - loss: 1.3222 - acc: 0.700 - ETA: 2s - loss: 1.1430 - acc: 0.716 - ETA: 1s - loss: 1.3747 - acc: 0.683 - ETA: 1s - loss: 1.2778 - acc: 0.686 - ETA: 1s - loss: 1.3128 - acc: 0.680 - ETA: 1s - loss: 1.3608 - acc: 0.661 - ETA: 1s - loss: 1.3507 - acc: 0.656 - ETA: 1s - loss: 1.3123 - acc: 0.665 - ETA: 1s - loss: 1.3631 - acc: 0.653 - ETA: 1s - loss: 1.3499 - acc: 0.653 - ETA: 1s - loss: 1.3408 - acc: 0.653 - ETA: 1s - loss: 1.3694 - acc: 0.650 - ETA: 1s - loss: 1.3694 - acc: 0.651 - ETA: 1s - loss: 1.3662 - acc: 0.653 - ETA: 1s - loss: 1.3635 - acc: 0.649 - ETA: 1s - loss: 1.3456 - acc: 0.652 - ETA: 1s - loss: 1.3618 - acc: 0.652 - ETA: 1s - loss: 1.3527 - acc: 0.656 - ETA: 1s - loss: 1.3466 - acc: 0.656 - ETA: 1s - loss: 1.3413 - acc: 0.657 - ETA: 0s - loss: 1.3613 - acc: 0.654 - ETA: 0s - loss: 1.3559 - acc: 0.656 - ETA: 0s - loss: 1.3752 - acc: 0.651 - ETA: 0s - loss: 1.3641 - acc: 0.653 - ETA: 0s - loss: 1.3628 - acc: 0.655 - ETA: 0s - loss: 1.3486 - acc: 0.659 - ETA: 0s - loss: 1.3387 - acc: 0.659 - ETA: 0s - loss: 1.3558 - acc: 0.658 - ETA: 0s - loss: 1.3419 - acc: 0.661 - ETA: 0s - loss: 1.3384 - acc: 0.662 - ETA: 0s - loss: 1.3479 - acc: 0.660 - ETA: 0s - loss: 1.3421 - acc: 0.662 - ETA: 0s - loss: 1.3465 - acc: 0.661 - ETA: 0s - loss: 1.3441 - acc: 0.662 - ETA: 0s - loss: 1.3487 - acc: 0.662 - ETA: 0s - loss: 1.3506 - acc: 0.662 - ETA: 0s - loss: 1.3539 - acc: 0.660 - ETA: 0s - loss: 1.3551 - acc: 0.660 - ETA: 0s - loss: 1.3647 - acc: 0.6600Epoch 00004: val_loss did not improve\n",
      "6680/6680 [==============================] - 2s - loss: 1.3656 - acc: 0.6602 - val_loss: 1.0789 - val_acc: 0.7054\n",
      "Epoch 6/32\n",
      "6640/6680 [============================>.] - ETA: 2s - loss: 0.7972 - acc: 0.750 - ETA: 1s - loss: 1.2568 - acc: 0.670 - ETA: 1s - loss: 1.0989 - acc: 0.686 - ETA: 1s - loss: 1.2324 - acc: 0.677 - ETA: 1s - loss: 1.1942 - acc: 0.688 - ETA: 1s - loss: 1.2126 - acc: 0.684 - ETA: 1s - loss: 1.2026 - acc: 0.688 - ETA: 1s - loss: 1.1835 - acc: 0.696 - ETA: 1s - loss: 1.1748 - acc: 0.697 - ETA: 1s - loss: 1.1687 - acc: 0.695 - ETA: 1s - loss: 1.1971 - acc: 0.689 - ETA: 1s - loss: 1.1894 - acc: 0.695 - ETA: 1s - loss: 1.1856 - acc: 0.699 - ETA: 1s - loss: 1.1901 - acc: 0.699 - ETA: 1s - loss: 1.1825 - acc: 0.701 - ETA: 1s - loss: 1.1866 - acc: 0.700 - ETA: 1s - loss: 1.2189 - acc: 0.695 - ETA: 1s - loss: 1.2283 - acc: 0.693 - ETA: 1s - loss: 1.2306 - acc: 0.692 - ETA: 0s - loss: 1.2332 - acc: 0.692 - ETA: 0s - loss: 1.2335 - acc: 0.693 - ETA: 0s - loss: 1.2429 - acc: 0.692 - ETA: 0s - loss: 1.2416 - acc: 0.693 - ETA: 0s - loss: 1.2546 - acc: 0.692 - ETA: 0s - loss: 1.2514 - acc: 0.693 - ETA: 0s - loss: 1.2559 - acc: 0.695 - ETA: 0s - loss: 1.2511 - acc: 0.695 - ETA: 0s - loss: 1.2461 - acc: 0.695 - ETA: 0s - loss: 1.2450 - acc: 0.696 - ETA: 0s - loss: 1.2494 - acc: 0.695 - ETA: 0s - loss: 1.2604 - acc: 0.694 - ETA: 0s - loss: 1.2488 - acc: 0.697 - ETA: 0s - loss: 1.2563 - acc: 0.695 - ETA: 0s - loss: 1.2613 - acc: 0.693 - ETA: 0s - loss: 1.2575 - acc: 0.693 - ETA: 0s - loss: 1.2572 - acc: 0.694 - ETA: 0s - loss: 1.2559 - acc: 0.694 - ETA: 0s - loss: 1.2545 - acc: 0.6947Epoch 00005: val_loss did not improve\n",
      "6680/6680 [==============================] - 2s - loss: 1.2528 - acc: 0.6949 - val_loss: 1.0544 - val_acc: 0.7257\n",
      "Epoch 7/32\n",
      "6540/6680 [============================>.] - ETA: 1s - loss: 1.0162 - acc: 0.650 - ETA: 1s - loss: 0.9749 - acc: 0.740 - ETA: 1s - loss: 1.1046 - acc: 0.722 - ETA: 1s - loss: 1.0790 - acc: 0.735 - ETA: 1s - loss: 1.1007 - acc: 0.735 - ETA: 1s - loss: 1.1035 - acc: 0.726 - ETA: 1s - loss: 1.1370 - acc: 0.719 - ETA: 1s - loss: 1.1135 - acc: 0.723 - ETA: 1s - loss: 1.0933 - acc: 0.731 - ETA: 1s - loss: 1.0846 - acc: 0.734 - ETA: 1s - loss: 1.0987 - acc: 0.735 - ETA: 1s - loss: 1.1094 - acc: 0.734 - ETA: 1s - loss: 1.1204 - acc: 0.733 - ETA: 1s - loss: 1.1161 - acc: 0.732 - ETA: 1s - loss: 1.1181 - acc: 0.729 - ETA: 1s - loss: 1.1259 - acc: 0.728 - ETA: 1s - loss: 1.1155 - acc: 0.732 - ETA: 1s - loss: 1.1383 - acc: 0.729 - ETA: 1s - loss: 1.1363 - acc: 0.729 - ETA: 1s - loss: 1.1313 - acc: 0.728 - ETA: 0s - loss: 1.1365 - acc: 0.730 - ETA: 0s - loss: 1.1374 - acc: 0.729 - ETA: 0s - loss: 1.1376 - acc: 0.728 - ETA: 0s - loss: 1.1501 - acc: 0.728 - ETA: 0s - loss: 1.1615 - acc: 0.727 - ETA: 0s - loss: 1.1692 - acc: 0.725 - ETA: 0s - loss: 1.1722 - acc: 0.725 - ETA: 0s - loss: 1.1752 - acc: 0.724 - ETA: 0s - loss: 1.1790 - acc: 0.724 - ETA: 0s - loss: 1.1686 - acc: 0.725 - ETA: 0s - loss: 1.1762 - acc: 0.724 - ETA: 0s - loss: 1.1849 - acc: 0.723 - ETA: 0s - loss: 1.1784 - acc: 0.723 - ETA: 0s - loss: 1.1812 - acc: 0.723 - ETA: 0s - loss: 1.1822 - acc: 0.723 - ETA: 0s - loss: 1.1835 - acc: 0.723 - ETA: 0s - loss: 1.1944 - acc: 0.722 - ETA: 0s - loss: 1.1955 - acc: 0.7214Epoch 00006: val_loss did not improve\n",
      "6680/6680 [==============================] - 2s - loss: 1.1957 - acc: 0.7210 - val_loss: 1.0517 - val_acc: 0.7401\n",
      "Epoch 8/32\n",
      "6620/6680 [============================>.] - ETA: 2s - loss: 1.9056 - acc: 0.650 - ETA: 2s - loss: 1.3211 - acc: 0.716 - ETA: 2s - loss: 1.2307 - acc: 0.726 - ETA: 1s - loss: 1.1902 - acc: 0.726 - ETA: 1s - loss: 1.1655 - acc: 0.726 - ETA: 1s - loss: 1.1035 - acc: 0.733 - ETA: 1s - loss: 1.1559 - acc: 0.727 - ETA: 1s - loss: 1.1161 - acc: 0.735 - ETA: 1s - loss: 1.1123 - acc: 0.737 - ETA: 1s - loss: 1.1038 - acc: 0.739 - ETA: 1s - loss: 1.1126 - acc: 0.739 - ETA: 1s - loss: 1.1382 - acc: 0.736 - ETA: 1s - loss: 1.1429 - acc: 0.738 - ETA: 1s - loss: 1.1408 - acc: 0.737 - ETA: 1s - loss: 1.1232 - acc: 0.741 - ETA: 1s - loss: 1.1258 - acc: 0.742 - ETA: 1s - loss: 1.1276 - acc: 0.741 - ETA: 1s - loss: 1.1395 - acc: 0.737 - ETA: 1s - loss: 1.1423 - acc: 0.738 - ETA: 0s - loss: 1.1333 - acc: 0.740 - ETA: 0s - loss: 1.1365 - acc: 0.738 - ETA: 0s - loss: 1.1325 - acc: 0.739 - ETA: 0s - loss: 1.1254 - acc: 0.741 - ETA: 0s - loss: 1.1325 - acc: 0.739 - ETA: 0s - loss: 1.1241 - acc: 0.740 - ETA: 0s - loss: 1.1267 - acc: 0.738 - ETA: 0s - loss: 1.1211 - acc: 0.738 - ETA: 0s - loss: 1.1302 - acc: 0.736 - ETA: 0s - loss: 1.1266 - acc: 0.736 - ETA: 0s - loss: 1.1324 - acc: 0.736 - ETA: 0s - loss: 1.1325 - acc: 0.736 - ETA: 0s - loss: 1.1305 - acc: 0.735 - ETA: 0s - loss: 1.1268 - acc: 0.736 - ETA: 0s - loss: 1.1317 - acc: 0.735 - ETA: 0s - loss: 1.1301 - acc: 0.735 - ETA: 0s - loss: 1.1299 - acc: 0.735 - ETA: 0s - loss: 1.1338 - acc: 0.735 - ETA: 0s - loss: 1.1369 - acc: 0.7341Epoch 00007: val_loss did not improve\n",
      "6680/6680 [==============================] - 2s - loss: 1.1384 - acc: 0.7337 - val_loss: 1.0502 - val_acc: 0.7581\n",
      "Epoch 9/32\n",
      "6620/6680 [============================>.] - ETA: 1s - loss: 0.6684 - acc: 0.850 - ETA: 1s - loss: 0.8621 - acc: 0.785 - ETA: 1s - loss: 1.0599 - acc: 0.757 - ETA: 1s - loss: 1.0500 - acc: 0.758 - ETA: 1s - loss: 1.0760 - acc: 0.760 - ETA: 1s - loss: 1.0669 - acc: 0.758 - ETA: 1s - loss: 1.0118 - acc: 0.768 - ETA: 1s - loss: 1.0675 - acc: 0.762 - ETA: 1s - loss: 1.0741 - acc: 0.761 - ETA: 1s - loss: 1.0822 - acc: 0.759 - ETA: 1s - loss: 1.0849 - acc: 0.757 - ETA: 1s - loss: 1.0862 - acc: 0.758 - ETA: 1s - loss: 1.0702 - acc: 0.762 - ETA: 1s - loss: 1.0727 - acc: 0.760 - ETA: 1s - loss: 1.0688 - acc: 0.760 - ETA: 1s - loss: 1.0658 - acc: 0.760 - ETA: 1s - loss: 1.0730 - acc: 0.758 - ETA: 1s - loss: 1.0659 - acc: 0.758 - ETA: 1s - loss: 1.0685 - acc: 0.758 - ETA: 0s - loss: 1.0648 - acc: 0.758 - ETA: 0s - loss: 1.0802 - acc: 0.758 - ETA: 0s - loss: 1.0796 - acc: 0.758 - ETA: 0s - loss: 1.0682 - acc: 0.759 - ETA: 0s - loss: 1.0758 - acc: 0.758 - ETA: 0s - loss: 1.0845 - acc: 0.755 - ETA: 0s - loss: 1.0888 - acc: 0.752 - ETA: 0s - loss: 1.0927 - acc: 0.753 - ETA: 0s - loss: 1.0864 - acc: 0.754 - ETA: 0s - loss: 1.0870 - acc: 0.754 - ETA: 0s - loss: 1.0930 - acc: 0.753 - ETA: 0s - loss: 1.0918 - acc: 0.753 - ETA: 0s - loss: 1.0883 - acc: 0.752 - ETA: 0s - loss: 1.0835 - acc: 0.753 - ETA: 0s - loss: 1.0859 - acc: 0.753 - ETA: 0s - loss: 1.0835 - acc: 0.753 - ETA: 0s - loss: 1.0763 - acc: 0.754 - ETA: 0s - loss: 1.0716 - acc: 0.755 - ETA: 0s - loss: 1.0761 - acc: 0.7542Epoch 00008: val_loss did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6680/6680 [==============================] - 2s - loss: 1.0746 - acc: 0.7546 - val_loss: 1.0897 - val_acc: 0.7533\n",
      "Epoch 10/32\n",
      "6600/6680 [============================>.] - ETA: 1s - loss: 0.7321 - acc: 0.800 - ETA: 2s - loss: 0.7912 - acc: 0.766 - ETA: 1s - loss: 1.0409 - acc: 0.744 - ETA: 1s - loss: 1.1378 - acc: 0.746 - ETA: 1s - loss: 1.0660 - acc: 0.762 - ETA: 1s - loss: 1.0335 - acc: 0.768 - ETA: 1s - loss: 0.9836 - acc: 0.774 - ETA: 1s - loss: 0.9640 - acc: 0.774 - ETA: 1s - loss: 0.9874 - acc: 0.773 - ETA: 1s - loss: 0.9664 - acc: 0.773 - ETA: 1s - loss: 0.9805 - acc: 0.769 - ETA: 1s - loss: 0.9797 - acc: 0.770 - ETA: 1s - loss: 0.9943 - acc: 0.768 - ETA: 1s - loss: 0.9914 - acc: 0.769 - ETA: 1s - loss: 0.9999 - acc: 0.769 - ETA: 1s - loss: 0.9849 - acc: 0.773 - ETA: 1s - loss: 0.9923 - acc: 0.771 - ETA: 1s - loss: 0.9970 - acc: 0.770 - ETA: 1s - loss: 0.9922 - acc: 0.768 - ETA: 0s - loss: 1.0024 - acc: 0.767 - ETA: 0s - loss: 0.9972 - acc: 0.767 - ETA: 0s - loss: 1.0171 - acc: 0.765 - ETA: 0s - loss: 1.0197 - acc: 0.765 - ETA: 0s - loss: 1.0225 - acc: 0.765 - ETA: 0s - loss: 1.0295 - acc: 0.765 - ETA: 0s - loss: 1.0252 - acc: 0.765 - ETA: 0s - loss: 1.0238 - acc: 0.766 - ETA: 0s - loss: 1.0164 - acc: 0.766 - ETA: 0s - loss: 1.0211 - acc: 0.767 - ETA: 0s - loss: 1.0278 - acc: 0.766 - ETA: 0s - loss: 1.0214 - acc: 0.767 - ETA: 0s - loss: 1.0313 - acc: 0.766 - ETA: 0s - loss: 1.0344 - acc: 0.766 - ETA: 0s - loss: 1.0341 - acc: 0.765 - ETA: 0s - loss: 1.0283 - acc: 0.765 - ETA: 0s - loss: 1.0321 - acc: 0.765 - ETA: 0s - loss: 1.0433 - acc: 0.764 - ETA: 0s - loss: 1.0396 - acc: 0.7648Epoch 00009: val_loss did not improve\n",
      "6680/6680 [==============================] - 2s - loss: 1.0427 - acc: 0.7651 - val_loss: 1.0255 - val_acc: 0.7653\n",
      "Epoch 11/32\n",
      "6580/6680 [============================>.] - ETA: 2s - loss: 0.9901 - acc: 0.750 - ETA: 2s - loss: 0.9501 - acc: 0.770 - ETA: 1s - loss: 0.7837 - acc: 0.800 - ETA: 1s - loss: 0.7651 - acc: 0.805 - ETA: 1s - loss: 0.8134 - acc: 0.800 - ETA: 1s - loss: 0.8339 - acc: 0.797 - ETA: 1s - loss: 0.9053 - acc: 0.790 - ETA: 1s - loss: 0.8983 - acc: 0.791 - ETA: 1s - loss: 0.8937 - acc: 0.788 - ETA: 1s - loss: 0.9069 - acc: 0.786 - ETA: 1s - loss: 0.9155 - acc: 0.784 - ETA: 1s - loss: 0.9050 - acc: 0.785 - ETA: 1s - loss: 0.8893 - acc: 0.787 - ETA: 1s - loss: 0.8878 - acc: 0.790 - ETA: 1s - loss: 0.9118 - acc: 0.789 - ETA: 1s - loss: 0.9107 - acc: 0.789 - ETA: 1s - loss: 0.9221 - acc: 0.789 - ETA: 1s - loss: 0.9412 - acc: 0.785 - ETA: 1s - loss: 0.9542 - acc: 0.781 - ETA: 0s - loss: 0.9567 - acc: 0.778 - ETA: 0s - loss: 0.9765 - acc: 0.777 - ETA: 0s - loss: 0.9796 - acc: 0.776 - ETA: 0s - loss: 0.9935 - acc: 0.774 - ETA: 0s - loss: 0.9879 - acc: 0.777 - ETA: 0s - loss: 0.9834 - acc: 0.777 - ETA: 0s - loss: 0.9861 - acc: 0.776 - ETA: 0s - loss: 0.9879 - acc: 0.777 - ETA: 0s - loss: 0.9876 - acc: 0.778 - ETA: 0s - loss: 0.9960 - acc: 0.776 - ETA: 0s - loss: 0.9986 - acc: 0.773 - ETA: 0s - loss: 1.0013 - acc: 0.774 - ETA: 0s - loss: 0.9984 - acc: 0.774 - ETA: 0s - loss: 0.9966 - acc: 0.774 - ETA: 0s - loss: 0.9932 - acc: 0.775 - ETA: 0s - loss: 0.9901 - acc: 0.774 - ETA: 0s - loss: 0.9890 - acc: 0.774 - ETA: 0s - loss: 0.9887 - acc: 0.774 - ETA: 0s - loss: 0.9922 - acc: 0.7748Epoch 00010: val_loss did not improve\n",
      "6680/6680 [==============================] - 2s - loss: 0.9905 - acc: 0.7749 - val_loss: 1.2961 - val_acc: 0.7545\n",
      "Epoch 12/32\n",
      "6620/6680 [============================>.] - ETA: 1s - loss: 1.0812 - acc: 0.750 - ETA: 2s - loss: 0.9429 - acc: 0.766 - ETA: 1s - loss: 0.8748 - acc: 0.777 - ETA: 1s - loss: 0.8882 - acc: 0.801 - ETA: 1s - loss: 0.8232 - acc: 0.808 - ETA: 1s - loss: 0.8438 - acc: 0.804 - ETA: 1s - loss: 0.8537 - acc: 0.803 - ETA: 1s - loss: 0.8669 - acc: 0.804 - ETA: 1s - loss: 0.9059 - acc: 0.796 - ETA: 1s - loss: 0.8831 - acc: 0.800 - ETA: 1s - loss: 0.8948 - acc: 0.798 - ETA: 1s - loss: 0.8902 - acc: 0.800 - ETA: 1s - loss: 0.8988 - acc: 0.801 - ETA: 1s - loss: 0.9018 - acc: 0.802 - ETA: 1s - loss: 0.9061 - acc: 0.799 - ETA: 1s - loss: 0.9168 - acc: 0.797 - ETA: 1s - loss: 0.9084 - acc: 0.798 - ETA: 1s - loss: 0.9136 - acc: 0.796 - ETA: 1s - loss: 0.9063 - acc: 0.796 - ETA: 0s - loss: 0.9149 - acc: 0.794 - ETA: 0s - loss: 0.9241 - acc: 0.791 - ETA: 0s - loss: 0.9409 - acc: 0.787 - ETA: 0s - loss: 0.9336 - acc: 0.788 - ETA: 0s - loss: 0.9205 - acc: 0.790 - ETA: 0s - loss: 0.9160 - acc: 0.789 - ETA: 0s - loss: 0.9224 - acc: 0.789 - ETA: 0s - loss: 0.9250 - acc: 0.789 - ETA: 0s - loss: 0.9408 - acc: 0.786 - ETA: 0s - loss: 0.9312 - acc: 0.787 - ETA: 0s - loss: 0.9396 - acc: 0.786 - ETA: 0s - loss: 0.9484 - acc: 0.786 - ETA: 0s - loss: 0.9559 - acc: 0.785 - ETA: 0s - loss: 0.9697 - acc: 0.783 - ETA: 0s - loss: 0.9657 - acc: 0.783 - ETA: 0s - loss: 0.9692 - acc: 0.783 - ETA: 0s - loss: 0.9755 - acc: 0.783 - ETA: 0s - loss: 0.9765 - acc: 0.784 - ETA: 0s - loss: 0.9783 - acc: 0.7844Epoch 00011: val_loss did not improve\n",
      "6680/6680 [==============================] - 2s - loss: 0.9821 - acc: 0.7843 - val_loss: 1.1828 - val_acc: 0.7605\n",
      "Epoch 13/32\n",
      "6500/6680 [============================>.] - ETA: 2s - loss: 0.3048 - acc: 0.900 - ETA: 1s - loss: 0.7044 - acc: 0.835 - ETA: 1s - loss: 0.8387 - acc: 0.800 - ETA: 1s - loss: 0.8349 - acc: 0.798 - ETA: 1s - loss: 0.7836 - acc: 0.813 - ETA: 1s - loss: 0.8537 - acc: 0.795 - ETA: 1s - loss: 0.8474 - acc: 0.797 - ETA: 1s - loss: 0.8670 - acc: 0.801 - ETA: 1s - loss: 0.9056 - acc: 0.792 - ETA: 1s - loss: 0.9206 - acc: 0.793 - ETA: 1s - loss: 0.9389 - acc: 0.794 - ETA: 1s - loss: 0.9623 - acc: 0.793 - ETA: 1s - loss: 0.9669 - acc: 0.792 - ETA: 1s - loss: 0.9664 - acc: 0.793 - ETA: 1s - loss: 0.9696 - acc: 0.791 - ETA: 1s - loss: 0.9743 - acc: 0.790 - ETA: 1s - loss: 0.9840 - acc: 0.789 - ETA: 1s - loss: 0.9746 - acc: 0.789 - ETA: 1s - loss: 0.9667 - acc: 0.791 - ETA: 0s - loss: 0.9785 - acc: 0.789 - ETA: 0s - loss: 0.9745 - acc: 0.791 - ETA: 0s - loss: 0.9667 - acc: 0.792 - ETA: 0s - loss: 0.9925 - acc: 0.789 - ETA: 0s - loss: 0.9771 - acc: 0.791 - ETA: 0s - loss: 0.9814 - acc: 0.791 - ETA: 0s - loss: 0.9773 - acc: 0.792 - ETA: 0s - loss: 0.9714 - acc: 0.792 - ETA: 0s - loss: 0.9860 - acc: 0.790 - ETA: 0s - loss: 0.9870 - acc: 0.791 - ETA: 0s - loss: 0.9912 - acc: 0.789 - ETA: 0s - loss: 0.9915 - acc: 0.789 - ETA: 0s - loss: 0.9958 - acc: 0.788 - ETA: 0s - loss: 0.9927 - acc: 0.789 - ETA: 0s - loss: 0.9928 - acc: 0.788 - ETA: 0s - loss: 0.9951 - acc: 0.789 - ETA: 0s - loss: 0.9949 - acc: 0.788 - ETA: 0s - loss: 0.9912 - acc: 0.7880Epoch 00012: val_loss did not improve\n",
      "6680/6680 [==============================] - 2s - loss: 0.9915 - acc: 0.7877 - val_loss: 1.2276 - val_acc: 0.7557\n",
      "Epoch 14/32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6640/6680 [============================>.] - ETA: 2s - loss: 0.3098 - acc: 0.950 - ETA: 1s - loss: 0.6524 - acc: 0.865 - ETA: 1s - loss: 0.7811 - acc: 0.823 - ETA: 1s - loss: 0.8118 - acc: 0.810 - ETA: 1s - loss: 0.8456 - acc: 0.802 - ETA: 1s - loss: 0.8183 - acc: 0.800 - ETA: 1s - loss: 0.8120 - acc: 0.803 - ETA: 1s - loss: 0.8179 - acc: 0.804 - ETA: 1s - loss: 0.8227 - acc: 0.803 - ETA: 1s - loss: 0.8098 - acc: 0.806 - ETA: 1s - loss: 0.8518 - acc: 0.801 - ETA: 1s - loss: 0.8709 - acc: 0.800 - ETA: 1s - loss: 0.8804 - acc: 0.800 - ETA: 1s - loss: 0.8657 - acc: 0.803 - ETA: 1s - loss: 0.8882 - acc: 0.800 - ETA: 1s - loss: 0.8822 - acc: 0.802 - ETA: 1s - loss: 0.8866 - acc: 0.804 - ETA: 1s - loss: 0.8868 - acc: 0.803 - ETA: 1s - loss: 0.8923 - acc: 0.801 - ETA: 0s - loss: 0.8865 - acc: 0.801 - ETA: 0s - loss: 0.8897 - acc: 0.800 - ETA: 0s - loss: 0.8882 - acc: 0.800 - ETA: 0s - loss: 0.8881 - acc: 0.800 - ETA: 0s - loss: 0.8872 - acc: 0.800 - ETA: 0s - loss: 0.8926 - acc: 0.800 - ETA: 0s - loss: 0.8940 - acc: 0.800 - ETA: 0s - loss: 0.8992 - acc: 0.800 - ETA: 0s - loss: 0.8994 - acc: 0.800 - ETA: 0s - loss: 0.9056 - acc: 0.800 - ETA: 0s - loss: 0.9152 - acc: 0.798 - ETA: 0s - loss: 0.9269 - acc: 0.797 - ETA: 0s - loss: 0.9301 - acc: 0.795 - ETA: 0s - loss: 0.9423 - acc: 0.796 - ETA: 0s - loss: 0.9546 - acc: 0.794 - ETA: 0s - loss: 0.9590 - acc: 0.794 - ETA: 0s - loss: 0.9568 - acc: 0.795 - ETA: 0s - loss: 0.9591 - acc: 0.795 - ETA: 0s - loss: 0.9586 - acc: 0.7958Epoch 00013: val_loss did not improve\n",
      "6680/6680 [==============================] - 2s - loss: 0.9583 - acc: 0.7960 - val_loss: 1.1463 - val_acc: 0.7605\n",
      "Epoch 15/32\n",
      "6660/6680 [============================>.] - ETA: 2s - loss: 0.6449 - acc: 0.900 - ETA: 1s - loss: 1.0714 - acc: 0.825 - ETA: 1s - loss: 1.0482 - acc: 0.813 - ETA: 1s - loss: 0.9598 - acc: 0.820 - ETA: 1s - loss: 0.9440 - acc: 0.813 - ETA: 1s - loss: 0.9424 - acc: 0.820 - ETA: 1s - loss: 0.9130 - acc: 0.822 - ETA: 1s - loss: 0.8905 - acc: 0.827 - ETA: 1s - loss: 0.8914 - acc: 0.824 - ETA: 1s - loss: 0.9396 - acc: 0.815 - ETA: 1s - loss: 0.9264 - acc: 0.814 - ETA: 1s - loss: 0.9402 - acc: 0.815 - ETA: 1s - loss: 0.9250 - acc: 0.816 - ETA: 1s - loss: 0.9444 - acc: 0.812 - ETA: 1s - loss: 0.9450 - acc: 0.812 - ETA: 1s - loss: 0.9497 - acc: 0.810 - ETA: 1s - loss: 0.9500 - acc: 0.810 - ETA: 1s - loss: 0.9474 - acc: 0.809 - ETA: 1s - loss: 0.9479 - acc: 0.807 - ETA: 1s - loss: 0.9417 - acc: 0.807 - ETA: 1s - loss: 0.9403 - acc: 0.804 - ETA: 0s - loss: 0.9457 - acc: 0.803 - ETA: 0s - loss: 0.9357 - acc: 0.804 - ETA: 0s - loss: 0.9384 - acc: 0.802 - ETA: 0s - loss: 0.9265 - acc: 0.802 - ETA: 0s - loss: 0.9204 - acc: 0.804 - ETA: 0s - loss: 0.9209 - acc: 0.804 - ETA: 0s - loss: 0.9228 - acc: 0.804 - ETA: 0s - loss: 0.9322 - acc: 0.802 - ETA: 0s - loss: 0.9355 - acc: 0.802 - ETA: 0s - loss: 0.9262 - acc: 0.803 - ETA: 0s - loss: 0.9204 - acc: 0.804 - ETA: 0s - loss: 0.9132 - acc: 0.805 - ETA: 0s - loss: 0.9104 - acc: 0.806 - ETA: 0s - loss: 0.9123 - acc: 0.804 - ETA: 0s - loss: 0.9132 - acc: 0.805 - ETA: 0s - loss: 0.9124 - acc: 0.805 - ETA: 0s - loss: 0.9112 - acc: 0.805 - ETA: 0s - loss: 0.9086 - acc: 0.805 - ETA: 0s - loss: 0.9219 - acc: 0.8047Epoch 00014: val_loss did not improve\n",
      "6680/6680 [==============================] - 2s - loss: 0.9238 - acc: 0.8043 - val_loss: 1.3408 - val_acc: 0.7617\n",
      "Epoch 16/32\n",
      "6560/6680 [============================>.] - ETA: 2s - loss: 0.0745 - acc: 1.000 - ETA: 2s - loss: 0.8225 - acc: 0.822 - ETA: 2s - loss: 0.7400 - acc: 0.811 - ETA: 2s - loss: 0.7419 - acc: 0.814 - ETA: 1s - loss: 0.7496 - acc: 0.819 - ETA: 1s - loss: 0.7815 - acc: 0.822 - ETA: 1s - loss: 0.8134 - acc: 0.811 - ETA: 1s - loss: 0.8454 - acc: 0.809 - ETA: 1s - loss: 0.8623 - acc: 0.809 - ETA: 1s - loss: 0.8315 - acc: 0.815 - ETA: 1s - loss: 0.8661 - acc: 0.816 - ETA: 1s - loss: 0.8529 - acc: 0.819 - ETA: 1s - loss: 0.8620 - acc: 0.817 - ETA: 1s - loss: 0.8542 - acc: 0.820 - ETA: 1s - loss: 0.8486 - acc: 0.819 - ETA: 1s - loss: 0.8497 - acc: 0.820 - ETA: 1s - loss: 0.8381 - acc: 0.820 - ETA: 1s - loss: 0.8238 - acc: 0.821 - ETA: 1s - loss: 0.8342 - acc: 0.819 - ETA: 1s - loss: 0.8441 - acc: 0.818 - ETA: 1s - loss: 0.8432 - acc: 0.819 - ETA: 1s - loss: 0.8551 - acc: 0.818 - ETA: 0s - loss: 0.8631 - acc: 0.815 - ETA: 0s - loss: 0.8779 - acc: 0.813 - ETA: 0s - loss: 0.8865 - acc: 0.811 - ETA: 0s - loss: 0.8847 - acc: 0.812 - ETA: 0s - loss: 0.8877 - acc: 0.811 - ETA: 0s - loss: 0.8975 - acc: 0.811 - ETA: 0s - loss: 0.8905 - acc: 0.812 - ETA: 0s - loss: 0.8872 - acc: 0.813 - ETA: 0s - loss: 0.8934 - acc: 0.811 - ETA: 0s - loss: 0.9044 - acc: 0.810 - ETA: 0s - loss: 0.8958 - acc: 0.812 - ETA: 0s - loss: 0.9018 - acc: 0.812 - ETA: 0s - loss: 0.9107 - acc: 0.811 - ETA: 0s - loss: 0.9109 - acc: 0.812 - ETA: 0s - loss: 0.9113 - acc: 0.811 - ETA: 0s - loss: 0.9055 - acc: 0.812 - ETA: 0s - loss: 0.9071 - acc: 0.812 - ETA: 0s - loss: 0.9112 - acc: 0.8111Epoch 00015: val_loss did not improve\n",
      "6680/6680 [==============================] - 2s - loss: 0.9137 - acc: 0.8111 - val_loss: 1.3460 - val_acc: 0.7557\n",
      "Epoch 17/32\n",
      "6580/6680 [============================>.] - ETA: 2s - loss: 1.0301 - acc: 0.850 - ETA: 1s - loss: 0.9846 - acc: 0.805 - ETA: 1s - loss: 0.8448 - acc: 0.811 - ETA: 1s - loss: 0.8825 - acc: 0.811 - ETA: 1s - loss: 0.8493 - acc: 0.817 - ETA: 1s - loss: 0.8721 - acc: 0.817 - ETA: 1s - loss: 0.8458 - acc: 0.824 - ETA: 1s - loss: 0.8297 - acc: 0.825 - ETA: 1s - loss: 0.8535 - acc: 0.826 - ETA: 1s - loss: 0.8898 - acc: 0.820 - ETA: 1s - loss: 0.9220 - acc: 0.816 - ETA: 1s - loss: 0.9055 - acc: 0.819 - ETA: 1s - loss: 0.9029 - acc: 0.819 - ETA: 1s - loss: 0.9035 - acc: 0.820 - ETA: 1s - loss: 0.9001 - acc: 0.820 - ETA: 1s - loss: 0.9000 - acc: 0.819 - ETA: 1s - loss: 0.8983 - acc: 0.820 - ETA: 1s - loss: 0.8836 - acc: 0.823 - ETA: 1s - loss: 0.8836 - acc: 0.823 - ETA: 1s - loss: 0.8783 - acc: 0.823 - ETA: 0s - loss: 0.8829 - acc: 0.823 - ETA: 0s - loss: 0.8856 - acc: 0.823 - ETA: 0s - loss: 0.8778 - acc: 0.823 - ETA: 0s - loss: 0.8729 - acc: 0.822 - ETA: 0s - loss: 0.8680 - acc: 0.823 - ETA: 0s - loss: 0.8741 - acc: 0.821 - ETA: 0s - loss: 0.8807 - acc: 0.821 - ETA: 0s - loss: 0.8667 - acc: 0.822 - ETA: 0s - loss: 0.8643 - acc: 0.822 - ETA: 0s - loss: 0.8698 - acc: 0.821 - ETA: 0s - loss: 0.8749 - acc: 0.821 - ETA: 0s - loss: 0.8769 - acc: 0.820 - ETA: 0s - loss: 0.8746 - acc: 0.820 - ETA: 0s - loss: 0.8771 - acc: 0.820 - ETA: 0s - loss: 0.8799 - acc: 0.820 - ETA: 0s - loss: 0.8886 - acc: 0.819 - ETA: 0s - loss: 0.8826 - acc: 0.820 - ETA: 0s - loss: 0.8838 - acc: 0.8213Epoch 00016: val_loss did not improve\n",
      "6680/6680 [==============================] - 2s - loss: 0.8845 - acc: 0.8211 - val_loss: 1.2181 - val_acc: 0.7784\n",
      "Epoch 18/32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6600/6680 [============================>.] - ETA: 1s - loss: 1.0181 - acc: 0.750 - ETA: 1s - loss: 0.8056 - acc: 0.820 - ETA: 1s - loss: 0.9142 - acc: 0.821 - ETA: 1s - loss: 0.8711 - acc: 0.835 - ETA: 1s - loss: 0.8274 - acc: 0.843 - ETA: 1s - loss: 0.8212 - acc: 0.840 - ETA: 1s - loss: 0.8480 - acc: 0.833 - ETA: 1s - loss: 0.8595 - acc: 0.831 - ETA: 1s - loss: 0.8594 - acc: 0.832 - ETA: 1s - loss: 0.8471 - acc: 0.831 - ETA: 1s - loss: 0.8755 - acc: 0.828 - ETA: 1s - loss: 0.8851 - acc: 0.828 - ETA: 1s - loss: 0.8870 - acc: 0.829 - ETA: 1s - loss: 0.8817 - acc: 0.831 - ETA: 1s - loss: 0.8428 - acc: 0.834 - ETA: 1s - loss: 0.8417 - acc: 0.834 - ETA: 1s - loss: 0.8533 - acc: 0.829 - ETA: 1s - loss: 0.8513 - acc: 0.829 - ETA: 1s - loss: 0.8354 - acc: 0.829 - ETA: 0s - loss: 0.8408 - acc: 0.828 - ETA: 0s - loss: 0.8506 - acc: 0.824 - ETA: 0s - loss: 0.8620 - acc: 0.821 - ETA: 0s - loss: 0.8524 - acc: 0.824 - ETA: 0s - loss: 0.8503 - acc: 0.823 - ETA: 0s - loss: 0.8402 - acc: 0.825 - ETA: 0s - loss: 0.8333 - acc: 0.826 - ETA: 0s - loss: 0.8345 - acc: 0.826 - ETA: 0s - loss: 0.8455 - acc: 0.825 - ETA: 0s - loss: 0.8438 - acc: 0.825 - ETA: 0s - loss: 0.8450 - acc: 0.825 - ETA: 0s - loss: 0.8547 - acc: 0.824 - ETA: 0s - loss: 0.8508 - acc: 0.826 - ETA: 0s - loss: 0.8573 - acc: 0.824 - ETA: 0s - loss: 0.8661 - acc: 0.824 - ETA: 0s - loss: 0.8602 - acc: 0.824 - ETA: 0s - loss: 0.8557 - acc: 0.826 - ETA: 0s - loss: 0.8556 - acc: 0.826 - ETA: 0s - loss: 0.8489 - acc: 0.8274Epoch 00017: val_loss did not improve\n",
      "6680/6680 [==============================] - 2s - loss: 0.8541 - acc: 0.8271 - val_loss: 1.3692 - val_acc: 0.7677\n",
      "Epoch 19/32\n",
      "6620/6680 [============================>.] - ETA: 2s - loss: 0.0054 - acc: 1.000 - ETA: 2s - loss: 0.5748 - acc: 0.875 - ETA: 1s - loss: 0.8104 - acc: 0.823 - ETA: 1s - loss: 0.8828 - acc: 0.810 - ETA: 1s - loss: 0.8573 - acc: 0.817 - ETA: 1s - loss: 0.8286 - acc: 0.818 - ETA: 1s - loss: 0.8439 - acc: 0.823 - ETA: 1s - loss: 0.8536 - acc: 0.821 - ETA: 1s - loss: 0.8646 - acc: 0.822 - ETA: 1s - loss: 0.8426 - acc: 0.825 - ETA: 1s - loss: 0.8692 - acc: 0.825 - ETA: 1s - loss: 0.8920 - acc: 0.825 - ETA: 1s - loss: 0.8742 - acc: 0.828 - ETA: 1s - loss: 0.8970 - acc: 0.828 - ETA: 1s - loss: 0.9016 - acc: 0.827 - ETA: 1s - loss: 0.9103 - acc: 0.825 - ETA: 1s - loss: 0.8895 - acc: 0.826 - ETA: 1s - loss: 0.8953 - acc: 0.826 - ETA: 1s - loss: 0.9076 - acc: 0.825 - ETA: 0s - loss: 0.8930 - acc: 0.826 - ETA: 0s - loss: 0.8988 - acc: 0.825 - ETA: 0s - loss: 0.8992 - acc: 0.824 - ETA: 0s - loss: 0.8834 - acc: 0.827 - ETA: 0s - loss: 0.8677 - acc: 0.830 - ETA: 0s - loss: 0.8749 - acc: 0.828 - ETA: 0s - loss: 0.8761 - acc: 0.828 - ETA: 0s - loss: 0.8672 - acc: 0.828 - ETA: 0s - loss: 0.8699 - acc: 0.829 - ETA: 0s - loss: 0.8699 - acc: 0.829 - ETA: 0s - loss: 0.8750 - acc: 0.829 - ETA: 0s - loss: 0.8741 - acc: 0.830 - ETA: 0s - loss: 0.8665 - acc: 0.831 - ETA: 0s - loss: 0.8775 - acc: 0.830 - ETA: 0s - loss: 0.8870 - acc: 0.829 - ETA: 0s - loss: 0.8841 - acc: 0.830 - ETA: 0s - loss: 0.8849 - acc: 0.829 - ETA: 0s - loss: 0.8883 - acc: 0.829 - ETA: 0s - loss: 0.8866 - acc: 0.8292Epoch 00018: val_loss did not improve\n",
      "6680/6680 [==============================] - 2s - loss: 0.8817 - acc: 0.8295 - val_loss: 1.3133 - val_acc: 0.7832\n",
      "Epoch 20/32\n",
      "6600/6680 [============================>.] - ETA: 2s - loss: 0.8737 - acc: 0.900 - ETA: 2s - loss: 0.9827 - acc: 0.833 - ETA: 1s - loss: 0.8810 - acc: 0.850 - ETA: 1s - loss: 0.8196 - acc: 0.857 - ETA: 1s - loss: 0.7868 - acc: 0.851 - ETA: 1s - loss: 0.7896 - acc: 0.848 - ETA: 1s - loss: 0.8094 - acc: 0.847 - ETA: 1s - loss: 0.8428 - acc: 0.842 - ETA: 1s - loss: 0.8434 - acc: 0.844 - ETA: 1s - loss: 0.8954 - acc: 0.834 - ETA: 1s - loss: 0.9072 - acc: 0.831 - ETA: 1s - loss: 0.9055 - acc: 0.833 - ETA: 1s - loss: 0.8982 - acc: 0.833 - ETA: 1s - loss: 0.9084 - acc: 0.831 - ETA: 1s - loss: 0.9213 - acc: 0.826 - ETA: 1s - loss: 0.9166 - acc: 0.827 - ETA: 1s - loss: 0.9032 - acc: 0.827 - ETA: 1s - loss: 0.8844 - acc: 0.830 - ETA: 1s - loss: 0.8788 - acc: 0.829 - ETA: 1s - loss: 0.8701 - acc: 0.831 - ETA: 0s - loss: 0.8761 - acc: 0.831 - ETA: 0s - loss: 0.8906 - acc: 0.830 - ETA: 0s - loss: 0.8823 - acc: 0.832 - ETA: 0s - loss: 0.8886 - acc: 0.831 - ETA: 0s - loss: 0.8868 - acc: 0.831 - ETA: 0s - loss: 0.8892 - acc: 0.831 - ETA: 0s - loss: 0.8951 - acc: 0.830 - ETA: 0s - loss: 0.8891 - acc: 0.830 - ETA: 0s - loss: 0.8850 - acc: 0.832 - ETA: 0s - loss: 0.8782 - acc: 0.833 - ETA: 0s - loss: 0.8753 - acc: 0.834 - ETA: 0s - loss: 0.8894 - acc: 0.833 - ETA: 0s - loss: 0.8855 - acc: 0.833 - ETA: 0s - loss: 0.8874 - acc: 0.833 - ETA: 0s - loss: 0.8949 - acc: 0.831 - ETA: 0s - loss: 0.8977 - acc: 0.829 - ETA: 0s - loss: 0.9010 - acc: 0.829 - ETA: 0s - loss: 0.8992 - acc: 0.8288Epoch 00019: val_loss did not improve\n",
      "6680/6680 [==============================] - 2s - loss: 0.8965 - acc: 0.8295 - val_loss: 1.3788 - val_acc: 0.7749\n",
      "Epoch 21/32\n",
      "6500/6680 [============================>.] - ETA: 1s - loss: 1.6813 - acc: 0.800 - ETA: 2s - loss: 1.2751 - acc: 0.805 - ETA: 2s - loss: 0.9964 - acc: 0.823 - ETA: 1s - loss: 0.9656 - acc: 0.832 - ETA: 1s - loss: 0.8791 - acc: 0.839 - ETA: 1s - loss: 0.8162 - acc: 0.852 - ETA: 1s - loss: 0.7716 - acc: 0.857 - ETA: 1s - loss: 0.7864 - acc: 0.855 - ETA: 1s - loss: 0.7649 - acc: 0.857 - ETA: 1s - loss: 0.7941 - acc: 0.852 - ETA: 1s - loss: 0.8109 - acc: 0.850 - ETA: 1s - loss: 0.7911 - acc: 0.852 - ETA: 1s - loss: 0.8393 - acc: 0.847 - ETA: 1s - loss: 0.8519 - acc: 0.844 - ETA: 1s - loss: 0.8642 - acc: 0.841 - ETA: 1s - loss: 0.8706 - acc: 0.836 - ETA: 1s - loss: 0.8682 - acc: 0.838 - ETA: 1s - loss: 0.8726 - acc: 0.839 - ETA: 1s - loss: 0.8656 - acc: 0.840 - ETA: 1s - loss: 0.8601 - acc: 0.841 - ETA: 0s - loss: 0.8550 - acc: 0.842 - ETA: 0s - loss: 0.8541 - acc: 0.844 - ETA: 0s - loss: 0.8606 - acc: 0.843 - ETA: 0s - loss: 0.8740 - acc: 0.843 - ETA: 0s - loss: 0.8659 - acc: 0.843 - ETA: 0s - loss: 0.8598 - acc: 0.843 - ETA: 0s - loss: 0.8583 - acc: 0.844 - ETA: 0s - loss: 0.8556 - acc: 0.844 - ETA: 0s - loss: 0.8513 - acc: 0.844 - ETA: 0s - loss: 0.8500 - acc: 0.843 - ETA: 0s - loss: 0.8362 - acc: 0.845 - ETA: 0s - loss: 0.8364 - acc: 0.844 - ETA: 0s - loss: 0.8422 - acc: 0.843 - ETA: 0s - loss: 0.8374 - acc: 0.843 - ETA: 0s - loss: 0.8380 - acc: 0.842 - ETA: 0s - loss: 0.8406 - acc: 0.841 - ETA: 0s - loss: 0.8376 - acc: 0.841 - ETA: 0s - loss: 0.8415 - acc: 0.8408Epoch 00020: val_loss did not improve\n",
      "6680/6680 [==============================] - 2s - loss: 0.8416 - acc: 0.8406 - val_loss: 1.2762 - val_acc: 0.7808\n",
      "Epoch 22/32\n",
      "6520/6680 [============================>.] - ETA: 2s - loss: 0.8078 - acc: 0.750 - ETA: 2s - loss: 0.9263 - acc: 0.815 - ETA: 1s - loss: 0.8499 - acc: 0.830 - ETA: 1s - loss: 0.8576 - acc: 0.825 - ETA: 1s - loss: 0.7660 - acc: 0.838 - ETA: 1s - loss: 0.7139 - acc: 0.848 - ETA: 1s - loss: 0.7175 - acc: 0.845 - ETA: 1s - loss: 0.7272 - acc: 0.848 - ETA: 1s - loss: 0.7374 - acc: 0.846 - ETA: 1s - loss: 0.7295 - acc: 0.848 - ETA: 1s - loss: 0.7078 - acc: 0.851 - ETA: 1s - loss: 0.7125 - acc: 0.851 - ETA: 1s - loss: 0.6929 - acc: 0.854 - ETA: 1s - loss: 0.7128 - acc: 0.852 - ETA: 1s - loss: 0.6912 - acc: 0.855 - ETA: 1s - loss: 0.7123 - acc: 0.851 - ETA: 1s - loss: 0.7295 - acc: 0.849 - ETA: 1s - loss: 0.7060 - acc: 0.852 - ETA: 1s - loss: 0.7135 - acc: 0.851 - ETA: 1s - loss: 0.7179 - acc: 0.850 - ETA: 0s - loss: 0.7269 - acc: 0.848 - ETA: 0s - loss: 0.7217 - acc: 0.848 - ETA: 0s - loss: 0.7405 - acc: 0.847 - ETA: 0s - loss: 0.7382 - acc: 0.849 - ETA: 0s - loss: 0.7478 - acc: 0.846 - ETA: 0s - loss: 0.7497 - acc: 0.846 - ETA: 0s - loss: 0.7560 - acc: 0.845 - ETA: 0s - loss: 0.7601 - acc: 0.845 - ETA: 0s - loss: 0.7701 - acc: 0.843 - ETA: 0s - loss: 0.7709 - acc: 0.843 - ETA: 0s - loss: 0.7661 - acc: 0.844 - ETA: 0s - loss: 0.7664 - acc: 0.844 - ETA: 0s - loss: 0.7625 - acc: 0.844 - ETA: 0s - loss: 0.7660 - acc: 0.844 - ETA: 0s - loss: 0.7789 - acc: 0.843 - ETA: 0s - loss: 0.7851 - acc: 0.842 - ETA: 0s - loss: 0.7905 - acc: 0.841 - ETA: 0s - loss: 0.7827 - acc: 0.8428Epoch 00021: val_loss did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6680/6680 [==============================] - 2s - loss: 0.7900 - acc: 0.8416 - val_loss: 1.4030 - val_acc: 0.7749\n",
      "Epoch 23/32\n",
      "6660/6680 [============================>.] - ETA: 2s - loss: 1.2534 - acc: 0.850 - ETA: 2s - loss: 0.8848 - acc: 0.860 - ETA: 1s - loss: 0.8266 - acc: 0.841 - ETA: 1s - loss: 0.7157 - acc: 0.868 - ETA: 1s - loss: 0.7588 - acc: 0.854 - ETA: 1s - loss: 0.7696 - acc: 0.847 - ETA: 1s - loss: 0.7428 - acc: 0.850 - ETA: 1s - loss: 0.6997 - acc: 0.855 - ETA: 1s - loss: 0.6657 - acc: 0.861 - ETA: 1s - loss: 0.6576 - acc: 0.862 - ETA: 1s - loss: 0.6622 - acc: 0.859 - ETA: 1s - loss: 0.6898 - acc: 0.856 - ETA: 1s - loss: 0.7016 - acc: 0.852 - ETA: 1s - loss: 0.7161 - acc: 0.850 - ETA: 1s - loss: 0.7187 - acc: 0.852 - ETA: 1s - loss: 0.7353 - acc: 0.850 - ETA: 1s - loss: 0.7513 - acc: 0.847 - ETA: 1s - loss: 0.7420 - acc: 0.850 - ETA: 1s - loss: 0.7457 - acc: 0.848 - ETA: 1s - loss: 0.7581 - acc: 0.847 - ETA: 0s - loss: 0.7651 - acc: 0.846 - ETA: 0s - loss: 0.7841 - acc: 0.845 - ETA: 0s - loss: 0.7819 - acc: 0.847 - ETA: 0s - loss: 0.7902 - acc: 0.846 - ETA: 0s - loss: 0.7820 - acc: 0.846 - ETA: 0s - loss: 0.7771 - acc: 0.847 - ETA: 0s - loss: 0.7817 - acc: 0.846 - ETA: 0s - loss: 0.8032 - acc: 0.844 - ETA: 0s - loss: 0.7974 - acc: 0.843 - ETA: 0s - loss: 0.7983 - acc: 0.843 - ETA: 0s - loss: 0.7921 - acc: 0.844 - ETA: 0s - loss: 0.7967 - acc: 0.843 - ETA: 0s - loss: 0.7943 - acc: 0.844 - ETA: 0s - loss: 0.7973 - acc: 0.843 - ETA: 0s - loss: 0.7946 - acc: 0.844 - ETA: 0s - loss: 0.7964 - acc: 0.844 - ETA: 0s - loss: 0.8013 - acc: 0.843 - ETA: 0s - loss: 0.7959 - acc: 0.844 - ETA: 0s - loss: 0.7943 - acc: 0.8441Epoch 00022: val_loss did not improve\n",
      "6680/6680 [==============================] - 2s - loss: 0.7932 - acc: 0.8442 - val_loss: 1.4780 - val_acc: 0.7689\n",
      "Epoch 24/32\n",
      "6640/6680 [============================>.] - ETA: 1s - loss: 0.0022 - acc: 1.000 - ETA: 1s - loss: 0.4554 - acc: 0.915 - ETA: 1s - loss: 0.4806 - acc: 0.905 - ETA: 1s - loss: 0.6727 - acc: 0.889 - ETA: 1s - loss: 0.7290 - acc: 0.873 - ETA: 1s - loss: 0.7945 - acc: 0.865 - ETA: 1s - loss: 0.8003 - acc: 0.858 - ETA: 1s - loss: 0.7983 - acc: 0.860 - ETA: 1s - loss: 0.7642 - acc: 0.861 - ETA: 1s - loss: 0.8039 - acc: 0.854 - ETA: 1s - loss: 0.7890 - acc: 0.857 - ETA: 1s - loss: 0.7888 - acc: 0.855 - ETA: 1s - loss: 0.7931 - acc: 0.854 - ETA: 1s - loss: 0.7836 - acc: 0.856 - ETA: 1s - loss: 0.7713 - acc: 0.858 - ETA: 1s - loss: 0.7654 - acc: 0.858 - ETA: 1s - loss: 0.7666 - acc: 0.858 - ETA: 1s - loss: 0.7567 - acc: 0.859 - ETA: 1s - loss: 0.7541 - acc: 0.859 - ETA: 1s - loss: 0.7552 - acc: 0.859 - ETA: 0s - loss: 0.7550 - acc: 0.859 - ETA: 0s - loss: 0.7528 - acc: 0.858 - ETA: 0s - loss: 0.7595 - acc: 0.856 - ETA: 0s - loss: 0.7596 - acc: 0.857 - ETA: 0s - loss: 0.7596 - acc: 0.856 - ETA: 0s - loss: 0.7710 - acc: 0.853 - ETA: 0s - loss: 0.7677 - acc: 0.852 - ETA: 0s - loss: 0.7659 - acc: 0.853 - ETA: 0s - loss: 0.7658 - acc: 0.853 - ETA: 0s - loss: 0.7655 - acc: 0.853 - ETA: 0s - loss: 0.7688 - acc: 0.853 - ETA: 0s - loss: 0.7709 - acc: 0.853 - ETA: 0s - loss: 0.7712 - acc: 0.853 - ETA: 0s - loss: 0.7668 - acc: 0.853 - ETA: 0s - loss: 0.7658 - acc: 0.854 - ETA: 0s - loss: 0.7739 - acc: 0.853 - ETA: 0s - loss: 0.7720 - acc: 0.853 - ETA: 0s - loss: 0.7766 - acc: 0.854 - ETA: 0s - loss: 0.7758 - acc: 0.8536Epoch 00023: val_loss did not improve\n",
      "6680/6680 [==============================] - 2s - loss: 0.7791 - acc: 0.8533 - val_loss: 1.6425 - val_acc: 0.7581\n",
      "Epoch 25/32\n",
      "6540/6680 [============================>.] - ETA: 2s - loss: 0.2393 - acc: 0.900 - ETA: 1s - loss: 0.5048 - acc: 0.880 - ETA: 1s - loss: 0.5919 - acc: 0.878 - ETA: 1s - loss: 0.7422 - acc: 0.864 - ETA: 1s - loss: 0.7837 - acc: 0.852 - ETA: 1s - loss: 0.7663 - acc: 0.859 - ETA: 1s - loss: 0.7904 - acc: 0.855 - ETA: 1s - loss: 0.7442 - acc: 0.859 - ETA: 1s - loss: 0.7275 - acc: 0.862 - ETA: 1s - loss: 0.7547 - acc: 0.861 - ETA: 1s - loss: 0.7714 - acc: 0.860 - ETA: 1s - loss: 0.7515 - acc: 0.862 - ETA: 1s - loss: 0.7292 - acc: 0.863 - ETA: 1s - loss: 0.7147 - acc: 0.866 - ETA: 1s - loss: 0.7179 - acc: 0.867 - ETA: 1s - loss: 0.7144 - acc: 0.868 - ETA: 1s - loss: 0.7120 - acc: 0.866 - ETA: 1s - loss: 0.7260 - acc: 0.863 - ETA: 1s - loss: 0.7239 - acc: 0.864 - ETA: 1s - loss: 0.7411 - acc: 0.862 - ETA: 0s - loss: 0.7289 - acc: 0.863 - ETA: 0s - loss: 0.7372 - acc: 0.860 - ETA: 0s - loss: 0.7377 - acc: 0.859 - ETA: 0s - loss: 0.7568 - acc: 0.856 - ETA: 0s - loss: 0.7663 - acc: 0.855 - ETA: 0s - loss: 0.7659 - acc: 0.856 - ETA: 0s - loss: 0.7667 - acc: 0.857 - ETA: 0s - loss: 0.7659 - acc: 0.857 - ETA: 0s - loss: 0.7588 - acc: 0.858 - ETA: 0s - loss: 0.7517 - acc: 0.859 - ETA: 0s - loss: 0.7611 - acc: 0.857 - ETA: 0s - loss: 0.7671 - acc: 0.858 - ETA: 0s - loss: 0.7650 - acc: 0.857 - ETA: 0s - loss: 0.7708 - acc: 0.856 - ETA: 0s - loss: 0.7753 - acc: 0.857 - ETA: 0s - loss: 0.7755 - acc: 0.857 - ETA: 0s - loss: 0.7753 - acc: 0.858 - ETA: 0s - loss: 0.7777 - acc: 0.8578Epoch 00024: val_loss did not improve\n",
      "6680/6680 [==============================] - 2s - loss: 0.7796 - acc: 0.8576 - val_loss: 1.6104 - val_acc: 0.7808\n",
      "Epoch 26/32\n",
      "6540/6680 [============================>.] - ETA: 2s - loss: 0.2357 - acc: 0.950 - ETA: 2s - loss: 0.6733 - acc: 0.855 - ETA: 2s - loss: 0.7558 - acc: 0.852 - ETA: 1s - loss: 0.6971 - acc: 0.861 - ETA: 1s - loss: 0.7053 - acc: 0.866 - ETA: 1s - loss: 0.7100 - acc: 0.866 - ETA: 1s - loss: 0.7021 - acc: 0.860 - ETA: 1s - loss: 0.7083 - acc: 0.861 - ETA: 1s - loss: 0.7252 - acc: 0.860 - ETA: 1s - loss: 0.7462 - acc: 0.862 - ETA: 1s - loss: 0.7834 - acc: 0.857 - ETA: 1s - loss: 0.7751 - acc: 0.859 - ETA: 1s - loss: 0.7798 - acc: 0.860 - ETA: 1s - loss: 0.7810 - acc: 0.858 - ETA: 1s - loss: 0.7805 - acc: 0.858 - ETA: 1s - loss: 0.7785 - acc: 0.859 - ETA: 1s - loss: 0.7897 - acc: 0.857 - ETA: 1s - loss: 0.7808 - acc: 0.858 - ETA: 1s - loss: 0.7692 - acc: 0.860 - ETA: 1s - loss: 0.7833 - acc: 0.858 - ETA: 0s - loss: 0.7954 - acc: 0.855 - ETA: 0s - loss: 0.7909 - acc: 0.856 - ETA: 0s - loss: 0.7858 - acc: 0.857 - ETA: 0s - loss: 0.7764 - acc: 0.857 - ETA: 0s - loss: 0.7704 - acc: 0.858 - ETA: 0s - loss: 0.7754 - acc: 0.859 - ETA: 0s - loss: 0.7617 - acc: 0.861 - ETA: 0s - loss: 0.7558 - acc: 0.861 - ETA: 0s - loss: 0.7611 - acc: 0.861 - ETA: 0s - loss: 0.7550 - acc: 0.862 - ETA: 0s - loss: 0.7469 - acc: 0.862 - ETA: 0s - loss: 0.7539 - acc: 0.861 - ETA: 0s - loss: 0.7687 - acc: 0.861 - ETA: 0s - loss: 0.7796 - acc: 0.860 - ETA: 0s - loss: 0.7919 - acc: 0.858 - ETA: 0s - loss: 0.7996 - acc: 0.858 - ETA: 0s - loss: 0.8009 - acc: 0.857 - ETA: 0s - loss: 0.7961 - acc: 0.858 - ETA: 0s - loss: 0.8016 - acc: 0.8586Epoch 00025: val_loss did not improve\n",
      "6680/6680 [==============================] - 2s - loss: 0.8116 - acc: 0.8572 - val_loss: 1.5964 - val_acc: 0.7856\n",
      "Epoch 27/32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6560/6680 [============================>.] - ETA: 2s - loss: 0.1527 - acc: 0.900 - ETA: 2s - loss: 1.1452 - acc: 0.833 - ETA: 2s - loss: 1.0452 - acc: 0.847 - ETA: 2s - loss: 0.9009 - acc: 0.848 - ETA: 1s - loss: 0.7883 - acc: 0.863 - ETA: 1s - loss: 0.8043 - acc: 0.860 - ETA: 1s - loss: 0.8007 - acc: 0.858 - ETA: 1s - loss: 0.8148 - acc: 0.855 - ETA: 1s - loss: 0.7997 - acc: 0.858 - ETA: 1s - loss: 0.7748 - acc: 0.860 - ETA: 1s - loss: 0.7467 - acc: 0.862 - ETA: 1s - loss: 0.7808 - acc: 0.859 - ETA: 1s - loss: 0.7905 - acc: 0.857 - ETA: 1s - loss: 0.7698 - acc: 0.858 - ETA: 1s - loss: 0.7555 - acc: 0.858 - ETA: 1s - loss: 0.7577 - acc: 0.859 - ETA: 1s - loss: 0.7678 - acc: 0.857 - ETA: 1s - loss: 0.7497 - acc: 0.858 - ETA: 1s - loss: 0.7684 - acc: 0.857 - ETA: 1s - loss: 0.7507 - acc: 0.857 - ETA: 0s - loss: 0.7695 - acc: 0.854 - ETA: 0s - loss: 0.7777 - acc: 0.851 - ETA: 0s - loss: 0.7766 - acc: 0.851 - ETA: 0s - loss: 0.7688 - acc: 0.852 - ETA: 0s - loss: 0.7631 - acc: 0.853 - ETA: 0s - loss: 0.7602 - acc: 0.855 - ETA: 0s - loss: 0.7594 - acc: 0.856 - ETA: 0s - loss: 0.7582 - acc: 0.856 - ETA: 0s - loss: 0.7631 - acc: 0.856 - ETA: 0s - loss: 0.7602 - acc: 0.857 - ETA: 0s - loss: 0.7656 - acc: 0.855 - ETA: 0s - loss: 0.7706 - acc: 0.854 - ETA: 0s - loss: 0.7750 - acc: 0.855 - ETA: 0s - loss: 0.7828 - acc: 0.854 - ETA: 0s - loss: 0.7915 - acc: 0.854 - ETA: 0s - loss: 0.7908 - acc: 0.855 - ETA: 0s - loss: 0.8055 - acc: 0.854 - ETA: 0s - loss: 0.8027 - acc: 0.8553Epoch 00026: val_loss did not improve\n",
      "6680/6680 [==============================] - 2s - loss: 0.8052 - acc: 0.8555 - val_loss: 1.5202 - val_acc: 0.7880\n",
      "Epoch 28/32\n",
      "6540/6680 [============================>.] - ETA: 2s - loss: 1.4516 - acc: 0.900 - ETA: 2s - loss: 0.6730 - acc: 0.880 - ETA: 1s - loss: 0.7558 - acc: 0.877 - ETA: 1s - loss: 0.8132 - acc: 0.879 - ETA: 1s - loss: 0.8134 - acc: 0.877 - ETA: 1s - loss: 0.8047 - acc: 0.873 - ETA: 1s - loss: 0.7858 - acc: 0.877 - ETA: 1s - loss: 0.7781 - acc: 0.875 - ETA: 1s - loss: 0.7718 - acc: 0.873 - ETA: 1s - loss: 0.8348 - acc: 0.870 - ETA: 1s - loss: 0.8176 - acc: 0.872 - ETA: 1s - loss: 0.8074 - acc: 0.873 - ETA: 1s - loss: 0.8516 - acc: 0.868 - ETA: 1s - loss: 0.8258 - acc: 0.868 - ETA: 1s - loss: 0.8070 - acc: 0.871 - ETA: 1s - loss: 0.8334 - acc: 0.870 - ETA: 1s - loss: 0.8430 - acc: 0.869 - ETA: 1s - loss: 0.8434 - acc: 0.870 - ETA: 1s - loss: 0.8276 - acc: 0.873 - ETA: 1s - loss: 0.8194 - acc: 0.871 - ETA: 0s - loss: 0.8180 - acc: 0.869 - ETA: 0s - loss: 0.8178 - acc: 0.867 - ETA: 0s - loss: 0.8094 - acc: 0.868 - ETA: 0s - loss: 0.8042 - acc: 0.868 - ETA: 0s - loss: 0.8020 - acc: 0.867 - ETA: 0s - loss: 0.8035 - acc: 0.867 - ETA: 0s - loss: 0.7998 - acc: 0.866 - ETA: 0s - loss: 0.8117 - acc: 0.865 - ETA: 0s - loss: 0.8088 - acc: 0.865 - ETA: 0s - loss: 0.8038 - acc: 0.865 - ETA: 0s - loss: 0.8016 - acc: 0.864 - ETA: 0s - loss: 0.8138 - acc: 0.863 - ETA: 0s - loss: 0.8147 - acc: 0.862 - ETA: 0s - loss: 0.8084 - acc: 0.862 - ETA: 0s - loss: 0.8049 - acc: 0.862 - ETA: 0s - loss: 0.8000 - acc: 0.862 - ETA: 0s - loss: 0.8005 - acc: 0.862 - ETA: 0s - loss: 0.7903 - acc: 0.8641Epoch 00027: val_loss did not improve\n",
      "6680/6680 [==============================] - 2s - loss: 0.7867 - acc: 0.8644 - val_loss: 1.5458 - val_acc: 0.7868\n",
      "Epoch 29/32\n",
      "6500/6680 [============================>.] - ETA: 2s - loss: 0.0473 - acc: 1.000 - ETA: 2s - loss: 0.7579 - acc: 0.861 - ETA: 2s - loss: 0.9292 - acc: 0.838 - ETA: 1s - loss: 0.9671 - acc: 0.838 - ETA: 1s - loss: 0.8300 - acc: 0.853 - ETA: 1s - loss: 0.8629 - acc: 0.847 - ETA: 1s - loss: 0.8715 - acc: 0.845 - ETA: 1s - loss: 0.8449 - acc: 0.848 - ETA: 1s - loss: 0.8219 - acc: 0.851 - ETA: 1s - loss: 0.8286 - acc: 0.854 - ETA: 1s - loss: 0.8252 - acc: 0.855 - ETA: 1s - loss: 0.8020 - acc: 0.861 - ETA: 1s - loss: 0.8172 - acc: 0.860 - ETA: 1s - loss: 0.8201 - acc: 0.859 - ETA: 1s - loss: 0.8131 - acc: 0.859 - ETA: 1s - loss: 0.8413 - acc: 0.857 - ETA: 1s - loss: 0.8374 - acc: 0.858 - ETA: 1s - loss: 0.8388 - acc: 0.859 - ETA: 1s - loss: 0.8135 - acc: 0.861 - ETA: 1s - loss: 0.8473 - acc: 0.859 - ETA: 0s - loss: 0.8433 - acc: 0.859 - ETA: 0s - loss: 0.8480 - acc: 0.858 - ETA: 0s - loss: 0.8316 - acc: 0.859 - ETA: 0s - loss: 0.8246 - acc: 0.861 - ETA: 0s - loss: 0.8294 - acc: 0.861 - ETA: 0s - loss: 0.8228 - acc: 0.861 - ETA: 0s - loss: 0.8206 - acc: 0.861 - ETA: 0s - loss: 0.8326 - acc: 0.860 - ETA: 0s - loss: 0.8348 - acc: 0.861 - ETA: 0s - loss: 0.8320 - acc: 0.861 - ETA: 0s - loss: 0.8319 - acc: 0.861 - ETA: 0s - loss: 0.8287 - acc: 0.862 - ETA: 0s - loss: 0.8247 - acc: 0.862 - ETA: 0s - loss: 0.8223 - acc: 0.863 - ETA: 0s - loss: 0.8324 - acc: 0.862 - ETA: 0s - loss: 0.8365 - acc: 0.861 - ETA: 0s - loss: 0.8323 - acc: 0.862 - ETA: 0s - loss: 0.8334 - acc: 0.8623Epoch 00028: val_loss did not improve\n",
      "6680/6680 [==============================] - 2s - loss: 0.8279 - acc: 0.8632 - val_loss: 1.6689 - val_acc: 0.7665\n",
      "Epoch 30/32\n",
      "6560/6680 [============================>.] - ETA: 1s - loss: 0.6284 - acc: 0.900 - ETA: 2s - loss: 0.8775 - acc: 0.855 - ETA: 2s - loss: 0.7450 - acc: 0.879 - ETA: 1s - loss: 0.7813 - acc: 0.871 - ETA: 1s - loss: 0.8627 - acc: 0.860 - ETA: 1s - loss: 0.8502 - acc: 0.863 - ETA: 1s - loss: 0.8188 - acc: 0.866 - ETA: 1s - loss: 0.7690 - acc: 0.873 - ETA: 1s - loss: 0.7356 - acc: 0.876 - ETA: 1s - loss: 0.7181 - acc: 0.878 - ETA: 1s - loss: 0.7409 - acc: 0.876 - ETA: 1s - loss: 0.7493 - acc: 0.875 - ETA: 1s - loss: 0.7323 - acc: 0.876 - ETA: 1s - loss: 0.7182 - acc: 0.878 - ETA: 1s - loss: 0.7263 - acc: 0.878 - ETA: 1s - loss: 0.7364 - acc: 0.876 - ETA: 1s - loss: 0.7332 - acc: 0.876 - ETA: 1s - loss: 0.7258 - acc: 0.877 - ETA: 1s - loss: 0.7306 - acc: 0.875 - ETA: 1s - loss: 0.7283 - acc: 0.876 - ETA: 0s - loss: 0.7246 - acc: 0.877 - ETA: 0s - loss: 0.7226 - acc: 0.876 - ETA: 0s - loss: 0.7286 - acc: 0.876 - ETA: 0s - loss: 0.7286 - acc: 0.877 - ETA: 0s - loss: 0.7290 - acc: 0.877 - ETA: 0s - loss: 0.7334 - acc: 0.875 - ETA: 0s - loss: 0.7409 - acc: 0.875 - ETA: 0s - loss: 0.7384 - acc: 0.874 - ETA: 0s - loss: 0.7360 - acc: 0.873 - ETA: 0s - loss: 0.7489 - acc: 0.872 - ETA: 0s - loss: 0.7538 - acc: 0.871 - ETA: 0s - loss: 0.7546 - acc: 0.871 - ETA: 0s - loss: 0.7504 - acc: 0.872 - ETA: 0s - loss: 0.7428 - acc: 0.873 - ETA: 0s - loss: 0.7417 - acc: 0.872 - ETA: 0s - loss: 0.7407 - acc: 0.872 - ETA: 0s - loss: 0.7414 - acc: 0.870 - ETA: 0s - loss: 0.7440 - acc: 0.8703Epoch 00029: val_loss did not improve\n",
      "6680/6680 [==============================] - 2s - loss: 0.7345 - acc: 0.8711 - val_loss: 1.4814 - val_acc: 0.7880\n",
      "Epoch 31/32\n",
      "6520/6680 [============================>.] - ETA: 2s - loss: 0.8417 - acc: 0.850 - ETA: 2s - loss: 0.6603 - acc: 0.877 - ETA: 2s - loss: 0.7647 - acc: 0.876 - ETA: 1s - loss: 0.6983 - acc: 0.875 - ETA: 1s - loss: 0.7253 - acc: 0.870 - ETA: 1s - loss: 0.6844 - acc: 0.875 - ETA: 1s - loss: 0.7123 - acc: 0.872 - ETA: 1s - loss: 0.7027 - acc: 0.875 - ETA: 1s - loss: 0.6993 - acc: 0.878 - ETA: 1s - loss: 0.7079 - acc: 0.873 - ETA: 1s - loss: 0.7338 - acc: 0.873 - ETA: 1s - loss: 0.7333 - acc: 0.871 - ETA: 1s - loss: 0.7273 - acc: 0.872 - ETA: 1s - loss: 0.7257 - acc: 0.872 - ETA: 1s - loss: 0.7160 - acc: 0.873 - ETA: 1s - loss: 0.7116 - acc: 0.874 - ETA: 1s - loss: 0.7110 - acc: 0.873 - ETA: 1s - loss: 0.7188 - acc: 0.870 - ETA: 1s - loss: 0.7267 - acc: 0.871 - ETA: 1s - loss: 0.7371 - acc: 0.869 - ETA: 0s - loss: 0.7387 - acc: 0.870 - ETA: 0s - loss: 0.7447 - acc: 0.870 - ETA: 0s - loss: 0.7386 - acc: 0.870 - ETA: 0s - loss: 0.7358 - acc: 0.870 - ETA: 0s - loss: 0.7342 - acc: 0.870 - ETA: 0s - loss: 0.7398 - acc: 0.870 - ETA: 0s - loss: 0.7344 - acc: 0.871 - ETA: 0s - loss: 0.7357 - acc: 0.870 - ETA: 0s - loss: 0.7387 - acc: 0.870 - ETA: 0s - loss: 0.7528 - acc: 0.868 - ETA: 0s - loss: 0.7618 - acc: 0.867 - ETA: 0s - loss: 0.7728 - acc: 0.867 - ETA: 0s - loss: 0.7782 - acc: 0.866 - ETA: 0s - loss: 0.7754 - acc: 0.868 - ETA: 0s - loss: 0.7725 - acc: 0.869 - ETA: 0s - loss: 0.7816 - acc: 0.868 - ETA: 0s - loss: 0.7847 - acc: 0.867 - ETA: 0s - loss: 0.7852 - acc: 0.8673Epoch 00030: val_loss did not improve\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6680/6680 [==============================] - 2s - loss: 0.7906 - acc: 0.8674 - val_loss: 1.8047 - val_acc: 0.7725\n",
      "Epoch 32/32\n",
      "6540/6680 [============================>.] - ETA: 2s - loss: 0.6886 - acc: 0.800 - ETA: 1s - loss: 0.5256 - acc: 0.875 - ETA: 1s - loss: 0.4768 - acc: 0.888 - ETA: 1s - loss: 0.4832 - acc: 0.900 - ETA: 1s - loss: 0.5297 - acc: 0.898 - ETA: 1s - loss: 0.5632 - acc: 0.892 - ETA: 1s - loss: 0.5730 - acc: 0.889 - ETA: 1s - loss: 0.5665 - acc: 0.888 - ETA: 1s - loss: 0.5742 - acc: 0.885 - ETA: 1s - loss: 0.6111 - acc: 0.883 - ETA: 1s - loss: 0.5788 - acc: 0.885 - ETA: 1s - loss: 0.5732 - acc: 0.887 - ETA: 1s - loss: 0.5715 - acc: 0.888 - ETA: 1s - loss: 0.5819 - acc: 0.886 - ETA: 1s - loss: 0.6033 - acc: 0.884 - ETA: 1s - loss: 0.5993 - acc: 0.883 - ETA: 1s - loss: 0.6185 - acc: 0.882 - ETA: 1s - loss: 0.6109 - acc: 0.884 - ETA: 1s - loss: 0.6351 - acc: 0.882 - ETA: 1s - loss: 0.6538 - acc: 0.879 - ETA: 0s - loss: 0.6489 - acc: 0.881 - ETA: 0s - loss: 0.6675 - acc: 0.880 - ETA: 0s - loss: 0.6847 - acc: 0.877 - ETA: 0s - loss: 0.6924 - acc: 0.876 - ETA: 0s - loss: 0.6857 - acc: 0.877 - ETA: 0s - loss: 0.6922 - acc: 0.876 - ETA: 0s - loss: 0.7053 - acc: 0.875 - ETA: 0s - loss: 0.7023 - acc: 0.876 - ETA: 0s - loss: 0.7152 - acc: 0.874 - ETA: 0s - loss: 0.7162 - acc: 0.874 - ETA: 0s - loss: 0.7247 - acc: 0.874 - ETA: 0s - loss: 0.7282 - acc: 0.874 - ETA: 0s - loss: 0.7377 - acc: 0.874 - ETA: 0s - loss: 0.7345 - acc: 0.875 - ETA: 0s - loss: 0.7322 - acc: 0.876 - ETA: 0s - loss: 0.7348 - acc: 0.875 - ETA: 0s - loss: 0.7406 - acc: 0.873 - ETA: 0s - loss: 0.7493 - acc: 0.8740Epoch 00031: val_loss did not improve\n",
      "6680/6680 [==============================] - 2s - loss: 0.7548 - acc: 0.8732 - val_loss: 1.7308 - val_acc: 0.7689\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x19ad3288c88>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### TODO: Train the model.\n",
    "tf_Xception_checkpointer = ModelCheckpoint(filepath='saved_models/weights.best.tf_Xception.hdf5', \n",
    "                               verbose=1, save_best_only=True)\n",
    "\n",
    "tf_Xception_model.fit(train_Xception, train_targets, \n",
    "          validation_data=(valid_Xception, valid_targets),\n",
    "          epochs=32, batch_size=20, callbacks=[tf_Xception_checkpointer], verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (IMPLEMENTATION) Load the Model with the Best Validation Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### TODO: Load the model weights with the best validation loss.\n",
    "tf_Xception_model.load_weights('saved_models/weights.best.tf_Xception.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (IMPLEMENTATION) Test the Model\n",
    "\n",
    "Try out your model on the test dataset of dog images. Ensure that your test accuracy is greater than 60%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 71.6507%\n"
     ]
    }
   ],
   "source": [
    "### TODO: Calculate classification accuracy on the test dataset.\n",
    "# get index of predicted dog breed for each image in test set\n",
    "tf_Xception_predictions = [np.argmax(tf_Xception_model.predict(np.expand_dims(feature, axis=0))) for feature in test_Xception]\n",
    "\n",
    "# report test accuracy\n",
    "test_accuracy = 100*np.sum(np.array(tf_Xception_predictions)==np.argmax(test_targets, axis=1))/len(tf_Xception_predictions)\n",
    "print('Test accuracy: %.4f%%' % test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (IMPLEMENTATION) Predict Dog Breed with the Model\n",
    "\n",
    "Write a function that takes an image path as input and returns the dog breed (`Affenpinscher`, `Afghan_hound`, etc) that is predicted by your model.  \n",
    "\n",
    "Similar to the analogous function in Step 5, your function should have three steps:\n",
    "1. Extract the bottleneck features corresponding to the chosen CNN model.\n",
    "2. Supply the bottleneck features as input to the model to return the predicted vector.  Note that the argmax of this prediction vector gives the index of the predicted dog breed.\n",
    "3. Use the `dog_names` array defined in Step 0 of this notebook to return the corresponding breed.\n",
    "\n",
    "The functions to extract the bottleneck features can be found in `extract_bottleneck_features.py`, and they have been imported in an earlier code cell.  To obtain the bottleneck features corresponding to your chosen CNN architecture, you need to use the function\n",
    "\n",
    "    extract_{network}\n",
    "    \n",
    "where `{network}`, in the above filename, should be one of `VGG19`, `Resnet50`, `InceptionV3`, or `Xception`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### TODO: Write a function that takes a path to an image as input\n",
    "### and returns the dog breed that is predicted by the model.\n",
    "def Xception_predict_breed(img_path):\n",
    "    # extract bottleneck features\n",
    "    tensor = path_to_tensor(img_path)\n",
    "    bottleneck_feature = extract_Xception(tensor)\n",
    "    \n",
    "    # obtain predicted vector\n",
    "    predicted_vector = tf_Xception_model.predict(bottleneck_feature, verbose=1)\n",
    "    #predicted_vector = tf_Xception_model.predict(np.expand_dims(bottleneck_feature, axis=0), verbose=1)\n",
    "    \n",
    "    # return dog breed that is predicted by the model\n",
    "    return dog_names[np.argmax(predicted_vector)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='step6'></a>\n",
    "## Step 6: Write your Algorithm\n",
    "\n",
    "Write an algorithm that accepts a file path to an image and first determines whether the image contains a human, dog, or neither.  Then,\n",
    "- if a __dog__ is detected in the image, return the predicted breed.\n",
    "- if a __human__ is detected in the image, return the resembling dog breed.\n",
    "- if __neither__ is detected in the image, provide output that indicates an error.\n",
    "\n",
    "You are welcome to write your own functions for detecting humans and dogs in images, but feel free to use the `face_detector` and `dog_detector` functions developed above.  You are __required__ to use your CNN from Step 5 to predict dog breed.  \n",
    "\n",
    "Some sample output for our algorithm is provided below, but feel free to design your own user experience!\n",
    "\n",
    "![Sample Human Output](images/sample_human_output.png)\n",
    "\n",
    "\n",
    "### (IMPLEMENTATION) Write your Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### TODO: Write your algorithm.\n",
    "### Feel free to use as many code cells as needed.\n",
    "def IdentifyBreed(img_path):\n",
    "    # Check if its a dog\n",
    "    if dog_detector(img_path):\n",
    "        print(\"Woof there dog!\")\n",
    "        dogBreed = Xception_predict_breed(img_path)\n",
    "        print(\"You are a\", dogBreed)\n",
    "        \n",
    "    elif face_detector(img_path):\n",
    "        print(\"Hi there human!\")\n",
    "        dogBreed = Xception_predict_breed(img_path)\n",
    "        print(\"You are a\", dogBreed)\n",
    "        \n",
    "    else:\n",
    "        print(\"Sorry, I do not recognize you!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='step7'></a>\n",
    "## Step 7: Test Your Algorithm\n",
    "\n",
    "In this section, you will take your new algorithm for a spin!  What kind of dog does the algorithm think that __you__ look like?  If you have a dog, does it predict your dog's breed accurately?  If you have a cat, does it mistakenly think that your cat is a dog?\n",
    "\n",
    "### (IMPLEMENTATION) Test Your Algorithm on Sample Images!\n",
    "\n",
    "Test your algorithm at least six images on your computer.  Feel free to use any images you like.  Use at least two human and two dog images.  \n",
    "\n",
    "__Question 6:__ Is the output better than you expected :) ?  Or worse :( ?  Provide at least three possible points of improvement for your algorithm.\n",
    "\n",
    "__Answer:__ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 8 total images.\n",
      "Hi there human!\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking : expected global_average_pooling2d_3_input to have shape (None, 7, 7, 512) but got array with shape (1, 7, 7, 2048)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-5c5d85fa95ab>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmy_images\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[0mIdentifyBreed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m     '''\n\u001b[0;32m     17\u001b[0m     \u001b[0mpil_im\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-31-2c13f67c67b7>\u001b[0m in \u001b[0;36mIdentifyBreed\u001b[1;34m(img_path)\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mface_detector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Hi there human!\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m         \u001b[0mdogBreed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mXception_predict_breed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"You are a\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdogBreed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-30-32cce2c30173>\u001b[0m in \u001b[0;36mXception_predict_breed\u001b[1;34m(img_path)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;31m# obtain predicted vector\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mpredicted_vector\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_Xception_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbottleneck_feature\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[1;31m#predicted_vector = tf_Xception_model.predict(np.expand_dims(bottleneck_feature, axis=0), verbose=1)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\hbhagava\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose)\u001b[0m\n\u001b[0;32m    907\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    908\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 909\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    910\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    911\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict_on_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\hbhagava\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose)\u001b[0m\n\u001b[0;32m   1497\u001b[0m         x = _standardize_input_data(x, self._feed_input_names,\n\u001b[0;32m   1498\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_feed_input_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1499\u001b[1;33m                                     check_batch_axis=False)\n\u001b[0m\u001b[0;32m   1500\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1501\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\hbhagava\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    138\u001b[0m                             \u001b[1;34m' to have shape '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshapes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m                             \u001b[1;34m' but got array with shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 140\u001b[1;33m                             str(array.shape))\n\u001b[0m\u001b[0;32m    141\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking : expected global_average_pooling2d_3_input to have shape (None, 7, 7, 512) but got array with shape (1, 7, 7, 2048)"
     ]
    }
   ],
   "source": [
    "## TODO: Execute your algorithm from Step 6 on\n",
    "## at least 6 images on your computer.\n",
    "## Feel free to use as many code cells as needed.\n",
    "# load filenames in myImages\n",
    "from PIL import Image\n",
    "my_images = np.array(glob(\"myImages/*.jpg\"))\n",
    "random.shuffle(my_images)\n",
    "\n",
    "# print statistics about the dataset\n",
    "print('There are %d total images.' % len(my_images))\n",
    "\n",
    "i = 0\n",
    "\n",
    "for item in my_images:\n",
    "    IdentifyBreed(item)\n",
    "    '''\n",
    "    pil_im = Image.open(item)\n",
    "    fig = plt.figure(figsize=(20,10))\n",
    "    ax = fig.add_subplot(len(my_images)/2, 2, i + 1, xticks=[], yticks=[])\n",
    "    i = i + 1\n",
    "    ax.imshow(np.asarray(pil_im))\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
